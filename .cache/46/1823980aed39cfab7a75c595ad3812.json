{"id":"node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","dependencies":[{"name":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/package.json","includedInParent":true,"mtime":1668685583661},{"name":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/.babelrc","includedInParent":true,"mtime":1668685583660},{"name":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":1668685787589},{"name":"../tensor_util_env","loc":{"line":17,"column":27},"parent":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","resolved":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js"},{"name":"./tensor_ops_util","loc":{"line":18,"column":27},"parent":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","resolved":"/Users/marianery/code/tfjs-models/pose-detection/demos/live_video/node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js"}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.tensor = tensor;\n\nvar _tensor_util_env = require(\"../tensor_util_env\");\n\nvar _tensor_ops_util = require(\"./tensor_ops_util\");\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * ```js\n * // Pass a `WebGLData` object and specify a shape yourself.\n *\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n * // For example, if your application includes a preprocessing step on the GPU,\n * // you could upload the GPU output directly to TF.js, rather than first\n * // downloading the values.\n *\n * // Example for WebGL2:\n * const customCanvas = document.createElement('canvas');\n * const customBackend = new tf.MathBackendWebGL(customCanvas);\n * tf.registerBackend('custom-webgl', () => customBackend);\n * await tf.setBackend('custom-webgl');\n * const gl = customBackend.gpgpu.gl;\n * const texture = gl.createTexture();\n * const tex2d = gl.TEXTURE_2D;\n * const width = 2;\n * const height = 2;\n *\n * gl.bindTexture(tex2d, texture);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n * gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n * gl.texImage2D(\n *   tex2d, 0, gl.RGBA32F, // internalFormat\n *   width, height, 0,\n *   gl.RGBA, // textureFormat\n *   gl.FLOAT, // textureType\n *   new Float32Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n * );\n *\n * // Currently, the `texture` has 4 pixels:\n * // Pixel0 is {R:0, G:1, B:2, A:3}\n * // Pixel1 is {R:4, G:5, B:6, A:7}\n * // Pixel2 is {R:8, G:9, B:10, A:11}\n * // Pixel3 is {R:12, G:13, B:14, A:15}\n *\n * const logicalShape = [height * width * 2];\n * const a = tf.tensor({texture, height, width, channels: 'BR'}, logicalShape);\n * // Tensor value will be [2, 0, 6, 4, 10, 8, 14, 12], since [2, 0] is the\n * // values of 'B' and 'R' channels of Pixel0, [6, 4] is the values of 'B' and\n * 'R'\n * // channels of Pixel1...\n *\n * // For postprocessing on the GPU, it's possible to retrieve the texture\n * // backing any tensor by calling the tensor's `dataToGPU` method like\n * // so:\n *\n * const tex = a.dataToGPU();\n * ```\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`, or a `WebGLData` object. If the\n * values are strings, they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * If the values is a `WebGLData` object, the dtype could only be 'float32' or\n * 'int32' and the object has to have: 1. texture, a `WebGLTexture`, the texture\n * must share the same `WebGLRenderingContext` with TFJS's WebGL backend (you\n * could create a custom WebGL backend from your texture's canvas) and the\n * internal texture format for the input texture must be floating point or\n * normalized integer; 2. height, the height of the texture; 3. width, the width\n * of the texture; 4. channels, a non-empty subset of 'RGBA', indicating the\n * values of which channels will be passed to the tensor, such as 'R' or 'BR'\n * (The order of the channels affect the order of tensor values. ). (If the\n * values passed from texture is less than the tensor size, zeros will be padded\n * at the rear.)\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction tensor(values, shape, dtype) {\n  const inferredShape = (0, _tensor_util_env.inferShape)(values, dtype);\n  return (0, _tensor_ops_util.makeTensor)(values, shape, inferredShape, dtype);\n}"},"sourceMaps":{"js":{"mappings":[{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":8,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":10,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":1,"column":0},"generated":{"line":12,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":25,"column":0},"generated":{"line":29,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":6},"generated":{"line":119,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":16},"generated":{"line":119,"column":9}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":6},"generated":{"line":119,"column":15}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":116,"column":4},"generated":{"line":119,"column":16}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":6},"generated":{"line":119,"column":22}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":116,"column":34},"generated":{"line":119,"column":24}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":6},"generated":{"line":119,"column":29}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":117,"column":4},"generated":{"line":119,"column":31}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":115,"column":6},"generated":{"line":119,"column":36}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":117,"column":20},"generated":{"line":119,"column":38}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":2},"generated":{"line":120,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":8},"generated":{"line":120,"column":8}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":21},"generated":{"line":120,"column":21}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":24},"generated":{"line":120,"column":24}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":35},"generated":{"line":120,"column":57}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":24},"generated":{"line":120,"column":63}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":43},"generated":{"line":120,"column":65}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":24},"generated":{"line":120,"column":70}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":118,"column":2},"generated":{"line":120,"column":71}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":2},"generated":{"line":121,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":121,"column":9}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":20},"generated":{"line":121,"column":42}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":121,"column":48}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":28},"generated":{"line":121,"column":50}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":121,"column":55}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":35},"generated":{"line":121,"column":57}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":121,"column":70}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":50},"generated":{"line":121,"column":72}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":121,"column":77}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":119,"column":2},"generated":{"line":121,"column":78}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":120,"column":1},"generated":{"line":122,"column":0}}],"sources":{"../../../../../../tfjs-core/src/ops/tensor.ts":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {DataType, Rank, ShapeMap, WebGLData} from '../types';\n\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * ```js\n * // Pass a `WebGLData` object and specify a shape yourself.\n *\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n * // For example, if your application includes a preprocessing step on the GPU,\n * // you could upload the GPU output directly to TF.js, rather than first\n * // downloading the values.\n *\n * // Example for WebGL2:\n * const customCanvas = document.createElement('canvas');\n * const customBackend = new tf.MathBackendWebGL(customCanvas);\n * tf.registerBackend('custom-webgl', () => customBackend);\n * await tf.setBackend('custom-webgl');\n * const gl = customBackend.gpgpu.gl;\n * const texture = gl.createTexture();\n * const tex2d = gl.TEXTURE_2D;\n * const width = 2;\n * const height = 2;\n *\n * gl.bindTexture(tex2d, texture);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n * gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n * gl.texImage2D(\n *   tex2d, 0, gl.RGBA32F, // internalFormat\n *   width, height, 0,\n *   gl.RGBA, // textureFormat\n *   gl.FLOAT, // textureType\n *   new Float32Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n * );\n *\n * // Currently, the `texture` has 4 pixels:\n * // Pixel0 is {R:0, G:1, B:2, A:3}\n * // Pixel1 is {R:4, G:5, B:6, A:7}\n * // Pixel2 is {R:8, G:9, B:10, A:11}\n * // Pixel3 is {R:12, G:13, B:14, A:15}\n *\n * const logicalShape = [height * width * 2];\n * const a = tf.tensor({texture, height, width, channels: 'BR'}, logicalShape);\n * // Tensor value will be [2, 0, 6, 4, 10, 8, 14, 12], since [2, 0] is the\n * // values of 'B' and 'R' channels of Pixel0, [6, 4] is the values of 'B' and\n * 'R'\n * // channels of Pixel1...\n *\n * // For postprocessing on the GPU, it's possible to retrieve the texture\n * // backing any tensor by calling the tensor's `dataToGPU` method like\n * // so:\n *\n * const tex = a.dataToGPU();\n * ```\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`, or a `WebGLData` object. If the\n * values are strings, they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * If the values is a `WebGLData` object, the dtype could only be 'float32' or\n * 'int32' and the object has to have: 1. texture, a `WebGLTexture`, the texture\n * must share the same `WebGLRenderingContext` with TFJS's WebGL backend (you\n * could create a custom WebGL backend from your texture's canvas) and the\n * internal texture format for the input texture must be floating point or\n * normalized integer; 2. height, the height of the texture; 3. width, the width\n * of the texture; 4. channels, a non-empty subset of 'RGBA', indicating the\n * values of which channels will be passed to the tensor, such as 'R' or 'BR'\n * (The order of the channels affect the order of tensor values. ). (If the\n * values passed from texture is less than the tensor size, zeros will be padded\n * at the rear.)\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor<R extends Rank>(\n    values: TensorLike|WebGLData, shape?: ShapeMap[R],\n    dtype?: DataType): Tensor<R> {\n  const inferredShape = inferShape(values, dtype);\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor<R>;\n}\n"},"lineCount":null}},"error":null,"hash":"9b708fe1673339ec3f9267eacfc8fffd","cacheData":{"env":{}}}