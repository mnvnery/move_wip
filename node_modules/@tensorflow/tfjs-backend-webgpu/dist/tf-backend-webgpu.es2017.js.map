{"version":3,"file":"tf-backend-webgpu.es2017.js","sources":["../../../../tfjs-backend-webgpu/src/flags_webgpu.ts","../../../../tfjs-backend-webgpu/src/adapter_info.ts","../../../../tfjs-backend-webgpu/src/buffer_manager.ts","../../../../tfjs-backend-webgpu/src/texture_manager.ts","../../../../tfjs-backend-webgpu/src/shader_util.ts","../../../../tfjs-backend-webgpu/src/webgpu_program.ts","../../../../tfjs-backend-webgpu/src/webgpu_util.ts","../../../../tfjs-backend-webgpu/src/backend_webgpu.ts","../../../../tfjs-backend-webgpu/src/base.ts","../../../../tfjs-backend-webgpu/src/binary_op_util.ts","../../../../tfjs-backend-webgpu/src/unary_op_util.ts","../../../../tfjs-backend-webgpu/src/activation_util.ts","../../../../tfjs-backend-webgpu/src/matmul_packed_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_reduce_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_small_output_size_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_splitK_webgpu.ts","../../../../tfjs-backend-webgpu/src/fill_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Fill.ts","../../../../tfjs-backend-webgpu/src/kernels/Reshape.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/_FusedMatMul.ts","../../../../tfjs-backend-webgpu/src/binary_op_complex_webgpu.ts","../../../../tfjs-backend-webgpu/src/binary_op_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Identity.ts","../../../../tfjs-backend-webgpu/src/kernels/Complex.ts","../../../../tfjs-backend-webgpu/src/unary_op_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/kernel_funcs_utils.ts","../../../../../tfjs-backend-cpu/src/kernels/Abs.ts","../../../../../tfjs-backend-cpu/src/utils/binary_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Cast.ts","../../../../../tfjs-backend-cpu/src/kernels/Add.ts","../../../../../tfjs-backend-cpu/src/kernels/Bincount_impl.ts","../../../../../tfjs-backend-cpu/src/utils/unary_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Ceil.ts","../../../../../tfjs-backend-cpu/src/kernels/Concat_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Equal.ts","../../../../../tfjs-backend-cpu/src/kernels/Exp.ts","../../../../../tfjs-backend-cpu/src/kernels/Expm1.ts","../../../../../tfjs-backend-cpu/src/kernels/Floor.ts","../../../../../tfjs-backend-cpu/src/kernels/GatherNd_Impl.ts","../../../../../tfjs-backend-cpu/src/kernels/GatherV2_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Greater.ts","../../../../../tfjs-backend-cpu/src/kernels/GreaterEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/Less.ts","../../../../../tfjs-backend-cpu/src/kernels/LessEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/LinSpace_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Log.ts","../../../../../tfjs-backend-cpu/src/kernels/Max_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Maximum.ts","../../../../../tfjs-backend-cpu/src/kernels/Minimum.ts","../../../../../tfjs-backend-cpu/src/kernels/Multiply.ts","../../../../../tfjs-backend-cpu/src/kernels/Neg.ts","../../../../../tfjs-backend-cpu/src/kernels/NotEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/Transpose_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Prod.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedGather_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Range_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Rsqrt.ts","../../../../../tfjs-backend-cpu/src/kernels/Scatter_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Sigmoid.ts","../../../../../tfjs-backend-cpu/src/kernels/Slice.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseReshape_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseSegmentReduction_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Sqrt.ts","../../../../../tfjs-backend-cpu/src/kernels/SquaredDifference.ts","../../../../../tfjs-backend-cpu/src/kernels/StridedSlice_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringSplit_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Sub.ts","../../../../../tfjs-backend-cpu/src/kernels/Tile_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/TopK_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Unique_impl.ts","../../../../../tfjs-backend-cpu/src/shared.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/shared.ts","../../../../tfjs-backend-webgpu/src/kernels/Abs.ts","../../../../tfjs-backend-webgpu/src/kernels/Add.ts","../../../../tfjs-backend-webgpu/src/addn_packed_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/AddN.ts","../../../../tfjs-backend-webgpu/src/argminmax_webgpu.ts","../../../../tfjs-backend-webgpu/src/transpose_shared_webgpu.ts","../../../../tfjs-backend-webgpu/src/transpose_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Transpose.ts","../../../../tfjs-backend-webgpu/src/kernels/ArgMax.ts","../../../../tfjs-backend-webgpu/src/kernels/ArgMin.ts","../../../../tfjs-backend-webgpu/src/kernels/Atan2.ts","../../../../tfjs-backend-webgpu/src/pool2d_webgpu.ts","../../../../tfjs-backend-webgpu/src/pool_filtersizeone_webgpu.ts","../../../../tfjs-backend-webgpu/src/reduce_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/reduce.ts","../../../../tfjs-backend-webgpu/src/kernels/Max.ts","../../../../tfjs-backend-webgpu/src/kernels/Mean.ts","../../../../tfjs-backend-webgpu/src/kernels/Pool_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/AvgPool.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul.ts","../../../../tfjs-backend-webgpu/src/slice_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Slice.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchToSpaceND.ts","../../../../tfjs-backend-webgpu/src/kernels/NotEqual.ts","../../../../tfjs-backend-webgpu/src/kernels/Real.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/int.ts","../../../../tfjs-backend-webgpu/src/kernels/Cast.ts","../../../../tfjs-backend-webgpu/src/kernels/Ceil.ts","../../../../tfjs-backend-webgpu/src/clip_vec4_webgpu.ts","../../../../tfjs-backend-webgpu/src/clip_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ClipByValue.ts","../../../../tfjs-backend-webgpu/src/concat_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Imag.ts","../../../../tfjs-backend-webgpu/src/kernels/Concat_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Concat.ts","../../../../tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts","../../../../tfjs-backend-webgpu/src/conv2d_naive_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2D_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2D.ts","../../../../tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts","../../../../tfjs-backend-webgpu/src/conv_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2DBackpropInput.ts","../../../../tfjs-backend-webgpu/src/kernels/Cos.ts","../../../../tfjs-backend-webgpu/src/kernels/Cosh.ts","../../../../tfjs-backend-webgpu/src/crop_and_resize_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/CropAndResize.ts","../../../../tfjs-backend-webgpu/src/cum_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Cum_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Cumprod.ts","../../../../tfjs-backend-webgpu/src/kernels/Cumsum.ts","../../../../tfjs-backend-webgpu/src/depth_to_space_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthToSpace.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_nchw_shared_webgpu.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_vec4_webgpu.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNative.ts","../../../../tfjs-backend-webgpu/src/kernels/Multiply.ts","../../../../tfjs-backend-webgpu/src/kernels/Sum.ts","../../../../tfjs-backend-webgpu/src/kernels/Einsum.ts","../../../../tfjs-backend-webgpu/src/kernels/Elu.ts","../../../../tfjs-backend-webgpu/src/kernels/Equal.ts","../../../../tfjs-backend-webgpu/src/kernels/Exp.ts","../../../../tfjs-backend-webgpu/src/kernels/ExpandDims.ts","../../../../tfjs-backend-webgpu/src/kernels/Expm1.ts","../../../../tfjs-backend-webgpu/src/flip_left_right_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FlipLeftRight.ts","../../../../tfjs-backend-webgpu/src/kernels/Floor.ts","../../../../tfjs-backend-webgpu/src/kernels/FloorDiv.ts","../../../../tfjs-backend-webgpu/src/from_pixels_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FromPixels.ts","../../../../tfjs-backend-webgpu/src/batchnorm_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedBatchNorm.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedConv2D.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedDepthwiseConv2D.ts","../../../../tfjs-backend-webgpu/src/gather_nd_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/GatherNd.ts","../../../../tfjs-backend-webgpu/src/gather_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/GatherV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Greater.ts","../../../../tfjs-backend-webgpu/src/kernels/GreaterEqual.ts","../../../../tfjs-backend-webgpu/src/kernels/IsNaN.ts","../../../../tfjs-backend-webgpu/src/kernels/LeakyRelu.ts","../../../../tfjs-backend-webgpu/src/kernels/Less.ts","../../../../tfjs-backend-webgpu/src/kernels/LessEqual.ts","../../../../tfjs-backend-webgpu/src/kernels/Log.ts","../../../../tfjs-backend-webgpu/src/kernels/LogicalAnd.ts","../../../../tfjs-backend-webgpu/src/kernels/LogicalNot.ts","../../../../tfjs-backend-webgpu/src/kernels/Maximum.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPool.ts","../../../../tfjs-backend-webgpu/src/kernels/Min.ts","../../../../tfjs-backend-webgpu/src/kernels/Minimum.ts","../../../../tfjs-backend-webgpu/src/mirror_pad_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/MirrorPad.ts","../../../../tfjs-backend-webgpu/src/kernels/Neg.ts","../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV3.ts","../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV5.ts","../../../../tfjs-backend-webgpu/src/kernels/ZerosLike.ts","../../../../tfjs-backend-webgpu/src/kernels/OnesLike.ts","../../../../tfjs-backend-webgpu/src/kernels/Pack.ts","../../../../tfjs-backend-webgpu/src/pad_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/PadV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Pow.ts","../../../../tfjs-backend-webgpu/src/kernels/Prelu.ts","../../../../tfjs-backend-webgpu/src/kernels/Prod.ts","../../../../tfjs-backend-webgpu/src/kernels/Range.ts","../../../../tfjs-backend-webgpu/src/kernels/RealDiv.ts","../../../../tfjs-backend-webgpu/src/kernels/Reciprocal.ts","../../../../tfjs-backend-webgpu/src/kernels/Relu.ts","../../../../tfjs-backend-webgpu/src/kernels/Relu6.ts","../../../../tfjs-backend-webgpu/src/resize_bilinear_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeBilinear.ts","../../../../tfjs-backend-webgpu/src/resize_nearest_neighbor_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeNearestNeighbor.ts","../../../../tfjs-backend-webgpu/src/rotate_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/RotateWithOffset.ts","../../../../tfjs-backend-webgpu/src/kernels/Rsqrt.ts","../../../../tfjs-backend-webgpu/src/scatter_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ScatterNd.ts","../../../../tfjs-backend-webgpu/src/select_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Select.ts","../../../../tfjs-backend-webgpu/src/kernels/Sigmoid.ts","../../../../tfjs-backend-webgpu/src/kernels/Sin.ts","../../../../tfjs-backend-webgpu/src/kernels/Sinh.ts","../../../../tfjs-backend-webgpu/src/kernels/Sub.ts","../../../../tfjs-backend-webgpu/src/kernels/Softmax.ts","../../../../tfjs-backend-webgpu/src/kernels/SpaceToBatchND.ts","../../../../tfjs-backend-webgpu/src/tile_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Tile.ts","../../../../tfjs-backend-webgpu/src/kernels/SparseToDense.ts","../../../../tfjs-backend-webgpu/src/kernels/SplitV.ts","../../../../tfjs-backend-webgpu/src/kernels/Sqrt.ts","../../../../tfjs-backend-webgpu/src/kernels/Square.ts","../../../../tfjs-backend-webgpu/src/kernels/SquaredDifference.ts","../../../../tfjs-backend-webgpu/src/strided_slice_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/StridedSlice.ts","../../../../tfjs-backend-webgpu/src/kernels/StringNGrams.ts","../../../../tfjs-backend-webgpu/src/kernels/Tanh.ts","../../../../tfjs-backend-webgpu/src/top_k_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/TopK.ts","../../../../tfjs-backend-webgpu/src/transform_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Transform.ts","../../../../tfjs-backend-webgpu/src/kernels/Unpack.ts","../../../../tfjs-backend-webgpu/src/register_all_kernels.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/** The batched dispatching calls size in the device queue. */\nENV.registerFlag('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE', () => 15);\n\n/**\n * Whether we forward execution to the CPU backend if tensors are small and\n * reside on the CPU.\n */\nENV.registerFlag('WEBGPU_CPU_FORWARD', () => true);\n\n/**\n * This flag is used to test different types of matmul programs.\n *\n * See MatMulProgramType in webgpu_util.ts for a list of available values.\n */\nENV.registerFlag('WEBGPU_MATMUL_PROGRAM_TYPE', () => -1);\n\n/**\n * Whether to use conv2dTranspose_naive which directly implement the\n * conv2dTranspose logic rather than using a matmul to simulate.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE', () => false);\n\n/**\n * Whether we use low power GPU. Otherwise, a high performance GPU will be\n * requested.\n */\nENV.registerFlag('WEBGPU_USE_LOW_POWER_GPU', () => false);\n\n/**\n * Threshold for input tensor size that determines whether WebGPU backend will\n * delegate computation to CPU.\n *\n * Default value is 1000.\n */\nENV.registerFlag('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD', () => 1000);\n\n/**\n * Whether to use a dummy canvas to make profiling tools like PIX work with\n * TFJS webgpu backend.\n */\nENV.registerFlag('WEBGPU_USE_PROFILE_TOOL', () => false);\n\n/**\n * Whether to use import API.\n */\nENV.registerFlag('WEBGPU_IMPORT_EXTERNAL_TEXTURE', () => true);\n\n/**\n * Whether to use conv2dNaive for debugging.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_DEBUG', () => false);\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// TODO: Remove it once webgpu/types is successfully upgraded.\n// https://github.com/tensorflow/tfjs/issues/6869\nexport interface GPUAdapterInfo {\n  vendor: string;\n  architecture: string;\n}\n\nexport class AdapterInfo {\n  private vendor: string;\n\n  constructor(adapterInfo: GPUAdapterInfo) {\n    if (adapterInfo) {\n      this.vendor = adapterInfo.vendor;\n    }\n  }\n\n  isIntel(): boolean {\n    return this.vendor === 'intel';\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class BufferManager {\n  private numUsedBuffers = 0;\n  private numFreeBuffers = 0;\n  private freeBuffers: Map<string, GPUBuffer[]> = new Map();\n  private usedBuffers: Map<string, GPUBuffer[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireUploadBuffer(size: number, usage: GPUBufferUsageFlags) {\n    return this.acquireBuffer(size, usage, true);\n  }\n\n  acquireBuffer(\n      size: number, usage: GPUBufferUsageFlags, mappedAtCreation = false) {\n    const key = getBufferKey(size, usage);\n    if (!this.freeBuffers.has(key)) {\n      this.freeBuffers.set(key, []);\n    }\n\n    if (!this.usedBuffers.has(key)) {\n      this.usedBuffers.set(key, []);\n    }\n\n    this.numBytesUsed += size;\n    this.numUsedBuffers++;\n\n    if (this.freeBuffers.get(key).length > 0) {\n      this.numFreeBuffers--;\n\n      const newBuffer = this.freeBuffers.get(key).shift();\n      this.usedBuffers.get(key).push(newBuffer);\n      return newBuffer;\n    }\n\n    this.numBytesAllocated += size;\n    const newBuffer = this.device.createBuffer({size, usage, mappedAtCreation});\n    this.usedBuffers.get(key).push(newBuffer);\n\n    return newBuffer;\n  }\n\n  releaseBuffer(buffer: GPUBuffer, size: number, usage: GPUBufferUsageFlags) {\n    if (this.freeBuffers.size === 0) {\n      return;\n    }\n\n    const key = getBufferKey(size, usage);\n    if (!this.freeBuffers.has(key)) {\n      this.freeBuffers.set(key, []);\n    }\n\n    this.freeBuffers.get(key).push(buffer);\n    this.numFreeBuffers++;\n    this.numUsedBuffers--;\n\n    const bufferList = this.usedBuffers.get(key);\n    const bufferIndex = bufferList.indexOf(buffer);\n    if (bufferIndex < 0) {\n      throw new Error(\n          'Cannot release a buffer that was never provided by this ' +\n          'buffer manager');\n    }\n    bufferList.splice(bufferIndex, 1);\n    this.numBytesUsed -= size;\n  }\n\n  releaseUploadBuffer(\n      buffer: GPUBuffer, size: number, usage: GPUBufferUsageFlags) {\n    buffer.mapAsync(GPUMapMode.WRITE)\n        .then(\n            () => {\n              this.releaseBuffer(buffer, size, usage);\n            },\n            (err) => {\n                // Do nothing;\n            });\n  }\n\n  getNumUsedBuffers(): number {\n    return this.numUsedBuffers;\n  }\n\n  getNumFreeBuffers(): number {\n    return this.numFreeBuffers;\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.usedBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.freeBuffers = new Map();\n    this.usedBuffers = new Map();\n    this.numUsedBuffers = 0;\n    this.numFreeBuffers = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getBufferKey(size: number, usage: GPUBufferUsageFlags) {\n  return `${size}_${usage}`;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class TextureManager {\n  private numUsedTextures = 0;\n  private numFreeTextures = 0;\n  private freeTextures: Map<string, GPUTexture[]> = new Map();\n  private usedTextures: Map<string, GPUTexture[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireTexture(\n      width: number, height: number, format: GPUTextureFormat,\n      usage: GPUTextureUsageFlags) {\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    if (!this.usedTextures.has(key)) {\n      this.usedTextures.set(key, []);\n    }\n\n    this.numBytesUsed += byteSize;\n    this.numUsedTextures++;\n\n    if (this.freeTextures.get(key).length > 0) {\n      this.numFreeTextures--;\n\n      const newTexture = this.freeTextures.get(key).shift();\n      this.usedTextures.get(key).push(newTexture);\n      return newTexture;\n    }\n\n    this.numBytesAllocated += byteSize;\n\n    const newTexture = this.device.createTexture({\n      size: [width, height],\n      format,\n      usage,\n    });\n    this.usedTextures.get(key).push(newTexture);\n\n    return newTexture;\n  }\n\n  releaseTexture(\n      texture: GPUTexture, width: number, height: number,\n      format: GPUTextureFormat, usage: GPUTextureUsageFlags) {\n    if (this.freeTextures.size === 0) {\n      return;\n    }\n\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    this.freeTextures.get(key).push(texture);\n    this.numFreeTextures++;\n    this.numUsedTextures--;\n\n    const textureList = this.usedTextures.get(key);\n    const textureIndex = textureList.indexOf(texture);\n    if (textureIndex < 0) {\n      throw new Error(\n          'Cannot release a texture that was never provided by this ' +\n          'texture manager');\n    }\n    textureList.splice(textureIndex, 1);\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    this.numBytesUsed -= byteSize;\n  }\n\n  getNumUsedTextures(): number {\n    return this.numUsedTextures;\n  }\n\n  getNumFreeTextures(): number {\n    return this.numFreeTextures;\n  }\n\n  dispose() {\n    this.freeTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.usedTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.freeTextures = new Map();\n    this.usedTextures = new Map();\n    this.numUsedTextures = 0;\n    this.numFreeTextures = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getTextureKey(\n    width: number, height: number, format: GPUTextureFormat,\n    usage: GPUTextureUsageFlags) {\n  return `${width}_${height}_${format}_${usage}`;\n}\n\nfunction getBytesPerElement(format: GPUTextureFormat) {\n  if (format === 'rgba8unorm') {\n    return 16;\n  } else {\n    throw new Error(`${format} is not supported!`);\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Generates GLSL that computes strides.\nexport function symbolicallyComputeStrides(\n    indicesArr: number[], variableName: string): string[] {\n  if (Math.max(...indicesArr) > 3) {\n    throw new Error('Cannot symbolically compute strides for rank > 4 tensor.');\n  }\n\n  const numCoords = indicesArr.length;\n  const shape = indicesArr.map(d => `${variableName}[${d}]`);\n  const strides = new Array(numCoords - 1);\n  strides[numCoords - 2] = shape[numCoords - 1];\n  for (let i = numCoords - 3; i >= 0; --i) {\n    strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;\n  }\n\n  return strides;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, Rank, ShapeMap, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {symbolicallyComputeStrides} from './shader_util';\n\nexport interface WebGPUProgram {\n  // Whether to use atomic built-in functions.\n  atomic?: boolean;\n  // dispatch specifies geometry of thread groups - derived from dispatchLayout.\n  dispatch: [number, number, number];\n  // dispatchLayout enumerates how tensor dimensions are distributed among\n  // dispatch x,y,z dimensions.\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  isFromPixels?: boolean;\n  isVec4?: boolean;\n  outputShape: number[];\n  // The unique key to distinguish different shader source code.\n  shaderKey: string;\n  // Whether to use output size for bounds checking.\n  size?: boolean;\n  uniforms?: string;\n  variableNames: string[];\n  // Describe each variable's type and must have one-one mapping with\n  // variableNames. If not set, all variables type will be either f32 or\n  // vec4<f32> based on isVec4 member.\n  variableTypes?: string[];\n  // workGroupSize.x * workGroupSize.y * workGroupSize.z = the number of threads\n  // in a thread group. Individual dimensions determines thread layout within\n  // the group.\n  workGroupSize: [number, number, number];\n  // Size of register cache in one dimension (assumes square cache).\n  // Each thread writes to workPerThread * workPerThread locations in the output\n  // buffer.\n  workPerThread?: number;\n  getUserCode: () => string;\n}\n\nexport const compileProgram =\n    (device: GPUDevice, program: WebGPUProgram, inputsData: InputInfo[],\n     output: TensorInfo): GPUComputePipeline => {\n      const outputData = {dtype: output.dtype, shape: output.shape};\n      const source = makeShader(inputsData, outputData, program);\n      const module = device.createShaderModule(\n          {code: source, label: program.constructor.name});\n      const pipeline = device.createComputePipeline({\n        compute: {module, entryPoint: '_start'},\n        label: program.constructor.name,\n        layout: 'auto'\n      });\n\n      return pipeline;\n    };\n\nexport function getCoordsDataType(rank: number): string {\n  if (rank <= 1) {\n    return 'i32';\n  } else if (rank === 2) {\n    return `vec2<i32>`;\n  } else if (rank === 3) {\n    return `vec3<i32>`;\n  } else if (rank === 4) {\n    return `vec4<i32>`;\n  } else if (rank === 5) {\n    return `vec5`;\n  } else if (rank === 6) {\n    return `vec6`;\n  } else {\n    throw Error(`GPU for rank ${rank} is not yet supported`);\n  }\n}\n\nexport function getCoordsXYZ(index: number): string {\n  if (index === 0) {\n    return 'x';\n  } else if (index === 1) {\n    return 'y';\n  } else if (index === 2) {\n    return 'z';\n  } else if (index === 3) {\n    return 'w';\n  } else if (index === 4) {\n    return 'u';\n  } else if (index === 5) {\n    return 'v';\n  } else {\n    throw Error(`Index ${index} is not yet supported`);\n  }\n}\n\nexport function getMainHeaderString(): string;\nexport function getMainHeaderString(index: string): string;\nexport function getMainHeaderString(...params: string[]): string {\n  let snippet: string;\n  switch (params.length) {\n    case 0:\n      snippet = `\n        ${getWorkGroupSizeString()}\n        fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n                  @builtin(global_invocation_id) GlobalId : vec3<u32>,\n                  @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {\n          localId = LocalId;\n          globalId = GlobalId;\n          numWorkgroups = NumWorkgroups;\n          main();\n        }\n\n        fn main()\n      `;\n      break;\n    case 1:\n      snippet = `\n        ${getWorkGroupSizeString()}\n        fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n                  @builtin(global_invocation_id) GlobalId : vec3<u32>,\n                  @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {\n          localId = LocalId;\n          globalId = GlobalId;\n          numWorkgroups = NumWorkgroups;\n          main(getGlobalIndex());\n        }\n\n        fn main(${params[0]} : i32)\n      `;\n      break;\n    default:\n      throw Error('Unreachable');\n  }\n  return snippet;\n}\n\nexport function getWorkGroupSizeString(): string {\n  return `\n  @compute @workgroup_size(workGroupSizeX, workGroupSizeY, workGroupSizeZ)\n`;\n}\n\nfunction makeShader(\n    inputInfo: InputInfo[], outputData: {dtype: DataType, shape: number[]},\n    program: WebGPUProgram): string {\n  const prefixSnippets: string[] = [];\n  prefixSnippets.push(`\n      const workGroupSizeX = ${program.workGroupSize[0]}u;\n      const workGroupSizeY = ${program.workGroupSize[1]}u;\n      const workGroupSizeZ = ${program.workGroupSize[2]}u;\n\n      var<private> localId: vec3<u32>;\n      var<private> globalId: vec3<u32>;\n      var<private> numWorkgroups: vec3<u32>;\n\n      // Only used when the y/z dimension of workgroup size is 1.\n      fn getGlobalIndex() -> i32 {\n        ${\n      isFlatDispatch(program) ?\n          `  return i32(globalId.x);` :\n          `  let localInvocationIndex = localId.z * workGroupSizeX * workGroupSizeY +\n                   localId.y * workGroupSizeX + localId.x;\n               let workGroupID = (globalId - localId)/vec3<u32>(\n                   workGroupSizeX, workGroupSizeY, workGroupSizeZ);\n\n               return i32((workGroupID.z * numWorkgroups.x * numWorkgroups.y +\n                   workGroupID.y * numWorkgroups.x + workGroupID.x) *\n                   (workGroupSizeX * workGroupSizeY * workGroupSizeZ) +\n                   localInvocationIndex);\n        `}\n      }\n    `);\n\n  if (program.isFromPixels) {\n    prefixSnippets.push(`\n        struct Uniform {\n          size            : i32,\n          numChannels     : i32,\n          outShapeStrides : vec2<i32>,\n        };\n\n        @group(0) @binding(0) var<storage, read_write> result: array<${\n        mapToWgslTypes(outputData.dtype, program.isVec4)}>;\n        @group(0) @binding(2) var<uniform> uniforms: Uniform;\n      `);\n    return [\n      commonSnippet,\n      prefixSnippets.join('\\n'),\n      getCoordsFromIndexSnippet(outputData.shape),\n      program.getUserCode(),\n    ].join('\\n');\n  }\n\n  let uniformDeclaration = 'struct Uniforms { NAN : f32, ';\n  program.variableNames.forEach((x, i) => {\n    const perDataType = getCoordsDataType(inputInfo[i].shape.length);\n    uniformDeclaration +=\n        `${x.charAt(0).toLowerCase() + x.slice(1)}Shape : ${perDataType}, `;\n  });\n  const outputDataType = getCoordsDataType(outputData.shape.length);\n  uniformDeclaration += `outShape : ${outputDataType}, `;\n  const stridesLength = outputData.shape.length - 1;\n  const stridesDataType = getCoordsDataType(stridesLength);\n  uniformDeclaration += `\n         outShapeStrides: ${stridesDataType}, `;\n\n  if (program.size) {\n    uniformDeclaration += 'size : i32, ';\n  }\n\n  if (program.uniforms) {\n    uniformDeclaration += program.uniforms;\n  }\n  uniformDeclaration += '};';\n  uniformDeclaration = insertAlignment(uniformDeclaration);\n\n  prefixSnippets.push(uniformDeclaration);\n\n  // Output buffer.\n  if (program.atomic) {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<atomic<i32>>;\n    `);\n  } else {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<${\n        mapToWgslTypes(outputData.dtype, program.isVec4)}>;\n    `);\n  }\n  program.variableNames.forEach((x, i) => {\n    prefixSnippets.push(`\n      @group(0) @binding(${1 + i}) var<storage, read> ${x}: array<${\n        program.variableTypes ?\n            program.variableTypes[i] :\n            mapToWgslTypes(inputInfo[i].dtype, program.isVec4)}>;\n        `);\n  });\n\n  if (uniformDeclaration !== '') {\n    prefixSnippets.push(`\n      @group(0) @binding(${\n        1 + program.variableNames.length}) var<uniform> uniforms: Uniforms;\n      `);\n  }\n\n  const coordsSnippet =\n      getOutputCoordsSnippet(outputData.shape, program.dispatchLayout);\n\n  const sources = [\n    commonSnippet, prefixSnippets.join('\\n'),\n    getCoordsFromIndexSnippet(outputData.shape), coordsSnippet,\n    getOutputIndexFromCoordsSnippet(outputData.shape.length)\n  ];\n  if (!program.atomic) {\n    sources.push(\n        setOutputSnippet(outputData.shape, outputData.dtype, program.isVec4));\n  }\n\n  const inputSnippet =\n      inputInfo\n          .map(\n              (x, i) => getInputSnippet(\n                  x, outputData.shape,\n                  program.variableTypes ?\n                      (program.variableTypes[i] === 'vec4<f32>') :\n                      program.isVec4,\n                  program.dispatchLayout.x.length === outputData.shape.length))\n          .join('\\n');\n  sources.push(inputSnippet);\n\n  sources.push(program.getUserCode());\n  const source = sources.join('\\n');\n  return source;\n}\n\nexport function makeShaderKey<R extends Rank>(\n    program: WebGPUProgram, shapes: Array<ShapeMap[R]>, inputsData: InputInfo[],\n    output: TensorInfo): string {\n  let key = program.shaderKey;\n  if (program.isFromPixels) {\n    return key;\n  }\n\n  const types = inputsData.map(d => d.dtype).concat(output.dtype);\n  const broadcastDims =\n      inputsData.map(d => backend_util.getBroadcastDims(d.shape, output.shape));\n  const inputShapesEqualsOutShape =\n      inputsData.map(d => util.arraysEqual(d.shape, output.shape)).join('_');\n  const broadcastDimsKey = broadcastDims.map(d => d.join('_')).join(';');\n\n  const flatDispatchString = isFlatDispatch(program) ? 'flatDispatch' : '';\n\n  key += '_' + (program.workGroupSize ? program.workGroupSize.join(',') : '') +\n      shapes.map(shape => shape.length).join(',') + types.join(',') +\n      program.variableNames.join(',') + broadcastDimsKey +\n      inputShapesEqualsOutShape + flatDispatchString;\n\n  return key;\n}\n\nconst commonSnippet = `\n  struct vec5 {x: i32, y: i32, z: i32, w: i32, u: i32};\n  struct vec6 {x: i32, y: i32, z: i32, w: i32, u: i32, v: i32};\n\n  // Checks whether coordinates lie within the bounds of the shape.\n  fn coordsInBounds2D(coord : vec2<i32>, shape : vec2<i32>) -> bool {\n    return all(coord >= vec2<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds3D(coord : vec3<i32>, shape : vec3<i32>) -> bool {\n    return all(coord >= vec3<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds4D(coord : vec4<i32>, shape : vec4<i32>) -> bool {\n    return all(coord >= vec4<i32>(0)) && all(coord < shape);\n  }\n\n  fn getIndexFromCoords1D(coord : i32, shape : i32) -> i32 {\n    return coord;\n  }\n  fn getIndexFromCoords2D(coords : vec2<i32>, shape : vec2<i32>) -> i32 {\n    return dot(coords, vec2<i32>(shape.y, 1));\n  }\n  fn getIndexFromCoords3D(coords : vec3<i32>, shape : vec3<i32>) -> i32 {\n    return dot(coords, vec3<i32>(shape.y * shape.z, shape.z, 1));\n  }\n  fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n    return dot(coords, vec4<i32>(\n        shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n  }\n  fn getIndexFromCoords5D(coords : vec5, shape : vec5) -> i32 {\n    let shapeStrides: vec5 = vec5(shape.y * shape.z * shape.w * shape.u, shape.z * shape.w * shape.u, shape.w * shape.u, shape.u, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u;\n  }\n  fn getIndexFromCoords6D(coords : vec6, shape : vec6) -> i32 {\n    let shapeStrides: vec6 = vec6(shape.y * shape.z * shape.w * shape.u * shape.v, shape.z * shape.w * shape.u * shape.v, shape.w * shape.u * shape.v, shape.u * shape.v, shape.v, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u + coords.v*shapeStrides.v;\n  }\n\n  fn idiv(a: i32, b: i32, sign: f32) -> i32 {\n    var res: i32 = a / b;\n    let modulo: i32 = a % b;\n    if (sign < 0. && modulo != 0) {\n      res = res - 1;\n    }\n    return res;\n  }\n\n  // NaN defination in IEEE 754-1985 is :\n  //   - sign = either 0 or 1.\n  //   - biased exponent = all 1 bits.\n  //   - fraction = anything except all 0 bits (since all 0 bits represents infinity).\n  // https://en.wikipedia.org/wiki/IEEE_754-1985#Representation_of_non-numbers\n  fn isnan(val: f32) -> bool {\n    let floatToUint: u32 = bitcast<u32>(val);\n    return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n  }\n  fn isnanVec4(val : vec4<f32>) -> vec4<bool> {\n    return vec4<bool>(isnan(val[0]), isnan(val[1]), isnan(val[2]), isnan(val[3]));\n  }\n`;\n\ntype InputInfo = {\n  dtype: DataType; shape: number[]; name: string;\n};\nexport type WGSLDataType = 'f32'|'i32'|'vec4<f32>'|'vec4<i32>'|'vec4<bool>';\n\n/**\n * Derives logical coordinates from a flat index. Performs integer division\n * with each stride and decrements the index until the index equals the final\n * dimension coordinate.\n */\nfunction getCoordsFromIndexSnippet(shape: number[]): string {\n  const rank = shape.length;\n\n  if (rank <= 1) {\n    return `fn getCoordsFromIndex(index : i32) -> i32 { return index; }`;\n  }\n\n  const strides = util.computeStrides(shape);\n  const dtype = getCoordsDataType(rank);\n\n  const coords: string[] = [];\n  for (let i = 0; i < rank; i++) {\n    coords.push(`d${i}`);\n  }\n\n  if (strides.length === 1) {\n    return `    fn getCoordsFromIndex(index : i32) -> vec2<i32> {\n      let d0 = index / uniforms.outShapeStrides; let d1 = index - d0 * uniforms.outShapeStrides;\n      return vec2<i32>(d0, d1);\n    }`;\n  }\n  let snippet;\n  snippet = 'var index2 = index;' +\n      strides\n          .map((_, i) => {\n            const line1 =\n                `let ${coords[i]} = index2 / uniforms.outShapeStrides.${\n                    getCoordsXYZ(i)}`;\n            const line2 = i === strides.length - 1 ?\n                `let ${coords[i + 1]} = index2 - ${\n                    coords[i]} * uniforms.outShapeStrides.${getCoordsXYZ(i)}` :\n                `index2 = index2 - ${coords[i]} * uniforms.outShapeStrides.${\n                    getCoordsXYZ(i)}`;\n            return `${line1}; ${line2};`;\n          })\n          .join('');\n\n  return `\n    fn getCoordsFromIndex(index : i32) -> ${dtype} {\n      ${snippet}\n      return ${dtype}(${coords.join(',')});\n    }\n  `;\n}\n\nfunction getInputAtCoordsSnippet(\n    inputInfo: InputInfo, isVec4: boolean): string {\n  const texName = inputInfo.name;\n  const rank = inputInfo.shape.length;\n  const type = getCoordsDataType(rank);\n  const funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n  const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, rank);\n  const inputs = dims.map(d => `${d} : i32`).join(', ');\n\n  if (rank < 1) {\n    if (isVec4) {\n      return `\n        fn ${funcName}() -> vec4<f32> {\n          return vec4<f32>(${texName}[0]);\n        }\n      `;\n    }\n\n    return `\n      fn ${funcName}() ->f32 {\n        return f32(${texName}[0]);\n      }\n    `;\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  let rankStr = `${rank}D`;\n  if (rank === 0) {\n    rankStr = '1D';\n  }\n\n  if (isVec4) {\n    return `\n      fn ${funcName}(${inputs}) -> vec4<f32> {\n        return vec4<f32>(${texName}[getIndexFromCoords${rankStr}(${type}(${\n        dims.join(',')}),\n          ${shapeStr}) / 4]);\n      }\n      `;\n  }\n\n  return `\n    fn ${funcName}(${inputs}) -> f32 {\n      return f32(${texName}[getIndexFromCoords${rankStr}(${type}(${\n      dims.join(',')}),\n        ${shapeStr})]);\n    }\n   `;\n}\n\nfunction getInputByOutputSnippet(\n    inputInfo: InputInfo, outShape: number[], isVec4: boolean,\n    isFlatDispatchLayout: boolean): string {\n  const texName = inputInfo.name;\n  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n\n  const funcName = 'get' + texFuncSnippet + 'ByOutput';\n\n  const inRank = inputInfo.shape.length;\n  const outRank = outShape.length;\n  const type = getCoordsDataType(outRank);\n\n  // If the inShape equals the outShape and the dispatch layout is flat, we can\n  // directly use |gl_GlobalInvocationID.x| as the index and don't need coords\n  // conversion between these two shapes.\n  if (util.arraysEqual(inputInfo.shape, outShape) && isFlatDispatchLayout) {\n    if (isVec4) {\n      return `\n      fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {\n        return vec4<f32>(${texName}[globalIndex]);\n      }\n\n      fn ${funcName}Coords(coords : ${type}) -> vec4<f32> {\n        return vec4<f32>(${texName}[${\n          outRank > 1 ? 'getOutputIndexFromCoords(coords)' : 'coords'} / 4]);\n      }\n      `;\n    } else {\n      return `\n    fn ${funcName}Index(globalIndex : i32) -> f32 {\n      return f32(${texName}[globalIndex]);\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> f32 {\n      return f32(${texName}[${\n          outRank > 1 ? 'getOutputIndexFromCoords(coords)' : 'coords'}]);\n    }\n    `;\n    }\n  }\n\n  const broadcastDims =\n      backend_util.getBroadcastDims(inputInfo.shape, outShape);\n  const rankDiff = outRank - inRank;\n\n  let coordsSnippet = '';\n\n  if (inRank === 0) {\n    if (isVec4) {\n      return `\n    fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {\n      return get${texFuncSnippet}();\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> vec4<f32> {\n      return get${texFuncSnippet}();\n    }\n  `;\n    }\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> f32{\n      return get${texFuncSnippet}();\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> f32{\n      return get${texFuncSnippet}();\n    }\n  `;\n  } else {\n    if (outRank < 2 && broadcastDims.length >= 1) {\n      coordsSnippet = 'coords = 0;';\n    } else {\n      coordsSnippet =\n          broadcastDims.map(d => `coords.${getCoordsXYZ(d + rankDiff)} = 0;`)\n              .join('\\n');\n    }\n  }\n\n  let unpackedCoordsSnippet = '';\n  if (outRank < 2 && inRank > 0) {\n    unpackedCoordsSnippet = 'coords';\n  } else {\n    if (outRank > 1) {\n      const coordsType = getCoordsDataType(inRank);\n      const coordsValues =\n          inputInfo.shape.map((s, i) => `coords.${getCoordsXYZ(i + rankDiff)}`)\n              .join(', ');\n      unpackedCoordsSnippet = `${coordsType}(${coordsValues})`;\n    } else {\n      unpackedCoordsSnippet = 'coords';\n    }\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  const rankStr = `${inRank}D`;\n  if (isVec4) {\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {\n      var coords = getCoordsFromIndex(globalIndex);\n      ${coordsSnippet}\n      return ${texName}[getIndexFromCoords${rankStr}(${\n        unpackedCoordsSnippet}, ${shapeStr}) / 4];\n    }\n\n    fn ${funcName}Coords(coordsIn : ${type}) -> vec4<f32> {\n      var coords = coordsIn;\n      ${coordsSnippet}\n      return ${texName}[getIndexFromCoords${rankStr}(${\n        unpackedCoordsSnippet}, ${shapeStr}) / 4];\n    }\n  `;\n  }\n\n  return `\n  fn ${funcName}Index(globalIndex : i32) -> f32 {\n    var coords = getCoordsFromIndex(globalIndex);\n    ${coordsSnippet}\n    return f32(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})]);\n  }\n\n  fn ${funcName}Coords(coordsIn : ${type}) -> f32 {\n    var coords = coordsIn;\n    ${coordsSnippet}\n    return f32(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})]);\n  }\n`;\n}\n\nfunction getInputSnippet(\n    inputInfo: InputInfo, outShape: number[], isVec4: boolean,\n    isFlatDispatchLayout: boolean): string {\n  let res = getInputAtCoordsSnippet(inputInfo, isVec4);\n\n  const inShape = inputInfo.shape;\n  if (inShape.length <= outShape.length) {\n    res += getInputByOutputSnippet(\n        inputInfo, outShape, isVec4, isFlatDispatchLayout);\n  }\n\n  return res;\n}\n\n/**\n * Generates getOutputCoords() function that computes output coordinates from\n * dispatch geometry to reduce arithmetic.\n */\nfunction getOutputCoordsSnippet(\n    outShape: number[],\n    dispatchLayout: {x: number[], y?: number[], z?: number[]}): string {\n  const {x, y = [], z = []} = dispatchLayout;\n\n  const outRank = outShape.length;\n  const rank = x.length + y.length + z.length;\n  // getOutputCoords is only meaningful when the output rank is same with\n  // dispatch layout rank.\n  if (rank !== outRank) {\n    return '';\n  }\n\n  if (x.length === outRank) {\n    const dtype = getCoordsDataType(outRank);\n    const snippet = `fn getOutputCoords() -> ${dtype}{\n    let globalIndex = getGlobalIndex();\n    return getCoordsFromIndex(globalIndex);\n  }\n  `;\n    return snippet;\n  }\n\n  let gatherDimensionsStr = '';\n  const dims = [x, y, z];\n\n  for (let i = 0; i < dims.length; i++) {\n    const arr = dims[i];\n\n    if (arr.length === 0) {\n      continue;\n    }\n\n    if (arr.length === 1) {\n      gatherDimensionsStr += `let d${arr[0]} = i32(globalId[${i}]);`;\n    } else {\n      const strides = symbolicallyComputeStrides(arr, 'uniforms.outShape');\n      gatherDimensionsStr += `var index${i} = i32(globalId[${i}]);`;\n      for (let j = 0; j < strides.length; j++) {\n        gatherDimensionsStr += `let d${arr[j]} = index${i} / ${strides[j]};`;\n\n        if (j === strides.length - 1) {\n          gatherDimensionsStr += `let d${arr[j + 1]} = ` +\n              `index${i} - d${arr[j]} * ${strides[j]};`;\n        } else {\n          gatherDimensionsStr +=\n              `index${i} = index${i} - d${arr[j]} * ${strides[j]};`;\n        }\n      }\n    }\n  }\n\n  const dimensions = [];\n  for (let i = 0; i < rank; i++) {\n    dimensions.push(`d${i}`);\n  }\n\n  const dtype = getCoordsDataType(rank);\n  let snippet = `fn getOutputCoords() -> ${dtype} {\n  ${gatherDimensionsStr}\n`;\n  if (dimensions.length === 0) {\n    snippet += `return ${dtype}(0); }`;\n  } else {\n    snippet += `return ${dtype}(${dimensions.join(',')}); }`;\n  }\n\n  return snippet;\n}\n\nfunction getOutputIndexFromCoordsSnippet(outRank: number) {\n  let snippet = '';\n  switch (outRank) {\n    case 0:\n    case 1:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : i32) -> i32 {\n          return coords;\n        }\n        `;\n      break;\n    case 2:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec2<i32>) -> i32 {\n          return dot(coords, vec2<i32>(uniforms.outShapeStrides, 1));\n        }\n        `;\n      break;\n    case 3:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec3<i32>) -> i32 {\n          return dot(coords, vec3<i32>(uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, 1));\n        }\n        `;\n      break;\n    case 4:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n          return dot(coords, vec4<i32>(\n            uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, uniforms.outShapeStrides.z, 1));\n        }\n        `;\n      break;\n    case 5:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec5) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u;\n        }\n        `;\n      break;\n    case 6:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec6) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u * uniforms.outShapeStrides.u +\n              coords.v;\n        }\n        `;\n      break;\n    default:\n      util.assert(false, () => `Unsupported ${outRank}D shape`);\n      break;\n  }\n  return snippet;\n}\n\nfunction isFlatDispatch(program: WebGPUProgram): boolean {\n  return program.dispatch[1] === 1 && program.dispatch[2] === 1;\n}\n\nexport function mapToWgslTypes(type: DataType, isVec4: boolean): WGSLDataType|\n    DataType {\n  if (type === 'float32') {\n    return isVec4 ? 'vec4<f32>' : 'f32';\n  } else if (type === 'int32') {\n    return isVec4 ? 'vec4<i32>' : 'i32';\n  } else if (type === 'bool') {\n    // Type 'bool' cannot be used in storage class,\n    // https://www.w3.org/TR/WGSL/#host-shareable-types.\n    return isVec4 ? 'vec4<i32>' : 'i32';\n  }\n\n  return type;\n}\n\nfunction setOutputSnippet(\n    outShape: number[], outBufferType: DataType, isVec4: boolean): string {\n  const outRank = outShape.length;\n  const wgslType = mapToWgslTypes(outBufferType, isVec4);\n  let snippet;\n  if (isVec4) {\n    snippet = `fn setOutputAtIndex(flatIndex : i32, value : vec4<f32>) {\n      result[flatIndex] = ${wgslType}(value);\n    }\n    fn setOutputAtIndexI32(flatIndex : i32, value : vec4<i32>) {\n      result[flatIndex] = ${wgslType}(value);\n    }`;\n  } else {\n    snippet = `fn setOutputAtIndex(flatIndex : i32, value : f32) {\n      result[flatIndex] = ${wgslType}(value);\n    }\n    fn setOutputAtIndexI32(flatIndex : i32, value : i32) {\n      result[flatIndex] = ${wgslType}(value);\n    }`;\n  }\n  if (outRank >= 2) {\n    const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, outRank);\n    const type = getCoordsDataType(outRank);\n\n    if (isVec4) {\n      snippet += `\n      fn setOutputAtCoords(${\n          dims.map(d => `${d} : i32`).join(', ')}, value : vec4<f32>) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndex(flatIndex / 4, value);\n      }\n      fn setOutputAtCoordsI32(${\n          dims.map(d => `${d} : i32`).join(', ')}, value : vec4<i32>) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndexI32(flatIndex / 4, value);\n      }\n    `;\n    } else {\n      snippet += `\n      fn setOutputAtCoords(${\n          dims.map(d => `${d} : i32`).join(', ')}, value : f32) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndex(flatIndex, value);\n      }\n      fn setOutputAtCoordsI32(${\n          dims.map(d => `${d} : i32`).join(', ')}, value : i32) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndexI32(flatIndex, value);\n      }\n    `;\n    }\n  }\n\n  return snippet;\n}\n\nfunction insertAlignment(uniformShader: string) {\n  // insert alignment when current pattern is vec5 or vec6\n  const curInsertRe = /(\\w+)\\s*:\\s*vec(5|6)/g;\n  uniformShader = uniformShader.replace(curInsertRe, (match) => {\n    return '@align(16) ' + match;\n  });\n\n  // insert alignment when previous pattern is vec5 or vec6\n  const preInsertRe = /vec(5|6)\\s*,\\s*(\\w+)/g;\n  uniformShader = uniformShader.replace(preInsertRe, (_, p1, p2) => {\n    return `vec${p1}, @align(16) ${p2}`;\n  });\n  return uniformShader;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType} from '@tensorflow/tfjs-core';\n\nconst arrayProduct = (arr: number[]) => {\n  let product = 1;\n  for (let i = 0; i < arr.length; i++) {\n    product *= arr[i];\n  }\n  return product;\n};\n\nexport function tilesFitEvenlyIntoShape(\n    tileSize: number[], shape: number[]): boolean {\n  if (tileSize.length !== shape.length) {\n    throw new Error(\n        `Cannot compute whether rank ${tileSize.length}` +\n        ` tiles fit evenly into rank ${shape.length} shape` +\n        ` - ranks must match.`);\n  }\n  return shape.every(\n      (dim: number, dimIdx: number) => dim % tileSize[dimIdx] === 0);\n}\n\n// Computes dispatch geometry based on layout of output dimensions and\n// workGroupSize.\nexport function computeDispatch(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    workGroupSize: [number, number, number] = [1, 1, 1],\n    elementsPerThread: [number, number, number] =\n        [1, 1, 1]): [number, number, number] {\n  const [dispatchX, dispatchY, dispatchZ] = [\n    Math.ceil(\n        arrayProduct(layout.x.map(d => outputShape[d])) /\n        (workGroupSize[0] * elementsPerThread[0])),\n    layout.y ? Math.ceil(\n                   arrayProduct(layout.y.map(d => outputShape[d])) /\n                   (workGroupSize[1] * elementsPerThread[1])) :\n               1,\n    layout.z ? Math.ceil(\n                   arrayProduct(layout.z.map(d => outputShape[d])) /\n                   (workGroupSize[2] * elementsPerThread[2])) :\n               1\n  ];\n  return [dispatchX, dispatchY, dispatchZ];\n}\n\nexport type WorkGroupInfo = {\n  workGroupSize: [number, number, number],\n  elementsPerThread: [number, number, number],\n};\n\nexport function computeWorkGroupInfoForMatMul(\n    dimAOuter: number, dimInner: number, dimBOuter: number,\n    transposeA = false): WorkGroupInfo {\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the input shapes to improve the EU occupancy.\n  // TODO: WebGPU limits the maximum allowed shared memory size as 16K. To make\n  // sure it doesn't exceed this limitations. Temporarily reduce the work group\n  // size to [8, 8, 1] and the work per thread size is [4, 4, 1]. But we should\n  // revisit it and find the balance between work group size and work per thread\n  // size.\n  const workGroupSize: [number, number, number] = [8, 8, 1];\n  const elementsPerThread: [number, number, number] = [4, 4, 1];\n\n  if (!transposeA) {\n    if (dimAOuter <= 8) {\n      elementsPerThread[1] = 1;\n    }\n\n    if (dimInner <= 16 && dimBOuter <= 16) {\n      workGroupSize[0] = 4;\n    }\n  }\n\n  return {workGroupSize, elementsPerThread};\n}\n\nexport function computeWorkGroupSizeForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [8, 8, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the output shape. For example, when one dimension is smaller\n  // than 4, it will be wasteful if we assign a larger size for this dimension,\n  // which results lots of threads doing useless work and reduces parallelism\n  // of hardware threads. But it is always a balance between work group size\n  // and shared memory. If one dimension is too small, such as 1, shared memory\n  // will won't be fully utilized.\n  if (dim0 <= 4) {\n    return [4, 16, 1];\n  }\n  if (dim1 <= 4) {\n    return [16, 4, 1];\n  }\n\n  return [16, 16, 1];\n}\n\nexport function computeWorkPerThreadForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [4, 4, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // The following conditions correspond to the values set in\n  // computeWorkGroupSizeForConv2d.\n  if (dim0 <= 4) {\n    return [1, 2, 1];\n  }\n  if (dim1 <= 4) {\n    return [2, 1, 1];\n  }\n\n  return [2, 2, 1];\n}\n\nexport function flatDispatchLayout(shape: number[]) {\n  return {x: shape.map((d, i) => i)};\n}\n\nexport function GPUBytesPerElement(dtype: DataType): number {\n  if (dtype === 'float32' || dtype === 'int32' || dtype === 'bool' ||\n      dtype === 'string') {\n    return 4;\n  } else if (dtype === 'complex64') {\n    return 8;\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\nexport function ArrayBufferToTypedArray(data: ArrayBuffer, dtype: DataType) {\n  if (dtype === 'float32') {\n    return new Float32Array(data);\n  } else if (dtype === 'int32') {\n    return new Int32Array(data);\n  } else if (dtype === 'bool' || dtype === 'string') {\n    return Uint8Array.from(new Int32Array(data));\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\nexport function isWebGPUSupported(): boolean {\n  return ((typeof window !== 'undefined') ||\n          //@ts-ignore\n          (typeof WorkerGlobalScope !== 'undefined')) &&\n      !!navigator.gpu;\n}\n\nexport enum MatMulProgramType {\n  MatMulReduceProgram,\n  MatMulSplitKProgram,\n  MatMulSmallOutputSizeProgram,\n  MatMulPackedProgram,\n  MatMulMax\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {backend_util, buffer, DataStorage, DataType, engine, env, GPUData, KernelBackend, Rank, RecursiveArray, ShapeMap, TensorBuffer, TensorInfo, TimingInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {AdapterInfo, GPUAdapterInfo} from './adapter_info';\nimport {BufferManager} from './buffer_manager';\nimport {TextureManager} from './texture_manager';\nimport * as webgpu_program from './webgpu_program';\nimport * as webgpu_util from './webgpu_util';\n\nexport interface WebGPUMemoryInfo extends backend_util.MemoryInfo {\n  numBytesInGPU: number;\n  numBytesAllocatedInGPU: number;\n  unreliable: boolean;\n}\n\nexport type BufferInfo = {\n  size: number,\n  usage: GPUBufferUsageFlags,\n  buffer: GPUBuffer\n};\n\nexport type TextureInfo = {\n  width: number,\n  height: number,\n  format: GPUTextureFormat,\n  usage: GPUTextureUsageFlags,\n  texture: GPUTexture|GPUExternalTexture\n};\n\ntype TensorData = {\n  values: backend_util.BackendValues,\n  dtype: DataType,\n  shape: number[],\n  refCount: number,\n  resourceInfo?: BufferInfo|TextureInfo,\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo}\n};\n\ninterface DataId {}\n\nexport type WebGPUKernelInfo = {\n  name: string; query: Promise<number>;\n};\n\nexport type TimerNode = RecursiveArray<WebGPUKernelInfo>|WebGPUKernelInfo;\n\nexport interface WebGPUTimingInfo extends TimingInfo {\n  uploadWaitMs: number;\n  downloadWaitMs: number;\n}\n\ntype ProgramUniform = Array<{type: string; data: number[]}>;\n\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nconst CPU_HANDOFF_SIZE_THRESHOLD =\n    env().getNumber('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD');\n\n// Reshape dispatch, not to exceed device limits.\nconst reshapeDispatch =\n    (device: GPUDevice,\n     program: webgpu_program.WebGPUProgram): [number, number, number] => {\n      const MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE =\n          device.limits.maxComputeWorkgroupsPerDimension;\n      const layout = program['dispatchLayout'];\n      const dispatch = program['dispatch'];\n      if (dispatch.every((d) => d <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE)) {\n        return dispatch;\n      }\n\n      util.assert(\n          dispatch[0] > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE &&\n              layout.y === undefined && layout.z === undefined,\n          () => 'Dispatch size exceeds WebGPU limits in Y or Z dimension.');\n\n      let dispatchAverage = Math.ceil(Math.sqrt(dispatch[0]));\n      if (dispatchAverage > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE) {\n        dispatchAverage = Math.ceil(Math.cbrt(dispatch[0]));\n        util.assert(\n            dispatchAverage <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE,\n            () => 'Total dispatch size exceeds WebGPU maximum.');\n        return [dispatchAverage, dispatchAverage, dispatchAverage];\n      } else {\n        return [dispatchAverage, dispatchAverage, 1];\n      }\n    };\n\nexport class WebGPUBackend extends KernelBackend {\n  bufferManager: BufferManager;\n  adapterInfo: AdapterInfo;\n  device: GPUDevice;\n  queue: GPUQueue;\n  tensorMap: DataStorage<TensorData>;\n  textureManager: TextureManager;\n\n  private activeTimers: TimerNode[];\n  private currentCommandEncoder: GPUCommandEncoder;\n  private currentComputePass: GPUComputePassEncoder;\n  private commandQueueOwnedIds = new WeakSet<DataId>();\n  private dispatchNumberInEncoder = 0;\n  private disposed = false;\n  private downloadWaitMs = 0;\n  private dummyCanvas: HTMLCanvasElement;\n  private dummyContext: GPUCanvasContext;\n  private tensorDataPendingDisposal: DataId[] = [];\n  private static nextDataId = 0;\n  private pipelineCache: {[key: string]: GPUComputePipeline};\n  private programTimersStack: TimerNode[];\n  private querySet: GPUQuerySet;\n  private stagingPendingDisposal: BufferInfo[] = [];\n  private supportTimeQuery: boolean;\n  private uniformPendingDisposal: BufferInfo[] = [];\n  private uploadWaitMs = 0;\n\n  private nextDataId(): number {\n    return WebGPUBackend.nextDataId++;\n  }\n\n  constructor(device: GPUDevice, adapterInfo?: GPUAdapterInfo) {\n    super();\n    if (!webgpu_util.isWebGPUSupported()) {\n      throw new Error('WebGPU is not supported on this device');\n    }\n    this.pipelineCache = {};\n    this.device = device;\n    this.queue = device.queue;\n    this.currentCommandEncoder = null;\n    this.currentComputePass = null;\n    this.supportTimeQuery = device.features.has('timestamp-query');\n    this.adapterInfo = new AdapterInfo(adapterInfo);\n\n    this.bufferManager = new BufferManager(this.device);\n    this.textureManager = new TextureManager(this.device);\n    this.tensorMap = new DataStorage(this, engine());\n    if (this.supportTimeQuery) {\n      this.querySet = this.device.createQuerySet({\n        type: 'timestamp',\n        count: 2,\n      });\n    }\n\n    // Profiling tools like PIX needs this dummy canvas to\n    // trigger capturing a frame.\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      this.dummyCanvas = document.createElement('canvas');\n      this.dummyCanvas.width = 1;\n      this.dummyCanvas.height = 1;\n\n      this.dummyContext = this.dummyCanvas.getContext('webgpu');\n      this.dummyContext.configure({\n        device,\n        format: 'bgra8unorm',\n      });\n\n      document.body.appendChild(this.dummyCanvas);\n    }\n  }\n\n  floatPrecision(): 32 {\n    return 32;\n  }\n\n  defaultGpuBufferUsage(): number {\n    return GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC |\n        GPUBufferUsage.COPY_DST;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or memory is not managed in this backend, false if memory is\n   * not cleared.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  disposeData(dataId: DataId, force = false): boolean {\n    if (this.tensorDataPendingDisposal.indexOf(dataId) >= 0) {\n      return false;\n    }\n    if (!this.tensorMap.has(dataId)) {\n      return true;\n    }\n\n    const tensorData = this.tensorMap.get(dataId);\n    this.decRef(dataId);\n    if (!force && tensorData.refCount > 0) {\n      return false;\n    }\n\n    // complex is never in commandQueueOwnedIds\n    if (this.commandQueueOwnedIds.has(dataId)) {\n      this.tensorDataPendingDisposal.push(dataId);\n      return false;\n    }\n\n    const {complexTensorInfos} = this.tensorMap.get(dataId);\n    if (complexTensorInfos != null) {\n      this.disposeData(complexTensorInfos.real.dataId, force);\n      this.disposeData(complexTensorInfos.imag.dataId, force);\n    }\n\n    this.releaseResource(dataId);\n    this.tensorMap.delete(dataId);\n\n    return true;\n  }\n\n  memory(): WebGPUMemoryInfo {\n    return {\n      numBytesInGPU: this.bufferManager.numBytesUsed,\n      numBytesAllocatedInGPU: this.bufferManager.numBytesAllocated,\n      unreliable: false\n    } as WebGPUMemoryInfo;\n  }\n\n  releaseResource(dataId: DataId) {\n    const tensorData = this.tensorMap.get(dataId);\n    if (!tensorData || !tensorData.resourceInfo) {\n      return;\n    }\n    if ('texture' in tensorData.resourceInfo) {\n      const textureInfo = tensorData.resourceInfo;\n      if (textureInfo.texture instanceof GPUTexture) {\n        this.textureManager.releaseTexture(\n            textureInfo.texture, textureInfo.width, textureInfo.height,\n            textureInfo.format, textureInfo.usage);\n      }\n      textureInfo.texture = null;\n    } else {\n      const bufferInfo = tensorData.resourceInfo;\n      this.bufferManager.releaseBuffer(\n          bufferInfo.buffer, bufferInfo.size, bufferInfo.usage);\n      bufferInfo.buffer = null;\n    }\n    tensorData.resourceInfo = null;\n  }\n\n  /** Return refCount of a `TensorData`. */\n  refCount(dataId: DataId): number {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (dtype === 'complex64' && values != null) {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    const dataId = {id: this.nextDataId()};\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount: 1});\n    return dataId;\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType, refCount: number): void {\n    if (dtype === 'complex64') {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount});\n  }\n\n  submitQueue() {\n    this.ensureComputePassEnded();\n    this.queue.submit([this.currentCommandEncoder.finish()]);\n    this.currentCommandEncoder = null;\n    this.dispatchNumberInEncoder = 0;\n\n    this.commandQueueOwnedIds = new WeakSet<DataId>();\n\n    this.tensorDataPendingDisposal.forEach(d => {\n      this.releaseResource(d);\n      this.tensorMap.delete(d);\n    });\n    this.uniformPendingDisposal.forEach(\n        d => this.bufferManager.releaseBuffer(d.buffer, d.size, d.usage));\n    this.stagingPendingDisposal.forEach(\n        d => this.bufferManager.releaseUploadBuffer(d.buffer, d.size, d.usage));\n\n    this.tensorDataPendingDisposal = [];\n    this.uniformPendingDisposal = [];\n    this.stagingPendingDisposal = [];\n  }\n\n  ensureCommandEncoderReady() {\n    if (!this.currentCommandEncoder) {\n      this.currentCommandEncoder = this.device.createCommandEncoder();\n    }\n  }\n\n  ensureComputePassEnded() {\n    if (this.currentComputePass) {\n      this.currentComputePass.end();\n      this.currentComputePass = null;\n    }\n  }\n\n  getComputePass() {\n    if (!this.currentComputePass) {\n      this.currentComputePass = this.currentCommandEncoder.beginComputePass();\n    }\n    return this.currentComputePass;\n  }\n\n  public async getBufferData(buffer: GPUBuffer, size: number):\n      Promise<backend_util.BackendValues> {\n    const staging = this.bufferManager.acquireBuffer(\n        size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);\n    this.ensureCommandEncoderReady();\n    this.ensureComputePassEnded();\n    this.currentCommandEncoder.copyBufferToBuffer(buffer, 0, staging, 0, size);\n    this.submitQueue();\n\n    await staging.mapAsync(GPUMapMode.READ);\n    const values = staging.getMappedRange().slice(0);\n\n    staging.unmap();\n    if (staging != null) {\n      this.bufferManager.releaseBuffer(\n          staging, size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);\n    }\n\n    // Need to get texture from swapChain to enable profiling tool\n    // to capture a frame\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      util.assert(\n          this.dummyContext !== undefined,\n          () => `Fail to get context for profiling tool`);\n      this.dummyContext.getCurrentTexture();\n    }\n\n    return values as backend_util.BackendValues;\n  }\n\n  private convertAndCacheOnCPU(dataId: DataId, data: backend_util.TypedArray):\n      backend_util.TypedArray {\n    const tensorData = this.tensorMap.get(dataId);\n    this.releaseResource(dataId);\n    tensorData.values = data;\n    return tensorData.values;\n  }\n\n  // TODO: Remove once this is fixed:\n  // https://github.com/tensorflow/tfjs/issues/1595\n  readSync(dataId: object): backend_util.BackendValues {\n    const tensorData = this.tensorMap.get(dataId);\n    const {values} = tensorData;\n\n    if (values == null) {\n      throw new Error(\n          'WebGPU readSync is only available for CPU-resident tensors.');\n    }\n\n    return values;\n  }\n\n  async read(dataId: object): Promise<backend_util.BackendValues> {\n    if (!this.tensorMap.has(dataId)) {\n      throw new Error(`Tensor ${dataId} was not registered!`);\n    }\n    const tensorData = this.tensorMap.get(dataId);\n\n    const {values} = tensorData;\n\n    if (values != null) {\n      // TODO(xing.xu@intel.com): Merge backend_util.BackendValues and\n      // backend_util.TypedArray.\n      return this.convertAndCacheOnCPU(\n                 dataId, values as backend_util.TypedArray) as\n          backend_util.BackendValues;\n    }\n\n    // Download the values from the GPU.\n    let vals: backend_util.BackendValues;\n    if (tensorData.dtype === 'complex64') {\n      const ps = await Promise.all([\n        this.read(tensorData.complexTensorInfos.real.dataId),\n        this.read(tensorData.complexTensorInfos.imag.dataId)\n      ]);\n\n      const realValues = ps[0];\n      const imagValues = ps[1];\n      vals = backend_util.mergeRealAndImagArrays(\n          realValues as Float32Array, imagValues as Float32Array);\n    } else {\n      const bufferInfo = tensorData.resourceInfo as BufferInfo;\n      const data = await this.getBufferData(bufferInfo.buffer, bufferInfo.size);\n      vals = webgpu_util.ArrayBufferToTypedArray(\n          data as ArrayBuffer, tensorData.dtype);\n    }\n    this.convertAndCacheOnCPU(dataId, vals);\n    return vals;\n  }\n\n  /**\n   * Read tensor to a new GPUBuffer.\n   * @param dataId The source tensor.\n   */\n  readToGPU(dataId: DataId): GPUData {\n    const srcTensorData = this.tensorMap.get(dataId);\n    const {values, dtype, shape, resourceInfo} = srcTensorData;\n\n    if (dtype === 'complex64') {\n      throw new Error('Does not support reading buffer for complex64 dtype.');\n    }\n\n    if (resourceInfo == null) {\n      if (values != null) {\n        throw new Error('Data is not on GPU but on CPU.');\n      } else {\n        throw new Error('There is no data on GPU or CPU.');\n      }\n    }\n\n    const size = (resourceInfo as BufferInfo).size;\n    const buffer = this.bufferManager.acquireBuffer(size, resourceInfo.usage);\n    this.ensureCommandEncoderReady();\n    this.ensureComputePassEnded();\n    this.currentCommandEncoder.copyBufferToBuffer(\n        (resourceInfo as BufferInfo).buffer, 0, buffer, 0, size);\n    this.submitQueue();\n\n    const tensorInfo = this.makeTensorInfo(shape, dtype);\n    // Make engine track this tensor, so that we can dispose it later.\n    const tensorRef = engine().makeTensorFromTensorInfo(tensorInfo);\n\n    const tensorData = this.tensorMap.get(tensorInfo.dataId);\n    tensorData\n        .resourceInfo = {size, usage: this.defaultGpuBufferUsage(), buffer};\n\n    return {tensorRef, buffer, bufSize: size};\n  }\n\n  bufferSync<R extends Rank, D extends DataType>(t: TensorInfo):\n      TensorBuffer<R, D> {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = (data as Uint8Array[]).map(d => util.decodeString(d));\n        return buffer(t.shape as ShapeMap[R], t.dtype, strings) as\n            TensorBuffer<R, D>;\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, data as TypedArray) as\n        TensorBuffer<R, D>;\n  }\n\n  async time(f: () => void): Promise<WebGPUTimingInfo> {\n    if (!this.supportTimeQuery) {\n      console.warn(\n          `This device doesn't support timestamp-query extension. ` +\n          `Start Chrome browser with flag ` +\n          `--disable-dawn-features=disallow_unsafe_apis then try again. ` +\n          `Otherwise, zero will be shown for the kernel time when profiling ` +\n          `mode is enabled. Using performance.now is not workable for webgpu ` +\n          `since it doesn't support synchronous data read from GPU.`);\n    }\n    const oldActiveTimers = this.activeTimers;\n    const newActiveTimers: TimerNode[] = [];\n\n    let outerMostTime = false;\n    if (this.programTimersStack == null) {\n      this.programTimersStack = newActiveTimers;\n      outerMostTime = true;\n    } else {\n      this.activeTimers.push(newActiveTimers);\n    }\n    this.activeTimers = newActiveTimers;\n\n    f();\n\n    const flattenedActiveTimerQueries =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.query))\n            .filter(d => d != null);\n    const flattenedActiveTimerNames =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.name))\n            .filter(d => d != null);\n\n    this.activeTimers = oldActiveTimers;\n\n    if (outerMostTime) {\n      this.programTimersStack = null;\n    }\n    const res: WebGPUTimingInfo = {\n      uploadWaitMs: this.uploadWaitMs,\n      downloadWaitMs: this.downloadWaitMs,\n      kernelMs: null,\n      wallMs: null\n    };\n\n    const kernelMs = await Promise.all(flattenedActiveTimerQueries);\n    res['kernelMs'] = util.sum(kernelMs);\n    res['getExtraProfileInfo'] = () =>\n        kernelMs.map((d, i) => ({name: flattenedActiveTimerNames[i], ms: d}))\n            .map(d => `${d.name}: ${d.ms}`)\n            .join(', ');\n    this.uploadWaitMs = 0;\n    this.downloadWaitMs = 0;\n    return res;\n  }\n\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      values = (values as {} as string[]).map(d => util.encodeString(d));\n    }\n    const dataId =\n        this.write(values as backend_util.BackendValues, shape, dtype);\n    return {dataId, shape, dtype};\n  }\n\n  private tensorToBinding(tensor?: TensorInfo): GPUBindingResource {\n    if (!tensor) {\n      return null;\n    }\n\n    const tensorData = this.tensorMap.get(tensor.dataId);\n    if ('texture' in tensorData.resourceInfo) {\n      const info = tensorData.resourceInfo;\n      if (info.texture instanceof GPUExternalTexture) {\n        return info.texture;\n      } else {\n        return info.texture.createView();\n      }\n    }\n    const bufferInfo = tensorData.resourceInfo;\n    return {offset: 0, size: bufferInfo.size, buffer: bufferInfo.buffer};\n  }\n\n  async getQueryTime(query: GPUQuerySet): Promise<number> {\n    if (this.supportTimeQuery) {\n      return this.getTimeFromQuerySet(query);\n    } else {\n      return 0;\n    }\n  }\n\n  uploadToGPU(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    // Already on the GPU.\n    if (tensorData.resourceInfo) {\n      return;\n    }\n\n    const size = webgpu_util.GPUBytesPerElement(tensorData.dtype) *\n        util.sizeFromShape(tensorData.shape);\n    const buffer =\n        this.bufferManager.acquireBuffer(size, this.defaultGpuBufferUsage());\n\n    tensorData\n        .resourceInfo = {size, usage: this.defaultGpuBufferUsage(), buffer};\n    if (tensorData.values) {\n      const stagingBuffer = this.bufferManager.acquireUploadBuffer(\n          size, GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC);\n      const arrayBuffer = stagingBuffer.getMappedRange();\n      if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {\n        new Int32Array(arrayBuffer).set(tensorData.values as TypedArray);\n      } else {\n        new Float32Array(arrayBuffer).set(tensorData.values as Float32Array);\n      }\n      stagingBuffer.unmap();\n      this.ensureCommandEncoderReady();\n      this.ensureComputePassEnded();\n      this.currentCommandEncoder.copyBufferToBuffer(\n          stagingBuffer, 0, buffer, 0, size);\n\n      const stagingInfo = {\n        size,\n        usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC,\n        buffer: stagingBuffer\n      };\n      this.stagingPendingDisposal.push(stagingInfo);\n      // TODO: WebGPU doesn't support read data synchronously from GPU to CPU.\n      // So it will report error when switching backend from WebGPU to others.\n      // There are two situations: 1) swithcing the backend after running a\n      // model; 2) swithcing the backend within the model. Temporarilly keep the\n      // values on CPU to solve the first issue.\n      // tensorData.values = null;\n    }\n  }\n\n  private makeUniforms(programUniform: ProgramUniform): GPUBindingResource {\n    let currentOffset = 0;\n    let preLength = 0;\n    const offsets: number[] = [];\n    programUniform.forEach((d) => {\n      if (d.data.length === 0) {\n        d.data = [1];\n      }\n      // https://www.w3.org/TR/WGSL/#alignof\n      let baseAlignment: number;\n      switch (d.data.length) {\n        case 1:\n          baseAlignment = 4;\n          break;\n        case 2:\n          baseAlignment = 8;\n          break;\n        case 3:\n          baseAlignment = 16;\n          break;\n        case 4:\n          baseAlignment = 16;\n          break;\n        case 5:\n          baseAlignment = 16;\n          break;\n        case 6:\n          baseAlignment = 16;\n          break;\n        default:\n          util.assert(false, () => `Unsupported ${d.data.length}D shape`);\n      }\n\n      if (preLength === 5 || preLength === 6) {\n        baseAlignment = 16;\n      }\n      currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n      preLength = d.data.length;\n      offsets.push(currentOffset);\n      currentOffset += d.data.length * 4;\n    });\n\n    const arrayBuffer = new ArrayBuffer(currentOffset);\n    programUniform.forEach((d, i) => {\n      const offset = offsets[i];\n      if (d.type === 'int32') {\n        new Int32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else if (d.type === 'uint32') {\n        new Uint32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else {\n        new Float32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      }\n    });\n\n    const uniformBuffer = this.bufferManager.acquireBuffer(\n        currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n    this.queue.writeBuffer(uniformBuffer, 0, arrayBuffer, 0, currentOffset);\n\n    const uniformInfo = {\n      size: currentOffset,\n      usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM,\n      buffer: uniformBuffer\n    };\n    this.uniformPendingDisposal.push(uniformInfo);\n\n    return {offset: 0, size: currentOffset, buffer: uniformBuffer};\n  }\n\n  public runWebGPUProgram(\n      program: webgpu_program.WebGPUProgram, inputs: TensorInfo[],\n      outputDtype: DataType, programDefinedUniform?: ProgramUniform,\n      output?: TensorInfo): TensorInfo {\n    if (!output) {\n      output = this.makeTensorInfo(program.outputShape, outputDtype);\n    }\n    if (util.sizeFromShape(output.shape) === 0) {\n      // Short-circuit the computation since the result is empty (has 0 in its\n      // shape).\n      this.tensorMap.get(output.dataId).values =\n          util.getTypedArrayFromDType(output.dtype as 'float32', 0);\n      return output;\n    }\n    this.uploadToGPU(output.dataId);\n    program.dispatch = reshapeDispatch(this.device, program);\n\n    // There are five kinds of uniforms: NAN, shapes, shape strides, program\n    // size, program defined uniforms.\n    let programUniform: ProgramUniform = [];\n    let bufferShapes: number[][] = [];\n    if (!program.isFromPixels) {\n      programUniform.push({type: 'float32', data: [NaN]});\n      bufferShapes = inputs.concat(output).map(d => d.shape);\n      const uniformsType = 'int32';\n      bufferShapes.map(d => {\n        programUniform.push({type: uniformsType, data: d});\n      });\n      const strides = util.computeStrides(output.shape);\n      programUniform.push({type: uniformsType, data: strides});\n      if (program.size) {\n        const size = util.sizeFromShape(program.outputShape);\n        programUniform.push(\n            {type: uniformsType, data: [program.isVec4 ? size / 4 : size]});\n      }\n    }\n\n    const inputsData = inputs.map((input: TensorInfo, i: number) => {\n      if (input.dtype === 'complex64') {\n        throw new Error(\n            `GPGPUProgram does not support complex64 input. For complex64 ` +\n            `dtypes, please separate the program into real and imaginary ` +\n            `parts.`);\n      }\n      this.uploadToGPU(input.dataId);\n\n      return {\n        // Returning dtype from tensorMap because it reflects dtype\n        // of underlying buffer, rather than abstract dtype.\n        dtype: this.tensorMap.get(input.dataId).dtype,\n        shape: input.shape,\n        name: program.variableNames[i]\n      };\n    });\n\n    const key =\n        webgpu_program.makeShaderKey(program, bufferShapes, inputsData, output);\n\n    let pipeline;\n    if (key in this.pipelineCache) {\n      pipeline = this.pipelineCache[key];\n    } else {\n      pipeline = webgpu_program.compileProgram(\n          this.device, program, inputsData, output);\n      this.pipelineCache[key] = pipeline;\n    }\n\n    if (programDefinedUniform) {\n      programUniform = [...programUniform, ...programDefinedUniform];\n    }\n    const bindings = [\n      this.tensorToBinding(output), ...inputs.map(t => this.tensorToBinding(t)),\n      this.makeUniforms(programUniform)\n    ];\n\n    const bindGroup = this.device.createBindGroup({\n      layout: pipeline.getBindGroupLayout(0),\n      entries: bindings.map((b, i) => ({binding: i, resource: b})),\n    });\n\n    this.ensureCommandEncoderReady();\n    const pass = this.getComputePass();\n    const shouldTimeProgram = this.activeTimers != null;\n    if (shouldTimeProgram) {\n      if (this.supportTimeQuery) {\n        // tslint:disable-next-line:no-any\n        (pass as any).writeTimestamp(this.querySet, 0);\n      }\n    }\n    pass.setPipeline(pipeline);\n    pass.setBindGroup(0, bindGroup);\n    pass.dispatchWorkgroups(\n        program.dispatch[0], program.dispatch[1], program.dispatch[2]);\n    if (shouldTimeProgram) {\n      if (this.supportTimeQuery) {\n        // tslint:disable-next-line:no-any\n        (pass as any).writeTimestamp(this.querySet, 1);\n      }\n    }\n    this.dispatchNumberInEncoder++;\n\n    inputs.forEach(input => {\n      this.commandQueueOwnedIds.add(input.dataId);\n    });\n    this.commandQueueOwnedIds.add(output.dataId);\n\n    if (env().get('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE') as\n        number <= this.dispatchNumberInEncoder) {\n      this.submitQueue();\n    }\n\n    if (shouldTimeProgram) {\n      this.activeTimers.push({\n        name: program.constructor.name,\n        query: this.getQueryTime(this.querySet)\n      });\n    }\n    return output;\n  }\n\n  async getTimeFromQuerySet(querySet: GPUQuerySet) {\n    const queryBuffer = this.bufferManager.acquireBuffer(\n        16, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n    const dst = this.bufferManager.acquireBuffer(\n        16, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n    this.ensureCommandEncoderReady();\n    this.ensureComputePassEnded();\n    this.currentCommandEncoder.resolveQuerySet(querySet, 0, 2, queryBuffer, 0);\n    this.currentCommandEncoder.copyBufferToBuffer(queryBuffer, 0, dst, 0, 16);\n    this.submitQueue();\n    await dst.mapAsync(GPUMapMode.READ);\n    const arrayBuf = new BigUint64Array(dst.getMappedRange());\n    const timeElapsedNanos = Number((arrayBuf[1] - arrayBuf[0]));\n    dst.unmap();\n    this.bufferManager.releaseBuffer(\n        dst, 16, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n    this.bufferManager.releaseBuffer(\n        queryBuffer, 16,\n        GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n    // Return milliseconds.\n    return timeElapsedNanos / 1000000;\n  }\n\n  shouldExecuteOnCPU(\n      inputs: TensorInfo[],\n      sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD): boolean {\n    return env().getBool('WEBGPU_CPU_FORWARD') &&\n        inputs.every(\n            input => this.tensorMap.get(input.dataId).resourceInfo == null &&\n                util.sizeFromShape(input.shape) < sizeThreshold);\n  }\n\n  numDataIds() {\n    return this.tensorMap.numDataIds() - this.tensorDataPendingDisposal.length;\n  }\n\n  dispose() {\n    if (this.disposed) {\n      return;\n    }\n    this.bufferManager.dispose();\n    this.textureManager.dispose();\n    this.disposed = true;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {env, registerBackend} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from './backend_webgpu';\nimport {isWebGPUSupported} from './webgpu_util';\n\nif (isWebGPUSupported()) {\n  registerBackend('webgpu', async () => {\n    // Remove it once we figure out how to correctly read the tensor data\n    // before the tensor is disposed in profiling mode.\n    env().set('CHECK_COMPUTATION_FOR_ERRORS', false);\n\n    const gpuDescriptor: GPURequestAdapterOptions = {\n      powerPreference: env().get('WEBGPU_USE_LOW_POWER_GPU') ?\n          'low-power' :\n          'high-performance'\n    };\n\n    const adapter = await navigator.gpu.requestAdapter(gpuDescriptor);\n    const adapterLimits = adapter.limits;\n    const deviceDescriptor: GPUDeviceDescriptor = {};\n    const supportTimeQuery = adapter.features.has('timestamp-query');\n    deviceDescriptor.requiredLimits = {\n      'maxComputeWorkgroupStorageSize':\n          adapterLimits.maxComputeWorkgroupStorageSize,\n      'maxComputeWorkgroupsPerDimension':\n          adapterLimits.maxComputeWorkgroupsPerDimension,\n      'maxStorageBufferBindingSize': adapterLimits.maxStorageBufferBindingSize,\n    };\n\n    if (supportTimeQuery) {\n      deviceDescriptor.requiredFeatures = ['timestamp-query'];\n    }\n    const device: GPUDevice = await adapter.requestDevice(deviceDescriptor);\n    // tslint:disable-next-line:no-any\n    const adapterInfo = await (adapter as any).requestAdapterInfo();\n    return new WebGPUBackend(device, adapterInfo);\n  }, 3 /*priority*/);\n}\n\n// Export webgpu utilities\nexport * from './webgpu';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum BinaryOpType {\n  MUL,\n  ADD,\n  ATAN2,\n  SUB,\n  DIV,\n  EQUAL,\n  GREATER,\n  GREATER_EQUAL,\n  LESS,\n  LESS_EQUAL,\n  LOGICAL_AND,\n  NOT_EQUAL,\n  SQUARED_DIFFERENCE,\n  INT_DIV,\n  POW,\n  PRELU,\n  MAX,\n  MIN,\n  COMPLEX_MULTIPLY_REAL,\n  COMPLEX_MULTIPLY_IMAG\n}\n\nconst CHECK_NAN_SNIPPET = `\n  if (isnan(a)) { return a; }\n  if (isnan(b)) { return b; }\n  `;\n\nconst CHECK_NAN_SNIPPET_VEC4_INNER = `\n  if (isNaN.r) {\n    resultTemp.r = valueForNaN;\n  }\n  if (isNaN.g) {\n    resultTemp.g = valueForNaN;\n  }\n  if (isNaN.b) {\n    resultTemp.b = valueForNaN;\n  }\n  if (isNaN.a) {\n    resultTemp.a = valueForNaN;\n  }\n  `;\n\nconst CHECK_NAN_SNIPPET_VEC4 = `\n  let isNaN = isnanVec4(a) | isnanVec4(b);\n  ${CHECK_NAN_SNIPPET_VEC4_INNER}\n  `;\n\nconst ADD = 'return a + b;';\n// (Ar + Ai)(Br + Bi) =\n// ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr\n// Yr = ArBr - AB\n// Yi = ArBi + AiBr\nconst COMPLEX_MULTIPLY_REAL = 'return areal * breal - aimag * bimag;';\nconst COMPLEX_MULTIPLY_IMAG = 'return areal * bimag + aimag * breal;';\nconst DIV = 'return a / b;';\nconst MUL = 'return a * b;';\nconst SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';\nconst SUB = 'return a - b;';\nconst EQUAL = 'return f32(a == b);';\nconst EQUAL_VEC4 = 'return vec4<f32>(a == b);';\nconst GREATER = 'return f32(a > b);';\nconst GREATER_VEC4 = 'return vec4<f32>(a > b);';\nconst GREATER_EQUAL = 'return f32(a >= b);';\nconst GREATER_EQUAL_VEC4 = 'return vec4<f32>(a >= b);';\nconst LESS = 'return f32(a < b);';\nconst LESS_VEC4 = 'return vec4<f32>(a < b);';\nconst LESS_EQUAL = 'return f32(a <= b);';\nconst LESS_EQUAL_VEC4 = 'return vec4<f32>(a <= b);';\nconst LOGICAL_AND = 'return f32(f32(a) >= 1.0 && f32(b) >= 1.0);';\nconst LOGICAL_AND_VEC4 = `return (vec4<f32>(a >= vec4<f32>(1.0)) *\n  vec4<f32>(b >= vec4<f32>(1.0)));`;\nconst INT_DIV = `\n  let s = sign(a) * sign(b);\n  let ia = i32(round(a));\n  let ib = i32(round(b));\n  return f32(idiv(ia, ib, s));\n  `;\n\nconst INT_DIV_VEC4 = `\n  let ia = vec4<i32>(round(a));\n  let ib = vec4<i32>(round(b));\n  let cond = ib != vec4<i32>(0);\n  var resultTemp = vec4<i32>(0);\n  let s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    resultTemp[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    resultTemp[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    resultTemp[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    resultTemp[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4<f32>(resultTemp);\n  `;\n\nconst NOT_EQUAL = `\n  if (isnan(a) || isnan(b)) {\n    return 1.0;\n  }\n  return f32(a != b);\n`;\nconst NOT_EQUAL_VEC4 = `\n  var resultTemp = vec4<f32>(a != b);\n  let valueForNaN = 1.0;\n  ${CHECK_NAN_SNIPPET_VEC4}\n\n  return resultTemp;\n`;\nconst POW = `\n  if(a < 0.0 && floor(b) < b) {\n    return uniforms.NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  if (round(abs(b) % 2.0) != 1.0) {\n    return pow(abs(a), b);\n  }\n  return sign(a) * pow(abs(a), b);\n  `;\nconst POW_VEC4 = `\n  let isModRound1Bool = vec4<i32>(round(abs(b) % vec4<f32>(2.0))) == vec4<i32>(1);\n  let isModRound1 = vec4<f32>(isModRound1Bool);\n  let multiplier = sign(a) * isModRound1 + (vec4<f32>(1.0) - isModRound1);\n  var resultTemp = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  let isExpZero = b == vec4<f32>(0.0);\n  if (isExpZero.r) {\n    resultTemp.r = 1.0;\n  }\n  if (isExpZero.g) {\n    resultTemp.g = 1.0;\n  }\n  if (isExpZero.b) {\n    resultTemp.b = 1.0;\n  }\n  if (isExpZero.a) {\n    resultTemp.a = 1.0;\n  }\n  let isNaN = (a < vec4<f32>(0.0)) & (floor(b) < b);\n  let valueForNaN = uniforms.NAN;\n  ${CHECK_NAN_SNIPPET_VEC4_INNER}\n  return resultTemp;\n  `;\n\nconst PRELU = `if (a < 0.0) { return b * a; }  return a;`;\nconst PRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (b * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n  `;\n\nfunction getBinaryWithNanString(\n    op: string, useVec4: boolean, valueForNaN = 'uniforms.NAN') {\n  const checkNanSnippet = useVec4 ? CHECK_NAN_SNIPPET_VEC4 : CHECK_NAN_SNIPPET;\n  return useVec4 ? `\n    let valueForNaN = ${valueForNaN};\n    var resultTemp = vec4<f32>(${op}(a, b));\n    ` + checkNanSnippet +\n          `\n    return resultTemp;\n  ` :\n                   checkNanSnippet + `\n    return ${op}(a, b);\n  `;\n}\n\nexport function getBinaryOpString(\n    type: BinaryOpType, useVec4?: boolean): string {\n  switch (type) {\n    case BinaryOpType.MUL:\n      return MUL;\n    case BinaryOpType.ADD:\n      return ADD;\n    case BinaryOpType.ATAN2:\n      return getBinaryWithNanString('atan2', useVec4);\n    case BinaryOpType.SUB:\n      return SUB;\n    case BinaryOpType.DIV:\n      return DIV;\n    case BinaryOpType.EQUAL:\n      return useVec4 ? EQUAL_VEC4 : EQUAL;\n    case BinaryOpType.GREATER:\n      return useVec4 ? GREATER_VEC4 : GREATER;\n    case BinaryOpType.GREATER_EQUAL:\n      return useVec4 ? GREATER_EQUAL_VEC4 : GREATER_EQUAL;\n    case BinaryOpType.LESS:\n      return useVec4 ? LESS_VEC4 : LESS;\n    case BinaryOpType.LESS_EQUAL:\n      return useVec4 ? LESS_EQUAL_VEC4 : LESS_EQUAL;\n    case BinaryOpType.LOGICAL_AND:\n      return useVec4 ? LOGICAL_AND_VEC4 : LOGICAL_AND;\n    case BinaryOpType.NOT_EQUAL:\n      return useVec4 ? NOT_EQUAL_VEC4 : NOT_EQUAL;\n    case BinaryOpType.SQUARED_DIFFERENCE:\n      return SQUARED_DIFFERENCE;\n    case BinaryOpType.INT_DIV:\n      return useVec4 ? INT_DIV_VEC4 : INT_DIV;\n    case BinaryOpType.PRELU:\n      return useVec4 ? PRELU_VEC4 : PRELU;\n    case BinaryOpType.MAX:\n      return getBinaryWithNanString('max', useVec4);\n    case BinaryOpType.MIN:\n      return getBinaryWithNanString('min', useVec4);\n    case BinaryOpType.POW:\n      return useVec4 ? POW_VEC4 : POW;\n    case BinaryOpType.COMPLEX_MULTIPLY_REAL:\n      return COMPLEX_MULTIPLY_REAL;\n    case BinaryOpType.COMPLEX_MULTIPLY_IMAG:\n      return COMPLEX_MULTIPLY_IMAG;\n    default:\n      throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum UnaryOpType {\n  ABS,\n  CEIL,\n  COS,\n  COSH,\n  ELU,\n  EXP,\n  EXPM1,\n  FLOOR,\n  IS_NAN,\n  LINEAR,\n  LOG,\n  LOGICAL_NOT,\n  NEG,\n  RELU,\n  RELU6,\n  LEAKYRELU,\n  RECIPROCAL,\n  RSQRT,\n  SIN,\n  SINH,\n  SIGMOID,\n  SQRT,\n  SQUARE,\n  TANH,\n  TO_INT\n}\n\nconst ABS = `return abs(a);`;\nconst CEIL = `return ceil(a);`;\nconst COS = `return cos(a);`;\nconst COSH = `\n  let e2x = exp(-a);\n  return (e2x + 1.0 / e2x) / 2.0;\n`;\nconst EXPM1 = `return exp(a) - 1.0;`;\nconst ELU = `if (a >= 0.0) { return a; }  return (exp(a) - 1.0);`;\nconst ELU_VEC4 = `\n  var resFloat = exp(a) - vec4<f32>(1.0);\n  if (a.r >= 0.0) {\n    resFloat.r = a.r;\n  }\n  if (a.g >= 0.0) {\n    resFloat.g = a.g;\n  }\n  if (a.b >= 0.0) {\n    resFloat.b = a.b;\n  }\n  if (a.a >= 0.0) {\n    resFloat.a = a.a;\n  }\n  return resFloat;\n`;\nconst EXP = `return exp(a);`;\nconst FLOOR = `return floor(a);`;\nconst IS_NAN = `return f32(isnan(a));`;\nconst LINEAR = `return a;`;\nconst LOG = `if (a < 0.0) { return uniforms.NAN; }\n  return log(a);`;\nconst LOGICAL_NOT = `return f32(!(a >= 1.0));`;\nconst NEG = `return -a;`;\nconst LEAKYRELU = `if (a < 0.0) { return uniforms.alpha * a; } return a;`;\nconst LEAKYRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (uniforms.alpha * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n`;\nconst RECIPROCAL = `return 1.0 / a;`;\nconst RELU = `return select(a, 0.0, a < 0.0);`;\nconst RELU6 = 'return clamp(a, 0.0, 6.0);';\nconst RELU6_VEC4 =\n    'return clamp(a, vec4<f32>(0.0, 0.0, 0.0, 0.0), vec4<f32>(6.0, 6.0, 6.0, 6.0));';\nconst RELU_VEC4 = `\n  return select(a, vec4<f32>(0.0), a < vec4<f32>(0.0));\n`;\nconst RSQRT = `return 1.0/sqrt(a);`;\nconst SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * a));`;\nconst SIN = `return sin(a);`;\nconst SINH = `\n  let e2x = exp(a);\n  return (e2x - 1.0 / e2x) / 2.0;\n`;\nconst SQRT = `return sqrt(a);`;\nconst SQUARE = `return a * a;`;\nconst TANH = `\n  let e2x = exp(-2.0 * abs(a));\n  return sign(a) * (1.0 - e2x) / (1.0 + e2x);\n`;\nconst TO_INT = `return f32(i32((a)));`;\n\nexport function getUnaryOpString(type: UnaryOpType, useVec4?: boolean): string {\n  switch (type) {\n    case UnaryOpType.ABS:\n      return ABS;\n    case UnaryOpType.COS:\n      return COS;\n    case UnaryOpType.COSH:\n      return COSH;\n    case UnaryOpType.CEIL:\n      return CEIL;\n    case UnaryOpType.ELU:\n      return useVec4 ? ELU_VEC4 : ELU;\n    case UnaryOpType.EXP:\n      return EXP;\n    case UnaryOpType.EXPM1:\n      return EXPM1;\n    case UnaryOpType.FLOOR:\n      return FLOOR;\n    case UnaryOpType.IS_NAN:\n      return IS_NAN;\n    case UnaryOpType.LINEAR:\n      return LINEAR;\n    case UnaryOpType.LOG:\n      return LOG;\n    case UnaryOpType.LOGICAL_NOT:\n      return LOGICAL_NOT;\n    case UnaryOpType.NEG:\n      return NEG;\n    case UnaryOpType.LEAKYRELU:\n      return useVec4 ? LEAKYRELU_VEC4 : LEAKYRELU;\n    case UnaryOpType.RECIPROCAL:\n      return RECIPROCAL;\n    case UnaryOpType.RELU:\n      return useVec4 ? RELU_VEC4 : RELU;\n    case UnaryOpType.RELU6:\n      return useVec4 ? RELU6_VEC4 : RELU6;\n    case UnaryOpType.RSQRT:\n      return RSQRT;\n    case UnaryOpType.SIGMOID:\n      return SIGMOID;\n    case UnaryOpType.SIN:\n      return SIN;\n    case UnaryOpType.SINH:\n      return SINH;\n    case UnaryOpType.SQRT:\n      return SQRT;\n    case UnaryOpType.SQUARE:\n      return SQUARE;\n    case UnaryOpType.TANH:\n      return TANH;\n    case UnaryOpType.TO_INT:\n      return TO_INT;\n\n    default:\n      throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\n\nexport const typeSnippet = (component: number) => {\n  switch (component) {\n    case 1:\n      return 'f32';\n    case 2:\n      return 'vec2<f32>';\n    case 3:\n      return 'vec3<f32>';\n    case 4:\n      return 'vec4<f32>';\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport function activationFnSnippet(\n    activation: backend_util.Activation, hasPreluActivationWeights = false,\n    packed = false, coordsLength = 3): string {\n  if (activation === null) {\n    return '';\n  }\n\n  let activationOpSnippet = '';\n  if (activation === 'linear') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LINEAR);\n  } else if (activation === 'relu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU, packed);\n  } else if (activation === 'elu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.ELU, packed);\n  } else if (activation === 'relu6') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU6, packed);\n  } else if (activation === 'prelu') {\n    activationOpSnippet = getBinaryOpString(BinaryOpType.PRELU, packed);\n  } else if (activation === 'sigmoid') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.SIGMOID, packed);\n  } else if (activation === 'leakyrelu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LEAKYRELU, packed);\n  } else {\n    throw new Error(`Activation ${\n        activation} has not been implemented for the WebGPU backend.`);\n  }\n  const elementSize = packed ? 4 : 1;\n  const dataType = typeSnippet(elementSize);\n  let activationFnSnippet = '';\n  if (hasPreluActivationWeights) {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        let b = getPreluActivationWeightsByOutputCoords(coords);\n        ${activationOpSnippet}\n      }`;\n  } else {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        ${activationOpSnippet}\n      }`;\n  }\n  return activationFnSnippet;\n}\n\nexport function biasActivationSnippet(\n    hasBias: boolean, activation: backend_util.Activation): string {\n  return `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      ${activation ? 'value = activation(value, coords);' : ''}\n      `;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkGroupInfoForMatMul} from './webgpu_util';\n\nexport function matMulReadFnSource(\n    batchAEqualOne: boolean, batchBEqualOne: boolean, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  util.assert(\n      transposeA && component === 1 || !transposeA,\n      () => `transposeA ${transposeA} is not compatible with component size ${\n          component}`);\n  const sampleA = `\n      let batch = ${batchAEqualOne ? '0' : 'batchIn'};\n      ${\n      transposeA ? `value = getA(batch, col, row);` :\n                   `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` :\n                               `value = getB(batch, row, col);`;\n\n  return `\n  fn mm_readA(batchIn: i32, row: i32, colIn: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    let col = colIn * ${component};\n    ${\n      fitAOuter && fitInner ?\n          sampleA :\n          `\n    ${\n              transposeA ?\n                  `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :\n                  `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batchIn: i32, row: i32, colIn: i32) -> ${typeSnippet(component)} {\n    let col = colIn * ${component};\n    let batch = ${batchBEqualOne ? '0' : 'batchIn'};\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\n\nexport function matMulReadWriteFnSource(\n    hasBias: boolean, activation: backend_util.Activation,\n    batchAEqualOne: boolean, batchBEqualOne: boolean, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  return `\n  ${\n      matMulReadFnSource(\n          batchAEqualOne, batchBEqualOne, transposeA, transposeB, fitAOuter,\n          fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${\n      typeSnippet(component)}) {\n    let col = colIn * ${component};\n    ${\n      fitAOuter && fitBOuter ?\n          '' :\n          'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / InnerElementSize + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / InnerElementSize + inputCol);\n        `;\n  }\n};\n\nconst calculateResultSnippet =\n    (transposeA: boolean, innerElementSize: number) => {\n      if (transposeA) {\n        return `\n        let ACached0 = mm_Asub[k * InnerElementSize][localRow];\n        let ACached1 = mm_Asub[k * InnerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * InnerElementSize + 2][localRow];\n        ${\n            innerElementSize === 3 ?\n                '' :\n                'let ACached3 = mm_Asub[k * InnerElementSize + 3][localRow];'}\n        for (var i = 0; i < RowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${\n            innerElementSize === 3 ?\n                '' :\n                'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n      } else {\n        return `\n        for (var i = 0; i < RowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${\n            innerElementSize === 3 ? '' :\n                                     'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n      }\n    };\n\nexport function makeMatMulPackedVec4Source(\n    workPerThread: number[], workGroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    isVectorA = false): string {\n  const tileAOuter = workGroupSize[1] * workPerThread[1];\n  const tileBOuter = workGroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workGroupSize[0];\n  const rowPerThreadB = tileInner / workGroupSize[1];\n  util.assert(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n       (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n          tileAWidth % workGroupSize[0] === 0 &&\n          tileInner % workGroupSize[1] === 0 && workPerThread[0] === 4,\n      () => `If transposeA ${transposeA} is true, innerElementSize ${\n          innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workGroupSize[0]${\n          workGroupSize[0]}. tileInner ${\n          tileInner} must be divisible by workGroupSize[1] ${\n          workGroupSize[1]}. ColPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${\n      tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${\n      tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  const RowPerThread = ${workPerThread[1]};\n  const ColPerThread = ${workPerThread[0]};\n  const InnerElementSize = ${innerElementSize};\n  const TileInner = ${tileInner};\n\n  @compute @workgroup_size(workGroupSizeX, workGroupSizeY, workGroupSizeZ)\n  fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n            @builtin(global_invocation_id) GlobalId : vec3<u32>,\n            @builtin(num_workgroups) NumWorkgroups: vec3<u32>,\n            @builtin(workgroup_id) workgroupId: vec3<u32>) {\n    localId = LocalId;\n    globalId = GlobalId;\n    numWorkgroups = NumWorkgroups;\n\n    let localRow = i32(localId.y);\n    let tileRow = ${isVectorA ? '0' : 'localRow * RowPerThread'};\n    let tileCol = i32(localId.x);\n\n    let globalRow = ${isVectorA ? '0' : 'i32(globalId.y) * RowPerThread'};\n    let globalCol = i32(globalId.x);\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               '(uniforms.dimInner - 1) / TileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, RowPerThread>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t = t + 1) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${\n      rowPerThreadB}; innerRow = innerRow + 1) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + TileInner;\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < TileInner / InnerElementSize; k = k + 1) {\n            let BCached0 = mm_Bsub[k * InnerElementSize][tileCol];\n            let BCached1 = mm_Bsub[k * InnerElementSize + 1][tileCol];\n            let BCached2 = mm_Bsub[k * InnerElementSize + 2][tileCol];\n            ${\n      innerElementSize === 3 ?\n          '' :\n          'let BCached3 = mm_Bsub[k * InnerElementSize + 3][tileCol];'}\n\n            ${calculateResultSnippet(transposeA, innerElementSize)}\n        }\n\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\n\nconst writeDataToSubASnippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :\n\n                      'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(\n    workPerThread: number[], workGroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    sequentialAccessByThreads = false): string {\n  const tileAOuter = workPerThread[1] * workGroupSize[1];\n  const tileBOuter = workPerThread[0] * workGroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(\n      tileAHight % workGroupSize[1] === 0 &&\n          tileAWidth % workGroupSize[0] === 0 &&\n          tileInner % workGroupSize[1] === 0,\n      () => `tileAHight ${tileAHight} must be divisible by workGroupSize[1]${\n          workGroupSize[1]}, tileAWidth ${\n          tileAWidth} must be divisible by workGroupSize[0]${\n          workGroupSize[0]}, tileInner ${\n          tileInner} must be divisible by workGroupSize[1]${workGroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workGroupSize[1];\n  const colPerThreadA = tileAWidth / workGroupSize[0];\n  const rowPerThreadB = tileInner / workGroupSize[1];\n  const matmulSnippet = sequentialAccessByThreads ?\n      `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t = t + 1) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileAHight}; inputRow = inputRow + ${workGroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n          tileAWidth}; inputCol = inputCol + ${workGroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileInner}; inputRow = inputRow + ${workGroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${\n          tileBOuter}; inputCol = inputCol + ${workGroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + TileInner;\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ColPerThread>;\n        for (var k = 0; k < TileInner; k = k + 1) {\n          for (var inner = 0; inner < ColPerThread; inner = inner + 1) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workGroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n            let ACached = ${\n          transposeA ?\n              `mm_Asub[k][localRow + innerRow * ${workGroupSize[1]}];` :\n              `mm_Asub[localRow + innerRow * ${workGroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n              acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                  ACached * BCached[innerCol];\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n        let gRow = globalRowStart + localRow + innerRow * ${workGroupSize[1]};\n        for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n          let gCol = globalColStart + localCol + innerCol * ${workGroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` :\n      `\n  let tileRow = i32(localId.y) * RowPerThread;\n  let tileCol = i32(localId.x) * ColPerThread;\n\n  let globalRow = i32(globalId.y) * RowPerThread;\n  let globalCol = i32(globalId.x) * ColPerThread;\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t = t + 1) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${\n          rowPerThreadA}; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < ${\n          colPerThreadA}; innerCol = innerCol + 1) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${\n          rowPerThreadB}; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + TileInner;\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ColPerThread>;\n    for (var k = 0; k < TileInner; k = k + 1) {\n      for (var inner = 0; inner < ColPerThread; inner = inner + 1) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n          acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n    const RowPerThread = ${workPerThread[1]};\n    const ColPerThread = ${workPerThread[0]};\n    const TileInner = ${tileInner};\n\n    @compute @workgroup_size(workGroupSizeX, workGroupSizeY, workGroupSizeZ)\n    fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n              @builtin(global_invocation_id) GlobalId : vec3<u32>,\n              @builtin(num_workgroups) NumWorkgroups: vec3<u32>,\n              @builtin(workgroup_id) workgroupId: vec3<u32>) {\n      localId = LocalId;\n      globalId = GlobalId;\n      numWorkgroups = NumWorkgroups;\n\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               '(uniforms.dimInner - 1) / TileInner + 1'};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ColPerThread>, RowPerThread>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < RowPerThread; innerRow = innerRow + 1) {\n        for (var innerCol = 0; innerCol < ColPerThread; innerCol = innerCol + 1) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\n\nconst readVectorASnippet = (transpose: boolean) => {\n  return transpose ? `\n      mm_readA(batch, colA, globalRow),\n      mm_readA(batch, colA + 1, globalRow),\n      mm_readA(batch, colA + 2, globalRow),\n      mm_readA(batch, colA + 3, globalRow)\n  ` :\n                     `\n      mm_readA(batch, globalRow, colA),\n      mm_readA(batch, globalRow, colA + 1),\n      mm_readA(batch, globalRow, colA + 2),\n      mm_readA(batch, globalRow, colA + 3)\n  `;\n};\n\nexport function makeVectorMatrixProductSource(\n    workGroupSize: [number, number, number], transposeA = false): string {\n  util.assert(\n      workGroupSize[1] === 1 && workGroupSize[2] === 1,\n      () => `A linear work group size is required. But got ${workGroupSize}.`);\n  return `\n    const TileSize = ${workGroupSize[0] * 4};\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workGroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / TileSize + 1;\n      let batch = i32(globalId.z);\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t = t + 1) {\n        // Load one tile of A into local memory.\n        let colA = t * TileSize + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < TileSize / 4; k = k + 1) {\n          let rowB = t * TileSize + k * 4;\n          let BCached = vec4<f32>(mm_readB(batch, rowB, globalCol),\n                              mm_readB(batch, rowB + 1, globalCol),\n                              mm_readB(batch, rowB + 2, globalCol),\n                              mm_readB(batch, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\n\nexport class MatMulPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workGroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  batchAEqualOne: boolean;\n  batchBEqualOne: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileInner: number;\n  isVectorA: boolean;\n  isVec4: boolean;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      aShape: [number, number, number], outputShape: [number, number, number],\n      batchAEqualOne: boolean, batchBEqualOne: boolean, transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null,\n      sequentialAccessByThreads = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||\n                   (outputShape[1] % 4 === 0 && transposeA)) &&\n        outputShape[2] % 4 === 0 && !transposeB;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workGroupSize = [32, 1, 1];\n    } else {\n      const workGroupInfo = computeWorkGroupInfoForMatMul(\n          outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workGroupSize = workGroupInfo.workGroupSize;\n      this.elementsPerThread = workGroupInfo.elementsPerThread;\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        this.elementsPerThread);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.batchAEqualOne = batchAEqualOne;\n    this.batchBEqualOne = batchBEqualOne;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] =\n        this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${\n        transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${\n        this.fitInner}_${this.isVec4}_${this.isVectorA}_${\n        this.batchAEqualOne}_${this.batchBEqualOne}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getShapeFit(dimAOuter: number, dimBOuter: number, dimInner: number):\n      boolean[] {\n    const tileAOuter = this.workGroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workGroupSize[0] * this.elementsPerThread[0];\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workGroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.batchAEqualOne,\n            this.batchBEqualOne,\n            false /* transposeA is implemented in makeMatMulPackedSource */,\n            this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.isVec4 ? 4 : 1)}\n      ${\n        this.isVec4 ?\n            makeMatMulPackedVec4Source(\n                this.elementsPerThread, this.workGroupSize, this.transposeA,\n                this.tileInner, false, null, this.isVectorA) :\n            (this.isVectorA ? makeVectorMatrixProductSource(\n                                  this.workGroupSize, this.transposeA) :\n                              makeMatMulPackedSource(\n                                  this.elementsPerThread, this.workGroupSize,\n                                  this.transposeA, this.tileInner, false, null,\n                                  this.sequentialAccessByThreads))}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport function makeMatMulReduceSource(): string {\n  return `\n    var<workgroup> sumValues : array<f32, workGroupSizeX>;\n    ${main()} {\n      let coords = getOutputCoords();\n      let batch = coords[0];\n      let row = coords[1];\n      let col = coords[2];\n      var sum = 0.0;\n      let Length = uniforms.dimInner;\n      for (var k = i32(localId.x); k < Length; k = k + i32(workGroupSizeX)) {\n        let dataA = mm_readA(batch, row, k);\n        let dataB = mm_readB(batch, k, col);\n        sum = sum + dataA * dataB;\n      }\n      sumValues[localId.x] = sum;\n      workgroupBarrier();\n\n      for(var currentSize = workGroupSizeX / 2u; currentSize > 1u;\n          currentSize = currentSize / 2u) {\n        if (localId.x < currentSize)\n        {\n          sumValues[localId.x] = sumValues[localId.x] + sumValues[localId.x + currentSize];\n        }\n        workgroupBarrier();\n      }\n\n      if (localId.x == 0u) {\n        sum = sumValues[0] + sumValues[1];\n        mm_write(batch, row, col, sum);\n      }\n    }\n  `;\n}\n\nexport class MatMulReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workGroupSize: [number, number, number] = [256, 1, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  batchAEqualOne: boolean;\n  batchBEqualOne: boolean;\n\n  constructor(\n      outputShape: [number, number, number], batchAEqualOne: boolean,\n      batchBEqualOne: boolean, transposeA = false, transposeB = false,\n      bias: TensorInfo = null, activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [], y: [1, 2], z: [0]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.batchAEqualOne = batchAEqualOne;\n    this.batchBEqualOne = batchBEqualOne;\n    this.shaderKey = `matMulReduce_${this.activation}_${transposeA}_${\n        transposeB}_${this.batchAEqualOne}_${this.batchBEqualOne}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.batchAEqualOne,\n            this.batchBEqualOne, this.transposeA, this.transposeB)}\n      ${makeMatMulReduceSource()}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\n\nexport function makeMatMulSmallOutputSizeSource(\n    workGroupSize: [number, number, number]): string {\n  const tileAOuter = workGroupSize[1];\n  const tileBOuter = workGroupSize[0];\n  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;\n  return `\n  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;\n  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n  // If the output size is small for matrix multiplication, avoid to use vec4\n  // and handle some elements per thread to optimally utilize the ALU.\n  // Read data from global memory to registers firstly, then store them into\n  // shared memory, so it is instruction-Level parallelism for arithmetic\n  // operations and others handle IO operations between barrier api, makes ALU\n  // and load/store units work simultaneously, could improves the performance.\n  ${main()} {\n    let tileRow = i32(localId.y);\n    let tileCol = i32(localId.x);\n    let globalRow = i32(globalId.y);\n    let globalCol = i32(globalId.x);\n    let batch = i32(globalId.z);\n\n    // uniforms.dimInner should be greater than 0.\n    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;\n    var acc = 0.0;\n\n    var globalColA = tileCol;\n    var globalRowB = 0;\n    var regA = mm_readA(batch, globalRow, globalColA);\n    var regB0 = mm_readB(batch, globalRowB + 2 * tileRow, globalCol);\n    var regB1 = mm_readB(batch, globalRowB + 2 * tileRow + 1, globalCol);\n    globalColA = globalColA + ${tileInner};\n    globalRowB = globalRowB + ${tileInner};\n\n    for (var t = 0; t < numTiles; t = t + 1) {\n      mm_Asub[tileRow][tileCol] = regA;\n      mm_Bsub[2 * tileRow][tileCol] = regB0;\n      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;\n\n      workgroupBarrier();\n\n      regA = mm_readA(batch, globalRow, globalColA);\n      regB0 = mm_readB(batch, globalRowB + 2 * tileRow, globalCol);\n      regB1 = mm_readB(batch, globalRowB + 2 * tileRow + 1, globalCol);\n      globalColA = globalColA + ${tileInner};\n      globalRowB = globalRowB + ${tileInner};\n\n      for (var k = 0; k < ${tileInner}; k = k + 1) {\n        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];\n      }\n      workgroupBarrier();\n    }\n\n    mm_write(batch, globalRow, globalCol, acc);\n  }\n  `;\n}\n\nexport class MatMulSmallOutputSizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workGroupSize: [number, number, number] = [16, 8, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  batchAEqualOne: boolean;\n  batchBEqualOne: boolean;\n\n  constructor(\n      aShape: [number, number, number], bShape: [number, number, number],\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    this.dispatch = [\n      Math.ceil(outputShape[2] / this.workGroupSize[0]),\n      Math.ceil(outputShape[1] / this.workGroupSize[1]), outputShape[0]\n    ];\n\n    const addBias = bias != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.batchAEqualOne = aShape[0] === 1;\n    this.batchBEqualOne = bShape[0] === 1;\n    this.shaderKey = `matMulSmallOutputSize_${this.activation}_${transposeA}_${\n        transposeB}_${this.batchAEqualOne}_${this.batchBEqualOne}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.batchAEqualOne,\n            this.batchBEqualOne, this.transposeA, this.transposeB)}\n      ${makeMatMulSmallOutputSizeSource(this.workGroupSize)}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source, matMulReadFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MatMulSplitKProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workGroupSize: [number, number, number] = [8, 8, 1];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  atomic = true;\n  batchAEqualOne: boolean;\n  batchBEqualOne: boolean;\n  isVec4 = false;\n  splitedDimInner = 128;\n\n  constructor(\n      outputShape: [number, number, number], dimInner: number,\n      batchAEqualOne: boolean, batchBEqualOne: boolean, transposeA = false,\n      transposeB = false) {\n    util.assert(\n        outputShape[0] === 1,\n        () => 'MatMulSplitKProgram only supports batch = 1.');\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0, 3]};\n    this.isVec4 = (transposeA && this.outputShape[1] % 4 === 0 ||\n                   !transposeA && dimInner % 4 === 0) &&\n        this.outputShape[2] % 4 === 0;\n    this.elementsPerThread = [4, 4, this.splitedDimInner];\n\n    if (!this.isVec4) {\n      if (this.outputShape[1] < 16) {\n        this.elementsPerThread[1] = 1;\n      }\n      if (this.outputShape[2] < 16) {\n        this.elementsPerThread[0] = 1;\n      }\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout,\n        [\n          this.outputShape[0], this.outputShape[1], this.outputShape[2],\n          dimInner\n        ],\n        this.workGroupSize, this.elementsPerThread);\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.batchAEqualOne = batchAEqualOne;\n    this.batchBEqualOne = batchBEqualOne;\n    this.shaderKey =\n        `matMulSplitK_${transposeA}_${transposeB}_${batchAEqualOne}_${\n            batchBEqualOne}_${this.elementsPerThread}_${this.isVec4}`;\n  }\n\n  getUserCode(): string {\n    // atomicAdd only supports uint/int type. For float, we use\n    // atomicCompareExchangeWeak to simulate.\n    const atomicAddSnippet = (component: number) => {\n      return `\n      for (var i = 0; i < ${component}; i = i + 1)\n      {\n        var oldValue = atomicLoad(&(result[flatIndex + i]));\n        var exchanged = false;\n        for (; !exchanged;) {\n          let newValueF32 = bitcast<f32>(oldValue) + ${\n          component > 1 ? 'value[i]' : 'value'};\n          let newValue = bitcast<i32>(newValueF32);\n          let res = atomicCompareExchangeWeak(&(result[flatIndex + i]), oldValue, newValue);\n          oldValue = res.old_value;\n          exchanged = res.exchanged;\n        }\n      }\n      `;\n    };\n\n    const component = this.isVec4 ? 4 : 1;\n    const userCode = `\n      ${\n        matMulReadFnSource(\n            this.batchAEqualOne, this.batchBEqualOne, false, this.transposeB,\n            false, false, false, component)}\n      fn mm_write(batch: i32, row : i32, colIn : i32, value : ${\n        typeSnippet(component)}) {\n        let col = colIn * ${component};\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n          let coords = vec3<i32>(batch, row, col);\n          let flatIndex = getOutputIndexFromCoords(coords);\n          // The problem is that we should initialize output to zero before using.\n          // Otherwise, the original value will be added to the result.\n          ${atomicAddSnippet(component)}\n        }\n      }\n      ${\n        this.isVec4 ? makeMatMulPackedVec4Source(\n                          this.elementsPerThread, this.workGroupSize,\n                          this.transposeA, 32, true, this.splitedDimInner) :\n                      makeMatMulPackedSource(\n                          this.elementsPerThread, this.workGroupSize,\n                          this.transposeA, 32, true, this.splitedDimInner)}\n    `;\n    return userCode;\n  }\n}\n\nexport class BiasActivationProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  private addBias: boolean;\n  private activation: backend_util.Activation;\n  private hasPreluActivationWeights: boolean;\n\n  constructor(\n      outputShape: number[], bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.addBias = bias != null;\n    this.hasPreluActivationWeights = preluActivationWeights != null;\n    this.activation = activation;\n    if (this.addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (this.hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `biasActivation_${activation}`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        var value = getXByOutputIndex(index);\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        setOutputAtIndex(index, value);\n      }\n    }\n    `;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FillProgram implements WebGPUProgram {\n  variableNames: string[] = [];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'value : f32,';\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = 'fill';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        setOutputAtIndex(index, uniforms.value);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FillProgram} from '../fill_webgpu';\n\nexport function fill(args: {backend: WebGPUBackend, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value} = attrs;\n  let {dtype} = attrs;\n\n  dtype = dtype || util.inferDtype(value);\n\n  if (dtype === 'string') {\n    // String type should be handled in CPU memory.\n    const values = util.getArrayFromDType(dtype, util.sizeFromShape(shape));\n    values.fill(value as string);\n    return backend.makeTensorInfo(shape, dtype, values);\n  } else {\n    const program = new FillProgram(shape);\n    const uniformData = [{type: 'float32', data: [value as number]}];\n    return backend.runWebGPUProgram(program, [], dtype, uniformData);\n  }\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'webgpu',\n  kernelFunc: fill as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function reshape(\n    args: {inputs: ReshapeInputs, backend: WebGPUBackend, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  // Backend needs to track refCount for the dataId for reshape op\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'webgpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcast_util, env, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MatMulPackedProgram} from '../matmul_packed_webgpu';\nimport {MatMulReduceProgram} from '../matmul_reduce_webgpu';\nimport {MatMulSmallOutputSizeProgram} from '../matmul_small_output_size_webgpu';\nimport {BiasActivationProgram, MatMulSplitKProgram} from '../matmul_splitK_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\nimport {MatMulProgramType} from '../webgpu_util';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\ntype BatchMatMulConfig = {\n  a: TensorInfo,\n  b: TensorInfo,\n  transposeA: boolean,\n  transposeB: boolean,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\nexport function batchMatMulImpl({\n  a,\n  b,\n  transposeA,\n  transposeB,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: BatchMatMulConfig): TensorInfo {\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape: [number, number, number] = transposeA ?\n      [batchDimA, innerShapeA, outerShapeA] :\n      [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape: [number, number, number] = transposeB ?\n      [batchDimB, outerShapeB, innerShapeB] :\n      [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n  const intermediates: TensorInfo[] = [a3d, b3d];\n\n  const batchDim = Math.max(batchDimA, batchDimB);\n  const batchAEqualOne = batchDimA === 1;\n  const batchBEqualOne = batchDimB === 1;\n\n  const inputs: TensorInfo[] = [a3d, b3d];\n  const dimensions = [\n    {type: 'int32', data: [outerShapeA]}, {type: 'int32', data: [outerShapeB]},\n    {type: 'int32', data: [innerShapeA]}\n  ];\n\n  let program: WebGPUProgram;\n  let out: TensorInfo;\n  const outputShape: [number, number, number] =\n      [batchDim, outerShapeA, outerShapeB];\n  let matmulProgramType = env().get('WEBGPU_MATMUL_PROGRAM_TYPE') as number;\n  if (matmulProgramType < 0) {\n    if (outerShapeA * outerShapeB <= 128) {\n      matmulProgramType = MatMulProgramType.MatMulReduceProgram;\n    } else if (\n        // These boundaries are based on bodypix-ResNet50-image-0.5.\n        // TODO: Relax or tight these boundaries when we have a complete matmul\n        // test coverage.\n        batchDim === 1 && outerShapeA <= 128 && outerShapeB <= 48 &&\n        innerShapeB >= 2000) {\n      matmulProgramType = MatMulProgramType.MatMulSplitKProgram;\n    } else if (\n        // When the output size is absolutely small or relatively small, we may\n        // use MatMulSmallOutputSizeProgram to get better performance.\n        // Absolutely small size means that the output size is smaller than [16,\n        // 512]. Relatively small size means that one demension size of the\n        // output is smaller than 16, and the output size is also more than or\n        // equal two times smaller than each of the two input sizes. For\n        // example, if input sizes are [12, 2048] and [2048, 1024], the output\n        // size is [12, 1024], which is relatively small compared to input\n        // sizes.\n        (outerShapeA <= 16 &&\n         (outerShapeB <= 512 || innerShapeB >= 2 * outerShapeB)) ||\n        (outerShapeB <= 16 &&\n         (outerShapeA <= 512 || innerShapeA >= 2 * outerShapeA))) {\n      matmulProgramType = MatMulProgramType.MatMulSmallOutputSizeProgram;\n    } else {\n      matmulProgramType = MatMulProgramType.MatMulPackedProgram;\n    }\n  }\n\n  switch (matmulProgramType) {\n    case MatMulProgramType.MatMulReduceProgram:\n      program = new MatMulReduceProgram(\n          outputShape, batchAEqualOne, batchBEqualOne, transposeA, transposeB,\n          bias, activation, preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulSplitKProgram: {\n      // The output buffer must be initailzed to zero before using since we\n      // use atomicAdd in MatMulSplitKProgram.\n      out = fill(\n          {backend, attrs: {shape: outputShape, value: 0, dtype: a.dtype}});\n      program = new MatMulSplitKProgram(\n          outputShape, innerShapeB, batchAEqualOne, batchBEqualOne, transposeA,\n          transposeB);\n      if (bias || activation) {\n        out =\n            backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n        const biasActivationProgram = new BiasActivationProgram(\n            out.shape, bias, activation, preluActivationWeights);\n        let uniformData = null;\n        const activationInputs: TensorInfo[] = [out];\n        if (bias) {\n          activationInputs.push(bias);\n        }\n        if (preluActivationWeights) {\n          activationInputs.push(preluActivationWeights);\n        }\n        if (activation === 'leakyrelu') {\n          uniformData = [{type: 'float32', data: [leakyreluAlpha]}];\n          biasActivationProgram.uniforms += ' alpha : f32,';\n        }\n        const outActivated = backend.runWebGPUProgram(\n            biasActivationProgram, activationInputs, out.dtype, uniformData);\n        intermediates.push(out);\n        const outReshaped = reshape(\n            {inputs: {x: outActivated}, backend, attrs: {shape: outShape}});\n        intermediates.push(outActivated);\n        for (const i of intermediates) {\n          backend.disposeData(i.dataId);\n        }\n        return outReshaped;\n      }\n      break;\n    }\n    case MatMulProgramType.MatMulSmallOutputSizeProgram:\n      program = new MatMulSmallOutputSizeProgram(\n          a3dShape, b3dShape, outputShape, transposeA, transposeB, bias,\n          activation, preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulPackedProgram:\n      // Experiments show that sequential access is more friendly for Intel\n      // GPUs.\n      const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n      program = new MatMulPackedProgram(\n          a3dShape, outputShape, batchAEqualOne, batchBEqualOne, transposeA,\n          transposeB, bias, activation, preluActivationWeights,\n          sequentialAccessByThreads);\n      break;\n    default:\n      throw new Error(`Unsupported MatMulProgramType ${matmulProgramType}.`);\n  }\n\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (preluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  out = backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n  const outReshaped =\n      reshape({inputs: {x: out}, backend, attrs: {shape: outShape}});\n  intermediates.push(out);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return outReshaped;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  return batchMatMulImpl({\n    a,\n    b,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'webgpu',\n  kernelFunc: _fusedMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpComplexProgram implements WebGPUProgram {\n  variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [128, 1, 1];\n  op: BinaryOpType;\n  size = true;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = `binaryOpComplex_${op}`;\n    this.op = op;\n  }\n\n  getUserCode(): string {\n    const opStr = getBinaryOpString(this.op, false);\n    const userCode = `\n      fn binaryOpComplex(\n          areal : f32, aimag : f32, breal : f32, bimag : f32) -> f32 {\n        ${opStr}\n      }\n\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let areal = getARealByOutputIndex(index);\n          let aimag = getAImagByOutputIndex(index);\n          let breal = getBRealByOutputIndex(index);\n          let bimag = getBImagByOutputIndex(index);\n          setOutputAtIndex(index, binaryOpComplex(areal, aimag, breal, bimag));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  isVec4: boolean;\n  op: BinaryOpType;\n  outputShape: number[];\n  shaderKey: string;\n  size = true;\n  variableNames = ['A', 'B'];\n  workGroupSize: [number, number, number];\n  workPerThread: number;\n\n  private lastDimensionSize: number;\n  private useSharedMemoryWithA: boolean;\n  private useSharedMemoryWithB: boolean;\n  private type: string;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.op = op;\n\n    this.useSharedMemoryWithA =\n        aShape.length <= 1 && bShape.length > 1 && aShape[0] < 128;\n    this.useSharedMemoryWithB =\n        bShape.length <= 1 && aShape.length > 1 && bShape[0] < 128;\n\n    if (this.useSharedMemoryWithA || this.useSharedMemoryWithB) {\n      this.isVec4 = false;\n      // lastDimensionSize is used as sharedBuf array size, so can not be\n      // used as uniform.\n      this.lastDimensionSize =\n          this.useSharedMemoryWithB ? bShape[0] : aShape[0];\n      this.shaderKey = `binary_${this.type}_${op}_${this.lastDimensionSize}_${\n          this.useSharedMemoryWithB}`;\n      this.type = 'shared';\n      // This is an experimental value when using shared memory.\n      // Note that the maximum of workgroup X dimension is 256.\n      this.workGroupSize = [256, 1, 1];\n      this.workPerThread = 1;\n    } else {\n      if (util.arraysEqual(aShape, bShape) &&\n          util.sizeFromShape(aShape) % 4 === 0) {\n        this.isVec4 = true;\n        this.type = 'vec4';\n        this.workPerThread = 4;\n      } else {\n        this.isVec4 = false;\n        this.type = 'plain';\n        this.workPerThread = 1;\n      }\n      this.shaderKey = `binary_${this.type}_${op}`;\n      // TODO(jiajia.qin@intel.com): Heuristically select a good work group\n      // size.\n      this.workGroupSize = [128, 1, 1];\n    }\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n  }\n\n  getUserCode(): string {\n    let userCode;\n    const dType = this.isVec4 ? 'vec4<f32>' : 'f32';\n    const opFnStr = `\n    fn binaryOperation(a : ${dType}, b : ${dType}) -> ${dType} {\n      ${getBinaryOpString(this.op, this.isVec4)}\n    };\n    `;\n\n    if (this.type === 'shared') {\n      const sharedIndexSnippet = this.lastDimensionSize > 1 ?\n          `coords[${this.outputShape.length - 1}]` :\n          '0';\n      const accessDataSnippet = this.useSharedMemoryWithB ?\n          `let a = getAByOutputIndex(index);\n          let b = sharedBuf[${sharedIndexSnippet}];` :\n          `let a = sharedBuf[${sharedIndexSnippet}];\n          let b = getBByOutputIndex(index);`;\n      userCode = `\n        ${opFnStr}\n        var<workgroup> sharedBuf : array<f32, ${this.lastDimensionSize}>;\n        ${main('index')} {\n          // Fill in the shared memory buffer.\n          let localIndex = i32(localId.x);\n          if(localIndex < ${this.lastDimensionSize}) {\n            sharedBuf[localIndex] = f32(${\n          this.useSharedMemoryWithB ? 'B' : 'A'}[localIndex]);\n          }\n          workgroupBarrier();\n\n          if(index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            ${accessDataSnippet}\n            setOutputAtIndex(index, binaryOperation(a, b));\n          }\n        }\n        `;\n    } else {\n      userCode = `\n       ${opFnStr}\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let a = getAByOutputIndex(index);\n           let b = getBByOutputIndex(index);\n           setOutputAtIndex(index, binaryOperation(a, b));\n         }\n       }\n       `;\n    }\n\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs} = args;\n  const {x} = inputs;\n\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'webgpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\n/**\n * Complex tensors share data with their real and imaginary components. Complex\n * tensors' reference to the components is tracked by refCount on the individual\n * component. The refCounts are increased by the identity call.\n *\n * When a complex tensor is disposed, it will reduce the refCount on the\n * components by calling disposeData on each.\n */\nexport function complex(args: {inputs: ComplexInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n  const complex = backend.tensorMap.get(complexInfo.dataId);\n\n  const realTensorInfo = identity({inputs: {x: real}, backend});\n\n  const imagTensorInfo = identity({inputs: {x: imag}, backend});\n\n  complex.complexTensorInfos = {real: realTensorInfo, imag: imagTensorInfo};\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'webgpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class UnaryOpProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A'];\n  workGroupSize: [number, number, number];\n  op: UnaryOpType;\n  uniforms?: string;\n  size = true;\n\n  constructor(outputShape: number[], op: UnaryOpType) {\n    // TODO(jiajia.qin@intel.com): Heuristically select a good work group size.\n    const workGroupSizeX = 128;\n    this.workGroupSize = [workGroupSizeX, 1, 1];\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.op = op;\n    this.shaderKey = `unary_${op}`;\n  }\n\n  getUserCode(): string {\n    return `\n      fn unaryOperation(a : f32) -> f32 {\n        ${getUnaryOpString(this.op, false)}\n      }\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let a = getAByOutputIndex(index);\n          setOutputAtIndex(index, unaryOperation(a));\n        }\n      }\n      `;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TensorInfo, TypedArray, UnaryInputs, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BinaryOpComplexProgram} from '../binary_op_complex_webgpu';\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\nimport {complex} from '../kernels/Complex';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nimport {SimpleBinaryKernelImplCPU, SimpleUnaryKernelImplCPU} from './shared';\n\ntype UnaryKernelFuncConfig = {\n  opType: UnaryOpType,\n  cpuKernelImpl?: SimpleUnaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opType Op type to create `UnaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc(\n    {opType, cpuKernelImpl, dtype}: UnaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    const $dtype = dtype || x.dtype;\n    if (webgpuBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webgpuBackend.tensorMap.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values as TypedArray, $dtype);\n      return webgpuBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const program: UnaryOpProgram = new UnaryOpProgram(x.shape, opType);\n    return webgpuBackend.runWebGPUProgram(program, [x], $dtype);\n  };\n}\n\ntype BinaryKernelFuncConfig = {\n  opType: BinaryOpType,\n  cpuKernelImpl?: SimpleBinaryKernelImplCPU,\n  supportsComplex?: boolean,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opType Op type to create `BinaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    {opType, cpuKernelImpl, supportsComplex = false, dtype}:\n        BinaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webgpuBackend.tensorMap.get(a.dataId);\n      const bData = webgpuBackend.tensorMap.get(b.dataId);\n      let real: TensorInfo, imag: TensorInfo;\n      if (opType !== BinaryOpType.MUL) {\n        [real, imag] = [\n          [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n          [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n        ].map(complexParts => {\n          const [aPart, bPart] = complexParts;\n\n          const aHandle = {\n            dataId: aPart.dataId,\n            dtype: aPart.dtype,\n            shape: a.shape\n          };\n          const bHandle = {\n            dataId: bPart.dataId,\n            dtype: bPart.dtype,\n            shape: b.shape\n          };\n\n          const program = new BinaryOpProgram(opType, a.shape, b.shape);\n          return webgpuBackend.runWebGPUProgram(\n              program, [aHandle, bHandle],\n              upcastType(aPart.dtype, bPart.dtype));\n        });\n      } else {\n        const realProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_REAL, a.shape, b.shape);\n        const imagProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_IMAG, a.shape, b.shape);\n\n        const inputs = [\n          {\n            dataId: aData.complexTensorInfos.real.dataId,\n            dtype: aData.complexTensorInfos.real.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: aData.complexTensorInfos.imag.dataId,\n            dtype: aData.complexTensorInfos.imag.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.real.dataId,\n            dtype: bData.complexTensorInfos.real.dtype,\n            shape: b.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.imag.dataId,\n            dtype: bData.complexTensorInfos.imag.dtype,\n            shape: b.shape\n          }\n        ];\n\n        real = webgpuBackend.runWebGPUProgram(realProgram, inputs, 'float32');\n        imag = webgpuBackend.runWebGPUProgram(imagProgram, inputs, 'float32');\n      }\n\n      const complexOutput =\n          complex({inputs: {real, imag}, backend: webgpuBackend});\n\n      webgpuBackend.disposeData(real.dataId);\n      webgpuBackend.disposeData(imag.dataId);\n\n      // TODO: Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' ||\n         webgpuBackend.shouldExecuteOnCPU([a, b])) &&\n        cpuKernelImpl != null) {\n      const aData = webgpuBackend.tensorMap.get(a.dataId).values as TypedArray;\n      const bData = webgpuBackend.tensorMap.get(b.dataId).values as TypedArray;\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aData as any as Uint8Array[]) :\n          aData;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bData as any as Uint8Array[]) :\n          bData;\n      const [outValues, outShape] =\n          cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      return webgpuBackend.makeTensorInfo(outShape, $dtype, outValues);\n    }\n    const program = new BinaryOpProgram(opType, a.shape, b.shape);\n    return webgpuBackend.runWebGPUProgram(program, [a, b], $dtype);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n\n  assertNotComplex(x, 'abs');\n\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n  resultValues = simpleAbsImpl(values);\n\n  return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataValues, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: DataValues,\n          bVals: DataValues, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, DataType, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function castImpl(\n    values: TypedArray, shape: number[], inputType: DataType,\n    dtype: DataType): [number[], DataType, TypedArray] {\n  if (dtype === 'int32') {\n    const resultValues = Int32Array.from(values);\n    return [shape, 'int32', resultValues];\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const zero = util.toTypedArray([0], inputType);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(shape, [], values, zero, 'bool');\n\n    return [resultShape, 'bool', resultData];\n  }\n  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);\n}\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const [resultShape, resultType, resultData] =\n      castImpl(values, x.shape, x.dtype, dtype);\n  return backend.makeTensorInfo(resultShape, resultType, resultData);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const addImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function bincountImpl(\n    xVals: TypedArray, weightsVals: TypedArray, weightsDtype: DataType,\n    weightsShape: number[], size: number): TypedArray {\n  const weightsSize = util.sizeFromShape(weightsShape);\n  const outVals = util.makeZerosTypedArray(size, weightsDtype) as TypedArray;\n\n  for (let i = 0; i < xVals.length; i++) {\n    const value = xVals[i];\n    if (value < 0) {\n      throw new Error('Input x must be non-negative!');\n    }\n\n    if (value >= size) {\n      continue;\n    }\n\n    if (weightsSize > 0) {\n      outVals[value] += weightsVals[i];\n    } else {\n      outVals[value] += 1;\n    }\n  }\n\n  return outVals;\n}\n\nexport function bincountReduceImpl<R extends Rank>(\n    xBuf: TensorBuffer<R>, weightsBuf: TensorBuffer<R>, size: number,\n    binaryOutput = false): TensorBuffer<R> {\n  const numRows = xBuf.shape[0];\n  const numCols = xBuf.shape[1];\n\n  const outBuf = buffer([numRows, size], weightsBuf.dtype);\n\n  for (let i = 0; i < numRows; i++) {\n    for (let j = 0; j < numCols; j++) {\n      const value = xBuf.get(i, j);\n      if (value < 0) {\n        throw new Error('Input x must be non-negative!');\n      }\n\n      if (value >= size) {\n        continue;\n      }\n\n      if (binaryOutput) {\n        outBuf.set(1, i, value);\n      } else {\n        if (weightsBuf.size > 0) {\n          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n        } else {\n          outBuf.set(outBuf.get(i, value) + 1, i, value);\n        }\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const equalImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a === b) ? 1 : 0);\nexport const equal =\n    binaryKernelFunc(Equal, equalImpl, null /* complexImpl */, 'bool');\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'cpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl, 'float32');\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function gatherNdImpl<R extends Rank>(\n    indicesData: TypedArray, paramsBuf: TensorBuffer<R>, dtype: DataType,\n    numSlices: number, sliceRank: number, sliceSize: number, strides: number[],\n    paramsShape: number[], paramsSize: number): TensorBuffer<R> {\n  const outBuf = buffer([numSlices, sliceSize], dtype);\n\n  for (let i = 0; i < numSlices; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      flattenIndex += dim * strides[j];\n      index.push(dim);\n    }\n    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n      throw new Error(\n          `Invalid indices: ${index} does not index into ${paramsShape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      outBuf.values[i * sliceSize + k] =\n          paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function gatherV2Impl<R extends Rank, D extends DataType>(\n    xBuf: TensorBuffer<R, D>, indicesBuf: TensorBuffer<R, D>,\n    flattenOutputShape: number[]): TensorBuffer<R, D> {\n  const outBuf = buffer(flattenOutputShape, xBuf.dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const newLoc = outBuf.indexToLoc(i);\n\n    const originalLoc: number[] = newLoc.slice();\n    const batchIdx = originalLoc[0];\n    const indicesIdx = originalLoc[2];\n    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n    originalLoc[2] = indicesBuf.values[indicesIndex] as number;\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    if (0 <= originalIndex && originalIndex < xBuf.values.length) {\n      outBuf.values[i] = xBuf.values[originalIndex];\n    } // Else, index is out of bounds, so leave the default zero val in outBuf.\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a > b) ? 1 : 0);\nexport const greater =\n    binaryKernelFunc(Greater, greaterImpl, null /* complexImpl */, 'bool');\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'cpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a >= b) ? 1 : 0);\nexport const greaterEqual = binaryKernelFunc(\n    GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'cpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a < b) ? 1 : 0);\nexport const less =\n    binaryKernelFunc(Less, lessImpl, null /* complexImpl */, 'bool');\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'cpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a <= b) ? 1 : 0);\nexport const lessEqual =\n    binaryKernelFunc(LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'cpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function linSpaceImpl(\n    start: number, stop: number, num: number): TypedArray {\n  const step = (stop - start) / (num - 1);\n\n  const values = util.makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value > max) {  // comparison with NaN always return false\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const maximumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.max(aValue as number, bValue as number)));\nexport const maximum = binaryKernelFunc(Maximum, maximumImpl);\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'cpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const minimumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.min(aValue as number, bValue as number)));\nexport const minimum = binaryKernelFunc(Minimum, minimumImpl);\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'cpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const multiplyImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, Neg, TensorInfo, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {multiplyImpl} from './Multiply';\n\nexport function negImpl(xVals: TypedArray, xShape: number[], xDtype: DataType):\n    [TypedArray, number[]] {\n  const minusOne =\n      util.createScalarValue(-1 as {} as 'float32', xDtype) as TypedArray;\n  return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\n\nexport function neg(args: {inputs: UnaryInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  assertNotComplex(x, 'neg');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);\n\n  return backend.makeTensorInfo(newShape, x.dtype, res);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'cpu',\n  kernelFunc: neg as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function prodImpl(\n    xShape: number[], xDtype: DataType, xVals: TypedArray,\n    reductionAxes: number[]):\n    {outVals: TypedArray, outShape: number[], outDtype: DataType} {\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, reductionAxes);\n  const outDtype = upcastType(xDtype, 'int32');\n  const outVals = util.makeZerosTypedArray(\n                      util.sizeFromShape(outShape), outDtype) as TypedArray;\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  for (let i = 0; i < outVals.length; ++i) {\n    const offset = i * reduceSize;\n    let prod = 1;\n    for (let j = 0; j < reduceSize; ++j) {\n      prod *= xVals[offset + j];\n    }\n    outVals[i] = prod;\n  }\n\n  return {outVals, outShape, outDtype};\n}\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: MathBackendCPU, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'prod');\n\n  const xRank = x.shape.length;\n  const axes = util.parseAxisParam(axis, x.shape);\n\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n  let reductionAxes = axes;\n  let permutedX = x;\n  const intermediateTensorInfos = [];\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    intermediateTensorInfos.push(permutedX);\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  const xVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  const {outVals, outShape, outDtype} =\n      prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);\n\n  let resultShape = outShape;\n  if (keepDims) {\n    resultShape = backend_util.expandShapeToKeepDim(outShape, axes);\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'cpu',\n  kernelFunc: prod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction validateIndices(\n    indices: TypedArray, indicesShape: number[], numParams: number) {\n  indices.forEach((index: number, i: number) => {\n    if (index < 0 || index >= numParams) {\n      const locString =\n          util.indexToLoc(\n                  i, indicesShape.length, util.computeStrides(indicesShape))\n              .join(',');\n      throw new Error(\n          `indices[${locString}] = ${index} is not in [0, ${numParams})`);\n    }\n  });\n}\n\nfunction validateSplits(\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  // Validate\n  for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n    const splits = paramsNestedSplits[dim];\n    const lastSplit = (dim === paramsNestedSplits.length - 1) ?\n        numParamsDenseValues :\n        paramsNestedSplits[dim + 1].length;\n    if (splits.length === 0) {\n      throw new Error('Ragged splits may not be empty');\n    }\n    if (splits[0] < 0) {\n      throw new Error('Ragged splits must be non-negative');\n    }\n    if (splits[splits.length - 1] > lastSplit) {\n      throw new Error('Ragged splits must not point past values');\n    }\n    for (let i = 1; i < splits.length; ++i) {\n      if (splits[i - 1] > splits[i]) {\n        throw new Error('Ragged splits must be sorted in ascending order');\n      }\n    }\n  }\n}\n\n// Construct the `splits` output tensors, encoded using a nested vector.\n// Also find the slices of values that need to be copied, and store them\n// in `valueSlices`.  The total number of values that will be copied (which\n// we need for allocating the output values tensor) is stored in `numValues`.\nfunction makeSplits(\n    indices: TypedArray, indicesShape: number[],\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  const valueSlices: Array<[number, number]> = [];\n  let numValues = 0;\n\n  const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;\n  const outSplits = new Array(numSplits).fill(null).map(() => [0]);\n\n  validateSplits(paramsNestedSplits, numParamsDenseValues);\n\n  // Add `splits` that come from all but the last dimension of the dense\n  // Tensor `indices`.  In particular, for each dimension D, we add a\n  // splits tensor whose values are:\n  //   range(reduceProd(splits.shape[:D]) + 1) * splits.shape[D+1]\n  // E.g., if indices.shape=[2, 3, 4] then we will add splits tensors:\n  //   [0, 3, 6]                    # length=2+1, stride=3\n  //   [0, 4, 8, 12, 16, 20, 24]    # length=2*3+1, stride=4\n  let nrows = 1;\n  for (let dim = 0; dim < indicesShape.length - 1; ++dim) {\n    nrows *= indicesShape[dim];\n    const rowLength = indicesShape[dim + 1];\n    for (let i = 1; i < nrows + 1; ++i) {\n      outSplits[dim].push(i * rowLength);\n    }\n  }\n\n  // Add `splits` that come from `paramsNestedSplits`.  Starting with the\n  // outermost ragged dimension (i.e., the first `splits` tensor), we work\n  // our way in, finding the range of values that should be copied.  As we\n  // go, we update the output `splits` for each dimension with the appropriate\n  // values.  In particular, the *lengths* of the slices from `param_splits`\n  // should be copied to generate corresponding slice lengths in the output\n  // splits.  E.g., if we are copying a ragged row with length 4, then we\n  // should add a new split point to outSplits that is 4 greater than the\n  // previous split point in outSplits.\n  for (let i = 0; i < indices.length; ++i) {\n    let start = indices[i];\n    let limit = indices[i] + 1;\n\n    // Copy splits.\n    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n      const splits = paramsNestedSplits[dim];\n      const outDim = dim + indicesShape.length - 1;\n      if (outDim >= 0) {\n        const outSplitsOutDim = outSplits[outDim];\n        const delta =\n            outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];\n        for (let j = start; j < limit; ++j) {\n          outSplits[outDim].push(splits[j + 1] + delta);\n        }\n      }\n      start = splits[start];\n      limit = splits[limit];\n    }\n    if (limit !== start) {\n      valueSlices.push([start, limit]);\n      numValues += limit - start;\n    }\n  }\n\n  return {outSplits, valueSlices, numValues};\n}\n\nfunction getSplits(outSplits: number[][]) {\n  const splitsOut: TypedArray[] = [];\n  for (let i = 0; i < outSplits.length; ++i) {\n    const numSplits = outSplits[i].length;\n    const splits = util.getArrayFromDType('int32', numSplits) as TypedArray;\n    splitsOut.push(splits);\n\n    outSplits[i].forEach((value, j: number) => splits[j] = value);\n  }\n\n  return splitsOut;\n}\n\nfunction computeFlatOuterDims(orig: number[], numOutDims: number) {\n  const outDims = orig.slice(0, numOutDims);\n  while (outDims.length < numOutDims) {\n    outDims.push(1);\n  }\n\n  for (let inDim = numOutDims; inDim < orig.length; inDim++) {\n    outDims[numOutDims - 1] *= orig[inDim];\n  }\n\n  return outDims;\n}\n// For each slice in `(start, limit)` in `valueSlices`, append\n// `paramsDenseValues[start,...,limit] to `values`.  `valueSize` indicates\n// the number of scalars contained in each value paramsDenseValues[i].\nfunction writeValueSlices(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    valueSlices: Array<[number, number]>, valueSize: number, values: TypedArray,\n    valuesShape: number[]) {\n  const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];\n  const valuesM = computeFlatOuterDims(valuesShape, 2)[1];\n\n  let outPos = 0;\n  for (const slice of valueSlices) {\n    for (let i = slice[0]; i < slice[1]; ++i) {\n      for (let j = 0; j < valueSize; ++j) {\n        values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];\n      }\n      ++outPos;\n    }\n  }\n}\n\nfunction getValues(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, valueSlices: Array<[number, number]>,\n    numValues: number): [TypedArray, number[]] {\n  const valuesShape = paramsDenseValuesShape.slice();\n  valuesShape[0] = numValues;\n\n  const valuesOut = util.getArrayFromDType(\n                        paramsDenseValuesDType,\n                        util.sizeFromShape(valuesShape)) as TypedArray;\n\n  const numElements = paramsDenseValues.length;\n  const valueSize =\n      numElements === 0 ? 0 : (numElements / paramsDenseValuesShape[0]);\n  writeValueSlices(\n      paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize,\n      valuesOut, valuesShape);\n\n  return [valuesOut, valuesShape];\n}\nexport function raggedGatherImpl(\n    paramsNestedSplits: TypedArray[], paramsNestedSplitsShapes: number[][],\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, indices: TypedArray,\n    indicesShape: number[],\n    outputRaggedRank: number): [TypedArray[], TypedArray, number[]] {\n  if (paramsNestedSplits.length === 0) {\n    throw new Error('paramsNestedSplits must be non empty');\n  }\n\n  if (paramsNestedSplitsShapes[0].length === 0) {\n    throw new Error('Split tensors must not be scalars');\n  }\n  const numParams = paramsNestedSplitsShapes[0][0] - 1;\n  validateIndices(indices, indicesShape, numParams);\n\n  if (paramsDenseValuesShape.length === 0) {\n    throw new Error('params.rank must be nonzero');\n  }\n  const numParamsDenseValues = paramsDenseValuesShape[0];\n\n  // Calculate the `splits`, and store the value slices that we need to\n  // copy in `valueSlices`.\n  const {outSplits, valueSlices, numValues} = makeSplits(\n      indices, indicesShape, paramsNestedSplits, numParamsDenseValues);\n\n  // Write the output tensors.\n  const outputNestedSplits = getSplits(outSplits);\n  const outputDenseValues = getValues(\n      paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType,\n      valueSlices, numValues);\n\n  return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcastTo, DataType, reshape, tidy, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport RowPartitionType = backend_util.RowPartitionType;\n// Based on\n// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc\nclass RaggedTensorToTensorOp {\n  private readonly rowPartitionTypes: RowPartitionType[];\n  private readonly raggedRank: number;\n  constructor(\n      private shape: TypedArray, private shapeShape: number[],\n      private values: TypedArray, private valuesShape: number[],\n      private valuesDType: DataType, private defaultValue: TypedArray,\n      private defaultValueShape: number[],\n      private readonly rowPartitionValues: TypedArray[],\n      private readonly rowPartitionValuesShapes: number[][],\n      rowPartitionTypeStrings: string[]) {\n    this.rowPartitionTypes =\n        backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);\n    this.raggedRank = backend_util.getRaggedRank(this.rowPartitionTypes);\n  }\n\n  private getRowPartitionTypeByDimension(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionTypes[dimension + 1];\n    } else {\n      return this.rowPartitionTypes[dimension];\n    }\n  }\n\n  // Returns the relationship between dimension and dimension + 1.\n  private getRowPartitionTensor(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionValues[dimension + 1];\n    } else {\n      return this.rowPartitionValues[dimension];\n    }\n  }\n\n  private getMaxWidth(dimension: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);\n    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);\n      case RowPartitionType.ROW_SPLITS:\n        return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);\n      default:\n        throw new Error(`Cannot handle partition type ${\n            RowPartitionType[this.getRowPartitionTypeByDimension(\n                dimension - 1)]}`);\n    }\n  }\n\n  static getMaxWidthRowSplit(rowSplit: TypedArray) {\n    const tensorLength = rowSplit.length;\n    if (tensorLength === 0 || tensorLength === 1) {\n      return 0;\n    }\n    let maxWidth = 0;\n    for (let i = 0; i < tensorLength - 1; ++i) {\n      const currentWidth = rowSplit[i + 1] - rowSplit[i];\n      if (currentWidth > maxWidth) {\n        maxWidth = currentWidth;\n      }\n    }\n    return maxWidth;\n  }\n\n  static getMaxWidthValueRowID(valueRowIds: TypedArray) {\n    const indexLength = valueRowIds.length;\n    if (indexLength === 0) {\n      return 0;\n    }\n    let firstEqualIndex = 0;\n    let firstEqualIndexValue = valueRowIds[0];\n    let maxWidth = 0;\n    for (let i = 1; i < indexLength; ++i) {\n      const value = valueRowIds[i];\n      if (value !== firstEqualIndexValue) {\n        firstEqualIndexValue = value;\n        maxWidth = Math.max(i - firstEqualIndex, maxWidth);\n        firstEqualIndex = i;\n      }\n    }\n    return Math.max(indexLength - firstEqualIndex, maxWidth);\n  }\n\n  private tensorShapeFromTensor(\n      t: TypedArray, tShape: number[], isPartial = true) {\n    if (tShape.length === 0) {\n      if (t[0] === -1) {\n        return [];\n      }\n      throw new Error(\n          `The only valid scalar shape tensor is the fully unknown shape specified as -1.`);\n    }\n    // MakePartialShape/MakeShapeHelper.\n    return makeShape(t, isPartial);\n  }\n\n  private calculateOutputSize(firstDim: number) {\n    const valueShape = this.valuesShape;\n    const defaultValueShape = this.defaultValueShape;\n\n    backend_util.validateDefaultValueShape(defaultValueShape, valueShape);\n\n    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);\n    const outputShape = backend_util.combineRaggedTensorToTensorShapes(\n        this.raggedRank, shape, valueShape);\n\n    const result = outputShape;\n\n    if (result[0] < 0) {\n      result[0] = firstDim;\n    }\n    for (let i = 1; i <= this.raggedRank; ++i) {\n      if (result[i] < 0) {\n        result[i] = this.getMaxWidth(i);\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * The outputIndex represents the index in the output tensor\n   * where the first element of a particular dimension would be written.\n   * If it is -1, it indicates that the index is out of scope.\n   * Example, given firstDimension = 10, firstDimensionOutput = 6,\n   * and outputIndexMultiplier = 100:\n   * result = [0 100 200 300 400 500 -1 -1 -1 -1]\n   * If firstDimensionOutput = 11 instead, then:\n   * result = [0 100 200 300 400 500 600 700 800 900]\n   */\n  private calculateFirstParentOutputIndex(\n      firstDimension: number, outputIndexMultiplier: number,\n      firstDimensionOutput: number) {\n    const minDimension = Math.min(firstDimension, firstDimensionOutput);\n    const result: number[] = [];\n    let currentOutputIndex = 0;\n    for (let i = 0; i < minDimension;\n         ++i, currentOutputIndex += outputIndexMultiplier) {\n      result.push(currentOutputIndex);\n    }\n    for (let i = minDimension; i < firstDimension; ++i) {\n      result.push(-1);\n    }\n    util.assert(\n        result.length === firstDimension,\n        () => 'Final length of result must be equal to firstDimension.');\n\n    return result;\n  }\n\n  private calculateOutputIndexRowSplit(\n      rowSplit: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowSplitSize = rowSplit.length;\n    const result: number[] = [];\n    for (let i = 0; i < rowSplitSize - 1; ++i) {\n      const rowLength = rowSplit[i + 1] - rowSplit[i];\n      let realLength = Math.min(outputSize, rowLength);\n      let parentOutputIndexCurrent = parentOutputIndex[i];\n\n      if (parentOutputIndexCurrent === -1) {\n        realLength = 0;\n      }\n      for (let j = 0; j < realLength; ++j) {\n        result.push(parentOutputIndexCurrent);\n        parentOutputIndexCurrent += outputIndexMultiplier;\n      }\n      for (let j = 0; j < rowLength - realLength; ++j) {\n        result.push(-1);\n      }\n    }\n    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {\n      throw new Error('Invalid row split size.');\n    }\n\n    return result;\n  }\n\n  // Calculate the output index of the first element of a list.\n  // The parentOutputIndex is the same computation for the previous list.\n  // -1 indicates an element or list that is out of range.\n  // The outputIndexMultiplier is the number of output indices one moves\n  // forward for each column.\n  // E.g., given:\n  // valueRowIds:[0 1 2 2 2 3 5 5 6]\n  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]\n  // outputIndexMultiplier: 10\n  // outputSize: 2\n  // You get:\n  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]\n  // result[0] = parentOutputIndex[valueRowIds[0]]\n  // result[1] = parentOutputIndex[valueRowIds[1]]\n  // result[2] = parentOutputIndex[valueRowIds[2]]\n  // result[3] = parentOutputIndex[valueRowIds[2] + 10]\n  // result[4] = -1 because it is the third element the size is 2.\n  // result[5] = parentOutputIndex[valueRowIds[3]]\n  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[8] = parentOutputIndex[valueRowIds[7]]\n  private calculateOutputIndexValueRowID(\n      valueRowIds: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const indexSize = valueRowIds.length;\n    const result: number[] = [];\n    if (indexSize === 0) {\n      return [];\n    }\n\n    let currentOutputColumn = 0;\n    let currentValueRowId = valueRowIds[0];\n\n    if (currentValueRowId >= parentOutputIndex.length) {\n      throw new Error(\n          `Got currentValueRowId=${currentValueRowId}, which is not less than ${\n              parentOutputIndex.length}`);\n    }\n\n    let currentOutputIndex = parentOutputIndex[currentValueRowId];\n    result.push(currentOutputIndex);\n    for (let i = 1; i < indexSize; ++i) {\n      const nextValueRowId = valueRowIds[i];\n      if (nextValueRowId === currentValueRowId) {\n        if (currentOutputIndex >= 0) {\n          ++currentOutputColumn;\n          if (currentOutputColumn < outputSize) {\n            currentOutputIndex += outputIndexMultiplier;\n          } else {\n            currentOutputIndex = -1;\n          }\n        }\n      } else {\n        currentOutputColumn = 0;\n        currentValueRowId = nextValueRowId;\n\n        if (nextValueRowId >= parentOutputIndex.length) {\n          throw new Error(\n              `Got nextValueRowId=${nextValueRowId} which is not less than ${\n                  parentOutputIndex.length}`);\n        }\n\n        currentOutputIndex = parentOutputIndex[nextValueRowId];\n      }\n      result.push(currentOutputIndex);\n    }\n\n    if (result.length !== valueRowIds.length) {\n      throw new Error('Invalid row ids.');\n    }\n\n    return result;\n  }\n\n  private calculateOutputIndex(\n      dimension: number, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension);\n    const partitionType = this.getRowPartitionTypeByDimension(dimension);\n    switch (partitionType) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return this.calculateOutputIndexValueRowID(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      case RowPartitionType.ROW_SPLITS:\n        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {\n          throw new Error(`Row partition size is greater than output size: ${\n              rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);\n        }\n        return this.calculateOutputIndexRowSplit(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      default:\n        throw new Error(\n            `Unsupported partition type: ${RowPartitionType[partitionType]}`);\n    }\n  }\n\n  private getFirstDimensionSize() {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (this.rowPartitionTypes.length === 0) {\n      throw new Error('No row_partition_types given.');\n    }\n    const firstPartitionType = this.rowPartitionTypes[0];\n    switch (firstPartitionType) {\n      case RowPartitionType.FIRST_DIM_SIZE:\n        return firstPartitionTensor[0];\n      case RowPartitionType.VALUE_ROWIDS:\n        throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');\n      case RowPartitionType.ROW_SPLITS:\n        return this.rowPartitionValuesShapes[0][0] - 1;\n      default:\n        throw new Error(\n            `Cannot handle type ${RowPartitionType[firstPartitionType]}`);\n    }\n  }\n\n  compute(): [number[], TypedArray] {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (firstPartitionTensor.length <= 0) {\n      throw new Error(\n          'Invalid first partition input. ' +\n          'Tensor requires at least one element.');\n    }\n    const firstDimension = this.getFirstDimensionSize();\n    const outputSize = this.calculateOutputSize(firstDimension);\n    const multiplier: number[] = new Array(this.raggedRank + 1);\n\n    multiplier[multiplier.length - 1] = 1;\n    for (let i = multiplier.length - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];\n    }\n    // Full size of the tensor.\n    const outputShape: number[] = makeShape(outputSize, false);\n    const outputTensor =\n        util.getArrayFromDType(\n            this.valuesDType, util.sizeFromShape(outputShape)) as TypedArray;\n\n    const fullSize = multiplier[0] * outputSize[0];\n    if (fullSize > 0) {\n      let outputIndex = this.calculateFirstParentOutputIndex(\n          firstDimension, multiplier[0], outputSize[0]);\n      for (let i = 1; i <= this.raggedRank; ++i) {\n        const newOutputIndex = this.calculateOutputIndex(\n            i - 1, outputIndex, multiplier[i], outputSize[i]);\n        outputIndex = newOutputIndex;\n      }\n\n      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);\n    }\n\n    return [outputShape, outputTensor];\n  }\n  setOutput(\n      raggedRank: number, outputIndex: number[], outputTensor: TypedArray,\n      outputShape: number[]) {\n    if (outputTensor.length === 0) {\n      return;\n    }\n\n    const valuesBase = this.values;\n    const outputBase = outputTensor;\n\n    let elementShape = outputShape.slice();\n    elementShape = elementShape.slice(raggedRank + 1);\n    const valueElementSize = util.sizeFromShape(elementShape);\n    const outputIndexSize = outputIndex.length;\n\n    // Broadcast the default value to value_element_size.  (We can skip this\n    // if defaultValueTensor.size == 1, since we use fill when that's true.)\n    let defaultValue = this.defaultValue;\n    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {\n      const srcShape = this.defaultValueShape;\n      tidy(() => {\n        const defaultValueTensor = reshape(defaultValue, srcShape);\n        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);\n        defaultValue = bCastDefault.dataSync();\n      });\n    }\n\n    // Loop through the outputIndex array, finding contiguous regions that\n    // should be copied.  Once we find the end of a contiguous region, copy it\n    // and add any necessary padding (with defaultValue).\n    let srcStart = 0;  // Start of contiguous region (in values)\n    let dstStart = 0;  // Destination for contiguous region (in output)\n    let dstEnd = 0;    // Destination for contiguous region (in output)\n    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {\n      // dstI is the destination where the value at srcI should be copied.\n      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;\n\n      // If we're still in a contiguous region, then update dstEnd go to the\n      // next srcI.\n      if (dstI === dstEnd) {\n        ++dstEnd;\n        continue;\n      }\n\n      // We found the end of contiguous region.  This can be because we found\n      // a gap (dstI > dstEnd), or a source value that shouldn't be copied\n      // because it's out-of-bounds (dstI == -1), or the end of the tensor\n      // (dstI === -1).\n      if (dstStart < dstEnd) {\n        // Copy the contiguous region.\n        const src = valuesBase.subarray(srcStart * valueElementSize);\n        const dst = outputBase.subarray(dstStart * valueElementSize);\n        const nVals = (dstEnd - dstStart) * valueElementSize;\n        copyArray(dst, src, nVals);\n      }\n\n      // Add any necessary padding (w/ defaultValue).\n      if (srcI >= outputIndexSize) {\n        // We reached the end of values: pad to the end of output.\n        const outputSize = outputTensor.length;\n        dstI = Math.floor(outputSize / valueElementSize);\n      }\n      if (dstI > dstEnd) {\n        if (this.defaultValue.length === 1) {\n          outputBase\n              .subarray(dstEnd * valueElementSize, dstI * valueElementSize)\n              .fill(this.defaultValue[0]);\n          dstEnd = dstI;\n        } else {\n          while (dstI > dstEnd) {\n            const dst = outputBase.slice(dstEnd * valueElementSize);\n            copyArray(dst, defaultValue, valueElementSize);\n            ++dstEnd;\n          }\n        }\n      }\n\n      // Update indices.\n      if (dstI < 0) {\n        // srcI should be skipped -- leave it out of the contiguous region.\n        srcStart = srcI + 1;\n        dstStart = dstEnd;\n      } else {\n        // srcI should be copied -- include it in the contiguous region.\n        srcStart = srcI;\n        dstStart = dstEnd;\n        dstEnd = dstStart + 1;\n      }\n    }\n  }\n}\n\nfunction copyArray(dst: TypedArray, src: TypedArray, size: number) {\n  for (let i = 0; i < size; i++) {\n    dst[i] = src[i];\n  }\n}\n\nfunction makeShape(shape: number[]|TypedArray, isPartial: boolean) {\n  const out: number[] = [];\n  for (let dim of shape) {\n    if (dim < 0) {\n      if (!isPartial) {\n        throw new Error(`Dimension ${dim} must be >= 0`);\n      }\n      if (dim < -1) {\n        throw new Error(`Dimension ${dim} must be >= -1`);\n      }\n      dim = -1;\n    }\n    out.push(dim);\n  }\n\n  return out;\n}\n\nexport function raggedTensorToTensorImpl(\n    shape: TypedArray, shapesShape: number[], values: TypedArray,\n    valuesShape: number[], valuesDType: DataType, defaultValue: TypedArray,\n    defaultValueShape: number[], rowPartitionValues: TypedArray[],\n    rowPartitionValuesShapes: number[][],\n    rowPartitionTypes: string[]): [number[], TypedArray] {\n  return new RaggedTensorToTensorOp(\n             shape, shapesShape, values, valuesShape, valuesDType, defaultValue,\n             defaultValueShape, rowPartitionValues, rowPartitionValuesShapes,\n             rowPartitionTypes)\n      .compute();\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {buffer, Rank, ShapeMap, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\ninterface DefaultValueTypeMap {\n  bool: boolean;\n  int32: number;\n  float32: number;\n  string: string;\n}\n\nexport function\nscatterImpl<R extends Rank, D extends 'float32'|'int32'|'bool'|'string'>(\n    indices: TensorBuffer<R, 'int32'>, updates: TensorBuffer<R, D>,\n    shape: number[], outputSize: number, sliceSize: number, numUpdates: number,\n    sliceRank: number, strides: number[], defaultValue: DefaultValueTypeMap[D],\n    sumDupeIndices: boolean): TensorBuffer<R, D> {\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const indicesData = indices.values as TypedArray;\n  const updatesData = updates.values;\n\n  if (outputSize === 0) {\n    return buffer(shape as ShapeMap[R], updates.dtype);\n  }\n\n  const outBuf = buffer(flattenShape, updates.dtype);\n  if (typeof defaultValue === 'string') {\n    (outBuf.values as string[]).fill(defaultValue);\n  } else if (typeof defaultValue === 'number') {\n    (outBuf.values as TypedArray).fill(defaultValue);\n  } else if (typeof defaultValue === 'boolean') {\n    (outBuf.values as TypedArray).fill(+defaultValue);\n  }\n\n  for (let i = 0; i < numUpdates; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      index.push(dim);\n      flattenIndex += dim * strides[j];\n    }\n\n    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      if (sumDupeIndices) {\n        (outBuf.values as TypedArray)[flattenIndex * sliceSize + k] +=\n            (updatesData as TypedArray)[i * sliceSize + k];\n      } else {\n        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n            updatesData[0] :\n            updatesData[i * sliceSize + k];\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidImpl =\n    createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseFillEmptyRowsImpl(\n    indices: TypedArray, indicesShape: number[], indicesDType: DataType,\n    values: TypedArray, valuesDType: DataType, denseShape: TypedArray,\n    defaultValue: number):\n    [TypedArray, number[], TypedArray, boolean[], number[]] {\n  const indicesCount = indicesShape[0];\n  const denseRows = denseShape[0];\n\n  const emptyRowIndicator: boolean[] = new Array(denseRows);\n  const reverseIndexMap: number[] = new Array(indicesCount);\n\n  const rank = indicesShape[1];\n\n  if (denseRows === 0) {\n    if (indicesCount !== 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n              indicesCount));\n    }\n    const outputIndices = util.getArrayFromDType(indicesDType, 0) as TypedArray;\n    const outputValues = util.getArrayFromDType(valuesDType, 0) as TypedArray;\n    return [\n      outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n    ];\n  }\n\n  let rowsAreOrdered = true;\n  let lastIndicesRow = 0;\n  const csrOffset: number[] = new Array(denseRows).fill(0);\n\n  for (let i = 0; i < indicesCount; ++i) {\n    // indices is a 2d tensor with shape of [N, rank]\n    const row = indices[i * rank];\n    if (row < 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));\n    }\n    if (row >= denseRows) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n              i, row, denseRows));\n    }\n    ++csrOffset[row];\n    rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n    lastIndicesRow = row;\n  }\n\n  let allRowsFull = true;\n  for (let row = 0; row < denseRows; ++row) {\n    // csrOffset here describes the number of elements in this dense row\n    const rowEmpty = (csrOffset[row] === 0);\n    emptyRowIndicator[row] = rowEmpty;\n    allRowsFull = allRowsFull && !rowEmpty;\n    // In filled version, each row has at least one element.\n    csrOffset[row] = Math.max(csrOffset[row], 1);\n    // Update csrOffset to represent the number of elements up to and\n    // including denseRows + 1:\n    //  csrOffset[0] == #{elements of row 0}\n    //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n    //  ..\n    //  csrOffset[i] == starting index for elements in row i + 1.\n    if (row > 0) {\n      csrOffset[row] += csrOffset[row - 1];\n    }\n  }\n\n  if (allRowsFull && rowsAreOrdered) {\n    const outputIndices: TypedArray = indices;\n    const outputValues: TypedArray = values;\n    for (let i = 0; i < indicesCount; ++i) {\n      reverseIndexMap[i] = i;\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  } else {\n    const fullIndicesCount = csrOffset[denseRows - 1];\n    const outputIndices =\n        util.getArrayFromDType(indicesDType, fullIndicesCount * rank) as\n        TypedArray;\n    const outputValues =\n        util.getArrayFromDType(valuesDType, fullIndicesCount) as TypedArray;\n    const filledCount: number[] = new Array(denseRows).fill(0);\n\n    // Fill in values for rows that are not missing\n    for (let i = 0; i < indicesCount; ++i) {\n      // indices is a 2d tensor with shape of [N, rank]\n      const row = indices[i * rank];\n      const offset = filledCount[row];\n      const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n      filledCount[row]++;  // Increment the filled count for this row.\n      for (let j = 0; j < rank; ++j) {\n        // indices and outputIndices are 2d tensors with shape of [N, rank]\n        outputIndices[outputI * rank + j] = indices[i * rank + j];\n      }\n      outputValues[outputI] = values[i];\n      // We'll need this reverse index map to backprop correctly.\n      reverseIndexMap[i] = outputI;\n    }\n\n    // Fill in values for rows that are missing\n    for (let row = 0; row < denseRows; ++row) {\n      const rowCount = filledCount[row];\n      if (rowCount === 0) {  // We haven't filled this row\n        const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n        // Remaining index values were set to zero already.\n        // Just need to set the row index in the right location.\n        // outputIndices is a 2d tensor with shape of [N, rank]\n        outputIndices[startingIndex * rank + 0] = row;\n        for (let col = 1; col < rank; ++col) {\n          outputIndices[startingIndex * rank + col] = 0;\n        }\n        outputValues[startingIndex] = defaultValue;\n      }\n    }\n    return [\n      outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseReshapeImpl(\n    inputIndices: TypedArray, inputIndicesShape: number[], inputDType: DataType,\n    inputShape: number[],\n    targetShape: number[]): [TypedArray, number[], number[]] {\n  const denseSize = util.sizeFromShape(inputShape);\n  const nnz = inputIndicesShape[0];\n  const outputRank = targetShape.length;\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  const outputShape: number[] = [];\n  let product = 1;\n  let unknownIndex = -1;\n  for (let d = 0; d < outputRank; ++d) {\n    const size = targetShape[d];\n    if (size === -1) {\n      if (unknownIndex !== -1) {\n        throw new Error(\n            backend_util\n                .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n                    unknownIndex, d));\n      }\n      unknownIndex = d;\n      outputShape.push(1);\n    } else {\n      if (size < 0) {\n        throw new Error(\n            backend_util.getSparseReshapeNegativeOutputDimErrorMessage(\n                d, size));\n      }\n      product *= size;\n      outputShape.push(size);\n    }\n  }\n  if (unknownIndex !== -1) {\n    if (product <= 0) {\n      throw new Error(\n          backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());\n    }\n    const missing = Math.trunc(denseSize / product);\n    if (product * missing !== denseSize) {\n      throw new Error(\n          backend_util.getSparseReshapeInputOutputMultipleErrorMessage(\n              inputShape, outputShape));\n    }\n\n    outputShape[unknownIndex] = missing;\n  }\n  const outputSize = util.sizeFromShape(outputShape);\n  if (outputSize !== denseSize) {\n    throw new Error(\n        backend_util.getSparseReshapeInputOutputMismatchErrorMessage(\n            inputShape, outputShape));\n  }\n\n  const inputRank = inputShape.length;\n  const inputStrides: number[] = [];\n  if (inputRank > 0) {\n    inputStrides[inputRank - 1] = 1;\n    for (let d = inputRank - 2; d >= 0; --d) {\n      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n    }\n  }\n\n  const outputStrides: number[] = [];\n  if (outputRank > 0) {\n    outputStrides[outputRank - 1] = 1;\n    for (let d = outputRank - 2; d >= 0; --d) {\n      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n    }\n  }\n\n  const newIndices =\n      util.getArrayFromDType(inputDType, nnz * outputRank) as TypedArray;\n  for (let i = 0; i < nnz; ++i) {\n    let id = 0;\n    for (let j = 0; j < inputRank; ++j) {\n      // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n      id += inputIndices[i * inputRank + j] * inputStrides[j];\n    }\n    for (let j = 0; j < outputRank; ++j) {\n      // newIndices is a 2d tensor with shape of [nnz, outputRank]\n      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n      id %= outputStrides[j];\n    }\n  }\n  return [newIndices, [nnz, outputRank], outputShape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseSegmentReductionImpl(\n    input: TypedArray, inputShape: number[], inputDType: DataType,\n    indices: TypedArray, segmentIds: TypedArray, isMean = false,\n    defaultValue = 0): [TypedArray, number[]] {\n  const numIndices = indices.length;\n\n  // Flatten the array to two dimensions\n  const inputFlat: number[] = [inputShape[0], input.length / inputShape[0]];\n  const numCol = inputFlat[1];\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  if (outputRows < 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  const outputShape = inputShape.slice();\n  outputShape[0] = outputRows;\n\n  const outputLength =\n      outputShape.reduce((product, value) => product * value, 1);\n  // Output array is initialized with the value 0 by default.\n  const output = util.getArrayFromDType(inputDType, outputLength) as TypedArray;\n\n  // Note that we do not initialize the output buffer with a default value, so\n  // we need to explicitly set missing indices to the default value.\n  if (numIndices === 0) {\n    if (outputRows > 0) {\n      output.fill(defaultValue);\n    }\n    return [output, outputShape];\n  }\n\n  if (outputRows <= 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  let start = 0, end = 1;\n  // Index from which the output is not initialized.\n  let uninitializedIndex = 0;\n  let outIndex = segmentIds[start];\n\n  while (true) {\n    // We initialize nextIndex to 0 to avoid may be uninitialized warning\n    let nextIndex = 0;\n    if (end < numIndices) {\n      nextIndex = segmentIds[end];\n      if (outIndex === nextIndex) {\n        ++end;\n        continue;\n      }\n      // We have a new segment here.  Verify that the segment ids are growing.\n      if (outIndex >= nextIndex) {\n        throw new Error(backend_util\n            .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());\n      }\n    }\n\n    if (outIndex < 0 || outIndex >= outputRows) {\n      throw new Error(\n          backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n              outIndex, outputRows));\n    }\n\n    // If there is a gap between two indices, we need to set that gap to the\n    // default value.\n    if (outIndex > uninitializedIndex) {\n      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);\n    }\n\n    for (let i = start; i < end; ++i) {\n      const index = indices[i];\n      if (index < 0 || index >= inputFlat[0]) {\n        throw new Error(\n            backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n                i, indices[i], inputFlat[0]));\n      }\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] += input[index * numCol + j];\n      }\n    }\n\n    if (isMean) {\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] /= end - start;\n      }\n    }\n\n    start = end;\n    ++end;\n    uninitializedIndex = outIndex + 1;\n    outIndex = nextIndex;\n    if (end > numIndices) {\n      break;\n    }\n  }\n\n  // Fill the gap at the end with the default value.\n  if (uninitializedIndex < outputRows) {\n    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);\n  }\n\n  return [output, outputShape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const squaredDifferenceImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => {\n      const diff = a - b;\n      return diff * diff;\n    }));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function stridedSliceImpl<R extends Rank>(\n    outShape: number[], xBuf: TensorBuffer<R>, strides: number[],\n    begin: number[]): TensorBuffer<R> {\n  const outBuf = buffer(outShape, xBuf.dtype);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const loc = outBuf.indexToLoc(i);\n\n    const newLoc: number[] = new Array(loc.length);\n    for (let j = 0; j < newLoc.length; j++) {\n      newLoc[j] = loc[j] * strides[j] + begin[j];\n    }\n    outBuf.set(xBuf.get(...newLoc), ...loc);\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nclass StringNGramsOp {\n  private separator: Uint8Array;\n  private nGramWidths: number[];\n  private padWidth: number;\n  private leftPad: Uint8Array;\n  private rightPad: Uint8Array;\n  private preserveShort: boolean;\n\n  constructor(\n      separator: string, nGramWidths: number[], leftPad: string,\n      rightPad: string, padWidth: number, preserveShortSequences: boolean) {\n    this.separator = util.encodeString(separator);\n    this.nGramWidths = nGramWidths;\n    this.leftPad = util.encodeString(leftPad);\n    this.rightPad = util.encodeString(rightPad);\n    this.padWidth = padWidth;\n    this.preserveShort = preserveShortSequences;\n  }\n\n  private getPadWidth(nGramWidth: number) {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'padWidth' arg, but in no case should the padding\n    // ever be wider than 'nGramWidth' - 1.\n    return Math.min(\n        this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n  }\n\n  private getNumNGrams(length: number, nGramWidth: number) {\n    const padWidth = this.getPadWidth(nGramWidth);\n    return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n  }\n\n  private createNGrams(\n      data: Uint8Array[], splitIndex: number, output: Uint8Array[],\n      outputStartIndex: number, numNGrams: number, nGramWidth: number) {\n    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n      const padWidth = this.getPadWidth(nGramWidth);\n      const leftPadding = Math.max(0, padWidth - nGramIndex);\n      const rightPadding =\n          Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n      const numTokens = nGramWidth - (leftPadding + rightPadding);\n      const dataStartIndex =\n          splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n\n      // Calculate the total expected size of the nGram so we can reserve the\n      // correct amount of space in the string.\n      let nGramSize = 0;\n      // Size of the left padding.\n      nGramSize += leftPadding * this.leftPad.length;\n      // Size of the tokens.\n      for (let n = 0; n < numTokens; ++n) {\n        nGramSize += data[dataStartIndex + n].length;\n      }\n      // Size of the right padding.\n      nGramSize += rightPadding * this.rightPad.length;\n      // Size of the separators.\n      const numSeparators = leftPadding + rightPadding + numTokens - 1;\n      nGramSize += numSeparators * this.separator.length;\n\n      // Build the nGram.\n      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n      const nGram = output[outputStartIndex + nGramIndex];\n\n      let nextNGramIndex = 0;\n      const appendToNGram = (str: Uint8Array) =>\n          str.forEach((value) => nGram[nextNGramIndex++] = value);\n\n      for (let n = 0; n < leftPadding; ++n) {\n        appendToNGram(this.leftPad);\n        appendToNGram(this.separator);\n      }\n      // Only output first numTokens - 1 pairs of data and separator\n      for (let n = 0; n < numTokens - 1; ++n) {\n        appendToNGram(data[dataStartIndex + n]);\n        appendToNGram(this.separator);\n      }\n      // Handle case when there are no tokens or no right padding as these\n      // can result in consecutive separators.\n      if (numTokens > 0) {\n        // If we have tokens, then output last and then pair each separator\n        // with the right padding that follows, to ensure nGram ends either with\n        // the token or with the right pad.\n        appendToNGram(data[dataStartIndex + numTokens - 1]);\n        for (let n = 0; n < rightPadding; ++n) {\n          appendToNGram(this.separator);\n          appendToNGram(this.rightPad);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the nGram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (let n = 0; n < rightPadding - 1; ++n) {\n          appendToNGram(this.rightPad);\n          appendToNGram(this.separator);\n        }\n        appendToNGram(this.rightPad);\n      }\n    }\n  }\n\n  // Data and splits together form the definition of the ragged tensor,\n  // where data is 1 dimensional and contains the values of the tensor\n  // and splits denotes the indices at which each row starts.\n  public compute(data: Uint8Array[], splits: Int32Array):\n      [Uint8Array[], Int32Array] {\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const inputDataSize = data.length;\n    const splitsSize = splits.length;\n    if (splitsSize > 0) {\n      let prevSplit = splits[0];\n      if (prevSplit !== 0) {\n        throw new Error(`First split value must be 0, got ${prevSplit}`);\n      }\n      for (let i = 1; i < splitsSize; ++i) {\n        let validSplits = splits[i] >= prevSplit;\n        validSplits = validSplits && (splits[i] <= inputDataSize);\n        if (!validSplits) {\n          throw new Error(`Invalid split value ${splits[i]}, must be in [${\n              prevSplit}, ${inputDataSize}]`);\n        }\n        prevSplit = splits[i];\n      }\n      if (prevSplit !== inputDataSize) {\n        throw new Error(`Last split value must be data size. Expected ${\n            inputDataSize}, got ${prevSplit}`);\n      }\n    }\n\n    const numBatchItems = splitsSize - 1;\n    const nGramsSplits = util.getArrayFromDType('int32', splitsSize);\n    // If there is no data or size, return an empty ragged tensor.\n    if (inputDataSize === 0 || splitsSize === 0) {\n      const empty: Uint8Array[] = new Array(inputDataSize);\n      for (let i = 0; i <= numBatchItems; ++i) {\n        nGramsSplits[i] = 0;\n      }\n      return [empty, nGramsSplits];\n    }\n\n    nGramsSplits[0] = 0;\n    for (let i = 1; i <= numBatchItems; ++i) {\n      const length = splits[i] - splits[i - 1];\n      let numNGrams = 0;\n      this.nGramWidths.forEach((nGramWidth) => {\n        numNGrams += this.getNumNGrams(length, nGramWidth);\n      });\n      if (this.preserveShort && length > 0 && numNGrams === 0) {\n        numNGrams = 1;\n      }\n      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n    }\n\n    const nGrams: Uint8Array[] = new Array(nGramsSplits[numBatchItems]);\n\n    for (let i = 0; i < numBatchItems; ++i) {\n      const splitIndex = splits[i];\n      let outputStartIdx = nGramsSplits[i];\n      this.nGramWidths.forEach((nGramWidth) => {\n        const length = splits[i + 1] - splits[i];\n        const numNGrams = this.getNumNGrams(length, nGramWidth);\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n        outputStartIdx += numNGrams;\n      });\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (nGramSplitsdata). If no ngrams were generated, then they will\n      // be equal (since we increment outputStartIdx by numNGrams every\n      // time we create a set of ngrams.)\n      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {\n        const dataLength = splits[i + 1] - splits[i];\n        // One legitimate reason to not have any ngrams when this.preserveShort\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (dataLength === 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one nGram.\n        const nGramWidth = dataLength + 2 * this.padWidth;\n        const numNGrams = 1;\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n      }\n    }\n    return [nGrams, nGramsSplits];\n  }\n}\n\nexport function stringNGramsImpl(\n    data: Uint8Array[], dataSplits: Int32Array, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): [Uint8Array[], Int32Array] {\n  return new StringNGramsOp(\n             separator, nGramWidths, leftPad, rightPad, padWidth,\n             preserveShortSequences)\n      .compute(data, dataSplits);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction split(\n    str: Uint8Array, delimiters: Uint8Array, skipEmpty: boolean,\n    result: Uint8Array[]): void {\n  if (!str.length) {\n    return;\n  }\n  // When the delimiter is empty, the input is split into individual characters.\n  if (delimiters.length === 0) {\n    for (let i = 0; i < str.length; ++i) {\n      result.push(str.subarray(i, i + 1));\n    }\n    return;\n  }\n  // When there is one delimiter, the input is split only at that delimiter.\n  if (delimiters.length === 1) {\n    const delimiter = delimiters[0];\n    let f = str.indexOf(delimiter);\n    while (f !== -1) {\n      const token = str.subarray(0, f);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      str = str.subarray(f + 1);\n      f = str.indexOf(delimiter);\n    }\n    if (!skipEmpty || str.length !== 0) {\n      result.push(str);\n    }\n    return;\n  }\n  // When there are multiple delimiters, the input is split at every instance\n  // one of the delimiters appears.\n  let tokenStart = 0;\n  for (let i = 0; i < str.length + 1; i++) {\n    if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n      const token = str.subarray(tokenStart, i);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      tokenStart = i + 1;\n    }\n  }\n}\n\nexport function stringSplitImpl(\n    input: Uint8Array[], delimiter: Uint8Array,\n    skipEmpty: boolean): [TypedArray, Uint8Array[], [number, number]] {\n  const batchSize = input.length;\n\n  // Empty delimiter means split the input character by character.\n  const tokens: Uint8Array[] = [];\n\n  let outputSize = 0;\n  let maxNumEntries = 0;\n  const numIndices: number[] = new Array(batchSize);\n  for (let i = 0; i < batchSize; ++i) {\n    const prevTokensLength = tokens.length;\n    split(input[i], delimiter, skipEmpty, tokens);\n    const nEntries = tokens.length - prevTokensLength;\n    numIndices[i] = nEntries;\n    outputSize += nEntries;\n    maxNumEntries = Math.max(maxNumEntries, nEntries);\n  }\n\n  const indices = util.getArrayFromDType('int32', outputSize * 2) as TypedArray;\n  const values: Uint8Array[] = new Array(outputSize);\n  const shape: [number, number] = [batchSize, maxNumEntries];\n\n  let c = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    for (let j = 0; j < numIndices[i]; ++j) {\n      // indices is a 2d tensor with shape of [outputSize, 2]\n      indices[c * 2] = i;\n      indices[c * 2 + 1] = j;\n      values[c] = tokens[c];\n      ++c;\n    }\n  }\n\n  return [indices, values, shape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function stringToHashBucketFastImpl(\n    input: Uint8Array[], numBuckets: number): TypedArray {\n  const output = util.getArrayFromDType('int32', input.length) as TypedArray;\n\n  for (let i = 0; i < input.length; ++i) {\n    output[i] =\n        util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const subImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\n\nexport function tileImpl<R extends Rank>(\n    xBuf: TensorBuffer<R, DataType>,\n    reps: number[]): TensorBuffer<R, DataType> {\n  const newShape: number[] = new Array(xBuf.rank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = xBuf.shape[i] * reps[i];\n  }\n  const result = buffer(newShape, xBuf.dtype);\n  for (let i = 0; i < result.values.length; ++i) {\n    const newLoc = result.indexToLoc(i);\n\n    const originalLoc: number[] = new Array(xBuf.rank);\n    for (let j = 0; j < originalLoc.length; j++) {\n      originalLoc[j] = newLoc[j] % xBuf.shape[j];\n    }\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    result.values[i] = xBuf.values[originalIndex];\n  }\n  return result as TensorBuffer<R, DataType>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the TopK kernel shared between webgl and cpu. */\n\nimport {buffer, NumericDataType, Rank, ShapeMap, Tensor, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\ntype Pair = {\n  value: number,\n  index: number\n};\n\nconst comparePair = (a: Pair, b: Pair) => {\n  const valueDiff = b.value - a.value;\n  return valueDiff === 0 ? a.index - b.index : valueDiff;\n};\n\n/**\n * Partitions array where all elements smaller than the (k+1) smallest element\n * are found to the left of it, and all larger to the right of it.\n * Based on the Floyd-Rivest Algorithm, ref:\n * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm\n * @param array: Array to partition\n * @param left: Left index for the interval\n * @param right: Right index for the interval\n * @param k: Desired index value, where array[k] is the (k+1)th smallest element\n *           when left = 0\n */\nfunction select(array: Pair[], k: number, left = 0, right = array.length - 1) {\n  while (right > left) {\n    // Use select recursively to sample a smaller set of size s\n    // the arbitrary constants 600 and 0.5 are used in the original\n    // version to minimize execution time.\n    if (right - left > 600) {\n      const n = right - left + 1;\n      const i = k - left + 1;\n      const z = Math.log(n);\n      const s = 0.5 * Math.exp(2 * z / 3);\n      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i - n / 2);\n      const newLeft = Math.max(left, Math.floor(k - i * s / n + sd));\n      const newRight = Math.min(right, Math.floor(k + (n - i) * s / n + sd));\n      select(array, k, newLeft, newRight);\n    }\n    // partition the elements between left and right around t\n    const t = array[k];\n    let i = left;\n    let j = right;\n\n    util.swap(array, left, k);\n\n    if (comparePair(array[right], t) > 0) {\n      util.swap(array, left, right);\n    }\n    while (i < j) {\n      util.swap(array, i, j);\n      i++;\n      j--;\n      while (comparePair(array[i], t) < 0) {\n        i = i + 1;\n      }\n      while (comparePair(array[j], t) > 0) {\n        j = j - 1;\n      }\n    }\n    if (comparePair(array[left], t) === 0) {\n      util.swap(array, left, j);\n    } else {\n      j = j + 1;\n      util.swap(array, j, right);\n    }\n    // Adjust left and right towards the boundaries of the subset\n    // containing the (k - left + 1)th smallest element.\n    if (j <= k) {\n      left = j + 1;\n    }\n    if (k <= j) {\n      right = j - 1;\n    }\n  }\n}\n\nexport function topKImpl<T extends Tensor, R extends Rank>(\n    x: TypedArray, xShape: number[], xDtype: NumericDataType, k: number,\n    sorted: boolean):\n    [TensorBuffer<R, NumericDataType>, TensorBuffer<R, 'int32'>] {\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const lastDim = xShape[xShape.length - 1];\n  const [batch, size] = [x.length / lastDim, lastDim];\n  const allTopKVals = util.getTypedArrayFromDType(xDtype, batch * k);\n  const allTopKIndices = util.getTypedArrayFromDType('int32', batch * k);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = x.subarray(offset, offset + size);\n\n    let valAndInd: Pair[] = new Array(vals.length);\n    vals.forEach(\n        (value: number, index: number) => valAndInd[index] = {value, index});\n\n    if (k < valAndInd.length) {\n      select(valAndInd, k);\n      valAndInd = valAndInd.slice(0, k);\n    }\n\n    if (sorted) {\n      valAndInd.sort(comparePair);\n    }\n    \n    const outOffset = b * k;\n    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n    for (let i = 0; i < k; i++) {\n      topKVals[i] = valAndInd[i].value;\n      topKIndices[i] = valAndInd[i].index;\n    }\n  }\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const outputShape = xShape.slice();\n  outputShape[outputShape.length - 1] = k;\n\n  return [\n    buffer(outputShape as ShapeMap[R], xDtype, allTopKVals),\n    buffer(outputShape as ShapeMap[R], 'int32', allTopKIndices)\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Shared functionality among backends.\nexport {simpleAbsImpl} from './kernels/Abs';\nexport {addImpl} from './kernels/Add';\nexport {bincountImpl, bincountReduceImpl} from './kernels/Bincount_impl';\nexport {castImpl} from './kernels/Cast';\nexport {ceilImpl} from './kernels/Ceil';\nexport {concatImpl} from './kernels/Concat_impl';\nexport {equalImpl} from './kernels/Equal';\nexport {expImpl} from './kernels/Exp';\nexport {expm1Impl} from './kernels/Expm1';\nexport {floorImpl} from './kernels/Floor';\nexport {gatherNdImpl} from './kernels/GatherNd_Impl';\nexport {gatherV2Impl} from './kernels/GatherV2_impl';\nexport {greaterImpl} from './kernels/Greater';\nexport {greaterEqualImpl} from './kernels/GreaterEqual';\nexport {lessImpl} from './kernels/Less';\nexport {lessEqualImpl} from './kernels/LessEqual';\nexport {linSpaceImpl} from './kernels/LinSpace_impl';\nexport {logImpl} from './kernels/Log';\nexport {maxImpl} from './kernels/Max_impl';\nexport {maximumImpl} from './kernels/Maximum';\nexport {minimumImpl} from './kernels/Minimum';\nexport {multiplyImpl} from './kernels/Multiply';\nexport {negImpl} from './kernels/Neg';\nexport {notEqualImpl} from './kernels/NotEqual';\nexport {prodImpl} from './kernels/Prod';\nexport {raggedGatherImpl} from './kernels/RaggedGather_impl';\nexport {raggedTensorToTensorImpl} from './kernels/RaggedTensorToTensor_impl';\nexport {rangeImpl} from './kernels/Range_impl';\nexport {rsqrtImpl} from './kernels/Rsqrt';\nexport {scatterImpl} from './kernels/Scatter_impl';\nexport {sigmoidImpl} from './kernels/Sigmoid';\nexport {sliceImpl} from './kernels/Slice';\nexport {sparseFillEmptyRowsImpl} from './kernels/SparseFillEmptyRows_impl';\nexport {sparseReshapeImpl} from './kernels/SparseReshape_impl';\nexport {sparseSegmentReductionImpl} from './kernels/SparseSegmentReduction_impl';\nexport {sqrtImpl} from './kernels/Sqrt';\nexport {squaredDifferenceImpl} from './kernels/SquaredDifference';\nexport {stridedSliceImpl} from './kernels/StridedSlice_impl';\nexport {stringNGramsImpl} from './kernels/StringNGrams_impl';\nexport {stringSplitImpl} from './kernels/StringSplit_impl';\nexport {stringToHashBucketFastImpl} from './kernels/StringToHashBucketFast_impl';\nexport {subImpl} from './kernels/Sub';\nexport {tileImpl} from './kernels/Tile_impl';\nexport {topKImpl} from './kernels/TopK_impl';\nexport {transposeImpl} from './kernels/Transpose_impl';\nexport {uniqueImpl} from './kernels/Unique_impl';\nexport {ComplexBinaryKernelImpl, SimpleBinaryKernelImpl} from './utils/binary_types';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Import shared functionality from tfjs-backend-cpu without triggering\n// side effects.\n// tslint:disable-next-line: no-imports-from-dist\nimport * as shared from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleBinaryKernelImpl} from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleUnaryImpl} from '@tensorflow/tfjs-backend-cpu/dist/utils/unary_types';\n\nexport type SimpleBinaryKernelImplCPU = SimpleBinaryKernelImpl;\nexport type SimpleUnaryKernelImplCPU = SimpleUnaryImpl;\nconst {\n  addImpl: addImplCPU,\n  castImpl: castImplCPU,\n  ceilImpl: ceilImplCPU,\n  concatImpl: concatImplCPU,\n  equalImpl: equalImplCPU,\n  expImpl: expImplCPU,\n  expm1Impl: expm1ImplCPU,\n  floorImpl: floorImplCPU,\n  gatherNdImpl: gatherNdImplCPU,\n  gatherV2Impl: gatherV2ImplCPU,\n  greaterEqualImpl: greaterEqualImplCPU,\n  greaterImpl: greaterImplCPU,\n  lessEqualImpl: lessEqualImplCPU,\n  lessImpl: lessImplCPU,\n  logImpl: logImplCPU,\n  maxImpl: maxImplCPU,\n  maximumImpl: maximumImplCPU,\n  minimumImpl: minimumImplCPU,\n  multiplyImpl: multiplyImplCPU,\n  negImpl: negImplCPU,\n  notEqualImpl: notEqualImplCPU,\n  prodImpl: prodImplCPU,\n  rangeImpl: rangeImplCPU,\n  rsqrtImpl: rsqrtImplCPU,\n  scatterImpl: scatterImplCPU,\n  simpleAbsImpl: simpleAbsImplCPU,\n  sliceImpl: sliceImplCPU,\n  stridedSliceImpl: stridedSliceImplCPU,\n  stringNGramsImpl: stringNGramsImplCPU,\n  subImpl: subImplCPU,\n  tileImpl: tileImplCPU,\n  topKImpl: topKImplCPU,\n  transposeImpl: transposeImplCPU,\n  uniqueImpl: uniqueImplCPU,\n} = shared;\n\nexport {\n  addImplCPU,\n  castImplCPU,\n  ceilImplCPU,\n  concatImplCPU,\n  equalImplCPU,\n  expImplCPU,\n  expm1ImplCPU,\n  floorImplCPU,\n  gatherNdImplCPU,\n  gatherV2ImplCPU,\n  greaterEqualImplCPU,\n  greaterImplCPU,\n  lessEqualImplCPU,\n  lessImplCPU,\n  logImplCPU,\n  maxImplCPU,\n  maximumImplCPU,\n  minimumImplCPU,\n  multiplyImplCPU,\n  prodImplCPU,\n  negImplCPU,\n  notEqualImplCPU,\n  scatterImplCPU,\n  simpleAbsImplCPU,\n  sliceImplCPU,\n  stridedSliceImplCPU,\n  stringNGramsImplCPU,\n  subImplCPU,\n  rangeImplCPU,\n  rsqrtImplCPU,\n  tileImplCPU,\n  topKImplCPU,\n  transposeImplCPU,\n  uniqueImplCPU,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {simpleAbsImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const abs =\n    unaryKernelFunc({opType: UnaryOpType.ABS, cpuKernelImpl: simpleAbsImplCPU});\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'webgpu',\n  kernelFunc: abs\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {addImplCPU as cpuAdd} from '../kernel_utils/shared';\n\nexport const addKernelFunc = binaryKernelFunc(\n    {opType: BinaryOpType.ADD, cpuKernelImpl: cpuAdd, supportsComplex: true});\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'webgpu',\n  kernelFunc: addKernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class AddNPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  workPerThread = 1;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shapes: number[][]) {\n    this.outputShape = shapes[0];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'addN';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    // Get target elements from every input tensor.\n    this.variableNames.forEach(variable => {\n      snippets.push(`let v${variable} = get${variable}ByOutputCoords(coords);`);\n    });\n    // Calculate the sum of all elements.\n    const operation = this.variableNames\n                          .map(variable => {\n                            return `v${variable}`;\n                          })\n                          .join(' + ');\n\n    const userCode = `\n      ${main('index')} {\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if (flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            ${snippets.join('\\n        ')}\n            setOutputAtIndex(flatIndex, ${operation});\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, KernelConfig, KernelFunc, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {AddNPackedProgram} from '../addn_packed_webgpu';\nimport {identity} from './Identity';\n\nexport function addN(args: {inputs: AddNInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n\n  const tensors = inputs;\n  if (tensors.length === 1) {\n    return identity({inputs: {x: tensors[0]}, backend});\n  }\n\n  const dtype =\n      tensors.map(t => t.dtype).reduce((d1, d2) => upcastType(d1, d2));\n  const shapes = tensors.map(t => t.shape);\n  const program = new AddNPackedProgram(shapes);\n  return backend.runWebGPUProgram(program, tensors, dtype);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'webgpu',\n  kernelFunc: addN as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ArgMinMaxProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  variableNames = ['x'];\n  uniforms = 'infinityValue : f32,';\n  inputShape: number[];\n  reductionFactor: number;\n  op: string;\n  size = true;\n  private type: string;\n\n  constructor(inputShape: number[], axis: number, reduceType: 'min'|'max') {\n    const axes = [axis];\n\n    this.op = reduceType === 'min' ? '<' : '>';\n\n    // |outShape| is the shape with the removed axis\n    const [outputShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(inputShape, axes);\n\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // The shared algorithm is mainly used for large reduce size. It fully\n    // utilizes the threads in one workgroup to do the reduction. However,\n    // when the reduce size is very small or the output shape is too large. It's\n    // better to use the plain algorithm to reduce the number of workgroups to\n    // speedup. The threthold can be further tuned.\n    if (util.sizeFromShape(reduceShape) < 32 ||\n        util.sizeFromShape(outputShape) > 1000) {\n      this.type = 'plain';\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workGroupSize);\n    } else {\n      this.type = 'shared';\n      // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n      // dispatch size.\n      this.dispatch =\n          computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n    }\n\n    this.inputShape = inputShape;\n    this.shaderKey = `argMinMax_${this.op}_${this.type}`;\n  }\n\n  getUserCode(): string {\n    const getInputShapeLastDim = () => {\n      if (this.inputShape.length === 1) {\n        return 'uniforms.xShape';\n      } else {\n        return `uniforms.xShape.${getCoordsXYZ(this.inputShape.length - 1)}`;\n      }\n    };\n\n    const splitOutputCoords = () => {\n      let snippet = '';\n      if (this.outputShape.length === 1) {\n        if (this.inputShape.length !== 1) {\n          snippet += 'outputCoords,';\n        }\n      } else {\n        for (let i = 0; i < this.outputShape.length; i++) {\n          snippet += `outputCoords.${getCoordsXYZ(i)},`;\n        }\n      }\n      return snippet;\n    };\n\n    if (this.type === 'shared') {\n      const sharedMemorySnippet = `\n      var<workgroup> xBestIndices : array<i32, ${this.workGroupSize[0]}>;\n      var<workgroup> xBestValues : array<f32, ${this.workGroupSize[0]}>;\n    `;\n      const userCode = `\n      fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n      }\n\n      ${sharedMemorySnippet}\n\n      ${main('index')} {\n        let outputIndex = index / i32(workGroupSizeX);\n        let reduceLength = ${getInputShapeLastDim()};\n\n        var bestIndex = i32(localId.x);\n        var bestValue = uniforms.infinityValue;\n        let outputCoords = getCoordsFromIndex(outputIndex);\n        for (var k = i32(localId.x); k < reduceLength && outputIndex < uniforms.size;\n            k = k + i32(workGroupSizeX)) {\n          let candidate = getX(${splitOutputCoords()} k);\n          if (!isnan(candidate) && candidate ${this.op} bestValue) {\n            bestValue = candidate;\n            bestIndex = k;\n          }\n        }\n        xBestValues[localId.x] = bestValue;\n        xBestIndices[localId.x] = bestIndex;\n        workgroupBarrier();\n\n        var reduceSize = min(u32(reduceLength), workGroupSizeX);\n        for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n            currentSize = reduceSize / 2u) {\n          let interval = DIV_CEIL(reduceSize, 2u);\n          if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              xBestValues[localId.x] = bestValue;\n              xBestIndices[localId.x] = xBestIndices[localId.x + interval];\n            }\n          }\n          reduceSize = interval;\n          workgroupBarrier();\n        }\n\n        if (localId.x == 0u && outputIndex < uniforms.size) {\n          setOutputAtIndexI32(outputIndex, xBestIndices[localId.x]);\n        }\n      }\n    `;\n      return userCode;\n    } else {\n      const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let outputCoords = getCoordsFromIndex(index);\n          var bestIndex = 0;\n          var bestValue = getX(${splitOutputCoords()} 0);\n          let reduceLength = ${getInputShapeLastDim()};\n          for (var i = 1; i < reduceLength; i++) {\n            let candidate = getX(${splitOutputCoords()} i);\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              bestIndex = i;\n            }\n          }\n          setOutputAtIndexI32(index, bestIndex);\n        }\n      }\n      `;\n      return userCode;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getWorkGroupSizeString, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class TransposeSharedProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[]};\n  dispatch: [number, number, number];\n  // Note that the maximum number of workgroup invocations by webgpu is 256.\n  workGroupSize: [number, number, number] = [16, 16, 1];\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [0], y: [1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize, [1, 1, 1]);\n\n    this.shaderKey = 'transposeShared';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      const TILE_DIM = ${this.workGroupSize[0]};\n      var<workgroup> tile : array<array<f32, ${this.workGroupSize[0] + 1}>, ${\n        this.workGroupSize[0]}>;\n      ${getWorkGroupSizeString()}\n      fn _start(@builtin(local_invocation_id) localId : vec3<u32>,\n                @builtin(workgroup_id) workgroupId : vec3<u32>) {\n        var x = i32(workgroupId.x) * TILE_DIM + i32(localId.x);\n        var y = i32(workgroupId.y) * TILE_DIM + i32(localId.y);\n        let width = uniforms.outShape[0];\n        let height = uniforms.outShape[1];\n        if (x < width && y < height) {\n          tile[localId.y][localId.x] = A[y * width + x];\n        }\n        workgroupBarrier();\n\n        x = i32(workgroupId.y) * TILE_DIM + i32(localId.x);\n        y = i32(workgroupId.x) * TILE_DIM + i32(localId.y);\n        if (x < height && y < width) {\n          setOutputAtIndex((y * height + x), tile[localId.x]\n            [localId.y]);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransposeProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  shaderKey: string;\n  outputShape: number[];\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  newDim: number[];\n  size = true;\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.newDim = newDim;\n    this.shaderKey = `transpose_${newDim}`;\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.outputShape.length);\n    const switched = getSwitchedCoords(this.newDim);\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let resRC = getCoordsFromIndex(flatIndex);\n            setOutputAtIndex(flatIndex, A[getIndexFromCoords${\n        this.outputShape.length}D(\n              ${dtype}(${switched}), uniforms.aShape)]);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nfunction getSwitchedCoords(newDim: number[]): string {\n  const rank = newDim.length;\n  if (rank > 6) {\n    throw Error(`Transpose for rank ${rank} is not yet supported`);\n  }\n  const switchedCoords = new Array(rank);\n  for (let i = 0; i < newDim.length; i++) {\n    switchedCoords[newDim[i]] = `resRC.${getCoordsXYZ(i)}`;\n  }\n\n  return switchedCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Transpose, TransposeAttrs, TransposeInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {transposeImplCPU as cpuTranspose} from '../kernel_utils/shared';\n\nimport {TransposeSharedProgram} from '../transpose_shared_webgpu';\nimport {TransposeProgram} from '../transpose_webgpu';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n  const webgpuBackend = backend;\n\n  const xRank = x.shape.length;\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = webgpuBackend.tensorMap.get(x.dataId);\n    const values = xData.values as TypedArray;\n    const outValues = cpuTranspose(values, x.shape, x.dtype, perm, newShape);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n  if (x.shape.length === 2 && util.arraysEqual(perm, [1, 0])) {\n    const program = new TransposeSharedProgram(x.shape, perm);\n    return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n  const program = new TransposeProgram(x.shape, perm);\n  return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'webgpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: WebGPUBackend, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMax', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'max');\n  const uniformData = [{type: 'float32', data: [Number.NEGATIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'webgpu',\n  kernelFunc: argMax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: WebGPUBackend, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMin', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'min');\n  const uniformData = [{type: 'float32', data: [Number.POSITIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'webgpu',\n  kernelFunc: argMin as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const atan2 = binaryKernelFunc({opType: BinaryOpType.ATAN2});\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'webgpu',\n  kernelFunc: atan2\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Pool2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms =\n      `stride : vec2<i32>, pad : vec2<i32>, dilation : vec2<i32>, convDims : vec2<i32>, filterDims : vec2<i32>,`;\n  // TODO(jiajia.qin@intel.com): Dynamically choose different workGroupSize for\n  // different output shapes.\n  workGroupSize: [number, number, number] = [128, 1, 1];\n  poolType: 'max'|'avg';\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo, poolType: 'max'|'avg') {\n    this.outputShape = convInfo.outShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = `pool2D_${poolType}`;\n    this.poolType = poolType;\n  }\n\n  getUserCode(): string {\n    let updateSnippet = `resultValue = max(value, resultValue);`;\n    if (this.poolType === 'avg') {\n      updateSnippet = `resultValue = resultValue + value; count = count + 1.0;`;\n    }\n\n    let returnValue = `resultValue`;\n    if (this.poolType === 'avg') {\n      returnValue = `resultValue / count`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let xRCCorner = vec2<i32>(coords.yz) * uniforms.stride - uniforms.pad;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          var resultValue = ${\n        this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};\n          var count = 0.0;\n\n          for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + uniforms.dilation.x) {\n            let xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= uniforms.convDims.x) {\n              continue;\n            }\n\n            for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + uniforms.dilation.y) {\n              let xC = xCCorner + wC;\n              if (xC < 0 || xC >= uniforms.convDims.y) {\n                continue;\n              }\n\n              let value = getX(batch, xR, xC, coords[3]);\n              ${updateSnippet}\n            }\n          }\n\n          setOutputAtIndex(index, ${returnValue});\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class PoolWithFilterSizeEqualsOneProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = `stride : vec2<i32>,`;\n  workGroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = 'poolWithFilterSizeEqualsOne';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let d = coords[3];\n\n          let xRCCorner = coords.yz * uniforms.stride;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          let value = getX(batch, xRCorner, xCCorner, d);\n          setOutputAtIndex(index, value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  variableNames = ['x'];\n  uniforms = 'reduceSize : i32,';\n  reduceType: 'max'|'mean'|'min'|'prod'|'sum';\n  inputShape: number[];\n  size = true;\n\n  constructor(\n      reduceInfo: backend_util.ReduceInfo,\n      reduceType: 'max'|'mean'|'min'|'prod'|'sum') {\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape, ] =\n        backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n\n  getUserCode(): string {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${\n          this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    }\n\n    const outputSnippet = this.reduceType === 'mean' ?\n        // tslint:disable-next-line:max-line-length\n        `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :\n        `setOutputAtIndex(outputIndex, bestValue);`;\n\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${this.workGroupSize[0]}>;\n       `;\n\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${\n        this.outputShape.length === 1 ?\n            'outputCoords' :\n            'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / i32(workGroupSizeX);\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), workGroupSizeX);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + i32(workGroupSizeX)) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), workGroupSizeX);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, sumOutType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {maxImplCPU} from './shared';\nimport {prodImplCPU} from './shared';\nimport {ReduceProgram} from '../reduce_webgpu';\nimport {reshape} from '../kernels/Reshape';\nimport {transpose} from '../kernels/Transpose';\n\ntype ReduceTypes = 'max'|'mean'|'min'|'prod'|'sum';\n\nexport function reduce(\n    x: TensorInfo, axis: number|number[], keepDims: boolean,\n    reduceType: ReduceTypes, backend: WebGPUBackend): TensorInfo {\n  const xRank = x.shape.length;\n  const toDispose = [];\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n\n  let input = x;\n  if (permutedAxes != null) {\n    input = transpose({inputs: {x}, attrs: {perm: permutedAxes}, backend});\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    toDispose.push(input);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(reduceType, axes, xRank);\n\n  const [reduceOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  let resOutShape = reduceOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    resOutShape = backend_util.expandShapeToKeepDim(reduceOutShape, origAxes);\n  }\n\n  let res;\n  if ((reduceType === 'max' || reduceType === 'prod') &&\n      backend.shouldExecuteOnCPU([input])) {\n    const xVals = backend.tensorMap.get(input.dataId).values as TypedArray;\n    switch (reduceType) {\n      case 'max':\n        const outValues = maxImplCPU(\n            xVals, util.sizeFromShape(reduceShape), resOutShape, x.dtype);\n        res = backend.makeTensorInfo(resOutShape, x.dtype, outValues);\n        break;\n      case 'prod':\n        const {outVals, outShape, outDtype} =\n            prodImplCPU(input.shape, input.dtype, xVals, axes);\n        res = backend.makeTensorInfo(outShape, outDtype, outVals);\n        break;\n      default:\n        throw new Error(\n            `${reduceType} CPU implementation is not yet supported.`);\n    }\n  } else {\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(input.shape);\n    const batchSize = xSize / inSize;\n\n    const reduceInfo = {windowSize: inSize, inSize, batchSize, outSize: 1};\n    const dtype = reduceType === 'mean' ? 'float32' : sumOutType(x.dtype);\n    const uniformData = [\n      {type: 'int32', data: [inSize]},\n    ];\n    const program = new ReduceProgram(reduceInfo, reduceType);\n    const reduced =\n        backend.runWebGPUProgram(program, [input], dtype, uniformData);\n    toDispose.push(reduced);\n\n    res = reshape({inputs: {x: reduced}, attrs: {shape: resOutShape}, backend});\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return res;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: WebGPUBackend, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  return reduce(x, reductionIndices, keepDims, 'max', backend);\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgpu',\n  kernelFunc: max as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function mean(\n    args: {inputs: MeanInputs, attrs: MeanAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'mean', backend);\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'webgpu',\n  kernelFunc: mean as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool2DProgram} from '../pool2d_webgpu';\nimport {PoolWithFilterSizeEqualsOneProgram} from '../pool_filtersizeone_webgpu';\n\nimport {identity} from './Identity';\nimport {max} from './Max';\nimport {mean} from './Mean';\nimport {reshape} from './Reshape';\n\ntype PoolType = 'max'|'avg';\nexport function poolImpl(\n    x: TensorInfo, convInfo: backend_util.Conv2DInfo, poolType: PoolType,\n    backend: WebGPUBackend): TensorInfo {\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    return identity({inputs: {x}, backend});\n  }\n\n  if (convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.filterHeight === convInfo.inHeight && convInfo.batchSize === 1 &&\n      convInfo.padInfo.type === 'VALID') {\n    const length = x.shape.length;\n    const reshapeX = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: [\n          x.shape[length - 3] * x.shape[length - 2] /* height * width */,\n          x.shape[length - 1] /* channel */\n        ]\n      }\n    });\n    let reduceX;\n    if (poolType === 'avg') {\n      reduceX = mean(\n          {inputs: {x: reshapeX}, backend, attrs: {axis: 0, keepDims: false}});\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      reduceX = max({\n        inputs: {x: reshapeX},\n        backend,\n        attrs: {reductionIndices: 0, keepDims: false}\n      });\n    }\n\n    const result = reshape(\n        {inputs: {x: reduceX}, backend, attrs: {shape: convInfo.outShape}});\n    backend.disposeData(reshapeX.dataId);\n    backend.disposeData(reduceX.dataId);\n    return result;\n  }\n\n  let program: Pool2DProgram|PoolWithFilterSizeEqualsOneProgram;\n  const dimensions =\n      [{type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}];\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1) {\n    program = new PoolWithFilterSizeEqualsOneProgram(convInfo);\n  } else {\n    if (poolType === 'avg') {\n      program = new Pool2DProgram(convInfo, 'avg');\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      program = new Pool2DProgram(convInfo, 'max');\n    }\n\n    dimensions.push(\n        {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        },\n        {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n          type: 'int32',\n          data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x], x.dtype, dimensions);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function avgPool(\n    args: {inputs: AvgPoolInputs, backend: WebGPUBackend, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'avg', backend);\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'webgpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  return batchMatMulImpl({a, b, transposeA, transposeB, backend});\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'webgpu',\n  kernelFunc: batchMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SliceProgram implements WebGPUProgram {\n  variableNames = ['source'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  rank: number;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  start: number[];\n  size = true;\n\n  constructor(start: number[], destSize: number[]) {\n    this.outputShape = destSize;\n    this.rank = destSize.length;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.start = start;\n    this.uniforms = `start : ${getCoordsDataType(start.length)}, `;\n    this.shaderKey = 'slice';\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.rank);\n    const sourceCoords = getCoords(this.rank);\n    let coordSum;\n    if (this.start.length === 1) {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc = uniforms.start + coords;`;\n      });\n    } else {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc.${coords[i]} = uniforms.start.${\n            getCoordsXYZ(i)} + coords.${coords[i]};`;\n      });\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          var sourceLoc : ${dtype};\n          let coords = getCoordsFromIndex(index);\n          ${coordSum.join('\\n')}\n          setOutputAtIndex(index, getSource(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nconst coords = ['x', 'y', 'z', 'w', 'u', 'v'];\n\nfunction getCoords(rank: number): string {\n  if (rank === 1) {\n    return 'sourceLoc';\n  } else if (rank <= 6) {\n    return coords.slice(0, rank).map(coord => `sourceLoc.${coord}`).join(',');\n  } else {\n    throw Error(`Slicing for rank ${rank} is not yet supported`);\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_webgpu';\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: WebGPUBackend, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xBufferInfo = backend.tensorMap.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xBufferInfo.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // TODO(xing.xu): Add shadow slice support.\n  const program = new SliceProgram($begin, $size);\n  const uniformData = [{type: 'int32', data: $begin}];\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport const batchToSpaceND = (args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: WebGPUBackend,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'batchToSpaceND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const toDispose = [];\n\n  const reshapedIntermediate =\n      reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const transposedIntermediate = transpose(\n      {inputs: {x: reshapedIntermediate}, backend, attrs: {perm: permuted}});\n  const reshapedIntermediate2 = reshape({\n    inputs: {x: transposedIntermediate},\n    backend,\n    attrs: {shape: reshapedPermuted}\n  });\n  const sliced = slice({\n    inputs: {x: reshapedIntermediate2},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  toDispose.push(reshapedIntermediate);\n  toDispose.push(transposedIntermediate);\n  toDispose.push(reshapedIntermediate2);\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return sliced;\n};\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'webgpu',\n  kernelFunc: batchToSpaceND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {notEqualImplCPU as cpuNotEqual} from '../kernel_utils/shared';\n\nexport const notEqual = binaryKernelFunc({\n  opType: BinaryOpType.NOT_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuNotEqual\n});\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'webgpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function real(args: {inputs: RealInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.real}, backend});\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'webgpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function int(input: TensorInfo, backend: WebGPUBackend): TensorInfo {\n  const program = new UnaryOpProgram(input.shape, UnaryOpType.TO_INT);\n  const output = backend.runWebGPUProgram(program, [input], 'int32');\n  return {dataId: output.dataId, shape: output.shape, dtype: output.dtype};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BinaryInputs, Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {castImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {notEqual} from './NotEqual';\nimport {real} from './Real';\n\nimport {int} from '../kernel_utils/int';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: WebGPUBackend, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO: Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeData(floatX.dataId);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n    backend.disposeData(realPart.dataId);\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const values = backend.tensorMap.get(x.dataId).values as TypedArray;\n    const [resultShape, resultType, resultData] =\n        castImplCPU(values, x.shape, x.dtype, dtype);\n    return backend.makeTensorInfo(resultShape, resultType, resultData);\n  }\n\n  if (dtype === 'int32') {\n    return int(x, backend);\n  }\n\n  if (dtype === 'bool') {\n    const zerosTensorInfo = backend.makeTensorInfo(\n        [], 'bool', util.getTypedArrayFromDType('bool', 1));\n\n    const binaryInputs: BinaryInputs = {a: x, b: zerosTensorInfo};\n\n    const result = notEqual({inputs: binaryInputs, backend}) as TensorInfo;\n    backend.disposeData(zerosTensorInfo.dataId);\n    return result;\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'webgpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {ceilImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const ceil =\n    unaryKernelFunc({opType: UnaryOpType.CEIL, cpuKernelImpl: ceilImplCPU});\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'webgpu',\n  kernelFunc: ceil\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 4;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  isVec4 = true;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'clipVec4';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          var clampedValue : vec4<f32>;\n          for (var i = 0; i < 4; i = i + 1) {\n            if (isnan(value[i])) {\n              clampedValue[i] = value[i];\n            } else {\n              clampedValue[i] = clamp(value[i], uniforms.minVal, uniforms.maxVal);\n            }\n          }\n\n          setOutputAtIndex(index, clampedValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  minVal: number;\n  maxVal: number;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = 'clip';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          if (isnan(value)) {\n            setOutputAtIndex(index, value);\n            return;\n          }\n          setOutputAtIndex(index, clamp(value, uniforms.minVal, uniforms.maxVal));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, ClipByValueInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {ClipVec4Program} from '../clip_vec4_webgpu';\nimport {ClipProgram} from '../clip_webgpu';\n\nexport function clipByValue(args: {\n  inputs: ClipByValueInputs,\n  backend: WebGPUBackend,\n  attrs: ClipByValueAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {clipValueMin, clipValueMax} = attrs;\n\n  let program: ClipProgram|ClipVec4Program;\n  const uniformData = [\n    {type: 'float32', data: [clipValueMin]},\n    {type: 'float32', data: [clipValueMax]}\n  ];\n  if (util.sizeFromShape(x.shape) % 4 === 0) {\n    program = new ClipVec4Program(x.shape);\n  } else {\n    program = new ClipProgram(x.shape);\n  }\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'webgpu',\n  kernelFunc: clipByValue as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ConcatProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = '';\n  workPerThread = 1;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  offsetLength: number;\n\n  constructor(shapes: Array<[number, number]>) {\n    this.outputShape =\n        backend_util.computeOutShape(shapes, 1 /* axis */) as [number, number];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.offsetLength = shapes.length - 1;\n    for (let i = 0; i < this.offsetLength; i++) {\n      this.uniforms += `offset${i} : i32,`;\n    }\n    this.shaderKey = 'concat';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    if (this.offsetLength > 0) {\n      snippets.push(\n          `if (yC < uniforms.offset0){ setOutputAtCoords(coords.x, coords.y, getT0(yR, yC)); }`);\n      for (let i = 1; i < this.offsetLength; i++) {\n        snippets.push(\n            `else if (yC < uniforms.offset${[i]}){ ` +\n            `setOutputAtCoords(coords.x, coords.y, getT${\n                i}(yR, yC - uniforms.offset${i - 1})); }`);\n      }\n      const lastIndex = this.offsetLength;\n      const lastShiftIndex = this.offsetLength - 1;\n      snippets.push(`else { setOutputAtCoords(coords.x, coords.y, getT${\n          lastIndex}(yR, yC - uniforms.offset${lastShiftIndex})); }`);\n    } else {\n      snippets.push(`setOutputAtCoords(coords.x, coords.y, getT0(yR, yC));`);\n    }\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            let yR = coords.x;\n            let yC = coords.y;\n\n            ${snippets.join('\\n        ')}\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function imag(args: {inputs: ImagInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.imag}, backend});\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'webgpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, ConcatInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ConcatProgram} from '../concat_webgpu';\nimport {concatImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concatImpl(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend): TensorInfo {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeData(r.dataId));\n    imags.forEach(i => backend.disposeData(i.dataId));\n    backend.disposeData(realConcated.dataId);\n    backend.disposeData(imagConcated.dataId);\n\n    return result;\n  }\n\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgpu doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = tensors2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    const outShape =\n        backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals =\n        concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n\n    const finalOutShape =\n        backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n\n    tensors2D.forEach(t => backend.disposeData(t.dataId));\n\n    return outInfo;\n  }\n\n  // There is a storage buffer limitation in compute stage, one for output so\n  // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1\n  const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;\n  if (inputs.length > maxInputNum) {\n    const reducedInputs = [];\n    for (let i = 0; i < inputs.length; i += maxInputNum) {\n      const subArray = inputs.slice(i, i + maxInputNum);\n      reducedInputs.push(concatImpl(subArray, axis, backend));\n    }\n    const result = concatImpl(reducedInputs, axis, backend);\n\n    for (const i of reducedInputs) {\n      backend.disposeData(i.dataId);\n    }\n\n    return result;\n  }\n\n  const {tensors2D, outShape} = computeTensors2D(inputs, axis, backend);\n  const shapes = (tensors2D).map(t => t.shape as [number, number]);\n  const program = new ConcatProgram(shapes);\n\n  const uniformData: Array<{type: string; data: number[]}> = [];\n  const offsets: number[] = new Array(shapes.length - 1);\n  if (offsets.length > 0) {\n    offsets[0] = shapes[0][1];\n    uniformData.push({type: 'int32', data: [offsets[0]]});\n    for (let i = 1; i < offsets.length; i++) {\n      offsets[i] = offsets[i - 1] + shapes[i][1];\n      uniformData.push({type: 'int32', data: [offsets[i]]});\n    }\n  }\n\n  const res = backend.runWebGPUProgram(\n      program, tensors2D, tensors2D[0].dtype, uniformData);\n  tensors2D.forEach(r => backend.disposeData(r.dataId));\n\n  const reshapedResult =\n      reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n  backend.disposeData(res.dataId);\n  return reshapedResult;\n}\n\nfunction computeTensors2D(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend) {\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(t => reshape({\n                                 inputs: {x: t},\n                                 backend,\n                                 attrs: {\n                                   shape: [\n                                     util.sizeFromShape(t.shape.slice(0, axis)),\n                                     util.sizeFromShape(t.shape.slice(axis))\n                                   ]\n                                 }\n                               }));\n\n  return {tensors2D, outShape};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\n\nexport function concat(\n    args: {inputs: ConcatInputs, attrs: ConcatAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  const outShape =\n      backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  return concatImpl($inputs, $axis, backend);\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'webgpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkGroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dCommonSnippet(\n    isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean,\n    fitInner: boolean, addBias = false,\n    activation: backend_util.Activation = null,\n    hasPreluActivationWeights = false, innerElementSizeX = 4,\n    innerElementSizeW = 4, innerElementSize = 4) {\n  const getXSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'resData = x[xIndex];';\n      case 3:\n        return 'resData = vec3<f32>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);';\n      case 4:\n        return 'resData = x[xIndex / 4];';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return W[row * uniforms.wShape[3] + colIn];';\n      case 4:\n        return 'return W[row * uniforms.wShape[3] / 4 + colIn];';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, xRow, xCol, xCh);\n      ` :\n                                         `\n      let coord = vec4<i32>(batch, xCh, xRow, xCol);\n      `;\n\n  const coordResSnippet = isChannelsLast ? `\n      let coords = vec4<i32>(\n        batch,\n        row / outWidth,\n        row % outWidth,\n        col);\n      ` :\n                                           `\n      let coords = vec4<i32>(\n        batch,\n        row,\n        col / outWidth,\n        col % outWidth);\n      `;\n\n  const xHight = isChannelsLast ? 'uniforms.xShape[1]' : 'uniforms.xShape[2]';\n  const xWidth = isChannelsLast ? 'uniforms.xShape[2]' : 'uniforms.xShape[3]';\n  const row = isChannelsLast ? 'row' : 'col';\n  const col = isChannelsLast ? 'col' : 'row';\n  const readXSnippet = `\n      let inChannels = uniforms.wShape[2];\n      let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (uniforms.filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % uniforms.filterDims[1];\n      let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];\n      let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];\n      let xCh = ${col} % inChannels;\n      var resData = ${typeSnippet(innerElementSizeX)}(0.0);\n      // The bounds checking is always needed since we use it to pad zero for\n      // the 'same' padding type.\n      if (xRow >= 0 && xRow < ${xHight} && xCol >= 0 && xCol < ${xWidth}) {\n        ${coordASnippet}\n        let xIndex = getIndexFromCoords4D(coord, uniforms.xShape);\n        ${getXSnippet(innerElementSizeX)}\n      }\n      return resData;`;\n\n  const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n      let col = colIn * ${innerElementSizeX};\n      ${readXSnippet}` :\n                                                            `\n      let col = colIn * ${innerElementSizeX};\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`) :\n                                   (fitInner && fitBOuter ? `\n      let col = colIn * ${innerElementSizeX};\n      ${readXSnippet}` :\n                                                            `\n      let col = colIn * ${innerElementSizeX};\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`);\n\n  const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n  const resType = typeSnippet(innerElementSize);\n  const aType = isChannelsLast ? typeSnippet(innerElementSizeX) :\n                                 typeSnippet(innerElementSizeW);\n  const bType = isChannelsLast ? typeSnippet(innerElementSizeW) :\n                                 typeSnippet(innerElementSizeX);\n  const userCode = `\n      ${\n      activationFnSnippet(\n          activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n      fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n        ${isChannelsLast ? sampleX : sampleW}\n      }\n\n      fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n        ${isChannelsLast ? sampleW : sampleX}\n      }\n\n      fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n        let col = colIn * ${innerElementSize};\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n        {\n        var value = valueIn;\n        let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n        ${coordResSnippet}\n        ${biasActivationSnippet(addBias, activation)}\n        setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }`;\n  return userCode;\n}\n\nexport class Conv2DMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableTypes: string[];\n  uniforms =\n      `filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>, dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workGroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileAOuter: number;\n  tileBOuter: number;\n  tileInner: number;\n  innerElementSize: number;\n  isVec4?: boolean;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, dimAOuter: number, dimBOuter: number,\n      dimInner: number, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false, sequentialAccessByThreads = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.isVec4 =\n        (((convInfo.inChannels % 4 === 0 || convInfo.inChannels % 3 === 0) &&\n          this.isChannelsLast) ||\n         (convInfo.outWidth % 4 === 0 && !this.isChannelsLast)) &&\n        convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = this.isChannelsLast ? {x: [3], y: [1, 2], z: [0]} :\n                                                {x: [2, 3], y: [1], z: [0]};\n    this.workGroupSize = computeWorkGroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      if (this.isChannelsLast && convInfo.inChannels % 4 !== 0) {\n        this.innerElementSize = 3;\n        this.variableTypes = ['f32', 'vec4<f32>'];\n      } else {\n        this.innerElementSize = 4;\n        this.variableTypes = ['vec4<f32>', 'vec4<f32>'];\n      }\n\n      if (addBias) {\n        this.variableNames.push('bias');\n        this.variableTypes.push('vec4<f32>');\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n        this.variableTypes.push('vec4<f32>');\n      }\n    } else {\n      this.innerElementSize = this.elementsPerThread[0];\n      if (addBias) {\n        this.variableNames.push('bias');\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n      }\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    this.tileAOuter = this.workGroupSize[1] * this.elementsPerThread[1];\n    this.tileBOuter = this.workGroupSize[0] * this.elementsPerThread[0];\n    this.tileInner = Math.max(\n        this.workGroupSize[0] * this.innerElementSize, this.workGroupSize[1]);\n\n    this.fitAOuter = dimAOuter % this.tileAOuter === 0;\n    this.fitBOuter = dimBOuter % this.tileBOuter === 0;\n    this.fitInner = dimInner % this.tileInner === 0;\n\n    this.shaderKey = `conv2DMM_${this.elementsPerThread}_${this.activation}}_${\n        this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${\n        this.innerElementSize}_${this.isChannelsLast}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(\n            this.elementsPerThread, this.workGroupSize, !this.isChannelsLast,\n            this.tileInner) :\n        makeMatMulPackedSource(\n            this.elementsPerThread, this.workGroupSize, !this.isChannelsLast,\n            this.tileInner, false, null, this.sequentialAccessByThreads);\n    const elementsSize =\n        this.isVec4 ? [this.innerElementSize, 4, 4] : [1, 1, 1];\n    const userCode = `\n    ${\n        conv2dCommonSnippet(\n            this.isChannelsLast, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.addBias, this.activation, this.hasPreluActivationWeights,\n            elementsSize[0], elementsSize[1], elementsSize[2])}\n    ${matMulSource}\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class Conv2DNaiveProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms =\n      'filterDims: vec2<i32>, pad: vec2<i32>, stride: vec2<i32>, dilation: vec2<i32>,';\n  workGroupSize: [number, number, number] = [4, 4, 8];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.dispatchLayout = this.isChannelsLast ? {x: [2], y: [1], z: [0, 3]} :\n                                                {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `conv2dnaive_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n       ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, false, 4)}\n       fn readInp(batch : i32, row : i32, col : i32, chan : i32) -> f32{\n         let coords = vec4<i32>(batch, row, col, chan);\n         if (coordsInBounds4D(coords, uniforms.xShape)) {\n           return  getX(batch, row, col, chan);\n         } else {\n          return 0.0;\n         }\n       }\n       fn readFilt(row : i32, col : i32, xChannel : i32, outChannel : i32) -> f32{\n         let coords = vec4<i32>(row, col, xChannel, outChannel);\n         if(coordsInBounds4D(coords, uniforms.wShape)) {\n           return getW(row, col, xChannel, outChannel);\n          } else {\n            return 0.0;\n          }\n       }\n       fn writeResult(batch : i32, row : i32, col : i32, chan : i32, valueIn : f32) {\n         let coords = ${\n        this.isChannelsLast ? `vec4<i32>(batch, row, col, chan);` :\n                              `vec4<i32>(batch, chan, row, col);`}\n         if (coordsInBounds4D(coords, uniforms.outShape)) {\n           var value = valueIn;\n           ${biasActivationSnippet(this.addBias, this.activation)}\n           setOutputAtCoords(coords.x, coords.y, coords.z, coords.w, value);\n         }\n       }\n       ${main('index')} {\n         let coords = getOutputCoords();\n         let batch = coords[0];\n         let outChannel = ${this.isChannelsLast ? `coords[3];` : `coords[1];`}\n         let outRow = ${this.isChannelsLast ? `coords[1];` : `coords[2];`}\n         let outCol = ${this.isChannelsLast ? `coords[2];` : `coords[3];`}\n         var acc : f32 = 0.0;\n         for (var row = 0; row < uniforms.filterDims[0]; row = row + 1) {\n           for (var col = 0; col < uniforms.filterDims[1]; col = col + 1) {\n             let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * row - uniforms.pad[0];\n             let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * col - uniforms.pad[1];\n             for (var xChannel = 0; xChannel < ${\n        this.isChannelsLast ? `uniforms.xShape[3];` :\n                              `uniforms.xShape[1];`} xChannel = xChannel + 1) {\n               ${\n        this.isChannelsLast ? `let v = readInp(batch, xRow, xCol, xChannel);` :\n                              `let v = readInp(batch, xChannel, xRow, xCol);`}\n               let f = readFilt(row, col, xChannel, outChannel);\n               acc = acc + v * f;\n             }\n           }\n         }\n         writeResult(batch, outRow, outCol, outChannel, acc);\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DMMProgram} from '../conv2d_mm_webgpu';\nimport {Conv2DNaiveProgram} from '../conv2d_naive_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\n\nimport {batchMatMulImpl} from './BatchMatMul_impl';\nimport {reshape} from './Reshape';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// conv2dByMatMul fuses height and width into one dimension to compute\n// batchMatMul, so bias and activation weights are also supposed to fuse the two\n// dimensions into one.\n//\n// This function computes the target shape for fusing height and width\n// dimensions. Returning null means the shape is already compatible.\nfunction getShapeForBatchMatMul(\n    shape: number[], isChannelsLast: boolean): number[] {\n  const length = shape.length;\n  if (length >= 3) {\n    return isChannelsLast ?\n        [\n          ...shape.slice(0, -3) /* batch */,\n          shape[length - 3] * shape[length - 2] /* height * width */,\n          shape[length - 1] /* channel */\n        ] :\n        [\n          ...shape.slice(0, -3) /* batch */, shape[length - 3] /* channel */,\n          shape[length - 2] * shape[length - 1] /* height * width */\n        ];\n  } else if (!isChannelsLast && length === 1 && shape[0] > 1) {\n    return [shape[0], 1];\n  } else {\n    return null;\n  }\n}\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nfunction conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = isChannelsLast ? false : true;\n  const transposeB = false;\n\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const intermediates: TensorInfo[] = [];\n  let xReshaped;\n  let filterReshaped;\n\n  if (sameSize) {\n    const sharedDim =\n        convInfo.inHeight * convInfo.inWidth * convInfo.inChannels;\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {shape: [1, convInfo.batchSize, sharedDim]}\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, sharedDim, convInfo.outChannels]}\n    });\n  } else {\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: isChannelsLast ?\n            [\n              convInfo.batchSize, convInfo.inHeight * convInfo.inWidth,\n              convInfo.inChannels\n            ] :\n            [\n              convInfo.batchSize, convInfo.inChannels,\n              convInfo.inHeight * convInfo.inWidth\n            ]\n      }\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n  }\n  intermediates.push(xReshaped);\n  intermediates.push(filterReshaped);\n\n  if (preluActivationWeights != null) {\n    const targetShape =\n        getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);\n    if (targetShape != null) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: targetShape}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n  }\n\n  if (bias != null) {\n    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);\n    if (targetShape != null) {\n      bias = reshape({inputs: {x: bias}, backend, attrs: {shape: targetShape}});\n      intermediates.push(bias);\n    }\n  }\n\n  const result = batchMatMulImpl({\n    a: isChannelsLast ? xReshaped : filterReshaped,\n    b: isChannelsLast ? filterReshaped : xReshaped,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    activation,\n    preluActivationWeights,\n    leakyreluAlpha\n  });\n  const out = reshape(\n      {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n  intermediates.push(result);\n\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n\n  return out;\n}\n\nexport function conv2DImpl({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const useNaiveConv2d = env().getBool('WEBGPU_USE_NAIVE_CONV2D_DEBUG');\n\n  if (!useNaiveConv2d &&\n      (sameSize ||\n       (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n        convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n        convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n        (convInfo.padInfo.type === 'SAME' ||\n         convInfo.padInfo.type === 'VALID')))) {\n    return conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  }\n\n  let program: WebGPUProgram;\n  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [...padInfo]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}\n  ];\n  if (useNaiveConv2d) {\n    program = new Conv2DNaiveProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n  } else {\n    const dimAOuter = isChannelsLast ? convInfo.outHeight * convInfo.outWidth :\n                                       convInfo.outChannels;\n    const dimBOuter = isChannelsLast ? convInfo.outChannels :\n                                       convInfo.outHeight * convInfo.outWidth;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.inChannels;\n    dimensions.push(\n        {type: 'int32', data: [dimAOuter]}, {type: 'int32', data: [dimBOuter]},\n        {type: 'int32', data: [dimInner]});\n\n    // Experiments show that sequential access is more friendly for Intel GPUs.\n    const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n    program = new Conv2DMMProgram(\n        convInfo, dimAOuter, dimBOuter, dimInner, hasBias, activation,\n        hasPreluActivationWeights, sequentialAccessByThreads);\n  }\n\n  const intermediates: TensorInfo[] = [];\n  const inputVar: TensorInfo[] = [x, filter];\n  if (hasBias) {\n    if (!isChannelsLast && bias.shape.length === 1) {\n      bias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      intermediates.push(bias);\n    }\n    inputVar.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    if (!isChannelsLast && preluActivationWeights.shape.length === 1) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n    inputVar.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const out = backend.runWebGPUProgram(program, inputVar, x.dtype, dimensions);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return out;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function conv2d(\n    args: {inputs: Conv2DInputs, attrs: Conv2DAttrs, backend: WebGPUBackend}) {\n  const {inputs, attrs, backend} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n  return conv2DImpl({x, filter, convInfo, backend});\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'webgpu',\n  kernelFunc: conv2d as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {typeSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkGroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dTransposeCommonSnippet(innerElementSize = 4) {\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return W[getIndexFromCoords4D(coord, uniforms.wShape)];';\n      case 4:\n        return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, uniforms.wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, uniforms.wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, uniforms.wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, uniforms.wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n\n  const readASnippet = `\n      let outRow = row / uniforms.outShape[2];\n      let outCol = row % uniforms.outShape[2];\n\n      let WRow = col / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n      let WCol = col / uniforms.outBackprop[3] % uniforms.filterDims[1];\n      let xR = f32(outRow - uniforms.pads[0] + WRow) / f32(uniforms.stride[0]);\n      let xC = f32(outCol - uniforms.pads[1] + WCol) / f32(uniforms.stride[1]);\n      if (xR < 0.0 || xR >= f32(uniforms.outBackprop[1]) || fract(xR) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(uniforms.outBackprop[2]) || fract(xC) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      let coord = vec4<i32>(\n          batch,\n          i32(xR),\n          i32(xC),\n          col % uniforms.outBackprop[3]);\n      return x[getIndexFromCoords4D(coord, uniforms.xShape)/${\n      innerElementSize}];`;\n\n  const sampleA = `if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readASnippet}\n      }\n      return ${typeSnippet(innerElementSize)}(0.0);`;\n\n  const userCode = `\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    let col = colIn * ${innerElementSize};\n    ${sampleA}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    let col = colIn * ${innerElementSize};\n    let coordX = uniforms.filterDims.x - 1 -\n        row / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n    let coordY = uniforms.filterDims.y - 1 -\n        (row / uniforms.outBackprop[3]) % uniforms.filterDims[1];\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter &&\n        coordX >= 0 && coordY >= 0) {\n      let rowInner = row % uniforms.outBackprop[3];\n      let coord = vec4<i32>(coordX, coordY, col, rowInner);\n      ${getWSnippet(innerElementSize)}\n    }\n    return ${typeSnippet(innerElementSize)}(0.0);\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${\n      typeSnippet(innerElementSize)}) {\n    let col = colIn * ${innerElementSize};\n    if (row < uniforms.dimAOuter && (col + ${\n      innerElementSize - 1}) < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outCoord = vec4<i32>(\n          batch,\n          row / uniforms.outShape[2],\n          row % uniforms.outShape[2],\n          col);\n      result[getIndexFromCoords4D(outCoord, uniforms.outShape)/${\n      innerElementSize}] = value;\n    }\n  }`;\n  return userCode;\n}\n\nexport class Conv2DDerInputMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableTypes: string[];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, stride : vec2<i32>, outBackprop : vec4<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,';\n  workGroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  isVec4?: boolean;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n    this.isVec4 =\n        convInfo.inChannels % 4 === 0 && convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = {x: [3], y: [1, 2], z: [0]};\n    this.workGroupSize = computeWorkGroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      this.variableTypes = ['vec4<f32>', 'f32'];\n    }\n\n    this.shaderKey =\n        `conv2DDerInputMM_${this.isVec4}_${this.elementsPerThread}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(this.elementsPerThread, this.workGroupSize) :\n        makeMatMulPackedSource(this.elementsPerThread, this.workGroupSize);\n    const userCode = `\n    ${conv2dTransposeCommonSnippet(this.isVec4 ? 4 : 1)}\n    ${matMulSource}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Conv2DDerInputProgram implements WebGPUProgram {\n  variableNames = ['dy', 'W'];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, stride : vec2<i32>, outBackprop : vec4<i32>,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.shaderKey = `conv2DDerInput_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const rowDim = this.isChannelsLast ? 1 : 2;\n    const colDim = this.isChannelsLast ? 2 : 3;\n    const channelDim = this.isChannelsLast ? 3 : 1;\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d1 = coords[${channelDim}];\n\n        let dyCorner = vec2<i32>(coords[${rowDim}], coords[${\n        colDim}]) - uniforms.pads;\n        let dyRCorner = dyCorner.x;\n        let dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {\n          let dyR = (f32(dyRCorner) + f32(wR)) / f32(uniforms.stride.x);\n          let wRPerm = uniforms.filterDims.x - 1 - wR;\n          if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) || fract(dyR) > 0.0 ||\n              wRPerm < 0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {\n            let dyC = (f32(dyCCorner) + f32(wC)) / f32(uniforms.stride.y);\n            let wCPerm = uniforms.filterDims.y - 1 - wC;\n            if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||\n                fract(dyC) > 0.0 || wCPerm < 0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            for (var d2 = 0; d2 < uniforms.outBackprop[3]; d2 = d2 + 1) {\n              if (${this.isChannelsLast}) {\n                let xValue = getDy(batch, idyR, idyC, d2);\n                let wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd = dotProd + xValue * wValue;\n              } else {\n                let xValue = getDy(batch, d2, idyR, idyC);\n                let wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd = dotProd + xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DDerInputMMProgram} from '../conv_backprop_mm_webgpu';\nimport {Conv2DDerInputProgram} from '../conv_backprop_webgpu';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  attrs: Conv2DBackpropInputAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.batchSize, convInfo.outHeight, convInfo.outWidth,\n        convInfo.outChannels\n      ]\n    },\n  ];\n  let program: Conv2DDerInputProgram|Conv2DDerInputMMProgram;\n  // When filter size is small, Conv2DDerInputProgram is much faster than\n  // Conv2DDerInputMMProgram.\n  if (env().getBool('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE') ||\n      convInfo.filterHeight <= 2 && convInfo.filterWidth <= 2 &&\n          convInfo.outChannels <= 16 && convInfo.inChannels === 1) {\n    program = new Conv2DDerInputProgram(convInfo);\n  } else {\n    program = new Conv2DDerInputMMProgram(convInfo);\n    const dimAOuter = convInfo.inHeight * convInfo.inWidth;\n    const dimBOuter = convInfo.inChannels;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.outChannels;\n    dimensions.push(\n        {type: 'uint32', data: [dimAOuter]},\n        {type: 'uint32', data: [dimBOuter]},\n        {type: 'uint32', data: [dimInner]});\n  }\n  return backend.runWebGPUProgram(program, [dy, filter], 'float32', dimensions);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: conv2DBackpropInput as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cos = unaryKernelFunc({opType: UnaryOpType.COS});\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'webgpu',\n  kernelFunc: cos\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cosh = unaryKernelFunc({opType: UnaryOpType.COSH});\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'webgpu',\n  kernelFunc: cosh\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class CropAndResizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['Image', 'Boxes', 'BoxInd'];\n  uniforms = 'extrapolationValue : f32,';\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  methodId: number;\n  cropHeightBiggerThan1: boolean;\n  cropWidthBiggerThan1: boolean;\n  size = true;\n\n  constructor(\n      channnel: number, boxShape: [number, number], cropSize: [number, number],\n      method: 'bilinear'|'nearest') {\n    const [numBoxes, ] = boxShape;\n    this.outputShape = [numBoxes, cropSize[0], cropSize[1], channnel];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.methodId = method === 'bilinear' ? 1 : 0;\n    this.cropHeightBiggerThan1 = this.outputShape[1] > 1;\n    this.cropWidthBiggerThan1 = this.outputShape[2] > 1;\n    this.shaderKey = `cropAndResize_${this.methodId}_${\n        this.cropHeightBiggerThan1}_${this.cropWidthBiggerThan1}`;\n  }\n\n  getUserCode(): string {\n    const [inputHeightFloat, inputWidthFloat] =\n        [`f32(uniforms.imageShape[1] - 1)`, `f32(uniforms.imageShape[2] - 1)`];\n\n    const [heightRatio, heightScale, inY] = this.cropHeightBiggerThan1 ?\n        [\n          `(${inputHeightFloat} / f32(uniforms.outShape[1] - 1))`,\n          '(y2-y1) * height_ratio',\n          `y1*${inputHeightFloat} + f32(y)*(height_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (y1+y2) * ${inputHeightFloat}`,\n        ];\n    const [widthRatio, widthScale, inX] = this.cropWidthBiggerThan1 ?\n        [\n          `(${inputWidthFloat} / f32(uniforms.outShape[2] - 1))`,\n          '(x2-x1) * width_ratio',\n          `x1*${inputWidthFloat} + f32(x)*(width_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (x1+x2) * ${inputWidthFloat}`,\n        ];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let height_ratio = f32(${heightRatio});\n        let width_ratio = f32(${widthRatio});\n        let b = coords[0];\n        let y = coords[1];\n        let x = coords[2];\n        let d = coords[3];\n        // get box vals\n        let y1 = getBoxes(b, 0);\n        let x1 = getBoxes(b, 1);\n        let y2 = getBoxes(b, 2);\n        let x2 = getBoxes(b, 3);\n        // get image in batch index\n        let bInd = i32(round(getBoxInd(b)));\n        if(bInd < 0 || bInd >= uniforms.outShape[0]) {\n          return;\n        }\n        let height_scale = ${heightScale};\n        let width_scale = ${widthScale};\n        let in_y = ${inY};\n        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let in_x = ${inX};\n        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let sourceFracIndexCR = vec2<f32>(in_x,in_y);\n        if(${this.methodId} == 1) {\n          // Compute the four integer indices.\n          let sourceFloorCR = vec2<i32>(sourceFracIndexCR);\n          let sourceCeilCR = vec2<i32>(ceil(sourceFracIndexCR));\n          let topLeft = getImage(bInd, sourceFloorCR.y, sourceFloorCR.x, d);\n          let bottomLeft = getImage(bInd, sourceCeilCR.y, sourceFloorCR.x, d);\n          let topRight = getImage(bInd, sourceFloorCR.y, sourceCeilCR.x, d);\n          let bottomRight = getImage(bInd, sourceCeilCR.y, sourceCeilCR.x, d);\n          let fracCR = sourceFracIndexCR - vec2<f32>(sourceFloorCR);\n          let top = topLeft + (topRight - topLeft) * fracCR.x;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          let newValue = top + (bottom - top) * fracCR.y;\n          setOutputAtIndex(index, newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          let sourceNearestCR = vec2<i32>(floor(\n            sourceFracIndexCR + vec2<f32>(0.5,0.5)));\n          let newValue = getImage(\n            bInd, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CropAndResizeProgram} from '../crop_and_resize_webgpu';\n\nexport const cropAndResize = (args: {\n  inputs: CropAndResizeInputs,\n  backend: WebGPUBackend,\n  attrs: CropAndResizeAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const program = new CropAndResizeProgram(\n      image.shape[3], boxes.shape as [number, number], cropSize, method);\n  const uniformData = [{type: 'float32', data: [extrapolationValue]}];\n  return backend.runWebGPUProgram(\n      program, [image, boxes, boxInd], 'float32', uniformData);\n};\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'webgpu',\n  kernelFunc: cropAndResize as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport enum CumOpType {\n  Prod = '*',\n  Sum = '+',\n}\n\nexport class CumProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workGroupSize: [number, number, number];\n  // pow(i32, i32) is not supported, use pow(f32, f32) instead.\n  uniforms = 'index : f32,';\n  size = true;\n  exclusive: boolean;\n  reverse: boolean;\n  op: CumOpType;\n\n  constructor(\n      op: CumOpType, shape: number[], exclusive: boolean, reverse: boolean) {\n    const workGroupSizeX = 128;\n    this.workGroupSize = [workGroupSizeX, 1, 1];\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.exclusive = exclusive;\n    this.reverse = reverse;\n    this.op = op;\n    this.shaderKey = `cum_${this.op}_${this.exclusive}_${this.reverse}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    const initVal = this.op === CumOpType.Prod ? '1.0' : '0.0';\n    const val = this.exclusive ? initVal :\n                                 `getX(${getCoords(rank, 'coords', this.op)})`;\n    const length = this.outputShape[this.outputShape.length - 1];\n    let condition = '';\n    let idxString = '';\n    // When exclusive is set, the cum op becomes roll op that copies the\n    // value from the previous index based on the direction specified by the\n    // reverse flag.\n    if (this.exclusive) {\n      condition = this.reverse ? `end != ${length - 1}` : 'end != 0';\n      idxString = this.reverse ? 'end + 1' : 'end - 1';\n    } else {\n      condition = this.reverse ? `end + pow2 < ${length}` : 'end >= pow2';\n      idxString = (this.reverse ? 'end + pow2' : 'end - pow2');\n    }\n    return `\n      ${main('index')} {\n       if (index < uniforms.size) {\n         var coords = getCoordsFromIndex(index);\n\n         let end = ${getFinalCoord(rank, 'coords', this.op)};\n         var val = ${val};\n         let pow2 = i32(pow(2.0, uniforms.index));\n         if (${condition}) {\n           let idx = ${idxString};\n           ${getFinalCoord(rank, 'coords', this.op)} = idx;\n           val ${this.op}= getX(${getCoords(rank, 'coords', this.op)});\n         }\n         setOutputAtIndex(index, val);\n       }\n      }\n    `;\n  }\n}\n\nfunction getCoords(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.x, ${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.x, ${name}.y, ${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n\nfunction getFinalCoord(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType, CumProgram} from '../cum_webgpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: WebGPUBackend, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGPU cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [i]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [0]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeData(result.dataId);\n    backend.disposeData(permutedX.dataId);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumprod, CumprodAttrs, CumprodInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumprod(\n    args: {inputs: CumprodInputs, backend: WebGPUBackend, attrs: CumprodAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Prod, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'webgpu',\n  kernelFunc: cumprod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: WebGPUBackend, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Sum, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgpu',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthToSpaceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  outputShape: number[];\n  dataFormat: string;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  uniforms = 'blockSize : i32,';\n\n  constructor(outputShape: number[], dataFormat: 'NHWC'|'NCHW') {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.shaderKey = `depthToSpace_${dataFormat}`;\n    this.dataFormat = dataFormat;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let h = ${this.getHeightCoordString()};\n          let w = ${this.getWidthCoordString()};\n          let d = ${this.getDepthCoordString()};\n\n          let in_h = h / uniforms.blockSize;\n          let offset_h = h % uniforms.blockSize;\n          let in_w = w / uniforms.blockSize;\n          let offset_w = w % uniforms.blockSize;\n          let offset_d = (offset_h * uniforms.blockSize + offset_w) *\n            ${this.getOutputDepthSize()};\n          let in_d = d + offset_d;\n\n          let rlt = ${this.getInputSamplingString()};\n          setOutputAtIndex(index, rlt);\n        }\n      }`;\n    return userCode;\n  }\n\n  private getHeightCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[1]`;\n    } else {\n      return `coords[2]`;\n    }\n  }\n\n  private getWidthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[2]`;\n    } else {\n      return `coords[3]`;\n    }\n  }\n\n  private getDepthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[3]`;\n    } else {\n      return `coords[1]`;\n    }\n  }\n\n  private getOutputDepthSize(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `uniforms.outShape[3]`;\n    } else {\n      return `uniforms.outShape[1]`;\n    }\n  }\n\n  private getInputSamplingString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `getX(b, in_h, in_w, in_d)`;\n    } else {\n      return `getX(b, in_d, in_h, in_w)`;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthToSpaceProgram} from '../depth_to_space_webgpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: WebGPUBackend,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  const batchSize = x.shape[0];\n  const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n  const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n  const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const outputShape = (dataFormat === 'NHWC') ?\n      [batchSize, outputHeight, outputWidth, outputDepth] :\n      [batchSize, outputDepth, outputHeight, outputWidth];\n\n  const uniformData = [\n    {type: 'int32', data: [blockSize]},\n  ];\n\n  const program = new DepthToSpaceProgram(outputShape, dataFormat);\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'webgpu',\n  kernelFunc: depthToSpace as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getWorkGroupSizeString, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class DepthwiseConv2DNCHWSharedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pad : vec2<i32>, inDims : vec2<i32>,`;\n  workGroupSize: [number, number, number] = [16, 16, 1];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  filterHeight: number;\n  filterWidth: number;\n\n  constructor(\n      outputShape: number[], filterHeight: number, filterWidth: number,\n      addBias = false, activation: backend_util.Activation = null,\n      hasPreluActivation = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.filterHeight = filterHeight;\n    this.filterWidth = filterWidth;\n    this.shaderKey = `depthwiseNCHW_${this.activation}_${this.filterHeight}_${\n        this.filterWidth}`;\n  }\n\n  getUserCode(): string {\n    const filterSize = this.filterWidth * this.filterHeight;\n    const workGroupSize =\n        this.workGroupSize[0] * this.workGroupSize[1] * this.workGroupSize[2];\n    const tileAHeight = this.workGroupSize[1] + this.filterHeight - 1;\n    const tileAWidth = this.workGroupSize[0] + this.filterWidth - 1;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHeight}>;\n      var<workgroup> mm_Bsub : array<array<f32, ${this.filterWidth}>, ${\n        this.filterHeight}>;\n      fn readX(batch : i32, channel : i32, row : i32, col : i32) -> f32 {\n        var value = 0.0;\n        if (row >=0 && row < uniforms.inDims[0] && col >=0 && col < uniforms.inDims[1])\n        {\n          value = getX(batch, channel, row, col);\n        }\n        return value;\n      }\n\n      ${getWorkGroupSizeString()}\n      fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n                @builtin(global_invocation_id) GlobalId : vec3<u32>,\n                @builtin(local_invocation_index) LocalIndex: u32,\n                @builtin(num_workgroups) NumWorkgroups: vec3<u32>) {\n        localId = LocalId;\n        globalId = GlobalId;\n        let localIndex = i32(LocalIndex);\n        numWorkgroups = NumWorkgroups;\n        let coords = getOutputCoords();\n        let batch = coords[0];\n        let xRCCorner = vec2<i32>(coords.zw) - uniforms.pad;\n        let channelMul = uniforms.wShape[3];\n        let d1 = coords[1] / channelMul;\n        let q = coords[1] % channelMul;\n\n        let inputRowStart = xRCCorner.x;\n        let inputColStart = xRCCorner.y;\n\n        let localRow = i32(localId.y);\n        let localCol = i32(localId.x);\n\n        // Load one tile of X into local memory.\n        for (var inputRow = localRow; inputRow < ${\n        tileAHeight}; inputRow = inputRow + ${this.workGroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n        tileAWidth}; inputCol = inputCol + ${this.workGroupSize[0]}) {\n            let rowOffset = inputRow - localRow;\n            let colOffset = inputCol - localCol;\n            mm_Asub[inputRow][inputCol] = readX(batch, d1, inputRowStart + rowOffset, inputColStart + colOffset);\n          }\n        }\n\n        // Load one tile of W into local memory.\n        var wIndex = localIndex;\n        ${\n        filterSize < workGroupSize ?\n            `if (wIndex < ${filterSize})` :\n            `for(; wIndex < ${filterSize}; wIndex = wIndex + ${workGroupSize})`}\n\n        {\n          let wRow = wIndex / ${this.filterWidth};\n          let wCol = wIndex % ${this.filterWidth};\n          mm_Bsub[wRow][wCol] = getW(wRow, wCol, d1, q);\n        }\n\n        workgroupBarrier();\n\n        var value = 0.0;\n        for (var wR = 0; wR < ${this.filterHeight}; wR = wR + 1) {\n          for (var wC = 0; wC < ${this.filterWidth}; wC = wC + 1) {\n            let xVal = mm_Asub[localRow + wR][localCol + wC];\n            let wVal = mm_Bsub[wR][wC];\n            value = fma(xVal, wVal, value);\n          }\n        }\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getWorkGroupSizeString, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class DepthwiseConv2DVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = 'pad : vec2<i32>, inDims : vec2<i32>,';\n  workGroupSize: [number, number, number] = [4, 4, 4];\n  workPerThread = 4;\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  isVec4 = true;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [4, this.workPerThread, 1]);\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n\n    this.shaderKey =\n        `depthwiseVec4_${activation}_${this.convInfo.filterHeight}_${\n            this.convInfo.filterWidth}_${this.convInfo.strideHeight}_${\n            this.convInfo.strideWidth}_${this.workPerThread}`;\n  }\n\n  getUserCode(): string {\n    const xNumber = (this.workPerThread - 1) * this.convInfo.strideWidth +\n        this.convInfo.filterWidth;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, true, 4)}\n      fn readX(batch : i32, row : i32, col : i32, channel : i32) -> vec4<f32> {\n        var value = vec4<f32>(0.0);\n        if (col >=0 && col < uniforms.inDims[1]) {\n          value = getX(batch, row, col, channel);\n        }\n        return value;\n      }\n\n      const strideHeight = ${this.convInfo.strideHeight};\n      const strideWidth = ${this.convInfo.strideWidth};\n      ${getWorkGroupSizeString()}\n      fn _start(@builtin(global_invocation_id) globalId: vec3<u32>) {\n        let batch = i32(globalId.z) / uniforms.outShape[1];\n        let r = i32(globalId.z) % uniforms.outShape[1];\n        let c = i32(globalId.y) * ${this.workPerThread};\n        let d1 = i32(globalId.x) * 4;\n        let xRCCorner = vec2<i32>(r, c) * vec2<i32>(strideHeight, strideWidth) - uniforms.pad;\n\n        let xRCorner = xRCCorner.x;\n        let xCCorner = xRCCorner.y;\n        var xVals : array<vec4<f32>, ${xNumber}>;\n        var dotProd : array<vec4<f32>, ${this.workPerThread}>;\n        for (var i = 0; i < ${this.workPerThread}; i++) {\n          dotProd[i] = vec4<f32>(0.0);\n        }\n\n        // Use constant instead of uniform can give better performance.\n        for (var wR = 0; wR < ${this.convInfo.filterHeight}; wR = wR + 1) {\n          let xR = xRCorner + wR;\n          if (xR >=0 && xR < uniforms.inDims[0]) {\n            for (var i = 0; i < ${xNumber}; i++) {\n              xVals[i] = readX(batch, xR, xCCorner + i, d1);\n            }\n            for (var wC = 0; wC < ${this.convInfo.filterWidth}; wC = wC + 1) {\n              let wValue = getW(wR, wC, d1, 0);\n              for (var i = 0; i < ${this.workPerThread}; i++) {\n                dotProd[i] = fma(xVals[i * strideWidth + wC], wValue, dotProd[i]);\n              }\n            }\n          }\n        }\n\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let coords = vec4<i32>(batch, r, c + i, d1);\n          if (coordsInBounds4D(coords, uniforms.outShape)) {\n            var value = dotProd[i];\n            ${biasActivationSnippet(this.addBias, this.activation)}\n            setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pad : vec2<i32>, inDims : vec2<i32>, filterHeight : i32,\n      filterWidth : i32, stride : vec2<i32>, dilation : vec2<i32>,`;\n  // This is an experimental value.\n  workGroupSize: [number, number, number] = [256, 1, 1];\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  isChannelsLast: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.shaderKey = `depthwise_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const getXSnippet = this.isChannelsLast ? 'getX(batch, xR, xC, d1);' :\n                                              'getX(batch, d1, xR, xC);';\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      ${main()} {\n        let coords = getOutputCoords();\n        let batch = coords[0];\n        let xRCCorner = vec2<i32>(coords.${\n        this.isChannelsLast ? 'yz' : 'zw'}) * uniforms.stride - uniforms.pad;\n        let d2 = coords[${this.isChannelsLast ? 3 : 1}];\n        let channelMul = uniforms.wShape[3];\n        let d1 = d2 / channelMul;\n        let q = d2 % channelMul;\n\n        let inputRowStart = xRCCorner.x;\n        let inputColStart = xRCCorner.y;\n        let inputRowEnd = inputRowStart + uniforms.filterHeight *\n            uniforms.dilation[0];\n        let inputColEnd = inputColStart + uniforms.filterWidth *\n            uniforms.dilation[1];\n\n        // Convolve x(?, ?, d1)|x(d1, ?, ?) with w(:, :, d1, q) to get\n        // y(yR, yC, d2)|y(d2, yR, yC). ? = to be determined. : = across all\n        // values in that axis. x(?, ?, d1) and y(yR, yC, d2) is for NHWC.\n        // x(d1, ?, ?) and y(d2, yR, yC) is for NCHW.\n        var value = 0.0;\n\n        // Extract if checking out of for loop for performance.\n        if (inputRowStart >= 0 && inputColStart >= 0 &&\n          inputRowEnd < uniforms.inDims[0] &&\n              inputColEnd < uniforms.inDims[1]) {\n            for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n              let xR = inputRowStart + wR * uniforms.dilation[0];\n\n              for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                let xC = inputColStart + wC * uniforms.dilation[1];\n\n                let xVal = ${getXSnippet};\n                let wVal = getW(wR, wC, d1, q);\n                value = value + xVal * wVal;\n              }\n            }\n          } else {\n            for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n              let xR = inputRowStart + wR * uniforms.dilation[0];\n\n              if (xR < 0 || xR >= uniforms.inDims[0]) {\n                continue;\n              }\n\n              for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                let xC = inputColStart + wC * uniforms.dilation[1];\n\n                if (xC < 0 || xC >= uniforms.inDims[1]) {\n                  continue;\n                }\n\n                let xVal = ${getXSnippet};\n                let wVal = getW(wR, wC, d1, q);\n                value = value + xVal * wVal;\n              }\n            }\n          }\n          ${biasActivationSnippet(this.addBias, this.activation)}\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DNCHWSharedProgram} from '../depthwise_conv2d_nchw_shared_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  attrs: DepthwiseConv2dNativeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */, $dataFormat);\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program|\n      DepthwiseConv2DNCHWSharedProgram;\n  if (!isChannelsLast && convInfo.inHeight > 16 && convInfo.inWidth > 16 &&\n      convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n      convInfo.dilationWidth === 1 && convInfo.dilationHeight === 1 &&\n      convInfo.inChannels === convInfo.outChannels) {\n    program = new DepthwiseConv2DNCHWSharedProgram(\n        convInfo.outShape, convInfo.filterHeight, convInfo.filterWidth);\n  } else if (\n      isChannelsLast && convInfo.inHeight > 4 && convInfo.inWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(convInfo);\n  } else {\n    program = new DepthwiseConv2DProgram(convInfo);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x, filter], x.dtype, dimensions);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNative as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {multiplyImplCPU as cpuMultiply} from '../kernel_utils/shared';\n\nexport const multiplyKernelFunc = binaryKernelFunc({\n  opType: BinaryOpType.MUL,\n  cpuKernelImpl: cpuMultiply,\n  supportsComplex: true\n});\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'webgpu',\n  kernelFunc: multiplyKernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: WebGPUBackend, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'sum', backend);\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'webgpu',\n  kernelFunc: sum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {multiplyKernelFunc} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: WebGPUBackend, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out =\n            multiplyKernelFunc({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeData(tensorInfo.dataId);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'webgpu',\n  kernelFunc: einsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const elu = unaryKernelFunc({opType: UnaryOpType.ELU});\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'webgpu',\n  kernelFunc: elu\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {equalImplCPU as cpuEqual} from '../kernel_utils/shared';\n\nexport const equal = binaryKernelFunc(\n    {opType: BinaryOpType.EQUAL, dtype: 'bool', cpuKernelImpl: cpuEqual});\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'webgpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const exp = unaryKernelFunc({\n  opType: UnaryOpType.EXP,\n  cpuKernelImpl: expImplCPU,\n  dtype: 'float32',\n});\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'webgpu',\n  kernelFunc: exp\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  attrs: ExpandDimsAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {dim} = attrs;\n  const {input} = inputs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'webgpu',\n  kernelFunc: expandDims as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expm1ImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const expm1 =\n    unaryKernelFunc({opType: UnaryOpType.EXPM1, cpuKernelImpl: expm1ImplCPU});\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'webgpu',\n  kernelFunc: expm1\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FlipLeftRightProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(imageShape: [number, number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.shaderKey = 'flipLeftRight';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let coordX = uniforms.xShape[2] - coords[2] - 1;\n          let outputValue = getX(coords[0], coords[1], coordX, coords[3]);\n          setOutputAtIndex(index, outputValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FlipLeftRightProgram} from '../flip_left_right_webgpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n    kernelName: FlipLeftRight,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, backend}) => {\n      const {image} = inputs as FlipLeftRightInputs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new FlipLeftRightProgram((image as Tensor4D).shape);\n      const output =\n          webgpuBackend.runWebGPUProgram(program, [image], image.dtype);\n      return output;\n  }\n};\n","\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {floorImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const floor =\n    unaryKernelFunc({opType: UnaryOpType.FLOOR, cpuKernelImpl: floorImplCPU});\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'webgpu',\n  kernelFunc: floor\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const floorDiv =\n    binaryKernelFunc({opType: BinaryOpType.INT_DIV, dtype: 'int32'});\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'webgpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FromPixelsProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  isFromPixels = true;\n  outputShape: number[] = [0];\n  shaderKey: string;\n  importVideo: boolean;\n  variableNames: string[] = [];\n  workGroupSize: [number, number, number] =\n      [256, 1, 1];  // The empirical value.\n\n  constructor(outputShape: number[], numChannels: number, importVideo = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [numChannels, 1, 1]);\n\n    this.importVideo = importVideo;\n    this.shaderKey = `fromPixels_${this.importVideo}`;\n  }\n\n  getUserCode(): string {\n    const textureLoad = this.importVideo ?\n        'textureLoad(src, vec2<i32>(coords.yx));' :\n        'textureLoad(src, vec2<i32>(coords.yx), 0)';\n    const textureType =\n        this.importVideo ? 'texture_external' : 'texture_2d<f32>';\n    return `\n      @binding(1) @group(0) var src: ${textureType};\n      ${main('index')} {\n        let flatIndex = index * uniforms.numChannels;\n        if (flatIndex < uniforms.size) {\n          let coords = getCoordsFromIndex(flatIndex);\n          let values = ${textureLoad};\n          for (var i = 0; i < uniforms.numChannels; i = i + 1) {\n            result[flatIndex + i] = i32(floor(255.0 * values[i]));\n          }\n        }\n      }\n  `;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use backend file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\nimport {FromPixels, FromPixelsAttrs, FromPixelsInputs, util} from '@tensorflow/tfjs-core';\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {TextureInfo, WebGPUBackend} from '../backend_webgpu';\nimport {FromPixelsProgram} from '../from_pixels_webgpu';\n\nexport const fromPixelsConfig: KernelConfig = {\n  kernelName: FromPixels,\n  backendName: 'webgpu',\n  kernelFunc: fromPixels as {} as KernelFunc,\n};\n\nlet fromPixels2DContext: CanvasRenderingContext2D;\nlet willReadFrequently = env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\nconst videoToTextureMap = new Map<object, object>();\n\nexport function fromPixels(args: {\n  inputs: FromPixelsInputs,\n  backend: WebGPUBackend,\n  attrs: FromPixelsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  let {pixels} = inputs;\n  const {numChannels} = attrs;\n\n  if (pixels == null) {\n    throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n  }\n\n  const isVideo = typeof (HTMLVideoElement) !== 'undefined' &&\n      pixels instanceof HTMLVideoElement;\n  const isImage = typeof (HTMLImageElement) !== 'undefined' &&\n      pixels instanceof HTMLImageElement;\n  const isCanvas = (typeof (HTMLCanvasElement) !== 'undefined' &&\n                    pixels instanceof HTMLCanvasElement) ||\n      (typeof (OffscreenCanvas) !== 'undefined' &&\n       pixels instanceof OffscreenCanvas);\n  const isImageBitmap =\n      typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap;\n\n  const [width, height] = isVideo ?\n      [\n        (pixels as HTMLVideoElement).videoWidth,\n        (pixels as HTMLVideoElement).videoHeight\n      ] :\n      [pixels.width, pixels.height];\n  const outputShape = [height, width, numChannels];\n\n  // Disable importExternalTexture temporarily as it has problem in spec and\n  // browser impl\n  const importVideo =\n      false && env().getBool('WEBGPU_IMPORT_EXTERNAL_TEXTURE') && isVideo;\n  const isVideoOrImage = isVideo || isImage;\n  if (isImageBitmap || isCanvas || isVideoOrImage) {\n    let textureInfo: TextureInfo;\n    if (importVideo) {\n      const videoElement = pixels as HTMLVideoElement;\n      if (!(videoToTextureMap.has(videoElement)) ||\n          (videoToTextureMap.get(videoElement) as GPUExternalTexture).expired) {\n        const externalTextureDescriptor = {source: videoElement};\n        videoToTextureMap.set(\n            videoElement,\n            backend.device.importExternalTexture(externalTextureDescriptor));\n      }\n\n      textureInfo = {\n        width,\n        height,\n        format: null,\n        usage: null,\n        texture: videoToTextureMap.get(videoElement) as GPUExternalTexture\n      };\n    } else {\n      if (isVideoOrImage) {\n        const newWillReadFrequently =\n            env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\n        if (fromPixels2DContext == null ||\n            newWillReadFrequently !== willReadFrequently) {\n          willReadFrequently = newWillReadFrequently;\n          fromPixels2DContext =\n              document.createElement('canvas').getContext(\n                  '2d', {willReadFrequently}) as CanvasRenderingContext2D;\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(\n            pixels as HTMLVideoElement | HTMLImageElement, 0, 0, width, height);\n        pixels = fromPixels2DContext.canvas;\n      }\n\n      const usage = GPUTextureUsage.COPY_DST |\n          GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING;\n      const format = 'rgba8unorm' as GPUTextureFormat;\n      const texture = backend.textureManager.acquireTexture(\n          outputShape[1], outputShape[0], format, usage);\n      backend.queue.copyExternalImageToTexture(\n          {source: pixels as HTMLCanvasElement | ImageBitmap}, {texture},\n          [outputShape[1], outputShape[0]]);\n      textureInfo = {width, height, format, usage, texture};\n    }\n\n    const size = util.sizeFromShape(outputShape);\n    const strides = util.computeStrides(outputShape);\n    const program =\n        new FromPixelsProgram(outputShape, numChannels, importVideo);\n\n    const uniformData = [\n      {type: 'uint32', data: [size]}, {type: 'uint32', data: [numChannels]},\n      {type: 'uint32', data: [...strides]}\n    ];\n    const input = backend.makeTensorInfo([height, width], 'int32');\n    const info = backend.tensorMap.get(input.dataId);\n    info.resourceInfo = textureInfo;\n\n    const result =\n        backend.runWebGPUProgram(program, [input], 'int32', uniformData);\n    backend.disposeData(input.dataId);\n    return result;\n  }\n\n  // TODO: Encoding should happen on GPU once we no longer have to download\n  // image data to the CPU.\n  const imageData = (pixels as ImageData | backend_util.PixelData).data;\n  let pixelArray = imageData;\n  if (numChannels != null && numChannels !== 4) {\n    pixelArray = new Uint8Array(pixels.width * pixels.height * numChannels);\n\n    const dataLength = imageData.length;\n    let j = 0;\n    for (let i = 0; i < dataLength; i++) {\n      if (i % 4 < numChannels) {\n        pixelArray[j++] = imageData[i];\n      }\n    }\n  }\n\n  const output =\n      backend.makeTensorInfo(outputShape, 'int32', new Int32Array(pixelArray));\n  backend.uploadToGPU(output.dataId);\n  return output;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BatchNormProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = 'varianceEpsilon : f32,';\n  // This is an experimental value.\n  workGroupSize: [number, number, number] = [128, 1, 1];\n  offsetShape: number[]|null;\n  scaleShape: number[]|null;\n  varianceEpsilon: number;\n  size = true;\n\n  constructor(\n      xShape: number[], meanShape: number[], varianceShape: number[],\n      offsetShape: number[]|null, scaleShape: number[]|null) {\n    this.variableNames = ['x', 'mean', 'variance'];\n    backend_util.assertAndGetBroadcastShape(xShape, meanShape);\n    backend_util.assertAndGetBroadcastShape(xShape, varianceShape);\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    if (offsetShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, offsetShape);\n      this.variableNames.push('offset');\n    }\n    if (scaleShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, scaleShape);\n      this.variableNames.push('scale');\n    }\n    this.offsetShape = offsetShape;\n    this.scaleShape = scaleShape;\n    this.shaderKey = 'batchNorm';\n  }\n\n  getUserCode(): string {\n    let offsetSnippet = '0.0';\n    if (this.offsetShape != null) {\n      offsetSnippet = 'getOffsetByOutputIndex(index)';\n    }\n\n    let scaleSnippet = '1.0';\n    if (this.scaleShape != null) {\n      scaleSnippet = 'getScaleByOutputIndex(index)';\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size)\n        {\n          let xValue = getXByOutputIndex(index);\n          let meanValue = getMeanByOutputIndex(index);\n          let varianValue = getVarianceByOutputIndex(index);\n          let offsetValue = ${offsetSnippet};\n          let scaleValue = ${scaleSnippet};\n          let inv = scaleValue * inverseSqrt(varianValue + f32(uniforms.varianceEpsilon));\n          setOutputAtIndex(index,dot(vec3<f32>(xValue, -meanValue, offsetValue), vec3<f32>(inv, inv, 1.0)));\n        }\n      }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, Tensor} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BatchNormProgram} from '../batchnorm_webgpu';\n\nexport const fusedBatchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x, scale, offset, mean, variance} = inputs as FusedBatchNormInputs;\n    const {varianceEpsilon} = attrs as unknown as FusedBatchNormAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const batchNormInputs = [x as Tensor, mean as Tensor, variance as Tensor];\n    let offsetShape = null;\n    if (offset != null) {\n      offsetShape = offset.shape;\n      batchNormInputs.push(offset as Tensor);\n    }\n    let scaleShape = null;\n    if (scale != null) {\n      scaleShape = scale.shape;\n      batchNormInputs.push(scale as Tensor);\n    }\n    const program = new BatchNormProgram(\n        x.shape, mean.shape, variance.shape, offsetShape, scaleShape);\n    const uniformData = [{type: 'float32', data: [varianceEpsilon]}];\n    return webGPUBackend.runWebGPUProgram(\n        program, batchNormInputs, x.dtype, uniformData);\n  }\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  attrs: FusedConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  return conv2DImpl({\n    x,\n    filter,\n    convInfo,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedConv2d as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  attrs: FusedDepthwiseConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {strides, pad, dilations, dimRoundingMode, activation, leakyreluAlpha} =\n      attrs;\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const programInputs: TensorInfo[] = [x, filter];\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n\n  if (hasBias) {\n    programInputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    programInputs.push(preluActivationWeights);\n  }\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program;\n  if (convInfo.inHeight > 4 && convInfo.inWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n  } else {\n    program = new DepthwiseConv2DProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const result =\n      backend.runWebGPUProgram(program, programInputs, 'float32', dimensions);\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedDepthwiseConv2D as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherNDProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  uniforms: string;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  sliceDim: number;\n  constructor(sliceDim: number, shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.shaderKey = `gathernd_${sliceDim}`;\n    this.sliceDim = sliceDim;\n    this.uniforms = `sliceDim : i32, strides : ${getCoordsDataType(sliceDim)},`;\n  }\n\n  getUserCode(): string {\n    let strideString;\n    if (this.sliceDim > 1) {\n      strideString = 'uniforms.strides[j]';\n    } else {\n      strideString = 'uniforms.strides';\n    }\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          var flattenIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexTemp = i32(round(getIndices(coords[0], j)));\n            let strideNum = ${strideString};\n            flattenIndex = flattenIndex + indexTemp * strideNum;\n          }\n\n          setOutputAtIndex(index, getA(flattenIndex, coords[1]));\n        }\n      }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {GatherNDProgram} from '../gather_nd_webgpu';\nimport {gatherNdImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numSlices, sliceRank]}});\n  const flattenX = reshape({\n    inputs: {x: params},\n    backend,\n    attrs: {shape: [(util.sizeFromShape(params.shape) / sliceSize), sliceSize]}\n  });\n  if (backend.shouldExecuteOnCPU([params, indices]) ||\n      params.dtype === 'string') {\n    const indicesData = backend.readSync(indices.dataId) as TypedArray;\n    const paramsBuf = backend.bufferSync<Rank, 'float32'>(params);\n    const outValue = gatherNdImplCPU(\n        indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize,\n        strides, params.shape, paramsSize);\n\n    return backend.makeTensorInfo(resultShape, params.dtype, outValue.values);\n  }\n  const program = new GatherNDProgram(sliceRank, [numSlices, sliceSize]);\n  const uniformData =\n      [{type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides}];\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], flattenX.dtype, uniformData);\n\n  const reshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: resultShape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'webgpu',\n  kernelFunc: gatherNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  aShape: number[];\n  size = true;\n\n  constructor(aShape: number[], outputShape: number[]) {\n    this.outputShape = aShape.slice();\n    this.aShape = aShape;\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.shaderKey = `gather`;\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.aShape);\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let indexZ = i32(getIndices(resRC.x, resRC.z));\n          let inBounds = select(0.0, 1.0, indexZ >= 0 && indexZ < uniforms.aShape[2]);\n          setOutputAtIndex(index, inBounds * getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\n// The input and output are always flattened into rank 4 tensors.\nfunction getSourceCoords(aShape: number[]): string {\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < aShape.length; i++) {\n    if (i === 2) {\n      sourceCoords.push('indexZ');\n    } else {\n      sourceCoords.push(`${currentCoords[i]}`);\n    }\n  }\n  return sourceCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, Rank, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {gatherV2ImplCPU} from '../kernel_utils/shared';\n\nimport {GatherProgram} from '../gather_webgpu';\nimport {reshape} from './Reshape';\n\nexport function gatherV2(\n    args:\n        {inputs: GatherV2Inputs, backend: WebGPUBackend, attrs: GatherV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  // Unlike WebGL, WebGPU won't check if index is out of bound by calling\n  // backend.readSync() function in debug mode.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, batchDims);\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const toDispose = [];\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  toDispose.push(flattenX);\n  toDispose.push(flattenIndex);\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  if (backend.shouldExecuteOnCPU([x, indices])) {\n    const indicesBufferInfo = backend.tensorMap.get(flattenIndex.dataId);\n    const indicesValues = indicesBufferInfo.values as TypedArray;\n    const indicesBuf =\n        buffer(flattenIndex.shape, flattenIndex.dtype, indicesValues) as\n        TensorBuffer<Rank>;\n    const xBufferInfo = backend.tensorMap.get(flattenX.dataId);\n    const xValues = xBufferInfo.values as TypedArray;\n    const xBuf =\n        buffer(flattenX.shape, flattenX.dtype, xValues) as TensorBuffer<Rank>;\n    const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);\n\n    toDispose.forEach(t => backend.disposeData(t.dataId));\n\n    return backend.makeTensorInfo(\n        shapeInfo.outputShape, outBuf.dtype, outBuf.values as TypedArray);\n  }\n\n  const program = new GatherProgram(flattenX.shape, flattenOutputShape);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndex], flattenX.dtype);\n  toDispose.push(res);\n\n  const reshaped = reshape(\n      {inputs: {x: res}, backend, attrs: {shape: shapeInfo.outputShape}});\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return reshaped;\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'webgpu',\n  kernelFunc: gatherV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterImplCPU as cpuGreater} from '../kernel_utils/shared';\n\nexport const greater = binaryKernelFunc({\n  opType: BinaryOpType.GREATER,\n  cpuKernelImpl: cpuGreater,\n  dtype: 'bool',\n});\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'webgpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterEqualImplCPU as cpuGreaterEqual} from '../kernel_utils/shared';\n\nexport const greaterEqual = binaryKernelFunc({\n  opType: BinaryOpType.GREATER_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuGreaterEqual\n});\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'webgpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isNaN =\n    unaryKernelFunc({opType: UnaryOpType.IS_NAN, dtype: 'bool'});\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'webgpu',\n  kernelFunc: isNaN\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: WebGPUBackend,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n  const uniformData = [{type: 'float32', data: [alpha]}];\n  const program = new UnaryOpProgram(x.shape, UnaryOpType.LEAKYRELU);\n  program.uniforms = 'alpha : f32,';\n  return backend.runWebGPUProgram(program, [x], 'float32', uniformData);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'webgpu',\n  kernelFunc: leakyRelu as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessImplCPU as cpuLess} from '../kernel_utils/shared';\n\nexport const less = binaryKernelFunc(\n    {opType: BinaryOpType.LESS, dtype: 'bool', cpuKernelImpl: cpuLess});\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'webgpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessEqualImplCPU as cpuLessEqual} from '../kernel_utils/shared';\n\nexport const lessEqual = binaryKernelFunc({\n  opType: BinaryOpType.LESS_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuLessEqual\n});\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'webgpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {logImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const log =\n    unaryKernelFunc({opType: UnaryOpType.LOG, cpuKernelImpl: logImplCPU});\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'webgpu',\n  kernelFunc: log\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const logicalAnd =\n    binaryKernelFunc({opType: BinaryOpType.LOGICAL_AND, dtype: 'bool'});\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'webgpu',\n  kernelFunc: logicalAnd\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const logicalNot = unaryKernelFunc({opType: UnaryOpType.LOGICAL_NOT});\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'webgpu',\n  kernelFunc: logicalNot\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {maximumImplCPU as cpuMaximum} from '../kernel_utils/shared';\n\nexport const maximum = binaryKernelFunc({\n  opType: BinaryOpType.MAX,\n  cpuKernelImpl: cpuMaximum,\n});\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'webgpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function maxPool(\n    args: {inputs: MaxPoolInputs, backend: WebGPUBackend, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'max', backend);\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'webgpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function min(\n    args: {inputs: MinInputs, backend: WebGPUBackend, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'min', backend);\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'webgpu',\n  kernelFunc: min as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {minimumImplCPU as cpuMinimum} from '../kernel_utils/shared';\n\nexport const minimum = binaryKernelFunc({\n  opType: BinaryOpType.MIN,\n  cpuKernelImpl: cpuMinimum,\n});\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'webgpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MirrorPadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  offset: number;\n  size = true;\n\n  constructor(\n      xShape: number[], paddings: Array<[number, number]>,\n      mode: 'reflect'|'symmetric') {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.xShape = xShape;\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.offset = mode === 'reflect' ? 0 : 1;\n    this.shaderKey = `mirrorPad_${mode}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.xShape.length;\n    // The length of paddings are same with the rank of the input tensor.\n    const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n    const end = this.xShape\n                    .map(\n                        (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                            rank > 1 ? `[${i}]` : ''}`)\n                    .join(',');\n\n    const shaderStart = rank === 1 ? 'start' : 'start[i]';\n    const shaderEnd = rank === 1 ? 'end' : 'end[i]';\n    const shaderOutC = rank === 1 ? 'outC' : 'outC[i]';\n    const dtype = getCoordsDataType(rank);\n    const unpackedCoords = rank > 1 ?\n        ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n        'coords';\n\n    return `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let start = ${dtype}(${start});\n          let end = ${dtype}(${end});\n          var outC = getCoordsFromIndex(index);\n          for (var i = 0; i < ${rank}; i = i + 1) {\n            if (${shaderOutC} < ${shaderStart}) {\n              ${shaderOutC} = ${shaderStart} * 2 - ${shaderOutC} - ${\n        this.offset};\n            } else if(${shaderOutC} >= ${shaderEnd}) {\n              ${shaderOutC} = (${shaderEnd} - 1) * 2 - ${shaderOutC} + ${\n        this.offset};\n            }\n          }\n          let coords = outC - start;\n          setOutputAtIndex(index, getX(${unpackedCoords}));\n        }\n      }\n    `;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, MirrorPad, MirrorPadAttrs, MirrorPadInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {MirrorPadProgram} from '../mirror_pad_webgpu';\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MirrorPadInputs;\n    const {paddings, mode} = attrs as unknown as MirrorPadAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n\n    const uniformData = paddings.map(p => {\n      return {type: 'int32', data: [p[0], p[1]]};\n    });\n    const program = new MirrorPadProgram(x.shape, paddings, mode);\n    const output =\n        webGPUBackend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n    return output;\n  }\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Neg, NegInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {negImplCPU} from '../kernel_utils/shared';\n\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\n// This doesn't use unaryKernelFunc because negImplCPU is not of type\n// SimpleUnaryKernelImplCPU.\nexport function neg(args: {inputs: NegInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = backend.tensorMap.get(x.dataId);\n    const [outValues, newShape] =\n        negImplCPU(xData.values as TypedArray, x.shape, x.dtype);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n\n  const program = new UnaryOpProgram(x.shape, UnaryOpType.NEG);\n\n  return backend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'webgpu',\n  kernelFunc: neg as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TypedArray} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV3Attrs\n}) {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const {selectedIndices} = kernel_impls.nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV3 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nexport type TypedArray = Float32Array|Int32Array|Uint8Array;\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} =\n      kernel_impls.nonMaxSuppressionV5Impl(\n          boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n          scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV5 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({\n      attrs: {\n        shape: x.shape,\n        dtype: x.dtype,\n        value: x.dtype === 'string' ? '' : 0\n      },\n      backend\n    });\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'webgpu',\n  kernelFunc: zerosLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported under string dtype');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({attrs: {shape: x.shape, dtype: x.dtype, value: 1}, backend});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'webgpu',\n  kernelFunc: onesLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: WebGPUBackend, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'webgpu',\n  kernelFunc: pack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class PadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'constantValue : f32,';\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  size = true;\n\n  constructor(xShape: number[], paddings: Array<[number, number]>) {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.xShape = xShape;\n    this.shaderKey = 'pad';\n  }\n\n  getUserCode(): string {\n    const rank = this.xShape.length;\n    const type = getCoordsDataType(rank);\n    // The length of paddings are same with the rank of the input tensor.\n    const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n    const end = this.xShape\n                    .map(\n                        (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                            rank > 1 ? `[${i}]` : ''}`)\n                    .join(',');\n    const startValue = rank > 1 ? `${type}(${start})` : `${start}`;\n    const endValue = rank > 1 ? `${type}(${end})` : `${end}`;\n\n    const leftPadCondition = rank > 1 ? `any(outC < start)` : `outC < start`;\n    const rightPadCondition = rank > 1 ? `any(outC >= end)` : `outC >= end`;\n\n    const unpackedCoords = rank > 1 ?\n        ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n        'coords';\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let start = ${startValue};\n          let end = ${endValue};\n          let outC = getCoordsFromIndex(index);\n\n          if (${leftPadCondition} || ${rightPadCondition}) {\n            setOutputAtIndex(index, uniforms.constantValue);\n          } else {\n            let coords = outC - start;\n            setOutputAtIndex(index, getX(${unpackedCoords}));\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\nimport {PadProgram} from '../pad_webgpu';\nimport {fill} from './Fill';\n\nexport const padV2 =\n    (args: {inputs: PadV2Inputs,\n            backend: WebGPUBackend,\n            attrs: PadV2Attrs}): TensorInfo => {\n      const {inputs, backend, attrs} = args;\n      const {x} = inputs;\n      const {paddings, constantValue} = attrs;\n      if (paddings.every(p => util.arraysEqual(p, [0, 0]))) {\n        return identity({inputs: {x}, backend});\n      }\n      if (util.sizeFromShape(x.shape) === 0) {\n        // Short-circuit the computation, since x doesn't have value, only\n        // the shape is used to compute output shape to pad.\n        const outputShape = paddings.map(\n            (p, i) =>\n                p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n        return fill({\n          backend,\n          attrs: {shape: outputShape, value: constantValue, dtype: x.dtype}\n        });\n      }\n      const uniformData = [{type: 'float32', data: [constantValue]}];\n      paddings.map(p => uniformData.push({type: 'int32', data: [p[0], p[1]]}));\n      const program = new PadProgram(x.shape, paddings);\n      return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n    };\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'webgpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const pow = binaryKernelFunc({\n  opType: BinaryOpType.POW,\n});\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'webgpu',\n  kernelFunc: pow\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prelu, PreluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\n\nexport function prelu(args: {inputs: PreluInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  const program = new BinaryOpProgram(BinaryOpType.PRELU, x.shape, alpha.shape);\n  return backend.runWebGPUProgram(program, [x, alpha], 'float32');\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'webgpu',\n  kernelFunc: prelu as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: WebGPUBackend, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'prod', backend);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'webgpu',\n  kernelFunc: prod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {rangeImplCPU} from '../kernel_utils/shared';\n\nexport const range =\n    (args: {backend: WebGPUBackend, attrs: RangeAttrs}): TensorInfo => {\n      const {backend, attrs} = args;\n      const {start, stop, step, dtype} = attrs;\n      const values = rangeImplCPU(start, stop, step, dtype);\n      return backend.makeTensorInfo([values.length], dtype, values);\n    };\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'webgpu',\n  kernelFunc: range as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const realDiv = binaryKernelFunc({opType: BinaryOpType.DIV});\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'webgpu',\n  kernelFunc: realDiv as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const reciprocal = unaryKernelFunc({opType: UnaryOpType.RECIPROCAL});\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'webgpu',\n  kernelFunc: reciprocal\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu = unaryKernelFunc({opType: UnaryOpType.RELU});\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'webgpu',\n  kernelFunc: relu\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu6 = unaryKernelFunc({opType: UnaryOpType.RELU6});\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'webgpu',\n  kernelFunc: relu6\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeBilinearProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, halfPixelCenters : f32,';\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.shaderKey = `resizeBilinear`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC =\n            (vec2<f32>(rc) + vec2<f32>(uniforms.halfPixelCenters)) *\n            effectiveInputOverOutputRatioRC - vec2<f32>(uniforms.halfPixelCenters);\n\n          // Compute the four integer indices.\n          let sourceFloorRC = vec2<i32>(sourceFracIndexRC);\n          let sourceCeilRC = vec2<i32>(\n            min(vec2<f32>(uniforms.xShape.yz) - vec2<f32>(1.0), ceil(sourceFracIndexRC)));\n\n          let topLeft = getX(b, sourceFloorRC.x, sourceFloorRC.y, d);\n          let bottomLeft = getX(b, sourceCeilRC.x, sourceFloorRC.y, d);\n          let topRight = getX(b, sourceFloorRC.x, sourceCeilRC.y, d);\n          let bottomRight = getX(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n          let fracRC = sourceFracIndexRC - vec2<f32>(sourceFloorRC);\n\n          let top = topLeft + (topRight - topLeft) * fracRC.y;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n          let newValue = top + (bottom - top) * fracRC.x;\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeBilinearProgram} from '../resize_bilinear_webgpu';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, size, halfPixelCenters} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  const halfPixelCentersValue = halfPixelCenters ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [halfPixelCentersValue]}\n  ];\n\n  const program = new ResizeBilinearProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth);\n\n  return backend.runWebGPUProgram(program, [images], 'float32', uniformData);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'webgpu',\n  kernelFunc: resizeBilinear as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeNearestNeighborProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, roundBase : f32,';\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  halfPixelCenters: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number, halfPixelCenters: boolean) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.halfPixelCenters = halfPixelCenters;\n    this.shaderKey = `resizeNearest_${halfPixelCenters}`;\n  }\n\n  getUserCode(): string {\n    let sourceFracIndexRC: string;\n    if (this.halfPixelCenters) {\n      sourceFracIndexRC =\n          `max((vec2<f32>(rc) + vec2<f32>(0.5)) * effectiveInputOverOutputRatioRC` +\n          `, vec2<f32>(0.0))`;\n    } else {\n      sourceFracIndexRC = `vec2<f32>(rc) * effectiveInputOverOutputRatioRC`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC = ${sourceFracIndexRC};\n\n          // Compute the coordinators of nearest neighbor point.\n          let inputShapeRC = vec2<f32>(f32(uniforms.xShape.y), f32(uniforms.xShape.z));\n          let sourceNearestRC = vec2<i32>(\n            min(inputShapeRC - 1.0, floor(sourceFracIndexRC + uniforms.roundBase)));\n          let newValue = getX(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeNearestNeighborProgram} from '../resize_nearest_neighbor_webgpu';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  // When align corners is false, we rounds the value with floor.\n  const roundBase = alignCorners ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [roundBase]}\n  ];\n\n  const program = new ResizeNearestNeighborProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth,\n      halfPixelCenters);\n  return backend.runWebGPUProgram(program, [images], images.dtype, uniformData);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'webgpu',\n  kernelFunc: resizeNearestNeighbor as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class RotateProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms: string;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  fillSnippet: string;\n  size = true;\n\n  constructor(\n      imageShape: [number, number, number, number],\n      fillValue: number|[number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.uniforms = `centerX : f32, centerY : f32, sinRadians : f32,\n          cosRadians : f32,`;\n    this.shaderKey = 'rotate';\n    this.outputShape = imageShape;\n\n    if (typeof fillValue === 'number') {\n      this.uniforms += ` fillValue : f32,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue;`;\n      this.shaderKey += '_float';\n    } else {\n      this.uniforms += ` fillValue : vec3<f32>,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue[coords[3]];`;\n      this.shaderKey += '_vec3';\n    }\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            let coordXFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.cosRadians - (f32(coords[1]) - uniforms.centerY) *\n                uniforms.sinRadians;\n            let coordYFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.sinRadians + (f32(coords[1]) - uniforms.centerY) *\n                uniforms.cosRadians;\n            let coordX = i32(round(coordXFloat + uniforms.centerX));\n            let coordY = i32(round(coordYFloat + uniforms.centerY));\n            ${this.fillSnippet}\n            if(coordX >= 0 && coordX < uniforms.xShape[2] && coordY >= 0 &&\n                coordY < uniforms.xShape[1]) {\n              outputValue = getX(coords[0], coordY, coordX, coords[3]);\n            }\n            setOutputAtIndex(index, outputValue);\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {RotateProgram} from '../rotate_webgpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n    kernelName: RotateWithOffset,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, attrs, backend}) => {\n      const {image} = inputs as RotateWithOffsetInputs;\n      const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new RotateProgram((image as Tensor4D).shape, fillValue);\n      const [centerX, centerY] =\n          backend_util.getImageCenter(center, image.shape[1], image.shape[2]);\n      const uniformData = [\n            {type: 'float32', data: [centerX]},\n            {type: 'float32', data: [centerY]},\n            {type: 'float32', data: [Math.sin(radians)]},\n            {type: 'float32', data: [Math.cos(radians)]}\n          ];\n\n      if (typeof fillValue === 'number') {\n        uniformData.push(\n            {type: 'float32', data: [Number.parseFloat(fillValue.toFixed(2))]});\n      } else {\n        uniformData.push({type: 'float32', data: fillValue});\n      }\n\n      const output = webgpuBackend.runWebGPUProgram(\n          program, [image], image.dtype, uniformData);\n      return output;\n   }\n };\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {rsqrtImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const rsqrt =\n    unaryKernelFunc({opType: UnaryOpType.RSQRT, cpuKernelImpl: rsqrtImplCPU});\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'webgpu',\n  kernelFunc: rsqrt\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\nimport {getCoordsDataType, getMainHeaderString as main, mapToWgslTypes, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ScatterProgram implements WebGPUProgram {\n  variableNames = ['updates', 'indices'];\n  uniforms: string;\n  outputShape: number[];\n  sumDupeIndices: boolean;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  updatesRank: number;\n  indicesRank: number;\n  sliceDimGreaterThanOne: boolean;\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      flattenXShape: number[], sliceDim: number, indicesRank: number,\n      updatesRank: number, strides: number[], shape: number[],\n      outputDtype: DataType, sumDupeIndices = true) {\n    this.outputShape = shape;\n    this.type = outputDtype;\n    this.sumDupeIndices = sumDupeIndices;\n    this.dispatchLayout = flatDispatchLayout(flattenXShape);\n    // Dispatching based on |updates| shape instead of output shape.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, flattenXShape, this.workGroupSize);\n    this.sliceDimGreaterThanOne = sliceDim > 1;\n    this.shaderKey = `scatter_${indicesRank}_${updatesRank}_${\n        this.sliceDimGreaterThanOne}_${outputDtype}_${sumDupeIndices}`;\n    const stridesType = getCoordsDataType(strides.length);\n    this.uniforms = `sliceDim : i32, strides: ${stridesType}, size: i32,`;\n    this.updatesRank = updatesRank;\n    this.indicesRank = indicesRank;\n  }\n\n  getUserCode(): string {\n    let indicesString = '';\n    if (this.indicesRank === 1) {\n      indicesString = 'coords[0]';\n    } else if (this.indicesRank === 2) {\n      indicesString = 'coords[0], j';\n    }\n    const indicesSnippet = `getIndices(${indicesString})`;\n\n    const strideString = this.sliceDimGreaterThanOne ? 'uniforms.strides[j]' :\n                                                       'uniforms.strides';\n\n    let outCoordsString = '';\n    let getUpdatesCoordsFromFlatIndex = '';\n    if (this.dispatchLayout.x.length === 1) {\n      outCoordsString = 'flattenedIndex';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> i32 {\n        return index;\n      }\n      `;\n    } else if (this.dispatchLayout.x.length === 2) {\n      outCoordsString = 'vec2<i32>(flattenedIndex, coords[1])';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> vec2<i32> {\n        // N.B. |updates| could be a scalar tensor, conceptually representing a\n        // 2D tensor with all values equal to that. By design, its size must be\n        // the same as |outShape[1]| in one dimension, and |indicesShape[0]|\n        // gives the other.\n        let sliceSize = uniforms.outShape[1];\n        let d0 = index / sliceSize;\n        let d1 = index - d0 * sliceSize;\n        return vec2<i32>(d0, d1);\n      }\n      `;\n    }\n    const updatesString =\n        Array.from({length: this.updatesRank}, (_, idx) => `coords[${idx}]`);\n    const updatesSnippet = `getUpdates(${updatesString.join(', ')})`;\n\n    const atomicRMW = (ptr: string, val: string) => {\n      let atomicAddSnippet = `atomicAdd(${ptr}, bitcast<i32>(${val}))`;\n      if (this.type === 'float32') {\n        atomicAddSnippet = `\n          {\n            var oldBits = 0;\n            var newBits = bitcast<i32>(${val});\n            loop {\n              let info = atomicCompareExchangeWeak(${ptr}, oldBits, newBits);\n              if (info.exchanged) {\n                break;\n              }\n              oldBits = info.old_value;\n              let oldValue = bitcast<f32>(oldBits);\n              let newValue = oldValue + (${val});\n              newBits = bitcast<i32>(newValue);\n            }\n          }\n        `;\n      }\n      const atomicStoreSnippet = `atomicStore(${ptr}, bitcast<i32>(${val}));`;\n      return this.sumDupeIndices ? atomicAddSnippet : atomicStoreSnippet;\n    };\n\n    const userCode = `\n    ${getUpdatesCoordsFromFlatIndex}\n\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getUpdatesCoordsFromFlatIndex(index);\n          var flattenedIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexInside = i32(round(${indicesSnippet}));\n            flattenedIndex = flattenedIndex + indexInside * ${strideString};\n          }\n          let updateValue =\n              ${mapToWgslTypes(this.type, false)}(${updatesSnippet});\n          let flatIndex = getOutputIndexFromCoords(${outCoordsString});\n\n          ${atomicRMW('&result[flatIndex]', 'updateValue')};\n        }\n      }`;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: WebGPUBackend,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  if (outputSize === 0) {\n    return backend.makeTensorInfo(shape, indices.dtype);\n  }\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numUpdates, sliceRank]}});\n  const flattenX = reshape(\n      {inputs: {x: updates}, backend, attrs: {shape: [numUpdates, sliceSize]}});\n\n  const type = flattenX.dtype;\n  const output =\n      fill({backend, attrs: {shape: flattenShape, value: 0, dtype: type}});\n  const size = util.sizeFromShape(flattenX.shape);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides},\n    {type: 'int32', data: [size]}\n  ];\n  const program = new ScatterProgram(\n      flattenX.shape, sliceRank, flattenIndices.shape.length,\n      flattenX.shape.length, strides, flattenShape, type);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], type, uniformData, output);\n\n  const reshaped = reshape({inputs: {x: res}, backend, attrs: {shape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'webgpu',\n  kernelFunc: scatterNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SelectProgram implements WebGPUProgram {\n  variableNames = ['c', 'a', 'b'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  cRank: number;\n  rank: number;\n  size = true;\n\n  constructor(cRank: number, shape: number[], rank: number) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n\n    this.cRank = cRank;\n    this.rank = rank;\n    this.shaderKey = 'select';\n  }\n\n  getUserCode(): string {\n    // TODO(WGSL): below code can be merged with getUserCode.\n    let cCoords;\n    let abCoords;\n    if (this.rank > 4) {\n      throw Error(`Where for rank ${this.rank} is not yet supported`);\n    }\n\n    if (this.rank === 1) {\n      abCoords = `resRC`;\n      cCoords = `resRC`;\n    } else {\n      const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n      const cCoordVars = [];\n      const abCoordVars = [];\n      for (let i = 0; i < this.outputShape.length; i++) {\n        abCoordVars.push(`${currentCoords[i]}`);\n        if (i < this.cRank) {\n          cCoordVars.push(`${currentCoords[i]}`);\n        }\n      }\n      cCoords = cCoordVars.join();\n      abCoords = abCoordVars.join();\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let cVal = getC(${cCoords});\n          if (cVal >= 1.0) {\n            setOutputAtIndex(index, getA(${abCoords}));\n          } else {\n            setOutputAtIndex(index, getB(${abCoords}));\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SelectProgram} from '../select_webgpu';\n\nexport function select(args: {inputs: SelectInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  const program =\n      new SelectProgram(condition.shape.length, t.shape, t.shape.length);\n  return backend.runWebGPUProgram(\n      program, [condition, t, e], upcastType(t.dtype, e.dtype));\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'webgpu',\n  kernelFunc: select as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sigmoid = unaryKernelFunc({opType: UnaryOpType.SIGMOID});\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'webgpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sin = unaryKernelFunc({opType: UnaryOpType.SIN});\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'webgpu',\n  kernelFunc: sin\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sinh = unaryKernelFunc({opType: UnaryOpType.SINH});\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'webgpu',\n  kernelFunc: sinh\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {subImplCPU as cpuSub} from '../kernel_utils/shared';\n\nexport const sub = binaryKernelFunc(\n    {opType: BinaryOpType.SUB, cpuKernelImpl: cpuSub, supportsComplex: true});\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'webgpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {exp} from './Exp';\nimport {max} from './Max';\nimport {realDiv} from './RealDiv';\nimport {reshape} from './Reshape';\nimport {sub} from './Sub';\nimport {sum} from './Sum';\n\nexport function softmax(\n    args: {inputs: SoftmaxInputs, backend: WebGPUBackend, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const axes = util.parseAxisParam([dim], logits.shape);\n\n  const maxLogit = max({\n    inputs: {x: logits},\n    backend,\n    attrs: {reductionIndices: axes, keepDims: false}\n  });\n\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n  const maxLogitsReshaped =\n      reshape({inputs: {x: maxLogit}, backend, attrs: {shape: expandedShape}});\n  const a =\n      sub({inputs: {a: logits, b: maxLogitsReshaped}, backend}) as TensorInfo;\n  const b = exp({inputs: {x: a}, backend}) as TensorInfo;\n  const sumExp =\n      sum({inputs: {x: b}, backend, attrs: {axis: axes, keepDims: false}});\n  const sumExpReshaped =\n      reshape({inputs: {x: sumExp}, backend, attrs: {shape: expandedShape}});\n  const res =\n      realDiv({inputs: {a: b, b: sumExpReshaped}, backend}) as TensorInfo;\n\n  backend.disposeData(maxLogit.dataId);\n  backend.disposeData(maxLogitsReshaped.dataId);\n  backend.disposeData(a.dataId);\n  backend.disposeData(b.dataId);\n  backend.disposeData(sumExp.dataId);\n  backend.disposeData(sumExpReshaped.dataId);\n\n  return res;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'webgpu',\n  kernelFunc: softmax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {padV2} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport const spaceToBatchND = (args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: WebGPUBackend,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'spaceToBatchND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...paddings as Array<[number, number]>);\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const toDispose = [];\n\n  const paddedX = padV2({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  });\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapedPaddedX = reshape(\n      {inputs: {x: paddedX}, backend, attrs: {shape: reshapedPaddedShape}});\n\n  const paddedXT = transpose({\n    inputs: {x: reshapedPaddedX},\n    backend,\n    attrs: {perm: permutedReshapedPaddedPermutation}\n  });\n\n  const result =\n      reshape({inputs: {x: paddedXT}, backend, attrs: {shape: flattenShape}});\n\n  toDispose.push(paddedX);\n  toDispose.push(reshapedPaddedX);\n  toDispose.push(paddedXT);\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return result;\n};\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'webgpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TileProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  rank: number;\n\n  constructor(aShape: number[], reps: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[i] * reps[i];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.rank = this.outputShape.length;\n    this.shaderKey = 'tile';\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.rank, 'uniforms.');\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          setOutputAtIndex(index, getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nfunction getSourceCoords(rank: number, uniformPrefix = ''): string {\n  if (rank >= 5) {\n    throw Error(`Tile for rank ${rank} is not yet supported`);\n  }\n  if (rank === 1) {\n    return `(resRC % ${uniformPrefix}aShape)`;\n  }\n\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < rank; i++) {\n    sourceCoords.push(`(${currentCoords[i]} % ${uniformPrefix}aShape[${i}])`);\n  }\n  return sourceCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {tileImplCPU} from '../kernel_utils/shared';\nimport {TileProgram} from '../tile_webgpu';\n\nexport function tile(\n    params: {inputs: TileInputs, backend: WebGPUBackend, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = params;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  // tile gpu program cannot handle rank >= 5 case.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string' ||\n      x.shape.length >= 5) {\n    // Even thought string tensor is always on CPU, just to be consistent on how\n    // to access tensor data.\n    const data = backend.readSync(x.dataId);\n    const value = x.dtype === 'string' ?\n        (data as Uint8Array[]).map(d => util.decodeString(d)) :\n        data as TypedArray;\n    const buf = buffer(x.shape, x.dtype, value);\n    const outBuf = tileImplCPU(buf, reps);\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n  }\n\n  const program = new TileProgram(x.shape, reps);\n  const output = backend.runWebGPUProgram(program, [x], x.dtype);\n\n  return output;\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'webgpu',\n  kernelFunc: tile as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {scatterImplCPU} from '../kernel_utils/shared';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {tile} from './Tile';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: WebGPUBackend,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n\n  const sumDupeIndices = false;\n  if (sparseValues.dtype === 'string') {\n    const indicesBuf = backend.bufferSync<Rank, 'int32'>(sparseIndices);\n    const updatesBuf = backend.bufferSync<Rank, 'string'>(sparseValues);\n    const $defaultValue = util.decodeString(\n        backend.readSync(defaultValue.dataId)[0] as Uint8Array);\n    const outBuf = scatterImplCPU(\n        indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates,\n        sliceRank, strides, $defaultValue, sumDupeIndices);\n    return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n  }\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const $sparseIndices = reshape({\n    inputs: {x: sparseIndices},\n    backend,\n    attrs: {shape: [numUpdates, sliceRank]}\n  });\n  const $sparseValues = sparseValues.shape.length ?\n      reshape({\n        inputs: {x: sparseValues},\n        backend,\n        attrs: {shape: [numUpdates, sliceSize]}\n      }) :\n      identity({inputs: {x: sparseValues}, backend});\n\n  const type = $sparseValues.dtype;\n  const zero =\n      backend.makeTensorInfo([], type, util.makeZerosTypedArray(1, type));\n\n  // Fill output tensor with the default value.\n  const $defaultValue = reshape({\n    inputs: {x: defaultValue},\n    backend,\n    attrs: {shape: Array(flattenShape.length).fill(1)}\n  });\n  const $denseValues =\n      tile({inputs: {x: $defaultValue}, backend, attrs: {reps: flattenShape}});\n\n  const size = util.sizeFromShape([numUpdates, sliceSize]);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]},\n    {type: 'int32', data: strides},\n    {type: 'int32', data: [size]},\n  ];\n\n  switch (numUpdates) {\n    case 0:\n      break;\n    case 1:\n      if (true) {\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type,\n            sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n      break;\n    default:\n      if (true) {\n        // First replace the default value with 0 at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            zero.shape.length, strides, flattenShape, type, sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [zero, $sparseIndices], type, uniformData, $denseValues);\n      }\n      {\n        // Then replace 0 with the (sum of) sparse value(s) at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n  }\n\n  const denseValues = reshape(\n      {inputs: {x: $denseValues}, backend, attrs: {shape: outputShape}});\n\n  backend.disposeData($sparseIndices.dataId);\n  backend.disposeData($sparseValues.dataId);\n  backend.disposeData($defaultValue.dataId);\n  backend.disposeData(zero.dataId);\n  backend.disposeData($denseValues.dataId);\n  return denseValues;\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'webgpu',\n  kernelFunc: sparseToDense as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SplitV, SplitVAttrs, SplitVInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: WebGPUBackend, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const xRank = x.shape.length;\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'webgpu',\n  kernelFunc: splitV as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sqrt = unaryKernelFunc({opType: UnaryOpType.SQRT});\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'webgpu',\n  kernelFunc: sqrt\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const program = new UnaryOpProgram(x.shape, UnaryOpType.SQUARE);\n    return webGPUBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const squaredDifference = binaryKernelFunc({\n  opType: BinaryOpType.SQUARED_DIFFERENCE,\n});\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'webgpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class StridedSliceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  // TODO(xing.xu): Increase the workPerThread.\n  workPerThread = 1;\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(destSize: number[]) {\n    this.outputShape = destSize;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize,\n        [this.workPerThread, 1, 1]);\n\n    const dtype = getCoordsDataType(this.outputShape.length);\n    this.uniforms = `begin : ${dtype},  strides : ${dtype}, `;\n    this.shaderKey = 'stridedSlice';\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    let newCoords = '';\n    if (rank === 1) {\n      newCoords = 'coords * uniforms.strides + uniforms.begin';\n    } else {\n      let outputAxis = 0;\n      newCoords =\n          this.outputShape\n              .map((_, i) => {\n                outputAxis++;\n                return this.outputShape.length === 1 ?\n                    `coords * uniforms.strides[${i}] + uniforms.begin[${i}]` :\n                    `coords[${outputAxis - 1}] * uniforms.strides[${\n                        i}] + uniforms.begin[${i}]`;\n              })\n              .join(',');\n    }\n\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let coords = getCoordsFromIndex(index);\n           setOutputAtIndex(index, getX(${newCoords}));\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, Rank, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stridedSliceImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {StridedSliceProgram} from '../strided_slice_webgpu';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: WebGPUBackend,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeData(sliced.dataId);\n  } else {\n    const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n    if (shouldExecuteOnCPU) {\n      const values = backend.readSync(x.dataId) as TypedArray;\n      const xBuf = buffer(x.shape, x.dtype, values) as TensorBuffer<Rank>;\n      const resultValues =\n          stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);\n      result = backend.makeTensorInfo(finalShape, x.dtype, resultValues.values);\n    } else {\n      const program = new StridedSliceProgram(finalShapeSparse);\n      const uniformData =\n          [{type: 'int32', data: $begin}, {type: 'int32', data: $strides}];\n      const resultValues =\n          backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n      result = reshape(\n          {inputs: {x: resultValues}, backend, attrs: {shape: finalShape}});\n      backend.disposeData(resultValues.dataId);\n    }\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'webgpu',\n  kernelFunc: stridedSlice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stringNGramsImplCPU} from '../kernel_utils/shared';\n\nexport function stringNGrams(args: {\n  inputs: StringNGramsInputs,\n  backend: WebGPUBackend,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  } = attrs;\n  const {data, dataSplits} = inputs;\n  const $data = backend.readSync(data.dataId) as Uint8Array[];\n  const $dataSplits = backend.readSync(dataSplits.dataId) as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImplCPU(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n  return [\n    backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n    backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n  ];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'webgpu',\n  kernelFunc: stringNGrams as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const tanh = unaryKernelFunc({opType: UnaryOpType.TANH});\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'webgpu',\n  kernelFunc: tanh\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\n// The original algorithm is based on computing the top K only, however\n// since for TFJS we require the indices of the top K values as well then the\n// algorithm found here is a bit modified. Rather than producing the values\n// at each step, the indices containing the top K are generated instead.\n// The output values are not generated to reduce the number of outputs in the\n// GPU, the values can easily be retrieved from the indices using a gather\n// op.\n\nexport class SwapProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workGroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.uniforms = `inputSize : i32, firstPass : i32, negativeInf : f32,\n        dir : i32, inc : i32,`;\n    this.shaderKey = 'swap';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // We compare elements pair-wise within a group of size 2 * inc.\n            // The comparing rule for each group alternates between ascending\n            // and descending. Within each group, we compare each pair at\n            // positions i and i+inc. To decide whether an element at position i\n            // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n            // inc, it is in the first half of the group, we denote it as x0,\n            // otherwise we denote it as x1.\n            // For example, as shown in the Bitonic top K paper referenced\n            // above, Figure5(a) shows that element[1] is in the second half of\n            // the group when group size is 2, but it is in the first half of\n            // the group when group size is 4.\n            let isFirstInPair = elemIdx % (2 * uniforms.inc) < uniforms.inc;\n            var i = 0;\n            if (isFirstInPair) {\n              i = elemIdx;\n            } else {\n              i = elemIdx - uniforms.inc;\n            }\n\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.inc;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.inc));\n            }\n\n            var x0 = f32(0.0);\n            var x1 = f32(0.0);\n            if (i0 < uniforms.inputSize) {\n              x0 = getX(batch, i0);\n            } else {\n              x0 = uniforms.negativeInf;\n            }\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = uniforms.negativeInf;\n            }\n\n            let reverse = elemIdx % (2 * uniforms.dir) >= uniforms.dir;\n            let isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n            if (reverse == isGreater) {\n              // Elements in opposite order of direction\n              let iTemp = i0;\n              i0 = i1;\n              i1 = iTemp;\n            }\n            if (isFirstInPair) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n\nexport class MergeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workGroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    // |n| Size of the original input of TopK\n    // |firstPass| indicates if this is the first time swap is being used which\n    // means no indices input containing the top K is present yet.\n    // |k| Top k elements desired\n    this.uniforms = `inputSize : i32, firstPass : i32, k : i32,`;\n    this.shaderKey = 'merge';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // The output size is half of the previous size.\n            // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _\n            // (k=4), we only need to output the indices at positions |, the\n            // indices at positions _ can be thrown away, see Figure5(b) After\n            // Phase 2 (Merge phase) in the Bitonic Top K paper referenced\n            // above.\n            // For example, the paper shows we only need to output the orange\n            // bars. The output sequence should look like this | | | | | | | |.\n            // Because the sequence is halved, to map the output index back to\n            // the previous sequence to find the corresponding value, we need\n            // to double the index. When we double the index, we basically\n            // interpolate a position, so 2i looks like\n            // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k\n            // position of each 2k positions by - elemIdx % k. E.g. for output\n            // at index 4,5,6,7, we want to get the corresponding element at\n            // original index 8,9,10,11, for output at index 8,9,10,11,\n            // we want to get the corresponding element at original index\n            // 16,17,18,19, so on and so forth.\n\n            var i = 0;\n            if (elemIdx < uniforms.k) {\n              i = elemIdx;\n            } else {\n              i = elemIdx * 2 - elemIdx % uniforms.k;\n            }\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.k;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.k));\n            }\n\n            let x0 = getX(batch, i0);\n            var x1 = f32(0.0);\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = x0;\n            }\n\n            if (x0 >= x1) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {topKImplCPU} from '../kernel_utils/shared';\nimport {MergeProgram, SwapProgram} from '../top_k_webgpu';\nimport {fill} from './Fill';\nimport {gatherV2} from './GatherV2';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nfunction disposeIntermediateTensorInfoOrNull(\n    backend: WebGPUBackend, tensorInfo: TensorInfo) {\n  if (tensorInfo !== null) {\n    backend.disposeData(tensorInfo.dataId);\n  }\n}\n\nfunction roundUpToPow2(num: number) {\n  let pow2 = 1;\n  while (pow2 < num) {\n    pow2 *= 2;\n  }\n  return pow2;\n}\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\nexport function topK(\n    args: {inputs: TopKInputs, backend: WebGPUBackend, attrs: TopKAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted}= attrs;\n\n  const xShape = x.shape;\n  const lastDim = xShape[xShape.length - 1];\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xVals = backend.readSync(x.dataId) as TypedArray;\n    const [allTopKVals, allTopKIndices] =\n        topKImplCPU(xVals, xShape, x.dtype as NumericDataType, k, sorted);\n\n    return [\n      backend.makeTensorInfo(\n          allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n      backend.makeTensorInfo(\n          allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n    ];\n  }\n\n  if (k === 0) {\n    xShape[xShape.length - 1] = 0;\n    return [\n      backend.makeTensorInfo(xShape, x.dtype, []),\n      backend.makeTensorInfo(xShape, 'int32', [])\n    ];\n  }\n\n  if (lastDim === 1 /* firstPass */) {\n    return [\n      x, fill({attrs: {shape: xShape, dtype: 'int32', value: 0}, backend})\n    ];\n  }\n\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const xSize = util.sizeFromShape(xShape);\n  const batch = xSize / lastDim;\n  const x2D = reshape({inputs: {x}, attrs: {shape: [batch, lastDim]}, backend});\n\n  const kPow2 = roundUpToPow2(k);\n  const lastDimPow2 = roundUpToPow2(lastDim);\n\n  // Only the indices containing the top K are kept at every step to reduce\n  // number of outputs in the GPU algorithms, so once the final set of indices\n  // is computed then gather is used to grab the corresponding values\n  // from the original input.\n  let indices: TensorInfo = null;\n\n  // GPU algorithm always takes in an indices input but this input is not used\n  // on the first run of a GPU algorithm, therefore if indices is null we simply\n  // pass in x2D instead of it but the value will not actually be used\n  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];\n\n  const runSwap = (dir: number, inc: number, shape: number[]) => {\n    const inputs = getInputs();\n    const program = new SwapProgram(shape);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataSwap = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'float32', data: [Number.NEGATIVE_INFINITY]},\n        {type: 'int32', data: [dir]},\n        {type: 'int32', data: [inc]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        program, inputs, 'int32', uniformDataSwap);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  };\n\n  // Step 1: local sort\n  for (let len = 1; len < kPow2; len *= 2) {\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, [batch, lastDimPow2]);\n    }\n  }\n\n  // Step 2: merge\n  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {\n    const inputs = getInputs();\n    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataMerge = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'int32', data: [kPow2]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        mergeProgram, inputs, 'int32', uniformDataMerge);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n    // Step 3: rebuild\n    const len = kPow2 / 2;\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, indices.shape);\n    }\n  }\n\n  // Keep only the requested top K results instead of kPow2\n  let prevIndices = indices;\n  indices = slice(\n      {inputs: {x: indices}, backend, attrs: {begin: 0, size: [batch, k]}});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  // Gather values on last dimension\n  let values = gatherV2(\n      {inputs: {x: x2D, indices}, backend, attrs: {axis: 1, batchDims: 1}});\n  disposeIntermediateTensorInfoOrNull(backend, x2D);\n\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const newShape = xShape.slice(0, -1);\n  newShape.push(k);\n\n  prevIndices = indices;\n  indices = reshape({inputs: {x: indices}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  const prevValues = values;\n  values = reshape({inputs: {x: values}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevValues);\n\n  return [values, indices];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'webgpu',\n  kernelFunc: topK as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransformProgram implements WebGPUProgram {\n  variableNames = ['Image', 'Transforms'];\n  outputShape: number[];\n  uniforms = 'interpolationModeId : i32, fillModeId : i32, fillValue : f32,';\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workGroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(outShape: [number, number, number, number]) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workGroupSize);\n    this.shaderKey = 'transform';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n          fn mapCoord(outCoord : f32, len : f32) -> f32{\n            var inCoord = outCoord;\n            if(uniforms.fillModeId == 2) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  if (inCoord < sz2) {\n                    inCoord = sz2 * f32(i32(f32(-inCoord / sz2))) +\n                    inCoord;\n                  }\n                  if (inCoord < -len) {\n                    inCoord = inCoord + sz2;\n                  } else {\n                    inCoord = -inCoord - 1.0;\n                  }\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  inCoord = inCoord - sz2 * f32(i32(f32(inCoord / sz2)));\n                  if (inCoord >= len) {\n                    inCoord = sz2 - inCoord - 1.0;\n                  }\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 3) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord + len * (f32(i32(f32(-inCoord / sz))) + 1.0);\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord - len * f32(i32(f32(inCoord / sz)));\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 4) {\n              return clamp(outCoord, 0.0, len - 1.0);\n            }\n            return outCoord;\n          }\n          fn readWithFillValue(batch : i32, coordY : i32, coordX : i32,\n            channel : i32) -> f32 {\n            var outputValue : f32;\n            if (0 <= coordY && coordY < uniforms.imageShape[1] && 0 <= coordX && coordX < uniforms.imageShape[2]) {\n                outputValue = getImage(batch, coordY, coordX, channel);\n            } else {\n              outputValue = uniforms.fillValue;\n            }\n            return outputValue;\n          }\n\n          ${main('index')} {\n            if (index < uniforms.size) {\n              let coords = getCoordsFromIndex(index);\n              var outputValue : f32;\n              let batch = coords[0];\n              let x = coords[2];\n              let y = coords[1];\n              let channel = coords[3];\n              let xf = f32(x);\n              let yf = f32(y);\n              let a1 = getTransforms(batch, 0);\n              let a2 = getTransforms(batch, 1);\n              let a3 = getTransforms(batch, 2);\n              let b1 = getTransforms(batch, 3);\n              let b2 = getTransforms(batch, 4);\n              let b3 = getTransforms(batch, 5);\n              let c1 = getTransforms(batch, 6);\n              let c2 = getTransforms(batch, 7);\n              let projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = uniforms.fillValue;\n              } else {\n                let inX = (a1 * xf + a2 * yf + a3) / projection;\n                let inY = (b1 * xf + b2 * yf + b3) / projection;\n                let mapX = mapCoord(inX, f32(uniforms.imageShape[2]));\n                let mapY = mapCoord(inY, f32(uniforms.imageShape[1]));\n\n                if (uniforms.interpolationModeId == 1) {\n                  let coordY = i32(round(mapY));\n                  let coordX = i32(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  let yFloor = floor(mapY);\n                  let xFloor = floor(mapX);\n                  let yCeil = yFloor + 1.0;\n                  let xCeil = xFloor + 1.0;\n                  let valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yFloor), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yFloor), i32(xCeil), channel);\n                  let valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yCeil), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yCeil), i32(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutputAtIndex(index, outputValue);\n            }\n          }\n        `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transform, TransformAttrs, TransformInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {TransformProgram} from '../transform_webgpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  backend: WebGPUBackend,\n  attrs: TransformAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape =\n      [batch, outHeight, outWidth,\n       numChannels] as [number, number, number, number];\n\n  const program = new TransformProgram(outShape);\n  const interpolationModeId = interpolation === 'nearest' ? 1 : 2;\n  let fillModeId: number;\n  switch (fillMode) {\n    case 'constant':\n      fillModeId = 1;\n      break;\n    case 'reflect':\n      fillModeId = 2;\n      break;\n    case 'wrap':\n      fillModeId = 3;\n      break;\n    case 'nearest':\n      fillModeId = 4;\n      break;\n    default:\n      fillModeId = 1;\n      break;\n  }\n  const uniformData = [\n    {type: 'int32', data: [interpolationModeId]},\n    {type: 'int32', data: [fillModeId]}, {type: 'float32', data: [fillValue]}\n  ];\n  return backend.runWebGPUProgram(\n      program, [image, transforms], 'float32', uniformData);\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'webgpu',\n  kernelFunc: transform as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args:\n        {inputs: UnpackInputs, backend: WebGPUBackend, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const x = value;\n  const xRank = x.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(xRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < xRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = x.shape[i];\n    }\n  }\n\n  const toDispose = [];\n\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n  size[axis] = 1;\n  const res: TensorInfo[] = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const sliced = slice({inputs: {x}, backend, attrs: {begin, size}});\n    const reshaped =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: outShape}});\n    res[i] = reshaped;\n\n    toDispose.push(sliced);\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'webgpu',\n  kernelFunc: unpack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {atan2Config} from './kernels/Atan2';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {complexConfig} from './kernels/Complex';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {equalConfig} from './kernels/Equal';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fromPixelsConfig} from './kernels/FromPixels';\nimport {fusedBatchNormConfig} from './kernels/FusedBatchNorm';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {imagConfig} from './kernels/Imag';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {logConfig} from './kernels/Log';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {selectConfig} from './kernels/Select';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {unpackConfig} from './kernels/Unpack';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  addConfig,\n  addNConfig,\n  argMaxConfig,\n  argMinConfig,\n  atan2Config,\n  avgPoolConfig,\n  batchMatMulConfig,\n  batchToSpaceNDConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  complexConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropInputConfig,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeConfig,\n  einsumConfig,\n  eluConfig,\n  equalConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fillConfig,\n  flipLeftRightConfig,\n  fromPixelsConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedBatchNormConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  imagConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  logConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  rangeConfig,\n  realConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeNearestNeighborConfig,\n  rotateWithOffsetConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  selectConfig,\n  sigmoidConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  softmaxConfig,\n  spaceToBatchNDConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  subConfig,\n  sumConfig,\n  tanhConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  unpackConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n"],"names":["env","backend_util","util","KernelBackend","webgpu_util.isWebGPUSupported","DataStorage","engine","webgpu_util.ArrayBufferToTypedArray","buffer","webgpu_util.GPUBytesPerElement","webgpu_program.makeShaderKey","webgpu_program.compileProgram","registerBackend","main","Fill","Reshape","broadcast_util","_FusedMatMul","Identity","Complex","upcastType","concatImpl","tidy","reshape","broadcastTo","slice_util","select","TensorBuffer","Abs","cpuAdd","Add","AddN","cpuTranspose","Transpose","ArgMax","ArgMin","Atan2","sumOutType","Max","Mean","AvgPool","BatchMatMul","getCoords","Slice","BatchToSpaceND","cpuNotEqual","NotEqual","Real","tf","Cast","Ceil","ClipByValue","Imag","Concat","Conv2D","Conv2DBackpropInput","Cos","Cosh","CropAndResize","Cumprod","Cumsum","DepthToSpace","DepthwiseConv2dNative","cpuMultiply","Multiply","Sum","Einsum","Elu","cpuEqual","Equal","Exp","ExpandDims","Expm1","FlipLeftRight","Floor","FloorDiv","FromPixels","FusedBatchNorm","FusedConv2D","FusedDepthwiseConv2D","GatherNd","getSourceCoords","GatherV2","cpuGreater","Greater","cpuGreaterEqual","GreaterEqual","IsNan","LeakyRelu","cpuLess","Less","cpuLessEqual","LessEqual","Log","LogicalAnd","LogicalNot","cpuMaximum","Maximum","MaxPool","Min","cpuMinimum","Minimum","MirrorPad","Neg","kernel_impls","NonMaxSuppressionV3","NonMaxSuppressionV5","ZerosLike","OnesLike","Pack","PadV2","Pow","Prelu","Prod","Range","RealDiv","Reciprocal","Relu","Relu6","ResizeBilinear","ResizeNearestNeighbor","RotateWithOffset","Rsqrt","ScatterNd","Select","Sigmoid","Sin","Sinh","cpuSub","Sub","Softmax","SpaceToBatchND","Tile","SparseToDense","SplitV","Sqrt","Square","SquaredDifference","StridedSlice","StringNGrams","Tanh","TopK","Transform","Unpack","registerKernel"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAAA;;;;;;;;;;;;;;;;IAmBA,MAAM,GAAG,GAAGA,MAAG,EAAE,CAAC;IAElB;IACA,GAAG,CAAC,YAAY,CAAC,mCAAmC,EAAE,MAAM,EAAE,CAAC,CAAC;IAEhE;;;;IAIA,GAAG,CAAC,YAAY,CAAC,oBAAoB,EAAE,MAAM,IAAI,CAAC,CAAC;IAEnD;;;;;IAKA,GAAG,CAAC,YAAY,CAAC,4BAA4B,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC;IAEzD;;;;IAIA,GAAG,CAAC,YAAY,CAAC,mCAAmC,EAAE,MAAM,KAAK,CAAC,CAAC;IAEnE;;;;IAIA,GAAG,CAAC,YAAY,CAAC,0BAA0B,EAAE,MAAM,KAAK,CAAC,CAAC;IAE1D;;;;;;IAMA,GAAG,CAAC,YAAY,CAAC,mCAAmC,EAAE,MAAM,IAAI,CAAC,CAAC;IAElE;;;;IAIA,GAAG,CAAC,YAAY,CAAC,yBAAyB,EAAE,MAAM,KAAK,CAAC,CAAC;IAEzD;;;IAGA,GAAG,CAAC,YAAY,CAAC,gCAAgC,EAAE,MAAM,IAAI,CAAC,CAAC;IAE/D;;;IAGA,GAAG,CAAC,YAAY,CAAC,+BAA+B,EAAE,MAAM,KAAK,CAAC;;ICvE9D;;;;;;;;;;;;;;;;UAwBa,WAAW;QAGtB,YAAY,WAA2B;YACrC,IAAI,WAAW,EAAE;gBACf,IAAI,CAAC,MAAM,GAAG,WAAW,CAAC,MAAM,CAAC;aAClC;SACF;QAED,OAAO;YACL,OAAO,IAAI,CAAC,MAAM,KAAK,OAAO,CAAC;SAChC;;;ICnCH;;;;;;;;;;;;;;;;UAiBa,aAAa;QASxB,YAAoB,MAAiB;YAAjB,WAAM,GAAN,MAAM,CAAW;YAR7B,mBAAc,GAAG,CAAC,CAAC;YACnB,mBAAc,GAAG,CAAC,CAAC;YACnB,gBAAW,GAA6B,IAAI,GAAG,EAAE,CAAC;YAClD,gBAAW,GAA6B,IAAI,GAAG,EAAE,CAAC;YAEnD,iBAAY,GAAG,CAAC,CAAC;YACjB,sBAAiB,GAAG,CAAC,CAAC;SAEY;QAEzC,mBAAmB,CAAC,IAAY,EAAE,KAA0B;YAC1D,OAAO,IAAI,CAAC,aAAa,CAAC,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;SAC9C;QAED,aAAa,CACT,IAAY,EAAE,KAA0B,EAAE,gBAAgB,GAAG,KAAK;YACpE,MAAM,GAAG,GAAG,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;YACtC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC9B,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAC/B;YAED,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC9B,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAC/B;YAED,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC;YAC1B,IAAI,CAAC,cAAc,EAAE,CAAC;YAEtB,IAAI,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM,GAAG,CAAC,EAAE;gBACxC,IAAI,CAAC,cAAc,EAAE,CAAC;gBAEtB,MAAM,SAAS,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,CAAC;gBACpD,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;gBAC1C,OAAO,SAAS,CAAC;aAClB;YAED,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC;YAC/B,MAAM,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,YAAY,CAAC,EAAC,IAAI,EAAE,KAAK,EAAE,gBAAgB,EAAC,CAAC,CAAC;YAC5E,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;YAE1C,OAAO,SAAS,CAAC;SAClB;QAED,aAAa,CAAC,MAAiB,EAAE,IAAY,EAAE,KAA0B;YACvE,IAAI,IAAI,CAAC,WAAW,CAAC,IAAI,KAAK,CAAC,EAAE;gBAC/B,OAAO;aACR;YAED,MAAM,GAAG,GAAG,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;YACtC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC9B,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAC/B;YAED,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YACvC,IAAI,CAAC,cAAc,EAAE,CAAC;YACtB,IAAI,CAAC,cAAc,EAAE,CAAC;YAEtB,MAAM,UAAU,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;YAC7C,MAAM,WAAW,GAAG,UAAU,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;YAC/C,IAAI,WAAW,GAAG,CAAC,EAAE;gBACnB,MAAM,IAAI,KAAK,CACX,0DAA0D;oBAC1D,gBAAgB,CAAC,CAAC;aACvB;YACD,UAAU,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC;YAClC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC;SAC3B;QAED,mBAAmB,CACf,MAAiB,EAAE,IAAY,EAAE,KAA0B;YAC7D,MAAM,CAAC,QAAQ,CAAC,UAAU,CAAC,KAAK,CAAC;iBAC5B,IAAI,CACD;gBACE,IAAI,CAAC,aAAa,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;aACzC,EACD,CAAC,GAAG;;aAEH,CAAC,CAAC;SACZ;QAED,iBAAiB;YACf,OAAO,IAAI,CAAC,cAAc,CAAC;SAC5B;QAED,iBAAiB;YACf,OAAO,IAAI,CAAC,cAAc,CAAC;SAC5B;QAED,OAAO;YACL,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,GAAG;gBACpC,OAAO,CAAC,OAAO,CAAC,MAAM;oBACpB,MAAM,CAAC,OAAO,EAAE,CAAC;iBAClB,CAAC,CAAC;aACJ,CAAC,CAAC;YAEH,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,GAAG;gBACpC,OAAO,CAAC,OAAO,CAAC,MAAM;oBACpB,MAAM,CAAC,OAAO,EAAE,CAAC;iBAClB,CAAC,CAAC;aACJ,CAAC,CAAC;YAEH,IAAI,CAAC,WAAW,GAAG,IAAI,GAAG,EAAE,CAAC;YAC7B,IAAI,CAAC,WAAW,GAAG,IAAI,GAAG,EAAE,CAAC;YAC7B,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC;YACxB,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC;YACxB,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC;YACtB,IAAI,CAAC,iBAAiB,GAAG,CAAC,CAAC;SAC5B;KACF;IAED,SAAS,YAAY,CAAC,IAAY,EAAE,KAA0B;QAC5D,OAAO,GAAG,IAAI,IAAI,KAAK,EAAE,CAAC;IAC5B;;IClIA;;;;;;;;;;;;;;;;UAiBa,cAAc;QASzB,YAAoB,MAAiB;YAAjB,WAAM,GAAN,MAAM,CAAW;YAR7B,oBAAe,GAAG,CAAC,CAAC;YACpB,oBAAe,GAAG,CAAC,CAAC;YACpB,iBAAY,GAA8B,IAAI,GAAG,EAAE,CAAC;YACpD,iBAAY,GAA8B,IAAI,GAAG,EAAE,CAAC;YAErD,iBAAY,GAAG,CAAC,CAAC;YACjB,sBAAiB,GAAG,CAAC,CAAC;SAEY;QAEzC,cAAc,CACV,KAAa,EAAE,MAAc,EAAE,MAAwB,EACvD,KAA2B;YAC7B,MAAM,eAAe,GAAG,kBAAkB,CAAC,MAAM,CAAC,CAAC;YACnD,MAAM,QAAQ,GAAG,KAAK,GAAG,MAAM,GAAG,eAAe,CAAC;YAClD,MAAM,GAAG,GAAG,aAAa,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;YACxD,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC/B,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAChC;YAED,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC/B,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAChC;YAED,IAAI,CAAC,YAAY,IAAI,QAAQ,CAAC;YAC9B,IAAI,CAAC,eAAe,EAAE,CAAC;YAEvB,IAAI,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM,GAAG,CAAC,EAAE;gBACzC,IAAI,CAAC,eAAe,EAAE,CAAC;gBAEvB,MAAM,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,CAAC;gBACtD,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;gBAC5C,OAAO,UAAU,CAAC;aACnB;YAED,IAAI,CAAC,iBAAiB,IAAI,QAAQ,CAAC;YAEnC,MAAM,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC;gBAC3C,IAAI,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC;gBACrB,MAAM;gBACN,KAAK;aACN,CAAC,CAAC;YACH,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;YAE5C,OAAO,UAAU,CAAC;SACnB;QAED,cAAc,CACV,OAAmB,EAAE,KAAa,EAAE,MAAc,EAClD,MAAwB,EAAE,KAA2B;YACvD,IAAI,IAAI,CAAC,YAAY,CAAC,IAAI,KAAK,CAAC,EAAE;gBAChC,OAAO;aACR;YAED,MAAM,GAAG,GAAG,aAAa,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;YACxD,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;gBAC/B,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;aAChC;YAED,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;YACzC,IAAI,CAAC,eAAe,EAAE,CAAC;YACvB,IAAI,CAAC,eAAe,EAAE,CAAC;YAEvB,MAAM,WAAW,GAAG,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;YAC/C,MAAM,YAAY,GAAG,WAAW,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;YAClD,IAAI,YAAY,GAAG,CAAC,EAAE;gBACpB,MAAM,IAAI,KAAK,CACX,2DAA2D;oBAC3D,iBAAiB,CAAC,CAAC;aACxB;YACD,WAAW,CAAC,MAAM,CAAC,YAAY,EAAE,CAAC,CAAC,CAAC;YACpC,MAAM,eAAe,GAAG,kBAAkB,CAAC,MAAM,CAAC,CAAC;YACnD,MAAM,QAAQ,GAAG,KAAK,GAAG,MAAM,GAAG,eAAe,CAAC;YAClD,IAAI,CAAC,YAAY,IAAI,QAAQ,CAAC;SAC/B;QAED,kBAAkB;YAChB,OAAO,IAAI,CAAC,eAAe,CAAC;SAC7B;QAED,kBAAkB;YAChB,OAAO,IAAI,CAAC,eAAe,CAAC;SAC7B;QAED,OAAO;YACL,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,GAAG;gBACtC,QAAQ,CAAC,OAAO,CAAC,OAAO;oBACtB,OAAO,CAAC,OAAO,EAAE,CAAC;iBACnB,CAAC,CAAC;aACJ,CAAC,CAAC;YAEH,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,GAAG;gBACtC,QAAQ,CAAC,OAAO,CAAC,OAAO;oBACtB,OAAO,CAAC,OAAO,EAAE,CAAC;iBACnB,CAAC,CAAC;aACJ,CAAC,CAAC;YAEH,IAAI,CAAC,YAAY,GAAG,IAAI,GAAG,EAAE,CAAC;YAC9B,IAAI,CAAC,YAAY,GAAG,IAAI,GAAG,EAAE,CAAC;YAC9B,IAAI,CAAC,eAAe,GAAG,CAAC,CAAC;YACzB,IAAI,CAAC,eAAe,GAAG,CAAC,CAAC;YACzB,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC;YACtB,IAAI,CAAC,iBAAiB,GAAG,CAAC,CAAC;SAC5B;KACF;IAED,SAAS,aAAa,CAClB,KAAa,EAAE,MAAc,EAAE,MAAwB,EACvD,KAA2B;QAC7B,OAAO,GAAG,KAAK,IAAI,MAAM,IAAI,MAAM,IAAI,KAAK,EAAE,CAAC;IACjD,CAAC;IAED,SAAS,kBAAkB,CAAC,MAAwB;QAClD,IAAI,MAAM,KAAK,YAAY,EAAE;YAC3B,OAAO,EAAE,CAAC;SACX;aAAM;YACL,MAAM,IAAI,KAAK,CAAC,GAAG,MAAM,oBAAoB,CAAC,CAAC;SAChD;IACH;;ICxIA;;;;;;;;;;;;;;;;IAiBA;aACgB,0BAA0B,CACtC,UAAoB,EAAE,YAAoB;QAC5C,IAAI,IAAI,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,CAAC,EAAE;YAC/B,MAAM,IAAI,KAAK,CAAC,0DAA0D,CAAC,CAAC;SAC7E;QAED,MAAM,SAAS,GAAG,UAAU,CAAC,MAAM,CAAC;QACpC,MAAM,KAAK,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,YAAY,IAAI,CAAC,GAAG,CAAC,CAAC;QAC3D,MAAM,OAAO,GAAG,IAAI,KAAK,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;QACzC,OAAO,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;QAC9C,KAAK,IAAI,CAAC,GAAG,SAAS,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,EAAE,CAAC,EAAE;YACvC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,MAAM,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC;SACtD;QAED,OAAO,OAAO,CAAC;IACjB;;ICjCA;;;;;;;;;;;;;;;;IAqDO,MAAM,cAAc,GACvB,CAAC,MAAiB,EAAE,OAAsB,EAAE,UAAuB,EAClE,MAAkB;QACjB,MAAM,UAAU,GAAG,EAAC,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAC,CAAC;QAC9D,MAAM,MAAM,GAAG,UAAU,CAAC,UAAU,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;QAC3D,MAAM,MAAM,GAAG,MAAM,CAAC,kBAAkB,CACpC,EAAC,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,CAAC,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;QACrD,MAAM,QAAQ,GAAG,MAAM,CAAC,qBAAqB,CAAC;YAC5C,OAAO,EAAE,EAAC,MAAM,EAAE,UAAU,EAAE,QAAQ,EAAC;YACvC,KAAK,EAAE,OAAO,CAAC,WAAW,CAAC,IAAI;YAC/B,MAAM,EAAE,MAAM;SACf,CAAC,CAAC;QAEH,OAAO,QAAQ,CAAC;IAClB,CAAC,CAAC;aAEU,iBAAiB,CAAC,IAAY;QAC5C,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,KAAK,CAAC;SACd;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,WAAW,CAAC;SACpB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,WAAW,CAAC;SACpB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,WAAW,CAAC;SACpB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,MAAM,CAAC;SACf;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,MAAM,CAAC;SACf;aAAM;YACL,MAAM,KAAK,CAAC,gBAAgB,IAAI,uBAAuB,CAAC,CAAC;SAC1D;IACH,CAAC;aAEe,YAAY,CAAC,KAAa;QACxC,IAAI,KAAK,KAAK,CAAC,EAAE;YACf,OAAO,GAAG,CAAC;SACZ;aAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,OAAO,GAAG,CAAC;SACZ;aAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,OAAO,GAAG,CAAC;SACZ;aAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,OAAO,GAAG,CAAC;SACZ;aAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,OAAO,GAAG,CAAC;SACZ;aAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,OAAO,GAAG,CAAC;SACZ;aAAM;YACL,MAAM,KAAK,CAAC,SAAS,KAAK,uBAAuB,CAAC,CAAC;SACpD;IACH,CAAC;aAIe,mBAAmB,CAAC,GAAG,MAAgB;QACrD,IAAI,OAAe,CAAC;QACpB,QAAQ,MAAM,CAAC,MAAM;YACnB,KAAK,CAAC;gBACJ,OAAO,GAAG;UACN,sBAAsB,EAAE;;;;;;;;;;;OAW3B,CAAC;gBACF,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,GAAG;UACN,sBAAsB,EAAE;;;;;;;;;;kBAUhB,MAAM,CAAC,CAAC,CAAC;OACpB,CAAC;gBACF,MAAM;YACR;gBACE,MAAM,KAAK,CAAC,aAAa,CAAC,CAAC;SAC9B;QACD,OAAO,OAAO,CAAC;IACjB,CAAC;aAEe,sBAAsB;QACpC,OAAO;;CAER,CAAC;IACF,CAAC;IAED,SAAS,UAAU,CACf,SAAsB,EAAE,UAA8C,EACtE,OAAsB;QACxB,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,cAAc,CAAC,IAAI,CAAC;+BACS,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC;+BACxB,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC;+BACxB,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC;;;;;;;;UASjD,cAAc,CAAC,OAAO,CAAC;QACnB,2BAA2B;QAC3B;;;;;;;;;SASD;;KAEJ,CAAC,CAAC;QAEL,IAAI,OAAO,CAAC,YAAY,EAAE;YACxB,cAAc,CAAC,IAAI,CAAC;;;;;;;uEAQhB,cAAc,CAAC,UAAU,CAAC,KAAK,EAAE,OAAO,CAAC,MAAM,CAAC;;OAEjD,CAAC,CAAC;YACL,OAAO;gBACL,aAAa;gBACb,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC;gBACzB,yBAAyB,CAAC,UAAU,CAAC,KAAK,CAAC;gBAC3C,OAAO,CAAC,WAAW,EAAE;aACtB,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SACd;QAED,IAAI,kBAAkB,GAAG,+BAA+B,CAAC;QACzD,OAAO,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;YACjC,MAAM,WAAW,GAAG,iBAAiB,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;YACjE,kBAAkB;gBACd,GAAG,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,WAAW,WAAW,IAAI,CAAC;SACzE,CAAC,CAAC;QACH,MAAM,cAAc,GAAG,iBAAiB,CAAC,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAClE,kBAAkB,IAAI,cAAc,cAAc,IAAI,CAAC;QACvD,MAAM,aAAa,GAAG,UAAU,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;QAClD,MAAM,eAAe,GAAG,iBAAiB,CAAC,aAAa,CAAC,CAAC;QACzD,kBAAkB,IAAI;4BACI,eAAe,IAAI,CAAC;QAE9C,IAAI,OAAO,CAAC,IAAI,EAAE;YAChB,kBAAkB,IAAI,cAAc,CAAC;SACtC;QAED,IAAI,OAAO,CAAC,QAAQ,EAAE;YACpB,kBAAkB,IAAI,OAAO,CAAC,QAAQ,CAAC;SACxC;QACD,kBAAkB,IAAI,IAAI,CAAC;QAC3B,kBAAkB,GAAG,eAAe,CAAC,kBAAkB,CAAC,CAAC;QAEzD,cAAc,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;;QAGxC,IAAI,OAAO,CAAC,MAAM,EAAE;YAClB,cAAc,CAAC,IAAI,CAAC;;KAEnB,CAAC,CAAC;SACJ;aAAM;YACL,cAAc,CAAC,IAAI,CAAC;qEAEhB,cAAc,CAAC,UAAU,CAAC,KAAK,EAAE,OAAO,CAAC,MAAM,CAAC;KACnD,CAAC,CAAC;SACJ;QACD,OAAO,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;YACjC,cAAc,CAAC,IAAI,CAAC;2BACG,CAAC,GAAG,CAAC,wBAAwB,CAAC,WACjD,OAAO,CAAC,aAAa;YACjB,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC;YACxB,cAAc,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,OAAO,CAAC,MAAM,CAAC;SACrD,CAAC,CAAC;SACR,CAAC,CAAC;QAEH,IAAI,kBAAkB,KAAK,EAAE,EAAE;YAC7B,cAAc,CAAC,IAAI,CAAC;2BAEhB,CAAC,GAAG,OAAO,CAAC,aAAa,CAAC,MAAM;OACjC,CAAC,CAAC;SACN;QAED,MAAM,aAAa,GACf,sBAAsB,CAAC,UAAU,CAAC,KAAK,EAAE,OAAO,CAAC,cAAc,CAAC,CAAC;QAErE,MAAM,OAAO,GAAG;YACd,aAAa,EAAE,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC;YACxC,yBAAyB,CAAC,UAAU,CAAC,KAAK,CAAC,EAAE,aAAa;YAC1D,+BAA+B,CAAC,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC;SACzD,CAAC;QACF,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;YACnB,OAAO,CAAC,IAAI,CACR,gBAAgB,CAAC,UAAU,CAAC,KAAK,EAAE,UAAU,CAAC,KAAK,EAAE,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC;SAC3E;QAED,MAAM,YAAY,GACd,SAAS;aACJ,GAAG,CACA,CAAC,CAAC,EAAE,CAAC,KAAK,eAAe,CACrB,CAAC,EAAE,UAAU,CAAC,KAAK,EACnB,OAAO,CAAC,aAAa;aAChB,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,WAAW;YACzC,OAAO,CAAC,MAAM,EAClB,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,MAAM,KAAK,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;aACpE,IAAI,CAAC,IAAI,CAAC,CAAC;QACpB,OAAO,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;QAE3B,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC,CAAC;QACpC,MAAM,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;aAEe,aAAa,CACzB,OAAsB,EAAE,MAA0B,EAAE,UAAuB,EAC3E,MAAkB;QACpB,IAAI,GAAG,GAAG,OAAO,CAAC,SAAS,CAAC;QAC5B,IAAI,OAAO,CAAC,YAAY,EAAE;YACxB,OAAO,GAAG,CAAC;SACZ;QAED,MAAM,KAAK,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAChE,MAAM,aAAa,GACf,UAAU,CAAC,GAAG,CAAC,CAAC,IAAIC,eAAY,CAAC,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC;QAC9E,MAAM,yBAAyB,GAC3B,UAAU,CAAC,GAAG,CAAC,CAAC,IAAIC,OAAI,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC3E,MAAM,gBAAgB,GAAG,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAEvE,MAAM,kBAAkB,GAAG,cAAc,CAAC,OAAO,CAAC,GAAG,cAAc,GAAG,EAAE,CAAC;QAEzE,GAAG,IAAI,GAAG,IAAI,OAAO,CAAC,aAAa,GAAG,OAAO,CAAC,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC;YACvE,MAAM,CAAC,GAAG,CAAC,KAAK,IAAI,KAAK,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC;YAC7D,OAAO,CAAC,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,gBAAgB;YAClD,yBAAyB,GAAG,kBAAkB,CAAC;QAEnD,OAAO,GAAG,CAAC;IACb,CAAC;IAED,MAAM,aAAa,GAAG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CA0DrB,CAAC;IAOF;;;;;IAKA,SAAS,yBAAyB,CAAC,KAAe;QAChD,MAAM,IAAI,GAAG,KAAK,CAAC,MAAM,CAAC;QAE1B,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,6DAA6D,CAAC;SACtE;QAED,MAAM,OAAO,GAAGA,OAAI,CAAC,cAAc,CAAC,KAAK,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,CAAC;QAEtC,MAAM,MAAM,GAAa,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;YAC7B,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;SACtB;QAED,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,OAAO;;;MAGL,CAAC;SACJ;QACD,IAAI,OAAO,CAAC;QACZ,OAAO,GAAG,qBAAqB;YAC3B,OAAO;iBACF,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;gBACR,MAAM,KAAK,GACP,OAAO,MAAM,CAAC,CAAC,CAAC,wCACZ,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC;gBAC1B,MAAM,KAAK,GAAG,CAAC,KAAK,OAAO,CAAC,MAAM,GAAG,CAAC;oBAClC,OAAO,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,eAChB,MAAM,CAAC,CAAC,CAAC,+BAA+B,YAAY,CAAC,CAAC,CAAC,EAAE;oBAC7D,qBAAqB,MAAM,CAAC,CAAC,CAAC,+BAC1B,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC;gBAC1B,OAAO,GAAG,KAAK,KAAK,KAAK,GAAG,CAAC;aAC9B,CAAC;iBACD,IAAI,CAAC,EAAE,CAAC,CAAC;QAElB,OAAO;4CACmC,KAAK;QACzC,OAAO;eACA,KAAK,IAAI,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC;;GAErC,CAAC;IACJ,CAAC;IAED,SAAS,uBAAuB,CAC5B,SAAoB,EAAE,MAAe;QACvC,MAAM,OAAO,GAAG,SAAS,CAAC,IAAI,CAAC;QAC/B,MAAM,IAAI,GAAG,SAAS,CAAC,KAAK,CAAC,MAAM,CAAC;QACpC,MAAM,IAAI,GAAG,iBAAiB,CAAC,IAAI,CAAC,CAAC;QACrC,MAAM,QAAQ,GAAG,KAAK,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAC5E,MAAM,IAAI,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;QACjE,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAEtD,IAAI,IAAI,GAAG,CAAC,EAAE;YACZ,IAAI,MAAM,EAAE;gBACV,OAAO;aACA,QAAQ;6BACQ,OAAO;;OAE7B,CAAC;aACH;YAED,OAAO;WACA,QAAQ;qBACE,OAAO;;KAEvB,CAAC;SACH;QAED,MAAM,QAAQ,GACV,YAAY,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,OAAO,CAAC;QAC1E,IAAI,OAAO,GAAG,GAAG,IAAI,GAAG,CAAC;QACzB,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,OAAO,GAAG,IAAI,CAAC;SAChB;QAED,IAAI,MAAM,EAAE;YACV,OAAO;WACA,QAAQ,IAAI,MAAM;2BACF,OAAO,sBAAsB,OAAO,IAAI,IAAI,IAC/D,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;YACV,QAAQ;;OAEb,CAAC;SACL;QAED,OAAO;SACA,QAAQ,IAAI,MAAM;mBACR,OAAO,sBAAsB,OAAO,IAAI,IAAI,IACzD,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;UACV,QAAQ;;IAEd,CAAC;IACL,CAAC;IAED,SAAS,uBAAuB,CAC5B,SAAoB,EAAE,QAAkB,EAAE,MAAe,EACzD,oBAA6B;QAC/B,MAAM,OAAO,GAAG,SAAS,CAAC,IAAI,CAAC;QAC/B,MAAM,cAAc,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,QAAQ,GAAG,KAAK,GAAG,cAAc,GAAG,UAAU,CAAC;QAErD,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,MAAM,CAAC;QACtC,MAAM,OAAO,GAAG,QAAQ,CAAC,MAAM,CAAC;QAChC,MAAM,IAAI,GAAG,iBAAiB,CAAC,OAAO,CAAC,CAAC;;;;QAKxC,IAAIA,OAAI,CAAC,WAAW,CAAC,SAAS,CAAC,KAAK,EAAE,QAAQ,CAAC,IAAI,oBAAoB,EAAE;YACvE,IAAI,MAAM,EAAE;gBACV,OAAO;WACF,QAAQ;2BACQ,OAAO;;;WAGvB,QAAQ,mBAAmB,IAAI;2BACf,OAAO,IACxB,OAAO,GAAG,CAAC,GAAG,kCAAkC,GAAG,QAAQ;;OAE9D,CAAC;aACH;iBAAM;gBACL,OAAO;SACJ,QAAQ;mBACE,OAAO;;;SAGjB,QAAQ,mBAAmB,IAAI;mBACrB,OAAO,IAChB,OAAO,GAAG,CAAC,GAAG,kCAAkC,GAAG,QAAQ;;KAEhE,CAAC;aACD;SACF;QAED,MAAM,aAAa,GACfD,eAAY,CAAC,gBAAgB,CAAC,SAAS,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QAC7D,MAAM,QAAQ,GAAG,OAAO,GAAG,MAAM,CAAC;QAElC,IAAI,aAAa,GAAG,EAAE,CAAC;QAEvB,IAAI,MAAM,KAAK,CAAC,EAAE;YAChB,IAAI,MAAM,EAAE;gBACV,OAAO;SACJ,QAAQ;kBACC,cAAc;;;SAGvB,QAAQ,mBAAmB,IAAI;kBACtB,cAAc;;GAE7B,CAAC;aACC;YACD,OAAO;SACF,QAAQ;kBACC,cAAc;;;SAGvB,QAAQ,mBAAmB,IAAI;kBACtB,cAAc;;GAE7B,CAAC;SACD;aAAM;YACL,IAAI,OAAO,GAAG,CAAC,IAAI,aAAa,CAAC,MAAM,IAAI,CAAC,EAAE;gBAC5C,aAAa,GAAG,aAAa,CAAC;aAC/B;iBAAM;gBACL,aAAa;oBACT,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,UAAU,YAAY,CAAC,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC;yBAC9D,IAAI,CAAC,IAAI,CAAC,CAAC;aACrB;SACF;QAED,IAAI,qBAAqB,GAAG,EAAE,CAAC;QAC/B,IAAI,OAAO,GAAG,CAAC,IAAI,MAAM,GAAG,CAAC,EAAE;YAC7B,qBAAqB,GAAG,QAAQ,CAAC;SAClC;aAAM;YACL,IAAI,OAAO,GAAG,CAAC,EAAE;gBACf,MAAM,UAAU,GAAG,iBAAiB,CAAC,MAAM,CAAC,CAAC;gBAC7C,MAAM,YAAY,GACd,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,UAAU,YAAY,CAAC,CAAC,GAAG,QAAQ,CAAC,EAAE,CAAC;qBAChE,IAAI,CAAC,IAAI,CAAC,CAAC;gBACpB,qBAAqB,GAAG,GAAG,UAAU,IAAI,YAAY,GAAG,CAAC;aAC1D;iBAAM;gBACL,qBAAqB,GAAG,QAAQ,CAAC;aAClC;SACF;QAED,MAAM,QAAQ,GACV,YAAY,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,OAAO,CAAC;QAC1E,MAAM,OAAO,GAAG,GAAG,MAAM,GAAG,CAAC;QAC7B,IAAI,MAAM,EAAE;YACV,OAAO;SACF,QAAQ;;QAET,aAAa;eACN,OAAO,sBAAsB,OAAO,IAC3C,qBAAqB,KAAK,QAAQ;;;SAGjC,QAAQ,qBAAqB,IAAI;;QAElC,aAAa;eACN,OAAO,sBAAsB,OAAO,IAC3C,qBAAqB,KAAK,QAAQ;;GAEvC,CAAC;SACD;QAED,OAAO;OACF,QAAQ;;MAET,aAAa;iBACF,OAAO,sBAAsB,OAAO,IAC/C,qBAAqB,KAAK,QAAQ;;;OAGjC,QAAQ,qBAAqB,IAAI;;MAElC,aAAa;iBACF,OAAO,sBAAsB,OAAO,IAC/C,qBAAqB,KAAK,QAAQ;;CAEvC,CAAC;IACF,CAAC;IAED,SAAS,eAAe,CACpB,SAAoB,EAAE,QAAkB,EAAE,MAAe,EACzD,oBAA6B;QAC/B,IAAI,GAAG,GAAG,uBAAuB,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;QAErD,MAAM,OAAO,GAAG,SAAS,CAAC,KAAK,CAAC;QAChC,IAAI,OAAO,CAAC,MAAM,IAAI,QAAQ,CAAC,MAAM,EAAE;YACrC,GAAG,IAAI,uBAAuB,CAC1B,SAAS,EAAE,QAAQ,EAAE,MAAM,EAAE,oBAAoB,CAAC,CAAC;SACxD;QAED,OAAO,GAAG,CAAC;IACb,CAAC;IAED;;;;IAIA,SAAS,sBAAsB,CAC3B,QAAkB,EAClB,cAAyD;QAC3D,MAAM,EAAC,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,EAAE,EAAC,GAAG,cAAc,CAAC;QAE3C,MAAM,OAAO,GAAG,QAAQ,CAAC,MAAM,CAAC;QAChC,MAAM,IAAI,GAAG,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC,MAAM,CAAC;;;QAG5C,IAAI,IAAI,KAAK,OAAO,EAAE;YACpB,OAAO,EAAE,CAAC;SACX;QAED,IAAI,CAAC,CAAC,MAAM,KAAK,OAAO,EAAE;YACxB,MAAM,KAAK,GAAG,iBAAiB,CAAC,OAAO,CAAC,CAAC;YACzC,MAAM,OAAO,GAAG,2BAA2B,KAAK;;;;GAIjD,CAAC;YACA,OAAO,OAAO,CAAC;SAChB;QAED,IAAI,mBAAmB,GAAG,EAAE,CAAC;QAC7B,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAEvB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACpC,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;YAEpB,IAAI,GAAG,CAAC,MAAM,KAAK,CAAC,EAAE;gBACpB,SAAS;aACV;YAED,IAAI,GAAG,CAAC,MAAM,KAAK,CAAC,EAAE;gBACpB,mBAAmB,IAAI,QAAQ,GAAG,CAAC,CAAC,CAAC,mBAAmB,CAAC,KAAK,CAAC;aAChE;iBAAM;gBACL,MAAM,OAAO,GAAG,0BAA0B,CAAC,GAAG,EAAE,mBAAmB,CAAC,CAAC;gBACrE,mBAAmB,IAAI,YAAY,CAAC,mBAAmB,CAAC,KAAK,CAAC;gBAC9D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;oBACvC,mBAAmB,IAAI,QAAQ,GAAG,CAAC,CAAC,CAAC,WAAW,CAAC,MAAM,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC;oBAErE,IAAI,CAAC,KAAK,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;wBAC5B,mBAAmB,IAAI,QAAQ,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK;4BAC1C,QAAQ,CAAC,OAAO,GAAG,CAAC,CAAC,CAAC,MAAM,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC;qBAC/C;yBAAM;wBACL,mBAAmB;4BACf,QAAQ,CAAC,WAAW,CAAC,OAAO,GAAG,CAAC,CAAC,CAAC,MAAM,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC;qBAC3D;iBACF;aACF;SACF;QAED,MAAM,UAAU,GAAG,EAAE,CAAC;QACtB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;YAC7B,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;SAC1B;QAED,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,CAAC;QACtC,IAAI,OAAO,GAAG,2BAA2B,KAAK;IAC5C,mBAAmB;CACtB,CAAC;QACA,IAAI,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE;YAC3B,OAAO,IAAI,UAAU,KAAK,QAAQ,CAAC;SACpC;aAAM;YACL,OAAO,IAAI,UAAU,KAAK,IAAI,UAAU,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;SAC1D;QAED,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,SAAS,+BAA+B,CAAC,OAAe;QACtD,IAAI,OAAO,GAAG,EAAE,CAAC;QACjB,QAAQ,OAAO;YACb,KAAK,CAAC,CAAC;YACP,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;SAIR,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;SAIR,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;SAIR,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;;SAKR,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;;;;;SAQR,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACJ,OAAO,IAAI;;;;;;;;;SASR,CAAC;gBACJ,MAAM;YACR;gBACEC,OAAI,CAAC,MAAM,CAAC,KAAK,EAAE,MAAM,eAAe,OAAO,SAAS,CAAC,CAAC;gBAC1D,MAAM;SACT;QACD,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,SAAS,cAAc,CAAC,OAAsB;QAC5C,OAAO,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;IAChE,CAAC;aAEe,cAAc,CAAC,IAAc,EAAE,MAAe;QAE5D,IAAI,IAAI,KAAK,SAAS,EAAE;YACtB,OAAO,MAAM,GAAG,WAAW,GAAG,KAAK,CAAC;SACrC;aAAM,IAAI,IAAI,KAAK,OAAO,EAAE;YAC3B,OAAO,MAAM,GAAG,WAAW,GAAG,KAAK,CAAC;SACrC;aAAM,IAAI,IAAI,KAAK,MAAM,EAAE;;;YAG1B,OAAO,MAAM,GAAG,WAAW,GAAG,KAAK,CAAC;SACrC;QAED,OAAO,IAAI,CAAC;IACd,CAAC;IAED,SAAS,gBAAgB,CACrB,QAAkB,EAAE,aAAuB,EAAE,MAAe;QAC9D,MAAM,OAAO,GAAG,QAAQ,CAAC,MAAM,CAAC;QAChC,MAAM,QAAQ,GAAG,cAAc,CAAC,aAAa,EAAE,MAAM,CAAC,CAAC;QACvD,IAAI,OAAO,CAAC;QACZ,IAAI,MAAM,EAAE;YACV,OAAO,GAAG;4BACc,QAAQ;;;4BAGR,QAAQ;MAC9B,CAAC;SACJ;aAAM;YACL,OAAO,GAAG;4BACc,QAAQ;;;4BAGR,QAAQ;MAC9B,CAAC;SACJ;QACD,IAAI,OAAO,IAAI,CAAC,EAAE;YAChB,MAAM,IAAI,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;YACpE,MAAM,IAAI,GAAG,iBAAiB,CAAC,OAAO,CAAC,CAAC;YAExC,IAAI,MAAM,EAAE;gBACV,OAAO,IAAI;6BAEP,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;mDACG,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;;;gCAIhE,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;mDACG,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;;;KAGrE,CAAC;aACD;iBAAM;gBACL,OAAO,IAAI;6BAEP,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;mDACG,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;;;gCAIhE,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;mDACG,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;;;KAGrE,CAAC;aACD;SACF;QAED,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,SAAS,eAAe,CAAC,aAAqB;;QAE5C,MAAM,WAAW,GAAG,uBAAuB,CAAC;QAC5C,aAAa,GAAG,aAAa,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC,KAAK;YACvD,OAAO,aAAa,GAAG,KAAK,CAAC;SAC9B,CAAC,CAAC;;QAGH,MAAM,WAAW,GAAG,uBAAuB,CAAC;QAC5C,aAAa,GAAG,aAAa,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE;YAC3D,OAAO,MAAM,EAAE,gBAAgB,EAAE,EAAE,CAAC;SACrC,CAAC,CAAC;QACH,OAAO,aAAa,CAAC;IACvB;;IC5zBA,MAAM,YAAY,GAAG,CAAC,GAAa;QACjC,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACnC,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;SACnB;QACD,OAAO,OAAO,CAAC;IACjB,CAAC,CAAC;aAEc,uBAAuB,CACnC,QAAkB,EAAE,KAAe;QACrC,IAAI,QAAQ,CAAC,MAAM,KAAK,KAAK,CAAC,MAAM,EAAE;YACpC,MAAM,IAAI,KAAK,CACX,+BAA+B,QAAQ,CAAC,MAAM,EAAE;gBAChD,+BAA+B,KAAK,CAAC,MAAM,QAAQ;gBACnD,sBAAsB,CAAC,CAAC;SAC7B;QACD,OAAO,KAAK,CAAC,KAAK,CACd,CAAC,GAAW,EAAE,MAAc,KAAK,GAAG,GAAG,QAAQ,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC;IACrE,CAAC;IAED;IACA;aACgB,eAAe,CAC3B,MAAiD,EAAE,WAAqB,EACxE,gBAA0C,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EACnD,oBACI,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;QACf,MAAM,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,GAAG;YACxC,IAAI,CAAC,IAAI,CACL,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;iBAC9C,aAAa,CAAC,CAAC,CAAC,GAAG,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC;YAC9C,MAAM,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CACL,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;iBAC9C,aAAa,CAAC,CAAC,CAAC,GAAG,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC9C,CAAC;YACZ,MAAM,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CACL,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;iBAC9C,aAAa,CAAC,CAAC,CAAC,GAAG,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC9C,CAAC;SACb,CAAC;QACF,OAAO,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;IAC3C,CAAC;aAOe,6BAA6B,CACzC,SAAiB,EAAE,QAAgB,EAAE,SAAiB,EACtD,UAAU,GAAG,KAAK;;;;;;;;QAQpB,MAAM,aAAa,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC1D,MAAM,iBAAiB,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAE9D,IAAI,CAAC,UAAU,EAAE;YACf,IAAI,SAAS,IAAI,CAAC,EAAE;gBAClB,iBAAiB,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aAC1B;YAED,IAAI,QAAQ,IAAI,EAAE,IAAI,SAAS,IAAI,EAAE,EAAE;gBACrC,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aACtB;SACF;QAED,OAAO,EAAC,aAAa,EAAE,iBAAiB,EAAC,CAAC;IAC5C,CAAC;aAEe,6BAA6B,CACzC,MAAiD,EAAE,WAAqB,EACxE,MAAM,GAAG,KAAK;QAChB,IAAI,MAAM,EAAE;YACV,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAClB;QAED,MAAM,IAAI,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,IAAI,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;;;;;;;;;QAS7D,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;SACnB;QACD,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SACnB;QAED,OAAO,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;IACrB,CAAC;aAEe,6BAA6B,CACzC,MAAiD,EAAE,WAAqB,EACxE,MAAM,GAAG,KAAK;QAChB,IAAI,MAAM,EAAE;YACV,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAClB;QAED,MAAM,IAAI,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,IAAI,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;;;;QAI7D,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAClB;QACD,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAClB;QAED,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IACnB,CAAC;aAEe,kBAAkB,CAAC,KAAe;QAChD,OAAO,EAAC,CAAC,EAAE,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAC,CAAC;IACrC,CAAC;aAEe,kBAAkB,CAAC,KAAe;QAChD,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,IAAI,KAAK,KAAK,MAAM;YAC5D,KAAK,KAAK,QAAQ,EAAE;YACtB,OAAO,CAAC,CAAC;SACV;aAAM,IAAI,KAAK,KAAK,WAAW,EAAE;YAChC,OAAO,CAAC,CAAC;SACV;aAAM;YACL,MAAM,IAAI,KAAK,CAAC,iBAAiB,KAAK,EAAE,CAAC,CAAC;SAC3C;IACH,CAAC;aAEe,uBAAuB,CAAC,IAAiB,EAAE,KAAe;QACxE,IAAI,KAAK,KAAK,SAAS,EAAE;YACvB,OAAO,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC;SAC/B;aAAM,IAAI,KAAK,KAAK,OAAO,EAAE;YAC5B,OAAO,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;SAC7B;aAAM,IAAI,KAAK,KAAK,MAAM,IAAI,KAAK,KAAK,QAAQ,EAAE;YACjD,OAAO,UAAU,CAAC,IAAI,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC,CAAC;SAC9C;aAAM;YACL,MAAM,IAAI,KAAK,CAAC,iBAAiB,KAAK,EAAE,CAAC,CAAC;SAC3C;IACH,CAAC;aAEe,iBAAiB;QAC/B,OAAO,CAAC,CAAC,OAAO,MAAM,KAAK,WAAW;;aAE7B,OAAO,iBAAiB,KAAK,WAAW,CAAC;YAC9C,CAAC,CAAC,SAAS,CAAC,GAAG,CAAC;IACtB,CAAC;IAED,IAAY,iBAMX;IAND,WAAY,iBAAiB;QAC3B,uFAAmB,CAAA;QACnB,uFAAmB,CAAA;QACnB,yGAA4B,CAAA;QAC5B,uFAAmB,CAAA;QACnB,mEAAS,CAAA;IACX,CAAC,EANW,iBAAiB,KAAjB,iBAAiB;;;;;;;;;;;;;;;;IC/K7B;;;;;;;;;;;;;;;;IA0EA;IACA;IACA,MAAM,0BAA0B,GAC5BF,MAAG,EAAE,CAAC,SAAS,CAAC,mCAAmC,CAAC,CAAC;IAEzD;IACA,MAAM,eAAe,GACjB,CAAC,MAAiB,EACjB,OAAqC;QACpC,MAAM,uCAAuC,GACzC,MAAM,CAAC,MAAM,CAAC,gCAAgC,CAAC;QACnD,MAAM,MAAM,GAAG,OAAO,CAAC,gBAAgB,CAAC,CAAC;QACzC,MAAM,QAAQ,GAAG,OAAO,CAAC,UAAU,CAAC,CAAC;QACrC,IAAI,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,uCAAuC,CAAC,EAAE;YACvE,OAAO,QAAQ,CAAC;SACjB;QAEDE,OAAI,CAAC,MAAM,CACP,QAAQ,CAAC,CAAC,CAAC,GAAG,uCAAuC;YACjD,MAAM,CAAC,CAAC,KAAK,SAAS,IAAI,MAAM,CAAC,CAAC,KAAK,SAAS,EACpD,MAAM,0DAA0D,CAAC,CAAC;QAEtE,IAAI,eAAe,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxD,IAAI,eAAe,GAAG,uCAAuC,EAAE;YAC7D,eAAe,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YACpDA,OAAI,CAAC,MAAM,CACP,eAAe,IAAI,uCAAuC,EAC1D,MAAM,6CAA6C,CAAC,CAAC;YACzD,OAAO,CAAC,eAAe,EAAE,eAAe,EAAE,eAAe,CAAC,CAAC;SAC5D;aAAM;YACL,OAAO,CAAC,eAAe,EAAE,eAAe,EAAE,CAAC,CAAC,CAAC;SAC9C;IACH,CAAC,CAAC;UAEO,aAAc,SAAQC,gBAAa;QA+B9C,YAAY,MAAiB,EAAE,WAA4B;YACzD,KAAK,EAAE,CAAC;YArBF,yBAAoB,GAAG,IAAI,OAAO,EAAU,CAAC;YAC7C,4BAAuB,GAAG,CAAC,CAAC;YAC5B,aAAQ,GAAG,KAAK,CAAC;YACjB,mBAAc,GAAG,CAAC,CAAC;YAGnB,8BAAyB,GAAa,EAAE,CAAC;YAKzC,2BAAsB,GAAiB,EAAE,CAAC;YAE1C,2BAAsB,GAAiB,EAAE,CAAC;YAC1C,iBAAY,GAAG,CAAC,CAAC;YAQvB,IAAI,CAACC,iBAA6B,EAAE,EAAE;gBACpC,MAAM,IAAI,KAAK,CAAC,wCAAwC,CAAC,CAAC;aAC3D;YACD,IAAI,CAAC,aAAa,GAAG,EAAE,CAAC;YACxB,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;YACrB,IAAI,CAAC,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC;YAC1B,IAAI,CAAC,qBAAqB,GAAG,IAAI,CAAC;YAClC,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;YAC/B,IAAI,CAAC,gBAAgB,GAAG,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;YAC/D,IAAI,CAAC,WAAW,GAAG,IAAI,WAAW,CAAC,WAAW,CAAC,CAAC;YAEhD,IAAI,CAAC,aAAa,GAAG,IAAI,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YACpD,IAAI,CAAC,cAAc,GAAG,IAAI,cAAc,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YACtD,IAAI,CAAC,SAAS,GAAG,IAAIC,cAAW,CAAC,IAAI,EAAEC,SAAM,EAAE,CAAC,CAAC;YACjD,IAAI,IAAI,CAAC,gBAAgB,EAAE;gBACzB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,MAAM,CAAC,cAAc,CAAC;oBACzC,IAAI,EAAE,WAAW;oBACjB,KAAK,EAAE,CAAC;iBACT,CAAC,CAAC;aACJ;;;YAID,IAAIN,MAAG,EAAE,CAAC,OAAO,CAAC,yBAAyB,CAAC,EAAE;gBAC5C,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;gBACpD,IAAI,CAAC,WAAW,CAAC,KAAK,GAAG,CAAC,CAAC;gBAC3B,IAAI,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC;gBAE5B,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,QAAQ,CAAC,CAAC;gBAC1D,IAAI,CAAC,YAAY,CAAC,SAAS,CAAC;oBAC1B,MAAM;oBACN,MAAM,EAAE,YAAY;iBACrB,CAAC,CAAC;gBAEH,QAAQ,CAAC,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;aAC7C;SACF;QA1CO,UAAU;YAChB,OAAO,aAAa,CAAC,UAAU,EAAE,CAAC;SACnC;QA0CD,cAAc;YACZ,OAAO,EAAE,CAAC;SACX;QAED,qBAAqB;YACnB,OAAO,cAAc,CAAC,OAAO,GAAG,cAAc,CAAC,QAAQ;gBACnD,cAAc,CAAC,QAAQ,CAAC;SAC7B;;;;;;;;QASD,WAAW,CAAC,MAAc,EAAE,KAAK,GAAG,KAAK;YACvC,IAAI,IAAI,CAAC,yBAAyB,CAAC,OAAO,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE;gBACvD,OAAO,KAAK,CAAC;aACd;YACD,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;gBAC/B,OAAO,IAAI,CAAC;aACb;YAED,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC9C,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACpB,IAAI,CAAC,KAAK,IAAI,UAAU,CAAC,QAAQ,GAAG,CAAC,EAAE;gBACrC,OAAO,KAAK,CAAC;aACd;;YAGD,IAAI,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;gBACzC,IAAI,CAAC,yBAAyB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBAC5C,OAAO,KAAK,CAAC;aACd;YAED,MAAM,EAAC,kBAAkB,EAAC,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YACxD,IAAI,kBAAkB,IAAI,IAAI,EAAE;gBAC9B,IAAI,CAAC,WAAW,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;gBACxD,IAAI,CAAC,WAAW,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;aACzD;YAED,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;YAC7B,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YAE9B,OAAO,IAAI,CAAC;SACb;QAED,MAAM;YACJ,OAAO;gBACL,aAAa,EAAE,IAAI,CAAC,aAAa,CAAC,YAAY;gBAC9C,sBAAsB,EAAE,IAAI,CAAC,aAAa,CAAC,iBAAiB;gBAC5D,UAAU,EAAE,KAAK;aACE,CAAC;SACvB;QAED,eAAe,CAAC,MAAc;YAC5B,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC9C,IAAI,CAAC,UAAU,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE;gBAC3C,OAAO;aACR;YACD,IAAI,SAAS,IAAI,UAAU,CAAC,YAAY,EAAE;gBACxC,MAAM,WAAW,GAAG,UAAU,CAAC,YAAY,CAAC;gBAC5C,IAAI,WAAW,CAAC,OAAO,YAAY,UAAU,EAAE;oBAC7C,IAAI,CAAC,cAAc,CAAC,cAAc,CAC9B,WAAW,CAAC,OAAO,EAAE,WAAW,CAAC,KAAK,EAAE,WAAW,CAAC,MAAM,EAC1D,WAAW,CAAC,MAAM,EAAE,WAAW,CAAC,KAAK,CAAC,CAAC;iBAC5C;gBACD,WAAW,CAAC,OAAO,GAAG,IAAI,CAAC;aAC5B;iBAAM;gBACL,MAAM,UAAU,GAAG,UAAU,CAAC,YAAY,CAAC;gBAC3C,IAAI,CAAC,aAAa,CAAC,aAAa,CAC5B,UAAU,CAAC,MAAM,EAAE,UAAU,CAAC,IAAI,EAAE,UAAU,CAAC,KAAK,CAAC,CAAC;gBAC1D,UAAU,CAAC,MAAM,GAAG,IAAI,CAAC;aAC1B;YACD,UAAU,CAAC,YAAY,GAAG,IAAI,CAAC;SAChC;;QAGD,QAAQ,CAAC,MAAc;YACrB,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;gBAC9B,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;gBAC9C,OAAO,UAAU,CAAC,QAAQ,CAAC;aAC5B;YACD,OAAO,CAAC,CAAC;SACV;;QAGD,MAAM,CAAC,MAAc;YACnB,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC9C,UAAU,CAAC,QAAQ,EAAE,CAAC;SACvB;;QAGD,MAAM,CAAC,MAAc;YACnB,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;gBAC9B,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;gBAC9C,UAAU,CAAC,QAAQ,EAAE,CAAC;aACvB;SACF;QAED,KAAK,CAAC,MAAkC,EAAE,KAAe,EAAE,KAAe;YAExE,IAAI,KAAK,KAAK,WAAW,IAAI,MAAM,IAAI,IAAI,EAAE;gBAC3C,MAAM,IAAI,KAAK,CACX,qCAAqC;oBACrC,oCAAoC,CAAC,CAAC;aAC3C;YACD,MAAM,MAAM,GAAG,EAAC,EAAE,EAAE,IAAI,CAAC,UAAU,EAAE,EAAC,CAAC;YACvC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,EAAE,EAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,CAAC,EAAC,CAAC,CAAC;YAChE,OAAO,MAAM,CAAC;SACf;QAED,IAAI,CACA,MAAc,EAAE,MAAkC,EAAE,KAAe,EACnE,KAAe,EAAE,QAAgB;YACnC,IAAI,KAAK,KAAK,WAAW,EAAE;gBACzB,MAAM,IAAI,KAAK,CACX,qCAAqC;oBACrC,oCAAoC,CAAC,CAAC;aAC3C;YACD,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,EAAE,EAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAC,CAAC,CAAC;SAC9D;QAED,WAAW;YACT,IAAI,CAAC,sBAAsB,EAAE,CAAC;YAC9B,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;YACzD,IAAI,CAAC,qBAAqB,GAAG,IAAI,CAAC;YAClC,IAAI,CAAC,uBAAuB,GAAG,CAAC,CAAC;YAEjC,IAAI,CAAC,oBAAoB,GAAG,IAAI,OAAO,EAAU,CAAC;YAElD,IAAI,CAAC,yBAAyB,CAAC,OAAO,CAAC,CAAC;gBACtC,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;gBACxB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;aAC1B,CAAC,CAAC;YACH,IAAI,CAAC,sBAAsB,CAAC,OAAO,CAC/B,CAAC,IAAI,IAAI,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC,CAAC,MAAM,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;YACtE,IAAI,CAAC,sBAAsB,CAAC,OAAO,CAC/B,CAAC,IAAI,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAAC,CAAC,CAAC,MAAM,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;YAE5E,IAAI,CAAC,yBAAyB,GAAG,EAAE,CAAC;YACpC,IAAI,CAAC,sBAAsB,GAAG,EAAE,CAAC;YACjC,IAAI,CAAC,sBAAsB,GAAG,EAAE,CAAC;SAClC;QAED,yBAAyB;YACvB,IAAI,CAAC,IAAI,CAAC,qBAAqB,EAAE;gBAC/B,IAAI,CAAC,qBAAqB,GAAG,IAAI,CAAC,MAAM,CAAC,oBAAoB,EAAE,CAAC;aACjE;SACF;QAED,sBAAsB;YACpB,IAAI,IAAI,CAAC,kBAAkB,EAAE;gBAC3B,IAAI,CAAC,kBAAkB,CAAC,GAAG,EAAE,CAAC;gBAC9B,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;aAChC;SACF;QAED,cAAc;YACZ,IAAI,CAAC,IAAI,CAAC,kBAAkB,EAAE;gBAC5B,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC,qBAAqB,CAAC,gBAAgB,EAAE,CAAC;aACzE;YACD,OAAO,IAAI,CAAC,kBAAkB,CAAC;SAChC;QAEM,MAAM,aAAa,CAAC,MAAiB,EAAE,IAAY;YAExD,MAAM,OAAO,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,CAC5C,IAAI,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YAC7D,IAAI,CAAC,yBAAyB,EAAE,CAAC;YACjC,IAAI,CAAC,sBAAsB,EAAE,CAAC;YAC9B,IAAI,CAAC,qBAAqB,CAAC,kBAAkB,CAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;YAC3E,IAAI,CAAC,WAAW,EAAE,CAAC;YAEnB,MAAM,OAAO,CAAC,QAAQ,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;YACxC,MAAM,MAAM,GAAG,OAAO,CAAC,cAAc,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAEjD,OAAO,CAAC,KAAK,EAAE,CAAC;YAChB,IAAI,OAAO,IAAI,IAAI,EAAE;gBACnB,IAAI,CAAC,aAAa,CAAC,aAAa,CAC5B,OAAO,EAAE,IAAI,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;aACvE;;;YAID,IAAIA,MAAG,EAAE,CAAC,OAAO,CAAC,yBAAyB,CAAC,EAAE;gBAC5CE,OAAI,CAAC,MAAM,CACP,IAAI,CAAC,YAAY,KAAK,SAAS,EAC/B,MAAM,wCAAwC,CAAC,CAAC;gBACpD,IAAI,CAAC,YAAY,CAAC,iBAAiB,EAAE,CAAC;aACvC;YAED,OAAO,MAAoC,CAAC;SAC7C;QAEO,oBAAoB,CAAC,MAAc,EAAE,IAA6B;YAExE,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC9C,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;YAC7B,UAAU,CAAC,MAAM,GAAG,IAAI,CAAC;YACzB,OAAO,UAAU,CAAC,MAAM,CAAC;SAC1B;;;QAID,QAAQ,CAAC,MAAc;YACrB,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC9C,MAAM,EAAC,MAAM,EAAC,GAAG,UAAU,CAAC;YAE5B,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,MAAM,IAAI,KAAK,CACX,6DAA6D,CAAC,CAAC;aACpE;YAED,OAAO,MAAM,CAAC;SACf;QAED,MAAM,IAAI,CAAC,MAAc;YACvB,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;gBAC/B,MAAM,IAAI,KAAK,CAAC,UAAU,MAAM,sBAAsB,CAAC,CAAC;aACzD;YACD,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAE9C,MAAM,EAAC,MAAM,EAAC,GAAG,UAAU,CAAC;YAE5B,IAAI,MAAM,IAAI,IAAI,EAAE;;;gBAGlB,OAAO,IAAI,CAAC,oBAAoB,CACrB,MAAM,EAAE,MAAiC,CACtB,CAAC;aAChC;;YAGD,IAAI,IAAgC,CAAC;YACrC,IAAI,UAAU,CAAC,KAAK,KAAK,WAAW,EAAE;gBACpC,MAAM,EAAE,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC;oBAC3B,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAC;oBACpD,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAC;iBACrD,CAAC,CAAC;gBAEH,MAAM,UAAU,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC;gBACzB,MAAM,UAAU,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC;gBACzB,IAAI,GAAGD,eAAY,CAAC,sBAAsB,CACtC,UAA0B,EAAE,UAA0B,CAAC,CAAC;aAC7D;iBAAM;gBACL,MAAM,UAAU,GAAG,UAAU,CAAC,YAA0B,CAAC;gBACzD,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,MAAM,EAAE,UAAU,CAAC,IAAI,CAAC,CAAC;gBAC1E,IAAI,GAAGM,uBAAmC,CACtC,IAAmB,EAAE,UAAU,CAAC,KAAK,CAAC,CAAC;aAC5C;YACD,IAAI,CAAC,oBAAoB,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;YACxC,OAAO,IAAI,CAAC;SACb;;;;;QAMD,SAAS,CAAC,MAAc;YACtB,MAAM,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YACjD,MAAM,EAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,YAAY,EAAC,GAAG,aAAa,CAAC;YAE3D,IAAI,KAAK,KAAK,WAAW,EAAE;gBACzB,MAAM,IAAI,KAAK,CAAC,sDAAsD,CAAC,CAAC;aACzE;YAED,IAAI,YAAY,IAAI,IAAI,EAAE;gBACxB,IAAI,MAAM,IAAI,IAAI,EAAE;oBAClB,MAAM,IAAI,KAAK,CAAC,gCAAgC,CAAC,CAAC;iBACnD;qBAAM;oBACL,MAAM,IAAI,KAAK,CAAC,iCAAiC,CAAC,CAAC;iBACpD;aACF;YAED,MAAM,IAAI,GAAI,YAA2B,CAAC,IAAI,CAAC;YAC/C,MAAM,MAAM,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,CAAC,IAAI,EAAE,YAAY,CAAC,KAAK,CAAC,CAAC;YAC1E,IAAI,CAAC,yBAAyB,EAAE,CAAC;YACjC,IAAI,CAAC,sBAAsB,EAAE,CAAC;YAC9B,IAAI,CAAC,qBAAqB,CAAC,kBAAkB,CACxC,YAA2B,CAAC,MAAM,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;YAC7D,IAAI,CAAC,WAAW,EAAE,CAAC;YAEnB,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;;YAErD,MAAM,SAAS,GAAGD,SAAM,EAAE,CAAC,wBAAwB,CAAC,UAAU,CAAC,CAAC;YAEhE,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;YACzD,UAAU;iBACL,YAAY,GAAG,EAAC,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,qBAAqB,EAAE,EAAE,MAAM,EAAC,CAAC;YAExE,OAAO,EAAC,SAAS,EAAE,MAAM,EAAE,OAAO,EAAE,IAAI,EAAC,CAAC;SAC3C;QAED,UAAU,CAAqC,CAAa;YAE1D,MAAM,IAAI,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YACrC,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;gBACxB,IAAI;;oBAEF,MAAM,OAAO,GAAI,IAAqB,CAAC,GAAG,CAAC,CAAC,IAAIJ,OAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;oBACtE,OAAOM,SAAM,CAAC,CAAC,CAAC,KAAoB,EAAE,CAAC,CAAC,KAAK,EAAE,OAAO,CAChC,CAAC;iBACxB;gBAAC,WAAM;oBACN,MAAM,IAAI,KAAK,CAAC,kDAAkD,CAAC,CAAC;iBACrE;aACF;YACD,OAAOA,SAAM,CAAC,CAAC,CAAC,KAAoB,EAAE,CAAC,CAAC,KAAK,EAAE,IAAkB,CAC3C,CAAC;SACxB;QAED,MAAM,IAAI,CAAC,CAAa;YACtB,IAAI,CAAC,IAAI,CAAC,gBAAgB,EAAE;gBAC1B,OAAO,CAAC,IAAI,CACR,yDAAyD;oBACzD,iCAAiC;oBACjC,+DAA+D;oBAC/D,mEAAmE;oBACnE,oEAAoE;oBACpE,0DAA0D,CAAC,CAAC;aACjE;YACD,MAAM,eAAe,GAAG,IAAI,CAAC,YAAY,CAAC;YAC1C,MAAM,eAAe,GAAgB,EAAE,CAAC;YAExC,IAAI,aAAa,GAAG,KAAK,CAAC;YAC1B,IAAI,IAAI,CAAC,kBAAkB,IAAI,IAAI,EAAE;gBACnC,IAAI,CAAC,kBAAkB,GAAG,eAAe,CAAC;gBAC1C,aAAa,GAAG,IAAI,CAAC;aACtB;iBAAM;gBACL,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;aACzC;YACD,IAAI,CAAC,YAAY,GAAG,eAAe,CAAC;YAEpC,CAAC,EAAE,CAAC;YAEJ,MAAM,2BAA2B,GAC7BN,OAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAmB,KAAK,CAAC,CAAC,KAAK,CAAC,CAAC;iBAChE,MAAM,CAAC,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,CAAC;YAChC,MAAM,yBAAyB,GAC3BA,OAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAmB,KAAK,CAAC,CAAC,IAAI,CAAC,CAAC;iBAC/D,MAAM,CAAC,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,CAAC;YAEhC,IAAI,CAAC,YAAY,GAAG,eAAe,CAAC;YAEpC,IAAI,aAAa,EAAE;gBACjB,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;aAChC;YACD,MAAM,GAAG,GAAqB;gBAC5B,YAAY,EAAE,IAAI,CAAC,YAAY;gBAC/B,cAAc,EAAE,IAAI,CAAC,cAAc;gBACnC,QAAQ,EAAE,IAAI;gBACd,MAAM,EAAE,IAAI;aACb,CAAC;YAEF,MAAM,QAAQ,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,2BAA2B,CAAC,CAAC;YAChE,GAAG,CAAC,UAAU,CAAC,GAAGA,OAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;YACrC,GAAG,CAAC,qBAAqB,CAAC,GAAG,MACzB,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAAC,IAAI,EAAE,yBAAyB,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAC,CAAC,CAAC;iBAChE,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC;iBAC9B,IAAI,CAAC,IAAI,CAAC,CAAC;YACpB,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC;YACtB,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC;YACxB,OAAO,GAAG,CAAC;SACZ;QAED,cAAc,CACV,KAAe,EAAE,KAAe,EAChC,MAA4C;YAC9C,IAAI,KAAK,KAAK,QAAQ,IAAI,MAAM,IAAI,IAAI,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC;gBACzDA,OAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE;gBAC5B,MAAM,GAAI,MAAyB,CAAC,GAAG,CAAC,CAAC,IAAIA,OAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;aACpE;YACD,MAAM,MAAM,GACR,IAAI,CAAC,KAAK,CAAC,MAAoC,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;YACnE,OAAO,EAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAC,CAAC;SAC/B;QAEO,eAAe,CAAC,MAAmB;YACzC,IAAI,CAAC,MAAM,EAAE;gBACX,OAAO,IAAI,CAAC;aACb;YAED,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACrD,IAAI,SAAS,IAAI,UAAU,CAAC,YAAY,EAAE;gBACxC,MAAM,IAAI,GAAG,UAAU,CAAC,YAAY,CAAC;gBACrC,IAAI,IAAI,CAAC,OAAO,YAAY,kBAAkB,EAAE;oBAC9C,OAAO,IAAI,CAAC,OAAO,CAAC;iBACrB;qBAAM;oBACL,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,CAAC;iBAClC;aACF;YACD,MAAM,UAAU,GAAG,UAAU,CAAC,YAAY,CAAC;YAC3C,OAAO,EAAC,MAAM,EAAE,CAAC,EAAE,IAAI,EAAE,UAAU,CAAC,IAAI,EAAE,MAAM,EAAE,UAAU,CAAC,MAAM,EAAC,CAAC;SACtE;QAED,MAAM,YAAY,CAAC,KAAkB;YACnC,IAAI,IAAI,CAAC,gBAAgB,EAAE;gBACzB,OAAO,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,CAAC;aACxC;iBAAM;gBACL,OAAO,CAAC,CAAC;aACV;SACF;QAED,WAAW,CAAC,MAAc;YACxB,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;;YAE9C,IAAI,UAAU,CAAC,YAAY,EAAE;gBAC3B,OAAO;aACR;YAED,MAAM,IAAI,GAAGO,kBAA8B,CAAC,UAAU,CAAC,KAAK,CAAC;gBACzDP,OAAI,CAAC,aAAa,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;YACzC,MAAM,MAAM,GACR,IAAI,CAAC,aAAa,CAAC,aAAa,CAAC,IAAI,EAAE,IAAI,CAAC,qBAAqB,EAAE,CAAC,CAAC;YAEzE,UAAU;iBACL,YAAY,GAAG,EAAC,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,qBAAqB,EAAE,EAAE,MAAM,EAAC,CAAC;YACxE,IAAI,UAAU,CAAC,MAAM,EAAE;gBACrB,MAAM,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC,mBAAmB,CACxD,IAAI,EAAE,cAAc,CAAC,SAAS,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;gBAC9D,MAAM,WAAW,GAAG,aAAa,CAAC,cAAc,EAAE,CAAC;gBACnD,IAAI,UAAU,CAAC,KAAK,KAAK,OAAO,IAAI,UAAU,CAAC,KAAK,KAAK,MAAM,EAAE;oBAC/D,IAAI,UAAU,CAAC,WAAW,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,MAAoB,CAAC,CAAC;iBAClE;qBAAM;oBACL,IAAI,YAAY,CAAC,WAAW,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,MAAsB,CAAC,CAAC;iBACtE;gBACD,aAAa,CAAC,KAAK,EAAE,CAAC;gBACtB,IAAI,CAAC,yBAAyB,EAAE,CAAC;gBACjC,IAAI,CAAC,sBAAsB,EAAE,CAAC;gBAC9B,IAAI,CAAC,qBAAqB,CAAC,kBAAkB,CACzC,aAAa,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;gBAEvC,MAAM,WAAW,GAAG;oBAClB,IAAI;oBACJ,KAAK,EAAE,cAAc,CAAC,SAAS,GAAG,cAAc,CAAC,QAAQ;oBACzD,MAAM,EAAE,aAAa;iBACtB,CAAC;gBACF,IAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;;;;;;;aAO/C;SACF;QAEO,YAAY,CAAC,cAA8B;YACjD,IAAI,aAAa,GAAG,CAAC,CAAC;YACtB,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,MAAM,OAAO,GAAa,EAAE,CAAC;YAC7B,cAAc,CAAC,OAAO,CAAC,CAAC,CAAC;gBACvB,IAAI,CAAC,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;oBACvB,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;iBACd;;gBAED,IAAI,aAAqB,CAAC;gBAC1B,QAAQ,CAAC,CAAC,IAAI,CAAC,MAAM;oBACnB,KAAK,CAAC;wBACJ,aAAa,GAAG,CAAC,CAAC;wBAClB,MAAM;oBACR,KAAK,CAAC;wBACJ,aAAa,GAAG,CAAC,CAAC;wBAClB,MAAM;oBACR,KAAK,CAAC;wBACJ,aAAa,GAAG,EAAE,CAAC;wBACnB,MAAM;oBACR,KAAK,CAAC;wBACJ,aAAa,GAAG,EAAE,CAAC;wBACnB,MAAM;oBACR,KAAK,CAAC;wBACJ,aAAa,GAAG,EAAE,CAAC;wBACnB,MAAM;oBACR,KAAK,CAAC;wBACJ,aAAa,GAAG,EAAE,CAAC;wBACnB,MAAM;oBACR;wBACEA,OAAI,CAAC,MAAM,CAAC,KAAK,EAAE,MAAM,eAAe,CAAC,CAAC,IAAI,CAAC,MAAM,SAAS,CAAC,CAAC;iBACnE;gBAED,IAAI,SAAS,KAAK,CAAC,IAAI,SAAS,KAAK,CAAC,EAAE;oBACtC,aAAa,GAAG,EAAE,CAAC;iBACpB;gBACD,aAAa,GAAG,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG,aAAa,CAAC,GAAG,aAAa,CAAC;gBACzE,SAAS,GAAG,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC;gBAC1B,OAAO,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;gBAC5B,aAAa,IAAI,CAAC,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC;aACpC,CAAC,CAAC;YAEH,MAAM,WAAW,GAAG,IAAI,WAAW,CAAC,aAAa,CAAC,CAAC;YACnD,cAAc,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;gBAC1B,MAAM,MAAM,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;gBAC1B,IAAI,CAAC,CAAC,IAAI,KAAK,OAAO,EAAE;oBACtB,IAAI,UAAU,CAAC,WAAW,EAAE,MAAM,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;iBAChE;qBAAM,IAAI,CAAC,CAAC,IAAI,KAAK,QAAQ,EAAE;oBAC9B,IAAI,WAAW,CAAC,WAAW,EAAE,MAAM,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;iBACjE;qBAAM;oBACL,IAAI,YAAY,CAAC,WAAW,EAAE,MAAM,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;iBAClE;aACF,CAAC,CAAC;YAEH,MAAM,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,CAClD,aAAa,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,OAAO,CAAC,CAAC;YACrE,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,aAAa,EAAE,CAAC,EAAE,WAAW,EAAE,CAAC,EAAE,aAAa,CAAC,CAAC;YAExE,MAAM,WAAW,GAAG;gBAClB,IAAI,EAAE,aAAa;gBACnB,KAAK,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,OAAO;gBACvD,MAAM,EAAE,aAAa;aACtB,CAAC;YACF,IAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAE9C,OAAO,EAAC,MAAM,EAAE,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,MAAM,EAAE,aAAa,EAAC,CAAC;SAChE;QAEM,gBAAgB,CACnB,OAAqC,EAAE,MAAoB,EAC3D,WAAqB,EAAE,qBAAsC,EAC7D,MAAmB;YACrB,IAAI,CAAC,MAAM,EAAE;gBACX,MAAM,GAAG,IAAI,CAAC,cAAc,CAAC,OAAO,CAAC,WAAW,EAAE,WAAW,CAAC,CAAC;aAChE;YACD,IAAIA,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;;;gBAG1C,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,MAAM;oBACpCA,OAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC,KAAkB,EAAE,CAAC,CAAC,CAAC;gBAC9D,OAAO,MAAM,CAAC;aACf;YACD,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YAChC,OAAO,CAAC,QAAQ,GAAG,eAAe,CAAC,IAAI,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;;;YAIzD,IAAI,cAAc,GAAmB,EAAE,CAAC;YACxC,IAAI,YAAY,GAAe,EAAE,CAAC;YAClC,IAAI,CAAC,OAAO,CAAC,YAAY,EAAE;gBACzB,cAAc,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,GAAG,CAAC,EAAC,CAAC,CAAC;gBACpD,YAAY,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC;gBACvD,MAAM,YAAY,GAAG,OAAO,CAAC;gBAC7B,YAAY,CAAC,GAAG,CAAC,CAAC;oBAChB,cAAc,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,YAAY,EAAE,IAAI,EAAE,CAAC,EAAC,CAAC,CAAC;iBACpD,CAAC,CAAC;gBACH,MAAM,OAAO,GAAGA,OAAI,CAAC,cAAc,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;gBAClD,cAAc,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,YAAY,EAAE,IAAI,EAAE,OAAO,EAAC,CAAC,CAAC;gBACzD,IAAI,OAAO,CAAC,IAAI,EAAE;oBAChB,MAAM,IAAI,GAAGA,OAAI,CAAC,aAAa,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;oBACrD,cAAc,CAAC,IAAI,CACf,EAAC,IAAI,EAAE,YAAY,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,MAAM,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,EAAC,CAAC,CAAC;iBACrE;aACF;YAED,MAAM,UAAU,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,KAAiB,EAAE,CAAS;gBACzD,IAAI,KAAK,CAAC,KAAK,KAAK,WAAW,EAAE;oBAC/B,MAAM,IAAI,KAAK,CACX,+DAA+D;wBAC/D,8DAA8D;wBAC9D,QAAQ,CAAC,CAAC;iBACf;gBACD,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;gBAE/B,OAAO;;;oBAGL,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,KAAK;oBAC7C,KAAK,EAAE,KAAK,CAAC,KAAK;oBAClB,IAAI,EAAE,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC;iBAC/B,CAAC;aACH,CAAC,CAAC;YAEH,MAAM,GAAG,GACLQ,aAA4B,CAAC,OAAO,EAAE,YAAY,EAAE,UAAU,EAAE,MAAM,CAAC,CAAC;YAE5E,IAAI,QAAQ,CAAC;YACb,IAAI,GAAG,IAAI,IAAI,CAAC,aAAa,EAAE;gBAC7B,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;aACpC;iBAAM;gBACL,QAAQ,GAAGC,cAA6B,CACpC,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,UAAU,EAAE,MAAM,CAAC,CAAC;gBAC9C,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,GAAG,QAAQ,CAAC;aACpC;YAED,IAAI,qBAAqB,EAAE;gBACzB,cAAc,GAAG,CAAC,GAAG,cAAc,EAAE,GAAG,qBAAqB,CAAC,CAAC;aAChE;YACD,MAAM,QAAQ,GAAG;gBACf,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,EAAE,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;gBACzE,IAAI,CAAC,YAAY,CAAC,cAAc,CAAC;aAClC,CAAC;YAEF,MAAM,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC;gBAC5C,MAAM,EAAE,QAAQ,CAAC,kBAAkB,CAAC,CAAC,CAAC;gBACtC,OAAO,EAAE,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAAC,OAAO,EAAE,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAC,CAAC,CAAC;aAC7D,CAAC,CAAC;YAEH,IAAI,CAAC,yBAAyB,EAAE,CAAC;YACjC,MAAM,IAAI,GAAG,IAAI,CAAC,cAAc,EAAE,CAAC;YACnC,MAAM,iBAAiB,GAAG,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC;YACpD,IAAI,iBAAiB,EAAE;gBACrB,IAAI,IAAI,CAAC,gBAAgB,EAAE;;oBAExB,IAAY,CAAC,cAAc,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC;iBAChD;aACF;YACD,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;YAC3B,IAAI,CAAC,YAAY,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;YAChC,IAAI,CAAC,kBAAkB,CACnB,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;YACnE,IAAI,iBAAiB,EAAE;gBACrB,IAAI,IAAI,CAAC,gBAAgB,EAAE;;oBAExB,IAAY,CAAC,cAAc,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC;iBAChD;aACF;YACD,IAAI,CAAC,uBAAuB,EAAE,CAAC;YAE/B,MAAM,CAAC,OAAO,CAAC,KAAK;gBAClB,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;aAC7C,CAAC,CAAC;YACH,IAAI,CAAC,oBAAoB,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YAE7C,IAAIX,MAAG,EAAE,CAAC,GAAG,CAAC,mCAAmC,CACvC,IAAI,IAAI,CAAC,uBAAuB,EAAE;gBAC1C,IAAI,CAAC,WAAW,EAAE,CAAC;aACpB;YAED,IAAI,iBAAiB,EAAE;gBACrB,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC;oBACrB,IAAI,EAAE,OAAO,CAAC,WAAW,CAAC,IAAI;oBAC9B,KAAK,EAAE,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,QAAQ,CAAC;iBACxC,CAAC,CAAC;aACJ;YACD,OAAO,MAAM,CAAC;SACf;QAED,MAAM,mBAAmB,CAAC,QAAqB;YAC7C,MAAM,WAAW,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,CAChD,EAAE,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,aAAa,CAAC,CAAC;YAChE,MAAM,GAAG,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,CACxC,EAAE,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YAE3D,IAAI,CAAC,yBAAyB,EAAE,CAAC;YACjC,IAAI,CAAC,sBAAsB,EAAE,CAAC;YAC9B,IAAI,CAAC,qBAAqB,CAAC,eAAe,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC;YAC3E,IAAI,CAAC,qBAAqB,CAAC,kBAAkB,CAAC,WAAW,EAAE,CAAC,EAAE,GAAG,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;YAC1E,IAAI,CAAC,WAAW,EAAE,CAAC;YACnB,MAAM,GAAG,CAAC,QAAQ,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;YACpC,MAAM,QAAQ,GAAG,IAAI,cAAc,CAAC,GAAG,CAAC,cAAc,EAAE,CAAC,CAAC;YAC1D,MAAM,gBAAgB,GAAG,MAAM,EAAE,QAAQ,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC;YAC7D,GAAG,CAAC,KAAK,EAAE,CAAC;YACZ,IAAI,CAAC,aAAa,CAAC,aAAa,CAC5B,GAAG,EAAE,EAAE,EAAE,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YAChE,IAAI,CAAC,aAAa,CAAC,aAAa,CAC5B,WAAW,EAAE,EAAE,EACf,cAAc,CAAC,QAAQ,GAAG,cAAc,CAAC,aAAa,CAAC,CAAC;;YAE5D,OAAO,gBAAgB,GAAG,OAAO,CAAC;SACnC;QAED,kBAAkB,CACd,MAAoB,EACpB,aAAa,GAAG,0BAA0B;YAC5C,OAAOA,MAAG,EAAE,CAAC,OAAO,CAAC,oBAAoB,CAAC;gBACtC,MAAM,CAAC,KAAK,CACR,KAAK,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,YAAY,IAAI,IAAI;oBAC1DE,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,GAAG,aAAa,CAAC,CAAC;SAC9D;QAED,UAAU;YACR,OAAO,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,GAAG,IAAI,CAAC,yBAAyB,CAAC,MAAM,CAAC;SAC5E;QAED,OAAO;YACL,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACjB,OAAO;aACR;YACD,IAAI,CAAC,aAAa,CAAC,OAAO,EAAE,CAAC;YAC7B,IAAI,CAAC,cAAc,CAAC,OAAO,EAAE,CAAC;YAC9B,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;SACtB;;IA7tBc,wBAAU,GAAG,CAAC;;IC9H/B;;;;;;;;;;;;;;;;IAwBA,IAAI,iBAAiB,EAAE,EAAE;QACvBU,kBAAe,CAAC,QAAQ,EAAE;;;YAGxBZ,MAAG,EAAE,CAAC,GAAG,CAAC,8BAA8B,EAAE,KAAK,CAAC,CAAC;YAEjD,MAAM,aAAa,GAA6B;gBAC9C,eAAe,EAAEA,MAAG,EAAE,CAAC,GAAG,CAAC,0BAA0B,CAAC;oBAClD,WAAW;oBACX,kBAAkB;aACvB,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,SAAS,CAAC,GAAG,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC;YAClE,MAAM,aAAa,GAAG,OAAO,CAAC,MAAM,CAAC;YACrC,MAAM,gBAAgB,GAAwB,EAAE,CAAC;YACjD,MAAM,gBAAgB,GAAG,OAAO,CAAC,QAAQ,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;YACjE,gBAAgB,CAAC,cAAc,GAAG;gBAChC,gCAAgC,EAC5B,aAAa,CAAC,8BAA8B;gBAChD,kCAAkC,EAC9B,aAAa,CAAC,gCAAgC;gBAClD,6BAA6B,EAAE,aAAa,CAAC,2BAA2B;aACzE,CAAC;YAEF,IAAI,gBAAgB,EAAE;gBACpB,gBAAgB,CAAC,gBAAgB,GAAG,CAAC,iBAAiB,CAAC,CAAC;aACzD;YACD,MAAM,MAAM,GAAc,MAAM,OAAO,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;;YAExE,MAAM,WAAW,GAAG,MAAO,OAAe,CAAC,kBAAkB,EAAE,CAAC;YAChE,OAAO,IAAI,aAAa,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;SAC/C,EAAE,CAAC,cAAc,CAAC;;;ICvDrB;;;;;;;;;;;;;;;;IAiBA,IAAY,YAqBX;IArBD,WAAY,YAAY;QACtB,6CAAG,CAAA;QACH,6CAAG,CAAA;QACH,iDAAK,CAAA;QACL,6CAAG,CAAA;QACH,6CAAG,CAAA;QACH,iDAAK,CAAA;QACL,qDAAO,CAAA;QACP,iEAAa,CAAA;QACb,+CAAI,CAAA;QACJ,2DAAU,CAAA;QACV,8DAAW,CAAA;QACX,0DAAS,CAAA;QACT,4EAAkB,CAAA;QAClB,sDAAO,CAAA;QACP,8CAAG,CAAA;QACH,kDAAK,CAAA;QACL,8CAAG,CAAA;QACH,8CAAG,CAAA;QACH,kFAAqB,CAAA;QACrB,kFAAqB,CAAA;IACvB,CAAC,EArBW,YAAY,KAAZ,YAAY,QAqBvB;IAED,MAAM,iBAAiB,GAAG;;;GAGvB,CAAC;IAEJ,MAAM,4BAA4B,GAAG;;;;;;;;;;;;;GAalC,CAAC;IAEJ,MAAM,sBAAsB,GAAG;;IAE3B,4BAA4B;GAC7B,CAAC;IAEJ,MAAM,GAAG,GAAG,eAAe,CAAC;IAC5B;IACA;IACA;IACA;IACA,MAAM,qBAAqB,GAAG,uCAAuC,CAAC;IACtE,MAAM,qBAAqB,GAAG,uCAAuC,CAAC;IACtE,MAAM,GAAG,GAAG,eAAe,CAAC;IAC5B,MAAM,GAAG,GAAG,eAAe,CAAC;IAC5B,MAAM,kBAAkB,GAAG,2BAA2B,CAAC;IACvD,MAAM,GAAG,GAAG,eAAe,CAAC;IAC5B,MAAM,KAAK,GAAG,qBAAqB,CAAC;IACpC,MAAM,UAAU,GAAG,2BAA2B,CAAC;IAC/C,MAAM,OAAO,GAAG,oBAAoB,CAAC;IACrC,MAAM,YAAY,GAAG,0BAA0B,CAAC;IAChD,MAAM,aAAa,GAAG,qBAAqB,CAAC;IAC5C,MAAM,kBAAkB,GAAG,2BAA2B,CAAC;IACvD,MAAM,IAAI,GAAG,oBAAoB,CAAC;IAClC,MAAM,SAAS,GAAG,0BAA0B,CAAC;IAC7C,MAAM,UAAU,GAAG,qBAAqB,CAAC;IACzC,MAAM,eAAe,GAAG,2BAA2B,CAAC;IACpD,MAAM,WAAW,GAAG,6CAA6C,CAAC;IAClE,MAAM,gBAAgB,GAAG;mCACU,CAAC;IACpC,MAAM,OAAO,GAAG;;;;;GAKb,CAAC;IAEJ,MAAM,YAAY,GAAG;;;;;;;;;;;;;;;;;;;;;GAqBlB,CAAC;IAEJ,MAAM,SAAS,GAAG;;;;;CAKjB,CAAC;IACF,MAAM,cAAc,GAAG;;;IAGnB,sBAAsB;;;CAGzB,CAAC;IACF,MAAM,GAAG,GAAG;;;;;;;;;;;GAWT,CAAC;IACJ,MAAM,QAAQ,GAAG;;;;;;;;;;;;;;;;;;;;;;IAsBb,4BAA4B;;GAE7B,CAAC;IAEJ,MAAM,KAAK,GAAG,2CAA2C,CAAC;IAC1D,MAAM,UAAU,GAAG;;;GAGhB,CAAC;IAEJ,SAAS,sBAAsB,CAC3B,EAAU,EAAE,OAAgB,EAAE,WAAW,GAAG,cAAc;QAC5D,MAAM,eAAe,GAAG,OAAO,GAAG,sBAAsB,GAAG,iBAAiB,CAAC;QAC7E,OAAO,OAAO,GAAG;wBACK,WAAW;iCACF,EAAE;KAC9B,GAAG,eAAe;YACb;;GAEP;YACgB,eAAe,GAAG;aACxB,EAAE;GACZ,CAAC;IACJ,CAAC;aAEe,iBAAiB,CAC7B,IAAkB,EAAE,OAAiB;QACvC,QAAQ,IAAI;YACV,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,GAAG,CAAC;YACb,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,GAAG,CAAC;YACb,KAAK,YAAY,CAAC,KAAK;gBACrB,OAAO,sBAAsB,CAAC,OAAO,EAAE,OAAO,CAAC,CAAC;YAClD,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,GAAG,CAAC;YACb,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,GAAG,CAAC;YACb,KAAK,YAAY,CAAC,KAAK;gBACrB,OAAO,OAAO,GAAG,UAAU,GAAG,KAAK,CAAC;YACtC,KAAK,YAAY,CAAC,OAAO;gBACvB,OAAO,OAAO,GAAG,YAAY,GAAG,OAAO,CAAC;YAC1C,KAAK,YAAY,CAAC,aAAa;gBAC7B,OAAO,OAAO,GAAG,kBAAkB,GAAG,aAAa,CAAC;YACtD,KAAK,YAAY,CAAC,IAAI;gBACpB,OAAO,OAAO,GAAG,SAAS,GAAG,IAAI,CAAC;YACpC,KAAK,YAAY,CAAC,UAAU;gBAC1B,OAAO,OAAO,GAAG,eAAe,GAAG,UAAU,CAAC;YAChD,KAAK,YAAY,CAAC,WAAW;gBAC3B,OAAO,OAAO,GAAG,gBAAgB,GAAG,WAAW,CAAC;YAClD,KAAK,YAAY,CAAC,SAAS;gBACzB,OAAO,OAAO,GAAG,cAAc,GAAG,SAAS,CAAC;YAC9C,KAAK,YAAY,CAAC,kBAAkB;gBAClC,OAAO,kBAAkB,CAAC;YAC5B,KAAK,YAAY,CAAC,OAAO;gBACvB,OAAO,OAAO,GAAG,YAAY,GAAG,OAAO,CAAC;YAC1C,KAAK,YAAY,CAAC,KAAK;gBACrB,OAAO,OAAO,GAAG,UAAU,GAAG,KAAK,CAAC;YACtC,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,sBAAsB,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;YAChD,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,sBAAsB,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;YAChD,KAAK,YAAY,CAAC,GAAG;gBACnB,OAAO,OAAO,GAAG,QAAQ,GAAG,GAAG,CAAC;YAClC,KAAK,YAAY,CAAC,qBAAqB;gBACrC,OAAO,qBAAqB,CAAC;YAC/B,KAAK,YAAY,CAAC,qBAAqB;gBACrC,OAAO,qBAAqB,CAAC;YAC/B;gBACE,MAAM,IAAI,KAAK,CAAC,cAAc,IAAI,sBAAsB,CAAC,CAAC;SAC7D;IACH;;IC7OA;;;;;;;;;;;;;;;;IAiBA,IAAY,WA0BX;IA1BD,WAAY,WAAW;QACrB,2CAAG,CAAA;QACH,6CAAI,CAAA;QACJ,2CAAG,CAAA;QACH,6CAAI,CAAA;QACJ,2CAAG,CAAA;QACH,2CAAG,CAAA;QACH,+CAAK,CAAA;QACL,+CAAK,CAAA;QACL,iDAAM,CAAA;QACN,iDAAM,CAAA;QACN,4CAAG,CAAA;QACH,4DAAW,CAAA;QACX,4CAAG,CAAA;QACH,8CAAI,CAAA;QACJ,gDAAK,CAAA;QACL,wDAAS,CAAA;QACT,0DAAU,CAAA;QACV,gDAAK,CAAA;QACL,4CAAG,CAAA;QACH,8CAAI,CAAA;QACJ,oDAAO,CAAA;QACP,8CAAI,CAAA;QACJ,kDAAM,CAAA;QACN,8CAAI,CAAA;QACJ,kDAAM,CAAA;IACR,CAAC,EA1BW,WAAW,KAAX,WAAW,QA0BtB;IAED,MAAM,GAAG,GAAG,gBAAgB,CAAC;IAC7B,MAAM,IAAI,GAAG,iBAAiB,CAAC;IAC/B,MAAM,GAAG,GAAG,gBAAgB,CAAC;IAC7B,MAAM,IAAI,GAAG;;;CAGZ,CAAC;IACF,MAAM,KAAK,GAAG,sBAAsB,CAAC;IACrC,MAAM,GAAG,GAAG,qDAAqD,CAAC;IAClE,MAAM,QAAQ,GAAG;;;;;;;;;;;;;;;CAehB,CAAC;IACF,MAAM,GAAG,GAAG,gBAAgB,CAAC;IAC7B,MAAM,KAAK,GAAG,kBAAkB,CAAC;IACjC,MAAM,MAAM,GAAG,uBAAuB,CAAC;IACvC,MAAM,MAAM,GAAG,WAAW,CAAC;IAC3B,MAAM,GAAG,GAAG;iBACK,CAAC;IAClB,MAAM,WAAW,GAAG,0BAA0B,CAAC;IAC/C,MAAM,GAAG,GAAG,YAAY,CAAC;IACzB,MAAM,SAAS,GAAG,uDAAuD,CAAC;IAC1E,MAAM,cAAc,GAAG;;;CAGtB,CAAC;IACF,MAAM,UAAU,GAAG,iBAAiB,CAAC;IACrC,MAAM,IAAI,GAAG,iCAAiC,CAAC;IAC/C,MAAM,KAAK,GAAG,4BAA4B,CAAC;IAC3C,MAAM,UAAU,GACZ,gFAAgF,CAAC;IACrF,MAAM,SAAS,GAAG;;CAEjB,CAAC;IACF,MAAM,KAAK,GAAG,qBAAqB,CAAC;IACpC,MAAM,OAAO,GAAG,qCAAqC,CAAC;IACtD,MAAM,GAAG,GAAG,gBAAgB,CAAC;IAC7B,MAAM,IAAI,GAAG;;;CAGZ,CAAC;IACF,MAAM,IAAI,GAAG,iBAAiB,CAAC;IAC/B,MAAM,MAAM,GAAG,eAAe,CAAC;IAC/B,MAAM,IAAI,GAAG;;;CAGZ,CAAC;IACF,MAAM,MAAM,GAAG,uBAAuB,CAAC;aAEvB,gBAAgB,CAAC,IAAiB,EAAE,OAAiB;QACnE,QAAQ,IAAI;YACV,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,IAAI,CAAC;YACd,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,IAAI,CAAC;YACd,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,OAAO,GAAG,QAAQ,GAAG,GAAG,CAAC;YAClC,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,KAAK;gBACpB,OAAO,KAAK,CAAC;YACf,KAAK,WAAW,CAAC,KAAK;gBACpB,OAAO,KAAK,CAAC;YACf,KAAK,WAAW,CAAC,MAAM;gBACrB,OAAO,MAAM,CAAC;YAChB,KAAK,WAAW,CAAC,MAAM;gBACrB,OAAO,MAAM,CAAC;YAChB,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,WAAW;gBAC1B,OAAO,WAAW,CAAC;YACrB,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,SAAS;gBACxB,OAAO,OAAO,GAAG,cAAc,GAAG,SAAS,CAAC;YAC9C,KAAK,WAAW,CAAC,UAAU;gBACzB,OAAO,UAAU,CAAC;YACpB,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,OAAO,GAAG,SAAS,GAAG,IAAI,CAAC;YACpC,KAAK,WAAW,CAAC,KAAK;gBACpB,OAAO,OAAO,GAAG,UAAU,GAAG,KAAK,CAAC;YACtC,KAAK,WAAW,CAAC,KAAK;gBACpB,OAAO,KAAK,CAAC;YACf,KAAK,WAAW,CAAC,OAAO;gBACtB,OAAO,OAAO,CAAC;YACjB,KAAK,WAAW,CAAC,GAAG;gBAClB,OAAO,GAAG,CAAC;YACb,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,IAAI,CAAC;YACd,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,IAAI,CAAC;YACd,KAAK,WAAW,CAAC,MAAM;gBACrB,OAAO,MAAM,CAAC;YAChB,KAAK,WAAW,CAAC,IAAI;gBACnB,OAAO,IAAI,CAAC;YACd,KAAK,WAAW,CAAC,MAAM;gBACrB,OAAO,MAAM,CAAC;YAEhB;gBACE,MAAM,IAAI,KAAK,CAAC,cAAc,IAAI,sBAAsB,CAAC,CAAC;SAC7D;IACH;;IClKA;;;;;;;;;;;;;;;;IAsBO,MAAM,WAAW,GAAG,CAAC,SAAiB;QAC3C,QAAQ,SAAS;YACf,KAAK,CAAC;gBACJ,OAAO,KAAK,CAAC;YACf,KAAK,CAAC;gBACJ,OAAO,WAAW,CAAC;YACrB,KAAK,CAAC;gBACJ,OAAO,WAAW,CAAC;YACrB,KAAK,CAAC;gBACJ,OAAO,WAAW,CAAC;YACrB;gBACE,MAAM,IAAI,KAAK,CAAC,GAAG,SAAS,8BAA8B,CAAC,CAAC;SAC/D;IACH,CAAC,CAAC;aAEc,mBAAmB,CAC/B,UAAmC,EAAE,yBAAyB,GAAG,KAAK,EACtE,MAAM,GAAG,KAAK,EAAE,YAAY,GAAG,CAAC;QAClC,IAAI,UAAU,KAAK,IAAI,EAAE;YACvB,OAAO,EAAE,CAAC;SACX;QAED,IAAI,mBAAmB,GAAG,EAAE,CAAC;QAC7B,IAAI,UAAU,KAAK,QAAQ,EAAE;YAC3B,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;SAC5D;aAAM,IAAI,UAAU,KAAK,MAAM,EAAE;YAChC,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC;SAClE;aAAM,IAAI,UAAU,KAAK,KAAK,EAAE;YAC/B,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC;SACjE;aAAM,IAAI,UAAU,KAAK,OAAO,EAAE;YACjC,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;SACnE;aAAM,IAAI,UAAU,KAAK,OAAO,EAAE;YACjC,mBAAmB,GAAG,iBAAiB,CAAC,YAAY,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;SACrE;aAAM,IAAI,UAAU,KAAK,SAAS,EAAE;YACnC,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,OAAO,EAAE,MAAM,CAAC,CAAC;SACrE;aAAM,IAAI,UAAU,KAAK,WAAW,EAAE;YACrC,mBAAmB,GAAG,gBAAgB,CAAC,WAAW,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;SACvE;aAAM;YACL,MAAM,IAAI,KAAK,CAAC,cACZ,UAAU,mDAAmD,CAAC,CAAC;SACpE;QACD,MAAM,WAAW,GAAG,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC;QACnC,MAAM,QAAQ,GAAG,WAAW,CAAC,WAAW,CAAC,CAAC;QAC1C,IAAI,mBAAmB,GAAG,EAAE,CAAC;QAC7B,IAAI,yBAAyB,EAAE;YAC7B,mBAAmB,GAAG;0BACA,QAAQ,iBAAiB,YAAY,aACvD,QAAQ;;UAEN,mBAAmB;QACrB,CAAC;SACN;aAAM;YACL,mBAAmB,GAAG;0BACA,QAAQ,iBAAiB,YAAY,aACvD,QAAQ;UACN,mBAAmB;QACrB,CAAC;SACN;QACD,OAAO,mBAAmB,CAAC;IAC7B,CAAC;aAEe,qBAAqB,CACjC,OAAgB,EAAE,UAAmC;QACvD,OAAO;QACD,OAAO,GAAG,gDAAgD,GAAG,EAAE;QAC/D,UAAU,GAAG,oCAAoC,GAAG,EAAE;OACvD,CAAC;IACR;;ICzFA;;;;;;;;;;;;;;;;aAsBgB,kBAAkB,CAC9B,cAAuB,EAAE,cAAuB,EAAE,UAAmB,EACrE,UAAmB,EAAE,SAAS,GAAG,KAAK,EAAE,SAAS,GAAG,KAAK,EAAE,QAAQ,GAAG,KAAK,EAC3E,SAAS,GAAG,CAAC;QACfE,OAAI,CAAC,MAAM,CACP,UAAU,IAAI,SAAS,KAAK,CAAC,IAAI,CAAC,UAAU,EAC5C,MAAM,cAAc,UAAU,0CAC1B,SAAS,EAAE,CAAC,CAAC;QACrB,MAAM,OAAO,GAAG;oBACE,cAAc,GAAG,GAAG,GAAG,SAAS;QAE9C,UAAU,GAAG,gCAAgC;QAChC,gCAAgC;;KAE9C,CAAC;QACJ,MAAM,OAAO,GAAG,UAAU,GAAG,gCAAgC;YAChC,gCAAgC,CAAC;QAE9D,OAAO;uDAC8C,WAAW,CAAC,SAAS,CAAC;kBAC3D,WAAW,CAAC,SAAS,CAAC;wBAChB,SAAS;MAE3B,SAAS,IAAI,QAAQ;QACjB,OAAO;QACP;MAEI,UAAU;YACN,yDAAyD;YACzD,0DAA0D;;QAEpE,OAAO;;KAEV;;;;uDAIkD,WAAW,CAAC,SAAS,CAAC;wBACrD,SAAS;kBACf,cAAc,GAAG,GAAG,GAAG,SAAS;kBAChC,WAAW,CAAC,SAAS,CAAC;MAClC,OAAO;;;GAGV,CAAC;IACJ,CAAC;aAEe,uBAAuB,CACnC,OAAgB,EAAE,UAAmC,EACrD,cAAuB,EAAE,cAAuB,EAAE,UAAmB,EACrE,UAAmB,EAAE,SAAS,GAAG,KAAK,EAAE,SAAS,GAAG,KAAK,EAAE,QAAQ,GAAG,KAAK,EAC3E,SAAS,GAAG,CAAC;QACf,OAAO;IAEH,kBAAkB,CACd,cAAc,EAAE,cAAc,EAAE,UAAU,EAAE,UAAU,EAAE,SAAS,EACjE,SAAS,EAAE,QAAQ,EAAE,SAAS,CAAC;2DAEnC,WAAW,CAAC,SAAS,CAAC;wBACJ,SAAS;MAE3B,SAAS,IAAI,SAAS;QAClB,EAAE;QACF,2DAA2D;;;;QAI7D,qBAAqB,CAAC,OAAO,EAAE,UAAU,CAAC;;;;GAI/C,CAAC;IACJ,CAAC;IAED,MAAM,0BAA0B,GAAG,CAAC,SAAkB;QACpD,IAAI,SAAS,EAAE;YACb,OAAO;;;;SAIF,CAAC;SAEP;aAAM;YACL,OAAO;;;;SAIF,CAAC;SACP;IACH,CAAC,CAAC;IAEF,MAAM,sBAAsB,GACxB,CAAC,UAAmB,EAAE,gBAAwB;QAC5C,IAAI,UAAU,EAAE;YACd,OAAO;;;;UAKH,gBAAgB,KAAK,CAAC;YAClB,EAAE;YACF,6DAA6D;;;;;YAMjE,gBAAgB,KAAK,CAAC;YAClB,EAAE;YACF,2CAA2C;UACjD,CAAC;SACJ;aAAM;YACL,OAAO;;;;;;YAOH,gBAAgB,KAAK,CAAC,GAAG,EAAE;YACF,yCAAyC;UACpE,CAAC;SACJ;IACH,CAAC,CAAC;aAEU,0BAA0B,CACtC,aAAuB,EAAE,aAAuC,EAChE,UAAU,GAAG,KAAK,EAAE,SAAS,GAAG,EAAE,EAAE,MAAM,GAAG,KAAK,EAAE,eAAe,GAAG,EAAE,EACxE,SAAS,GAAG,KAAK;QACnB,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,UAAU,GAAG,UAAU,GAAG,UAAU,GAAG,SAAS,CAAC;QACvD,MAAM,UAAU,GAAG,UAAU,GAAG,SAAS,GAAG,UAAU,CAAC;QACvD,MAAM,gBAAgB,GAAG,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,aAAa,GAAG,SAAS,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACnDA,OAAI,CAAC,MAAM,CACP,CAAC,CAAC,UAAU,IAAI,gBAAgB,KAAK,CAAC,IAAI,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC;aAC9D,CAAC,UAAU,KAAK,gBAAgB,KAAK,CAAC,IAAI,gBAAgB,KAAK,CAAC,CAAC,CAAC;YAChE,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC;YACnC,SAAS,GAAG,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChE,MAAM,iBAAiB,UAAU,8BAC7B,gBAAgB,yBAAyB,aAAa,CAAC,CAAC,CAAC;wCAC3B,gBAAgB;mBACrC,UAAU,yCACnB,aAAa,CAAC,CAAC,CAAC,eAChB,SAAS,0CACT,aAAa,CAAC,CAAC,CAAC,kBAAkB,aAAa,CAAC,CAAC,CAAC,aAAa,CAAC,CAAC;QACzE,OAAO;4CACmC,gBAAgB,UACtD,UAAU,GAAG,gBAAgB,MAAM,UAAU;oDAE7C,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,MAAM,SAAS;;yBAEzB,aAAa,CAAC,CAAC,CAAC;yBAChB,aAAa,CAAC,CAAC,CAAC;6BACZ,gBAAgB;sBACvB,SAAS;;;;;;;;;;;;oBAYX,SAAS,GAAG,GAAG,GAAG,yBAAyB;;;sBAGzC,SAAS,GAAG,GAAG,GAAG,gCAAgC;;kBAEtD,MAAM,GAAG,GAAG,GAAG,iBAAiB;gDACF,UAAU;;qBAGpD,MAAM,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,eAAe,GAAG,SAAS,CAAC,EAAE;QAC3C,yCAAyC;mBACrC,MAAM,GAAG,qBAAqB,eAAe,EAAE,GAAG,GAAG;;;;;gCAKxC,aAAa;;;;;;cAM/B,0BAA0B,CAAC,UAAU,CAAC;;;;4CAK9C,aAAa;;;;;;;;;;;;;cAcb,gBAAgB,KAAK,CAAC;QAClB,EAAE;QACF,4DAA4D;;cAExD,sBAAsB,CAAC,UAAU,EAAE,gBAAgB,CAAC;;;;;;;;;IAS9D,CAAC;IACL,CAAC;IAED,MAAM,sBAAsB,GAAG,CAAC,SAAkB;QAChD,IAAI,SAAS,EAAE;YACb,OAAO;;;;SAIF,CAAC;SAEP;aAAM;YACL,OAAO;;;;SAIF,CAAC;SACP;IACH,CAAC,CAAC;IAEF,MAAM,uBAAuB,GAAG,CAAC,UAAmB;QAClD,OAAO,UAAU,GAAG,+CAA+C;YAE/C,+CAA+C,CAAC;IACtE,CAAC,CAAC;IAEF;IACA;aACgB,sBAAsB,CAClC,aAAuB,EAAE,aAAuC,EAChE,UAAU,GAAG,KAAK,EAAE,SAAS,GAAG,EAAE,EAAE,MAAM,GAAG,KAAK,EAAE,eAAe,GAAG,EAAE,EACxE,yBAAyB,GAAG,KAAK;QACnC,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,UAAU,GAAG,UAAU,GAAG,UAAU,GAAG,SAAS,CAAC;QACvD,MAAM,UAAU,GAAG,UAAU,GAAG,SAAS,GAAG,UAAU,CAAC;QACvDA,OAAI,CAAC,MAAM,CACP,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC;YAC/B,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC;YACnC,SAAS,GAAG,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EACtC,MAAM,cAAc,UAAU,yCAC1B,aAAa,CAAC,CAAC,CAAC,gBAChB,UAAU,yCACV,aAAa,CAAC,CAAC,CAAC,eAChB,SAAS,yCAAyC,aAAa,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;QAC9E,MAAM,aAAa,GAAG,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,aAAa,GAAG,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,aAAa,GAAG,SAAS,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,aAAa,GAAG,yBAAyB;YAC3C;;;kDAG4C,UAAU;kDACV,UAAU;;;;;mDAMlD,UAAU,2BAA2B,aAAa,CAAC,CAAC,CAAC;qDAErD,UAAU,2BAA2B,aAAa,CAAC,CAAC,CAAC;cACjD,sBAAsB,CAAC,UAAU,CAAC;;;;mDAKtC,SAAS,2BAA2B,aAAa,CAAC,CAAC,CAAC;yDAEpD,UAAU,2BAA2B,aAAa,CAAC,CAAC,CAAC;;;;;;;;;;;;;6DAaF,aAAa,CAAC,CAAC,CAAC;;;4BAInE,UAAU;YACN,oCAAoC,aAAa,CAAC,CAAC,CAAC,IAAI;YACxD,iCAAiC,aAAa,CAAC,CAAC,CAAC,OAAO;;;;;;;;;;4DAUV,aAAa,CAAC,CAAC,CAAC;;8DAEd,aAAa,CAAC,CAAC,CAAC;;;;OAIvE;YACD;;;;;;8CAMwC,UAAU;;oCAEpB,aAAa;oCACb,aAAa;oCACb,aAAa;;;;wCAKvC,aAAa;0CAEb,aAAa;;;UAGb,sBAAsB,CAAC,UAAU,CAAC;;;;;wCAMlC,aAAa;;;;;;;;;;;;;;;;;;;;UAoBb,uBAAuB,CAAC,UAAU,CAAC;;;;;;;;;;;;;;;;GAgB1C,CAAC;QAEF,OAAO;gDACuC,UAAU,MAAM,UAAU;gDAC1B,UAAU,MAAM,SAAS;2BAC9C,aAAa,CAAC,CAAC,CAAC;2BAChB,aAAa,CAAC,CAAC,CAAC;wBACnB,SAAS;;;;;;;;;;;oBAWb,MAAM,GAAG,GAAG,GAAG,iBAAiB;uBAE9C,MAAM,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,eAAe,GAAG,SAAS,CAAC,EAAE;QAC3C,yCAAyC;qBACnC,MAAM,GAAG,qBAAqB,eAAe,EAAE,GAAG,GAAG;;;;;;;;;;QAUlE,aAAa;;GAElB,CAAC;IACJ,CAAC;IAED,MAAM,kBAAkB,GAAG,CAAC,SAAkB;QAC5C,OAAO,SAAS,GAAG;;;;;GAKlB;YACkB;;;;;GAKlB,CAAC;IACJ,CAAC,CAAC;aAEc,6BAA6B,CACzC,aAAuC,EAAE,UAAU,GAAG,KAAK;QAC7DA,OAAI,CAAC,MAAM,CACP,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChD,MAAM,iDAAiD,aAAa,GAAG,CAAC,CAAC;QAC7E,OAAO;uBACc,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;gDACK,aAAa,CAAC,CAAC,CAAC;;MAE1DW,mBAAI,EAAE;;;;;;;;;;;;;;uCAc2B,kBAAkB,CAAC,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;GAoBlE,CAAC;IACJ,CAAC;UAEY,mBAAmB;QAwB9B,YACI,MAAgC,EAAE,WAAqC,EACvE,cAAuB,EAAE,cAAuB,EAAE,UAAU,GAAG,KAAK,EACpE,UAAU,GAAG,KAAK,EAAE,OAAmB,IAAI,EAC3C,aAAsC,IAAI,EAC1C,yBAAqC,IAAI,EACzC,yBAAyB,GAAG,KAAK;YAzBrC,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,mDAAmD,CAAC;YAyB7D,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YAC/C,MAAM,QAAQ,GAAG,UAAU,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACpD,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,QAAQ,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,UAAU;iBACjC,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,UAAU,CAAC;gBACnD,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,UAAU,CAAC;YAC5C,IAAI,CAAC,SAAS,GAAG,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,UAAU,CAAC;YAErD,IAAI,CAAC,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,SAAS,EAAE;;gBAElC,IAAI,CAAC,iBAAiB,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;gBACnC,IAAI,CAAC,aAAa,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;aACjC;iBAAM;gBACL,MAAM,aAAa,GAAG,6BAA6B,CAC/C,WAAW,CAAC,CAAC,CAAC,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC;gBAC1D,IAAI,CAAC,aAAa,GAAG,aAAa,CAAC,aAAa,CAAC;gBACjD,IAAI,CAAC,iBAAiB,GAAG,aAAa,CAAC,iBAAiB,CAAC;aAC1D;YAED,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,IAAI,CAAC,iBAAiB,CAAC,CAAC;YAE5B,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;YAC7B,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;YACjE,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YAED,IAAI,yBAAyB,EAAE;gBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAC3D,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAC3D,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,CAAC;gBAC3C,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,gBAAgB,IAAI,CAAC,iBAAiB,IAAI,UAAU,IACjE,UAAU,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,SAAS,IACjE,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,SAAS,IAC9C,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,IAC1C,IAAI,CAAC,yBAAyB,EAAE,CAAC;SACtC;QAED,WAAW,CAAC,SAAiB,EAAE,SAAiB,EAAE,QAAgB;YAEhE,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;YACrE,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;YAErE,IAAI,CAAC,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,SAAS,EAAE;;gBAElC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aAC5C;iBAAM;gBACL,IAAI,CAAC,SAAS,GAAG,UAAU,CAAC;aAC7B;YAED,MAAM,SAAS,GAAG,SAAS,GAAG,UAAU,KAAK,CAAC,CAAC;YAC/C,MAAM,SAAS,GAAG,SAAS,GAAG,UAAU,KAAK,CAAC,CAAC;YAC/C,MAAM,QAAQ,GAAG,QAAQ,GAAG,IAAI,CAAC,SAAS,KAAK,CAAC,CAAC;YACjD,OAAO,CAAC,SAAS,EAAE,SAAS,EAAE,QAAQ,CAAC,CAAC;SACzC;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QAEb,mBAAmB,CACf,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,EAAE,IAAI,CAAC,MAAM,CAAC;QAEjE,uBAAuB,CACnB,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,cAAc,EAClD,IAAI,CAAC,cAAc,EACnB,KAAK,4DACL,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAC9D,IAAI,CAAC,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC;QAExB,IAAI,CAAC,MAAM;YACP,0BAA0B,CACtB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,UAAU,EAC3D,IAAI,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,SAAS,CAAC;aAC/C,IAAI,CAAC,SAAS,GAAG,6BAA6B,CACzB,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,UAAU,CAAC;gBACxC,sBAAsB,CAClB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAC1C,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAC5C,IAAI,CAAC,yBAAyB,CAAC,CAAC;KAC7D,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICznBH;;;;;;;;;;;;;;;;aAwBgB,sBAAsB;QACpC,OAAO;;MAEHA,mBAAI,EAAE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA6BT,CAAC;IACJ,CAAC;UAEY,mBAAmB;QAgB9B,YACI,WAAqC,EAAE,cAAuB,EAC9D,cAAuB,EAAE,UAAU,GAAG,KAAK,EAAE,UAAU,GAAG,KAAK,EAC/D,OAAmB,IAAI,EAAE,aAAsC,IAAI,EACnE,yBAAqC,IAAI;YAf7C,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,mDAAmD,CAAC;YAC/D,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAcpD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YACjD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;YAC7B,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;YACjE,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YAED,IAAI,yBAAyB,EAAE;gBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAC3D,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,SAAS,GAAG,gBAAgB,IAAI,CAAC,UAAU,IAAI,UAAU,IAC1D,UAAU,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC;SAChE;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACb,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,CAAC;QAEpE,uBAAuB,CACnB,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,cAAc,EAClD,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,UAAU,CAAC;QAC1D,sBAAsB,EAAE;KAC3B,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICpHH;;;;;;;;;;;;;;;;aAsBgB,+BAA+B,CAC3C,aAAuC;QACzC,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,UAAU,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,SAAS,GAAG,UAAU,GAAG,UAAU,GAAG,UAAU,GAAG,UAAU,CAAC;QACpE,OAAO;8CACqC,SAAS,MAAM,UAAU;8CACzB,UAAU,MAAM,SAAS;;;;;;;;IAQnEA,mBAAI,EAAE;;;;;;;;+CAQqC,SAAS;;;;;;;;gCAQxB,SAAS;gCACT,SAAS;;;;;;;;;;;;kCAYP,SAAS;kCACT,SAAS;;4BAEf,SAAS;;;;;;;;GAQlC,CAAC;IACJ,CAAC;UAEY,4BAA4B;QAgBvC,YACI,MAAgC,EAAE,MAAgC,EAClE,WAAqC,EAAE,UAAU,GAAG,KAAK,EACzD,UAAU,GAAG,KAAK,EAAE,OAAmB,IAAI,EAC3C,aAAsC,IAAI,EAC1C,yBAAqC,IAAI;YAhB7C,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,mDAAmD,CAAC;YAC/D,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAenD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAE/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YAC/C,IAAI,CAAC,QAAQ,GAAG;gBACd,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC;gBACjD,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC;aAClE,CAAC;YAEF,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;YAC7B,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YAED,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;YACjE,IAAI,yBAAyB,EAAE;gBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAC3D,IAAI,CAAC,cAAc,GAAG,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACtC,IAAI,CAAC,cAAc,GAAG,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACtC,IAAI,CAAC,SAAS,GAAG,yBAAyB,IAAI,CAAC,UAAU,IAAI,UAAU,IACnE,UAAU,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC;SAChE;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACb,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,CAAC;QAEpE,uBAAuB,CACnB,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,cAAc,EAClD,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,UAAU,CAAC;QAC1D,+BAA+B,CAAC,IAAI,CAAC,aAAa,CAAC;KACtD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC7IH;;;;;;;;;;;;;;;;UAwBa,mBAAmB;QAiB9B,YACI,WAAqC,EAAE,QAAgB,EACvD,cAAuB,EAAE,cAAuB,EAAE,UAAU,GAAG,KAAK,EACpE,UAAU,GAAG,KAAK;YAftB,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,mDAAmD,CAAC;YAC/D,kBAAa,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAIpD,WAAM,GAAG,IAAI,CAAC;YAGd,WAAM,GAAG,KAAK,CAAC;YACf,oBAAe,GAAG,GAAG,CAAC;YAMpBX,OAAI,CAAC,MAAM,CACP,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,EACpB,MAAM,8CAA8C,CAAC,CAAC;YAC1D,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC;YAClD,IAAI,CAAC,MAAM,GAAG,CAAC,UAAU,IAAI,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC;gBAC3C,CAAC,UAAU,IAAI,QAAQ,GAAG,CAAC,KAAK,CAAC;gBAC5C,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;YAClC,IAAI,CAAC,iBAAiB,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,eAAe,CAAC,CAAC;YAEtD,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;gBAChB,IAAI,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,EAAE,EAAE;oBAC5B,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;iBAC/B;gBACD,IAAI,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,EAAE,EAAE;oBAC5B,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;iBAC/B;aACF;YAED,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EACnB;gBACE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;gBAC7D,QAAQ;aACT,EACD,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,iBAAiB,CAAC,CAAC;YAEhD,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,SAAS;gBACV,gBAAgB,UAAU,IAAI,UAAU,IAAI,cAAc,IACtD,cAAc,IAAI,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;SACnE;QAED,WAAW;;;YAGT,MAAM,gBAAgB,GAAG,CAAC,SAAiB;gBACzC,OAAO;4BACe,SAAS;;;;;uDAM3B,SAAS,GAAG,CAAC,GAAG,UAAU,GAAG,OAAO;;;;;;;OAOvC,CAAC;aACH,CAAC;YAEF,MAAM,SAAS,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC;YACtC,MAAM,QAAQ,GAAG;QAEb,kBAAkB,CACd,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,cAAc,EAAE,KAAK,EAAE,IAAI,CAAC,UAAU,EAChE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,SAAS,CAAC;gEAEnC,WAAW,CAAC,SAAS,CAAC;4BACF,SAAS;;;;;;YAMzB,gBAAgB,CAAC,SAAS,CAAC;;;QAI/B,IAAI,CAAC,MAAM,GAAG,0BAA0B,CACtB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAC1C,IAAI,CAAC,UAAU,EAAE,EAAE,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,CAAC;YACpD,sBAAsB,CAClB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAC1C,IAAI,CAAC,UAAU,EAAE,EAAE,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,CAAC;KACrE,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;KACF;UAEY,qBAAqB;QAahC,YACI,WAAqB,EAAE,OAAmB,IAAI,EAC9C,aAAsC,IAAI,EAC1C,yBAAqC,IAAI;YAb7C,aAAQ,GAAG,EAAE,CAAC;YAGd,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YASV,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;YAC5B,IAAI,CAAC,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;YAChE,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YAED,IAAI,IAAI,CAAC,yBAAyB,EAAE;gBAClC,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,SAAS,GAAG,kBAAkB,UAAU,EAAE,CAAC;SACjD;QAED,WAAW;YACT,OAAO;MACL,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,CAAC;MACpEW,mBAAI,CAAC,OAAO,CAAC;;;;UAIT,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC;;;;KAIzD,CAAC;SACH;;;IClLH;;;;;;;;;;;;;;;;UAoBa,WAAW;QAUtB,YAAY,KAAe;YAT3B,kBAAa,GAAa,EAAE,CAAC;YAC7B,gBAAW,GAAa,EAAE,CAAC;YAI3B,aAAQ,GAAG,cAAc,CAAC;YAC1B,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC;SACzB;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;MACfA,mBAAI,CAAC,OAAO,CAAC;;;;;GAKhB,CAAC;YACA,OAAO,QAAQ,CAAC;SACjB;;;IChDH;;;;;;;;;;;;;;;;aAsBgB,IAAI,CAAC,IAAgD;QAEnE,MAAM,EAAC,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QAC9B,MAAM,EAAC,KAAK,EAAE,KAAK,EAAC,GAAG,KAAK,CAAC;QAC7B,IAAI,EAAC,KAAK,EAAC,GAAG,KAAK,CAAC;QAEpB,KAAK,GAAG,KAAK,IAAIX,OAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;QAExC,IAAI,KAAK,KAAK,QAAQ,EAAE;;YAEtB,MAAM,MAAM,GAAGA,OAAI,CAAC,iBAAiB,CAAC,KAAK,EAAEA,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC;YACxE,MAAM,CAAC,IAAI,CAAC,KAAe,CAAC,CAAC;YAC7B,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;SACrD;aAAM;YACL,MAAM,OAAO,GAAG,IAAI,WAAW,CAAC,KAAK,CAAC,CAAC;YACvC,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,KAAe,CAAC,EAAC,CAAC,CAAC;YACjE,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,EAAE,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;SAClE;IACH,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEY,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;IC9CD;;;;;;;;;;;;;;;;aAqBgB,OAAO,CACnB,IAA0E;QAE5E,MAAM,EAAC,MAAM,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QAC7B,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,KAAK,EAAC,GAAG,KAAK,CAAC;QAEtB,MAAM,KAAK,GAAGZ,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QAC1C,MAAM,MAAM,GAAGA,OAAI,CAAC,sBAAsB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACzD,MAAM,MAAM,GAAGA,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QAE1CA,OAAI,CAAC,MAAM,CACP,KAAK,KAAK,MAAM,EAChB,MAAM,kBAAkB,MAAM,SAAS,MAAM,wBAAwB;YACjE,UAAU,CAAC,CAAC,KAAK,SAAS,KAAK,mCAAmC;YAClE,8CAA8C,CAAC,CAAC;;QAGxD,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;QAC9B,OAAO,EAAC,MAAM,EAAE,CAAC,CAAC,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC,CAAC;IAC3D,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEa,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;IC/CD;;;;;;;;;;;;;;;;aA0CgB,eAAe,CAAC,EAC9B,CAAC,EACD,CAAC,EACD,UAAU,EACV,UAAU,EACV,OAAO,EACP,IAAI,GAAG,IAAI,EACX,sBAAsB,GAAG,IAAI,EAC7B,cAAc,GAAG,CAAC,EAClB,UAAU,GAAG,IAAI,EACC;QAClB,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAE7B,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QACzE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QAEzE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QACzE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QAEzE,MAAM,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExC,MAAM,SAAS,GAAGb,OAAI,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;QACjD,MAAM,SAAS,GAAGA,OAAI,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;QAEjD,MAAM,iBAAiB,GAAGc,iBAAc,CAAC,0BAA0B,CAC/D,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,QAAQ,GAAG,iBAAiB,CAAC,MAAM,CAAC,CAAC,WAAW,EAAE,WAAW,CAAC,CAAC,CAAC;QAEtEd,OAAI,CAAC,MAAM,CACP,WAAW,KAAK,WAAW,EAC3B,MAAM,kCAAkC,WAAW,SAAS;YACxD,GAAG,WAAW,4BAA4B,CAAC,CAAC,KAAK,OAAO;YACxD,GAAG,CAAC,CAAC,KAAK,mBAAmB,UAAU,EAAE;YACzC,mBAAmB,UAAU,cAAc,CAAC,CAAC;QAErD,MAAM,QAAQ,GAA6B,UAAU;YACjD,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC;YACrC,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC;QAC1C,MAAM,QAAQ,GAA6B,UAAU;YACjD,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC;YACrC,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC;;QAG1C,MAAM,GAAG,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QACzE,MAAM,GAAG,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QACzE,MAAM,aAAa,GAAiB,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;QAE/C,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC;QAChD,MAAM,cAAc,GAAG,SAAS,KAAK,CAAC,CAAC;QACvC,MAAM,cAAc,GAAG,SAAS,KAAK,CAAC,CAAC;QAEvC,MAAM,MAAM,GAAiB,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;QACxC,MAAM,UAAU,GAAG;YACjB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,WAAW,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,WAAW,CAAC,EAAC;YAC1E,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,WAAW,CAAC,EAAC;SACrC,CAAC;QAEF,IAAI,OAAsB,CAAC;QAC3B,IAAI,GAAe,CAAC;QACpB,MAAM,WAAW,GACb,CAAC,QAAQ,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC;QACzC,IAAI,iBAAiB,GAAGF,MAAG,EAAE,CAAC,GAAG,CAAC,4BAA4B,CAAW,CAAC;QAC1E,IAAI,iBAAiB,GAAG,CAAC,EAAE;YACzB,IAAI,WAAW,GAAG,WAAW,IAAI,GAAG,EAAE;gBACpC,iBAAiB,GAAG,iBAAiB,CAAC,mBAAmB,CAAC;aAC3D;iBAAM;;;;YAIH,QAAQ,KAAK,CAAC,IAAI,WAAW,IAAI,GAAG,IAAI,WAAW,IAAI,EAAE;gBACzD,WAAW,IAAI,IAAI,EAAE;gBACvB,iBAAiB,GAAG,iBAAiB,CAAC,mBAAmB,CAAC;aAC3D;iBAAM;;;;;;;;;;YAUH,CAAC,WAAW,IAAI,EAAE;iBAChB,WAAW,IAAI,GAAG,IAAI,WAAW,IAAI,CAAC,GAAG,WAAW,CAAC;iBACtD,WAAW,IAAI,EAAE;qBAChB,WAAW,IAAI,GAAG,IAAI,WAAW,IAAI,CAAC,GAAG,WAAW,CAAC,CAAC,EAAE;gBAC5D,iBAAiB,GAAG,iBAAiB,CAAC,4BAA4B,CAAC;aACpE;iBAAM;gBACL,iBAAiB,GAAG,iBAAiB,CAAC,mBAAmB,CAAC;aAC3D;SACF;QAED,QAAQ,iBAAiB;YACvB,KAAK,iBAAiB,CAAC,mBAAmB;gBACxC,OAAO,GAAG,IAAI,mBAAmB,CAC7B,WAAW,EAAE,cAAc,EAAE,cAAc,EAAE,UAAU,EAAE,UAAU,EACnE,IAAI,EAAE,UAAU,EAAE,sBAAsB,CAAC,CAAC;gBAC9C,MAAM;YACR,KAAK,iBAAiB,CAAC,mBAAmB,EAAE;;;gBAG1C,GAAG,GAAG,IAAI,CACN,EAAC,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAE,KAAK,EAAE,CAAC,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC,EAAC,CAAC,CAAC;gBACtE,OAAO,GAAG,IAAI,mBAAmB,CAC7B,WAAW,EAAE,WAAW,EAAE,cAAc,EAAE,cAAc,EAAE,UAAU,EACpE,UAAU,CAAC,CAAC;gBAChB,IAAI,IAAI,IAAI,UAAU,EAAE;oBACtB,GAAG;wBACC,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,UAAU,EAAE,GAAG,CAAC,CAAC;oBACxE,MAAM,qBAAqB,GAAG,IAAI,qBAAqB,CACnD,GAAG,CAAC,KAAK,EAAE,IAAI,EAAE,UAAU,EAAE,sBAAsB,CAAC,CAAC;oBACzD,IAAI,WAAW,GAAG,IAAI,CAAC;oBACvB,MAAM,gBAAgB,GAAiB,CAAC,GAAG,CAAC,CAAC;oBAC7C,IAAI,IAAI,EAAE;wBACR,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;qBAC7B;oBACD,IAAI,sBAAsB,EAAE;wBAC1B,gBAAgB,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;qBAC/C;oBACD,IAAI,UAAU,KAAK,WAAW,EAAE;wBAC9B,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,cAAc,CAAC,EAAC,CAAC,CAAC;wBAC1D,qBAAqB,CAAC,QAAQ,IAAI,eAAe,CAAC;qBACnD;oBACD,MAAM,YAAY,GAAG,OAAO,CAAC,gBAAgB,CACzC,qBAAqB,EAAE,gBAAgB,EAAE,GAAG,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;oBACrE,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;oBACxB,MAAM,WAAW,GAAG,OAAO,CACvB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;oBACpE,aAAa,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;oBACjC,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;wBAC7B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;qBAC/B;oBACD,OAAO,WAAW,CAAC;iBACpB;gBACD,MAAM;aACP;YACD,KAAK,iBAAiB,CAAC,4BAA4B;gBACjD,OAAO,GAAG,IAAI,4BAA4B,CACtC,QAAQ,EAAE,QAAQ,EAAE,WAAW,EAAE,UAAU,EAAE,UAAU,EAAE,IAAI,EAC7D,UAAU,EAAE,sBAAsB,CAAC,CAAC;gBACxC,MAAM;YACR,KAAK,iBAAiB,CAAC,mBAAmB;;;gBAGxC,MAAM,yBAAyB,GAAG,OAAO,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;gBAChE,OAAO,GAAG,IAAI,mBAAmB,CAC7B,QAAQ,EAAE,WAAW,EAAE,cAAc,EAAE,cAAc,EAAE,UAAU,EACjE,UAAU,EAAE,IAAI,EAAE,UAAU,EAAE,sBAAsB,EACpD,yBAAyB,CAAC,CAAC;gBAC/B,MAAM;YACR;gBACE,MAAM,IAAI,KAAK,CAAC,iCAAiC,iBAAiB,GAAG,CAAC,CAAC;SAC1E;QAED,IAAI,IAAI,EAAE;YACR,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SACnB;QACD,IAAI,sBAAsB,EAAE;YAC1B,MAAM,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;SACrC;QACD,IAAI,UAAU,KAAK,WAAW,EAAE;YAC9B,UAAU,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,cAAc,CAAC,EAAC,CAAC,CAAC;YAC3D,OAAO,CAAC,QAAQ,IAAI,eAAe,CAAC;SACrC;QACD,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,UAAU,EAAE,GAAG,CAAC,CAAC;QAC1E,MAAM,WAAW,GACb,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QACnE,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACxB,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;YAC7B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;SAC/B;QACD,OAAO,WAAW,CAAC;IACrB;;ICxNA;;;;;;;;;;;;;;;;aAsBgB,YAAY,CAAC,IAI5B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,CAAC,EAAE,IAAI,EAAE,sBAAsB,EAAC,GAAG,MAAM,CAAC;QACpD,MAAM,EAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,cAAc,EAAC,GAAG,KAAK,CAAC;QAEnE,OAAO,eAAe,CAAC;YACrB,CAAC;YACD,CAAC;YACD,UAAU;YACV,UAAU;YACV,OAAO;YACP,IAAI;YACJ,sBAAsB;YACtB,cAAc;YACd,UAAU;SACX,CAAC,CAAC;IACL,CAAC;IAEM,MAAM,kBAAkB,GAAiB;QAC9C,UAAU,EAAEiB,eAAY;QACxB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,YAAgC;KAC7C;;IChDD;;;;;;;;;;;;;;;;UAsBa,sBAAsB;QAUjC,YAAY,EAAgB,EAAE,MAAgB,EAAE,MAAgB;YAThE,kBAAa,GAAG,CAAC,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC;YAKrD,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAEtD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAGhB,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YAC3E,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,mBAAmB,EAAE,EAAE,CAAC;YACzC,IAAI,CAAC,EAAE,GAAG,EAAE,CAAC;SACd;QAED,WAAW;YACT,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC;YAChD,MAAM,QAAQ,GAAG;;;UAGX,KAAK;;;QAGPY,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;KAShB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC7DH;;;;;;;;;;;;;;;;UAuBa,eAAe;QAiB1B,YAAY,EAAgB,EAAE,MAAgB,EAAE,MAAgB;YAVhE,SAAI,GAAG,IAAI,CAAC;YACZ,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAUzB,IAAI,CAAC,WAAW,GAAGZ,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YAC3E,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,EAAE,GAAG,EAAE,CAAC;YAEb,IAAI,CAAC,oBAAoB;gBACrB,MAAM,CAAC,MAAM,IAAI,CAAC,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;YAC/D,IAAI,CAAC,oBAAoB;gBACrB,MAAM,CAAC,MAAM,IAAI,CAAC,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;YAE/D,IAAI,IAAI,CAAC,oBAAoB,IAAI,IAAI,CAAC,oBAAoB,EAAE;gBAC1D,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;;;gBAGpB,IAAI,CAAC,iBAAiB;oBAClB,IAAI,CAAC,oBAAoB,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACtD,IAAI,CAAC,SAAS,GAAG,UAAU,IAAI,CAAC,IAAI,IAAI,EAAE,IAAI,IAAI,CAAC,iBAAiB,IAChE,IAAI,CAAC,oBAAoB,EAAE,CAAC;gBAChC,IAAI,CAAC,IAAI,GAAG,QAAQ,CAAC;;;gBAGrB,IAAI,CAAC,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;gBACjC,IAAI,CAAC,aAAa,GAAG,CAAC,CAAC;aACxB;iBAAM;gBACL,IAAIC,OAAI,CAAC,WAAW,CAAC,MAAM,EAAE,MAAM,CAAC;oBAChCA,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;oBACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC;oBACnB,IAAI,CAAC,IAAI,GAAG,MAAM,CAAC;oBACnB,IAAI,CAAC,aAAa,GAAG,CAAC,CAAC;iBACxB;qBAAM;oBACL,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;oBACpB,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC;oBACpB,IAAI,CAAC,aAAa,GAAG,CAAC,CAAC;iBACxB;gBACD,IAAI,CAAC,SAAS,GAAG,UAAU,IAAI,CAAC,IAAI,IAAI,EAAE,EAAE,CAAC;;;gBAG7C,IAAI,CAAC,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;aAClC;YACD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;SACjC;QAED,WAAW;YACT,IAAI,QAAQ,CAAC;YACb,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,GAAG,WAAW,GAAG,KAAK,CAAC;YAChD,MAAM,OAAO,GAAG;6BACS,KAAK,SAAS,KAAK,QAAQ,KAAK;QACrD,iBAAiB,CAAC,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAM,CAAC;;KAE1C,CAAC;YAEF,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBAC1B,MAAM,kBAAkB,GAAG,IAAI,CAAC,iBAAiB,GAAG,CAAC;oBACjD,UAAU,IAAI,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,GAAG;oBACxC,GAAG,CAAC;gBACR,MAAM,iBAAiB,GAAG,IAAI,CAAC,oBAAoB;oBAC/C;8BACoB,kBAAkB,IAAI;oBAC1C,qBAAqB,kBAAkB;4CACL,CAAC;gBACvC,QAAQ,GAAG;UACP,OAAO;gDAC+B,IAAI,CAAC,iBAAiB;UAC5DW,mBAAI,CAAC,OAAO,CAAC;;;4BAGK,IAAI,CAAC,iBAAiB;0CAExC,IAAI,CAAC,oBAAoB,GAAG,GAAG,GAAG,GAAG;;;;;;cAMjC,iBAAiB;;;;SAItB,CAAC;aACL;iBAAM;gBACL,QAAQ,GAAG;SACR,OAAO;SACPA,mBAAI,CAAC,OAAO,CAAC;;;;;;;QAOd,CAAC;aACJ;YAED,OAAO,QAAQ,CAAC;SACjB;;;ICvIH;;;;;;;;;;;;;;;;aAoBgB,QAAQ,CACpB,IAAsD;QACxD,MAAM,EAAC,MAAM,EAAC,GAAG,IAAI,CAAC;QACtB,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QAEnB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;QAC9B,OAAO,EAAC,MAAM,EAAE,CAAC,CAAC,MAAM,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC,CAAC;IAC5D,CAAC;IAEM,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAEK,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAA4B;KACzC;;ICjCD;;;;;;;;;;;;;;;;IAsBA;;;;;;;;aAQgB,OAAO,CAAC,IAAqD;QAE3E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,IAAI,EAAE,IAAI,EAAC,GAAG,MAAM,CAAC;QAE5B,MAAM,WAAW,GAAG,OAAO,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QACpE,MAAM,OAAO,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;QAE1D,MAAM,cAAc,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,IAAI,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAE9D,MAAM,cAAc,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,IAAI,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAE9D,OAAO,CAAC,kBAAkB,GAAG,EAAC,IAAI,EAAE,cAAc,EAAE,IAAI,EAAE,cAAc,EAAC,CAAC;QAE1E,OAAO,WAAW,CAAC;IACrB,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;ICnDD;;;;;;;;;;;;;;;;UAqBa,cAAc;QAWzB,YAAY,WAAqB,EAAE,EAAe;YANlD,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YAItB,SAAI,GAAG,IAAI,CAAC;;YAIV,MAAM,cAAc,GAAG,GAAG,CAAC;YAC3B,IAAI,CAAC,aAAa,GAAG,CAAC,cAAc,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC5C,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,EAAE,GAAG,EAAE,CAAC;YACb,IAAI,CAAC,SAAS,GAAG,SAAS,EAAE,EAAE,CAAC;SAChC;QAED,WAAW;YACT,OAAO;;UAED,gBAAgB,CAAC,IAAI,CAAC,EAAE,EAAE,KAAK,CAAC;;QAElCN,mBAAI,CAAC,OAAO,CAAC;;;;;;OAMd,CAAC;SACL;;;ICxDH;;;;;;;;;;;;;;;;IAmCA;;;;;;;;;aASgB,eAAe,CAC3B,EAAC,MAAM,EAAE,aAAa,EAAE,KAAK,EAAwB;QACvD,OAAO,CAAC,EAAC,MAAM,EAAE,OAAO,EAAC;YACvB,MAAM,EAAC,CAAC,EAAC,GAAG,MAAqB,CAAC;YAClC,MAAM,aAAa,GAAG,OAAwB,CAAC;YAE/C,MAAM,MAAM,GAAG,KAAK,IAAI,CAAC,CAAC,KAAK,CAAC;YAChC,IAAI,aAAa,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,aAAa,IAAI,IAAI,EAAE;gBAClE,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;gBACpD,MAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,MAAoB,EAAE,MAAM,CAAC,CAAC;gBACpE,OAAO,aAAa,CAAC,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;aACjE;YAED,MAAM,OAAO,GAAmB,IAAI,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;YACpE,OAAO,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;SAC7D,CAAC;IACJ,CAAC;IASD;;;;;;;;;aASgB,gBAAgB,CAC5B,EAAC,MAAM,EAAE,aAAa,EAAE,eAAe,GAAG,KAAK,EAAE,KAAK,EAC5B;QAC5B,OAAO,CAAC,EAAC,MAAM,EAAE,OAAO,EAAC;YACvB,MAAM,EAAC,CAAC,EAAE,CAAC,EAAC,GAAG,MAAsB,CAAC;YACtC,MAAM,aAAa,GAAG,OAAwB,CAAC;YAE/C,IAAI,eAAe,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;gBAC9C,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;gBACpD,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;gBACpD,IAAI,IAAgB,EAAE,IAAgB,CAAC;gBACvC,IAAI,MAAM,KAAK,YAAY,CAAC,GAAG,EAAE;oBAC/B,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG;wBACb,CAAC,KAAK,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC;wBAC9D,CAAC,KAAK,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC;qBAC/D,CAAC,GAAG,CAAC,YAAY;wBAChB,MAAM,CAAC,KAAK,EAAE,KAAK,CAAC,GAAG,YAAY,CAAC;wBAEpC,MAAM,OAAO,GAAG;4BACd,MAAM,EAAE,KAAK,CAAC,MAAM;4BACpB,KAAK,EAAE,KAAK,CAAC,KAAK;4BAClB,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf,CAAC;wBACF,MAAM,OAAO,GAAG;4BACd,MAAM,EAAE,KAAK,CAAC,MAAM;4BACpB,KAAK,EAAE,KAAK,CAAC,KAAK;4BAClB,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf,CAAC;wBAEF,MAAM,OAAO,GAAG,IAAI,eAAe,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;wBAC9D,OAAO,aAAa,CAAC,gBAAgB,CACjC,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAC3BO,aAAU,CAAC,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;qBAC3C,CAAC,CAAC;iBACJ;qBAAM;oBACL,MAAM,WAAW,GAAG,IAAI,sBAAsB,CAC1C,YAAY,CAAC,qBAAqB,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;oBAC1D,MAAM,WAAW,GAAG,IAAI,sBAAsB,CAC1C,YAAY,CAAC,qBAAqB,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;oBAE1D,MAAM,MAAM,GAAG;wBACb;4BACE,MAAM,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM;4BAC5C,KAAK,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,KAAK;4BAC1C,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf;wBACD;4BACE,MAAM,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM;4BAC5C,KAAK,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,KAAK;4BAC1C,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf;wBACD;4BACE,MAAM,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM;4BAC5C,KAAK,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,KAAK;4BAC1C,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf;wBACD;4BACE,MAAM,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM;4BAC5C,KAAK,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,KAAK;4BAC1C,KAAK,EAAE,CAAC,CAAC,KAAK;yBACf;qBACF,CAAC;oBAEF,IAAI,GAAG,aAAa,CAAC,gBAAgB,CAAC,WAAW,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;oBACtE,IAAI,GAAG,aAAa,CAAC,gBAAgB,CAAC,WAAW,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;iBACvE;gBAED,MAAM,aAAa,GACf,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,IAAI,EAAE,IAAI,EAAC,EAAE,OAAO,EAAE,aAAa,EAAC,CAAC,CAAC;gBAE5D,aAAa,CAAC,WAAW,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBACvC,aAAa,CAAC,WAAW,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;;gBAIvC,OAAO,aAAa,CAAC;aACtB;YAED,MAAM,MAAM,GAAG,KAAK,IAAIA,aAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;YACrD,IAAI,CAAC,CAAC,CAAC,KAAK,KAAK,QAAQ,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ;gBAC5C,aAAa,CAAC,kBAAkB,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACzC,aAAa,IAAI,IAAI,EAAE;gBACzB,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB,CAAC;gBACzE,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB,CAAC;gBACzE,MAAM,YAAY,GAAG,CAAC,CAAC,KAAK,KAAK,QAAQ;;oBAErCnB,eAAY,CAAC,sBAAsB,CAAC,KAA4B,CAAC;oBACjE,KAAK,CAAC;gBACV,MAAM,YAAY,GAAG,CAAC,CAAC,KAAK,KAAK,QAAQ;;oBAErCA,eAAY,CAAC,sBAAsB,CAAC,KAA4B,CAAC;oBACjE,KAAK,CAAC;gBACV,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GACvB,aAAa,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,YAAY,EAAE,YAAY,EAAE,MAAM,CAAC,CAAC;gBAExE,OAAO,aAAa,CAAC,cAAc,CAAC,QAAQ,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;aAClE;YACD,MAAM,OAAO,GAAG,IAAI,eAAe,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;YAC9D,OAAO,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;SAChE,CAAC;IACJ;;IClLA;;;;;;;;;;;;;;;;aAsBgB,aAAa,CAAC,IAAgB;QAC5C,MAAM,YAAY,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;SACrC;QACD,OAAO,YAAY,CAAC;IACtB;;IC5BA;;;;;;;;;;;;;;;;IAqBA;;;aAGgB,4BAA4B,CAAC,EAAyB;QAEpE,OAAO,CAAC,MAAgB,EAAE,MAAgB,EAAE,KAAiB,EACrD,KAAiB,EAAE,KAAe;YACxC,MAAM,QAAQ,GAAGA,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YAEzE,MAAM,UAAU,GAAG,QAAQ,CAAC,MAAM,CAAC;YACnC,MAAM,aAAa,GAAGC,OAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAC;YACpD,MAAM,UAAU,GAAGA,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;YAEhD,MAAM,MAAM,GACRA,OAAI,CAAC,sBAAsB,CAAC,KAAwB,EAAE,UAAU,CAAC,CAAC;YAEtE,MAAM,KAAK,GAAG,MAAM,CAAC,MAAM,CAAC;YAC5B,MAAM,KAAK,GAAG,MAAM,CAAC,MAAM,CAAC;YAE5B,MAAM,QAAQ,GAAGA,OAAI,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;YAC7C,MAAM,QAAQ,GAAGA,OAAI,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;YAE7C,MAAM,cAAc,GAAGD,eAAY,CAAC,gBAAgB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;YACvE,MAAM,cAAc,GAAGA,eAAY,CAAC,gBAAgB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;YAEvE,IAAI,cAAc,CAAC,MAAM,GAAG,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oBACtC,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,GAAG,KAAK,CAAC,MAAM,CAAC,EAAE,KAAK,CAAC,CAAC,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC;iBAClE;aACF;iBAAM;gBACL,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oBACtC,MAAM,GAAG,GAAGC,OAAI,CAAC,UAAU,CAAC,CAAC,EAAE,UAAU,EAAE,aAAa,CAAC,CAAC;oBAE1D,MAAM,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,CAAC;oBAC/B,cAAc,CAAC,OAAO,CAAC,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,MAAM,MAAM,GAAGA,OAAI,CAAC,UAAU,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,CAAC,CAAC;oBAEtD,MAAM,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,CAAC;oBAC/B,cAAc,CAAC,OAAO,CAAC,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,MAAM,MAAM,GAAGA,OAAI,CAAC,UAAU,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,CAAC,CAAC;oBAEtD,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,EAAE,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC;iBAC9C;aACF;YAED,OAAO,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;SAC3B,CAAC;IACJ;;ICpEA;;;;;;;;;;;;;;;;aA0BgB,QAAQ,CACpB,MAAkB,EAAE,KAAe,EAAE,SAAmB,EACxD,KAAe;QACjB,IAAI,KAAK,KAAK,OAAO,EAAE;YACrB,MAAM,YAAY,GAAG,UAAU,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAC7C,OAAO,CAAC,KAAK,EAAE,OAAO,EAAE,YAAY,CAAC,CAAC;SACvC;QAED,IAAI,KAAK,KAAK,MAAM,EAAE;;;;YAIpB,MAAM,IAAI,GAAGA,OAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;YAE/C,MAAM,CAAC,UAAU,EAAE,WAAW,CAAC,GAAG,4BAA4B,CAC1D,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,EAAE,MAAM,EAAE,IAAI,EAAE,MAAM,CAAC,CAAC;YAElE,OAAO,CAAC,WAAW,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;SAC1C;QACD,MAAM,IAAI,KAAK,CAAC,iCAAiC,SAAS,OAAO,KAAK,EAAE,CAAC,CAAC;IAC5E;;IC9CA;;;;;;;;;;;;;;;;IAsBO,MAAM,OAAO,GAChB,4BAA4B,EAAE,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,GAAG,CAAC,EAAE;;ICvBnE;;;;;;;;;;;;;;;;aAmBgB,YAAY,CACxB,KAAiB,EAAE,WAAuB,EAAE,YAAsB,EAClE,YAAsB,EAAE,IAAY;QACtC,MAAM,WAAW,GAAGA,OAAI,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;QACrD,MAAM,OAAO,GAAGA,OAAI,CAAC,mBAAmB,CAAC,IAAI,EAAE,YAAY,CAAe,CAAC;QAE3E,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACrC,MAAM,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YACvB,IAAI,KAAK,GAAG,CAAC,EAAE;gBACb,MAAM,IAAI,KAAK,CAAC,+BAA+B,CAAC,CAAC;aAClD;YAED,IAAI,KAAK,IAAI,IAAI,EAAE;gBACjB,SAAS;aACV;YAED,IAAI,WAAW,GAAG,CAAC,EAAE;gBACnB,OAAO,CAAC,KAAK,CAAC,IAAI,WAAW,CAAC,CAAC,CAAC,CAAC;aAClC;iBAAM;gBACL,OAAO,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;aACrB;SACF;QAED,OAAO,OAAO,CAAC;IACjB,CAAC;aAEe,kBAAkB,CAC9B,IAAqB,EAAE,UAA2B,EAAE,IAAY,EAChE,YAAY,GAAG,KAAK;QACtB,MAAM,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAE9B,MAAM,MAAM,GAAGM,SAAM,CAAC,CAAC,OAAO,EAAE,IAAI,CAAC,EAAE,UAAU,CAAC,KAAK,CAAC,CAAC;QAEzD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,EAAE,CAAC,EAAE,EAAE;YAChC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,EAAE,CAAC,EAAE,EAAE;gBAChC,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBAC7B,IAAI,KAAK,GAAG,CAAC,EAAE;oBACb,MAAM,IAAI,KAAK,CAAC,+BAA+B,CAAC,CAAC;iBAClD;gBAED,IAAI,KAAK,IAAI,IAAI,EAAE;oBACjB,SAAS;iBACV;gBAED,IAAI,YAAY,EAAE;oBAChB,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;iBACzB;qBAAM;oBACL,IAAI,UAAU,CAAC,IAAI,GAAG,CAAC,EAAE;wBACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;qBACnE;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;qBAChD;iBACF;aACF;SACF;QAED,OAAO,MAAyB,CAAC;IACnC;;IC7EA;;;;;;;;;;;;;;;;IAqBA;;;aAGgB,qBAAqB,CAAC,EAAwB;QAE5D,OAAO,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK;YAC1B,MAAM,SAAS,GACXN,OAAI,CAAC,sBAAsB,CAAC,KAAwB,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;YACzE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBACtC,SAAS,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;aACrC;YACD,OAAO,SAAS,CAAC;SAClB,CAAC;IACJ;;IClCA;;;;;;;;;;;;;;;;IAsBO,MAAM,QAAQ,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;;ICtBpE;;;;;;;;;;;;;;;;aAmBgBmB,YAAU,CACtB,MAAqD,EAAE,QAAkB,EACzE,KAAe,EAAE,YAAqB;QACxC,MAAM,OAAO,GAAGnB,OAAI,CAAC,iBAAiB,CAAC,KAAK,EAAEA,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,CAAC;QAE5E,IAAI,YAAY,IAAI,KAAK,KAAK,QAAQ,EAAE;;YAEtC,IAAI,MAAM,GAAG,CAAC,CAAC;YACf,MAAM,CAAC,OAAO,CAAC,KAAK;gBAClB,MAAM,IAAI,GAAGA,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;gBAE5C,OAAsB,CAAC,GAAG,CAAC,KAAK,CAAC,IAAkB,EAAE,MAAM,CAAC,CAAC;gBAC9D,MAAM,IAAI,IAAI,CAAC;aAChB,CAAC,CAAC;SACJ;aAAM;YACL,IAAI,SAAS,GAAG,CAAC,CAAC;YAElB,MAAM,CAAC,OAAO,CAAC,KAAK;gBAClB,MAAM,WAAW,GAAG,KAAK,KAAK,QAAQ;oBAClCD,eAAY,CAAC,sBAAsB,CAAC,KAAK,CAAC,IAAoB,CAAC;oBAC/D,KAAK,CAAC,IAAkB,CAAC;gBAE7B,IAAI,IAAI,GAAG,CAAC,CAAC;gBAEb,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,GAAG,EAAE;oBAC7C,MAAM,MAAM,GAAG,GAAG,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC;oBAC7C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,GAAG,EAAE;wBAC7C,OAAO,CAAC,MAAM,GAAG,GAAG,CAAC,GAAG,WAAW,CAAC,IAAI,EAAE,CAAC,CAAC;qBAC7C;iBACF;gBAED,SAAS,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;aAC7B,CAAC,CAAC;SACJ;QAED,OAAO,OAAO,CAAC;IACjB;;ICvDA;;;;;;;;;;;;;;;;IAsBO,MAAM,SAAS,GAClB,4BAA4B,CAAC,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;;ICvB7E;;;;;;;;;;;;;;;;IAsBO,MAAM,OAAO,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;;ICtBlE;;;;;;;;;;;;;;;;IAsBO,MAAM,SAAS,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;;ICtBtE;;;;;;;;;;;;;;;;IAsBO,MAAM,SAAS,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;;ICtBtE;;;;;;;;;;;;;;;;aAmBgB,YAAY,CACxB,WAAuB,EAAE,SAA0B,EAAE,KAAe,EACpE,SAAiB,EAAE,SAAiB,EAAE,SAAiB,EAAE,OAAiB,EAC1E,WAAqB,EAAE,UAAkB;QAC3C,MAAM,MAAM,GAAGO,SAAM,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,EAAE,KAAK,CAAC,CAAC;QAErD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;YAClC,MAAM,KAAK,GAAG,EAAE,CAAC;YACjB,IAAI,YAAY,GAAG,CAAC,CAAC;YACrB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,MAAM,GAAG,GAAG,WAAW,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC;gBAC3C,YAAY,IAAI,GAAG,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;gBACjC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;aACjB;YACD,IAAI,YAAY,GAAG,CAAC,IAAI,YAAY,IAAI,UAAU,GAAG,SAAS,EAAE;gBAC9D,MAAM,IAAI,KAAK,CACX,oBAAoB,KAAK,wBAAwB,WAAW,EAAE,CAAC,CAAC;aACrE;YAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC;oBAC5B,SAAS,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,UAAU,CAAC,YAAY,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC;aAC1E;SACF;QAED,OAAO,MAAyB,CAAC;IACnC;;IC7CA;;;;;;;;;;;;;;;;aAmBgB,YAAY,CACxB,IAAwB,EAAE,UAA8B,EACxD,kBAA4B;QAC9B,MAAM,MAAM,GAAGA,SAAM,CAAC,kBAAkB,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;QACtD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;YACpC,MAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEpC,MAAM,WAAW,GAAa,MAAM,CAAC,KAAK,EAAE,CAAC;YAC7C,MAAM,QAAQ,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YAChC,MAAM,UAAU,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YAClC,MAAM,YAAY,GAAG,UAAU,CAAC,UAAU,CAAC,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC,CAAC;YACnE,WAAW,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,MAAM,CAAC,YAAY,CAAW,CAAC;YAE3D,MAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,CAAC;YAEnD,IAAI,CAAC,IAAI,aAAa,IAAI,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE;gBAC5D,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;aAC/C;SACF;QAED,OAAO,MAA4B,CAAC;IACtC;;ICxCA;;;;;;;;;;;;;;;;IAsBO,MAAM,WAAW,GACpB,4BAA4B,CAAC,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;;ICvB3E;;;;;;;;;;;;;;;;IAsBO,MAAM,gBAAgB,GACzB,4BAA4B,CAAC,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;;ICvB5E;;;;;;;;;;;;;;;;IAsBO,MAAM,QAAQ,GACjB,4BAA4B,CAAC,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;;ICvB3E;;;;;;;;;;;;;;;;IAsBO,MAAM,aAAa,GACtB,4BAA4B,CAAC,CAAC,CAAS,EAAE,CAAS,KAAK,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;;ICvB5E;;;;;;;;;;;;;;;;aAmBgB,YAAY,CACxB,KAAa,EAAE,IAAY,EAAE,GAAW;QAC1C,MAAM,IAAI,GAAG,CAAC,IAAI,GAAG,KAAK,KAAK,GAAG,GAAG,CAAC,CAAC,CAAC;QAExC,MAAM,MAAM,GAAGN,OAAI,CAAC,mBAAmB,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;QACxD,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;QAClB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC;SAClC;QAED,OAAO,MAAM,CAAC;IAChB;;IC9BA;;;;;;;;;;;;;;;;IAsBO,MAAM,OAAO,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;;ICtBlE;;;;;;;;;;;;;;;;aAmBgB,OAAO,CACnB,KAAiB,EAAE,UAAkB,EAAE,QAAkB,EACzD,KAAe;QACjB,MAAM,IAAI,GAAGA,OAAI,CAAC,sBAAsB,CACpC,KAAwB,EAAEA,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,CAAC;QAE5D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,MAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC;YACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,MAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAChC,IAAI,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC;oBACnB,KAAK,GAAG,GAAG,EAAE;oBACf,GAAG,GAAG,KAAK,CAAC;iBACb;aACF;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;SACf;QACD,OAAO,IAAI,CAAC;IACd;;ICtCA;;;;;;;;;;;;;;;;IAsBO,MAAM,WAAW,GAAG,4BAA4B,EAClD,CAAC,MAAM,EAAE,MAAM,KAAK,IAAI,CAAC,GAAG,CAAC,MAAgB,EAAE,MAAgB,CAAC,EAAE;;ICvBvE;;;;;;;;;;;;;;;;IAsBO,MAAM,WAAW,GAAG,4BAA4B,EAClD,CAAC,MAAM,EAAE,MAAM,KAAK,IAAI,CAAC,GAAG,CAAC,MAAgB,EAAE,MAAgB,CAAC,EAAE;;ICvBvE;;;;;;;;;;;;;;;;IAqBO,MAAM,YAAY,GAAG,4BAA4B,EACnD,CAAC,MAAc,EAAE,MAAc,KAAK,MAAM,GAAG,MAAM,EAAE;;ICtB1D;;;;;;;;;;;;;;;;aAuBgB,OAAO,CAAC,KAAiB,EAAE,MAAgB,EAAE,MAAgB;QAE3E,MAAM,QAAQ,GACVA,OAAI,CAAC,iBAAiB,CAAC,CAAC,CAAoB,EAAE,MAAM,CAAe,CAAC;QACxE,OAAO,YAAY,CAAC,EAAE,EAAE,MAAM,EAAE,QAAQ,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IAC3D;;IC5BA;;;;;;;;;;;;;;;;IAsBO,MAAM,YAAY,GACrB,4BAA4B,EAAE,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE;;ICvB/D;;;;;;;;;;;;;;;;aAoBgB,aAAa,CACzB,KAAiB,EAAE,MAAgB,EAAE,KAAe,EAAE,IAAc,EACpE,QAAkB;QACpB,MAAM,KAAK,GAAG,MAAM,CAAC,MAAM,CAAC;QAC5B,MAAM,KAAK,GAAGA,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QACzC,MAAM,QAAQ,GAAGA,OAAI,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;QAC7C,MAAM,UAAU,GAAGA,OAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAC;QAEjD,MAAM,MAAM,GAAGA,OAAI,CAAC,sBAAsB,CACtC,KAAwB,EAAEA,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,CAAC;QAE5D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,EAAE,CAAC,EAAE;YAC9B,MAAM,GAAG,GAAGA,OAAI,CAAC,UAAU,CAAC,CAAC,EAAE,KAAK,EAAE,QAAQ,CAAC,CAAC;;YAGhD,MAAM,MAAM,GAAa,IAAI,KAAK,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC/C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBACtC,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;aAC1B;YAED,MAAM,QAAQ,GAAGA,OAAI,CAAC,UAAU,CAAC,MAAM,EAAE,KAAK,EAAE,UAAU,CAAC,CAAC;YAC5D,MAAM,CAAC,QAAQ,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;SAC7B;QACD,OAAO,MAAM,CAAC;IAChB;;IC5CA;;;;;;;;;;;;;;;;aAuBgB,QAAQ,CACpB,MAAgB,EAAE,MAAgB,EAAE,KAAiB,EACrD,aAAuB;QAEzB,MAAM,CAAC,QAAQ,EAAE,WAAW,CAAC,GACzBD,eAAY,CAAC,yBAAyB,CAAC,MAAM,EAAE,aAAa,CAAC,CAAC;QAClE,MAAM,QAAQ,GAAGmB,aAAU,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;QAC7C,MAAM,OAAO,GAAGlB,OAAI,CAAC,mBAAmB,CACpBA,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,EAAE,QAAQ,CAAe,CAAC;QAC1E,MAAM,UAAU,GAAGA,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QAEnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACvC,MAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,IAAI,GAAG,CAAC,CAAC;YACb,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,IAAI,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;aAC3B;YACD,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;SACnB;QAED,OAAO,EAAC,OAAO,EAAE,QAAQ,EAAE,QAAQ,EAAC,CAAC;IACvC;;IC5CA;;;;;;;;;;;;;;;;IAmBA,SAAS,eAAe,CACpB,OAAmB,EAAE,YAAsB,EAAE,SAAiB;QAChE,OAAO,CAAC,OAAO,CAAC,CAAC,KAAa,EAAE,CAAS;YACvC,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,SAAS,EAAE;gBACnC,MAAM,SAAS,GACXA,OAAI,CAAC,UAAU,CACP,CAAC,EAAE,YAAY,CAAC,MAAM,EAAEA,OAAI,CAAC,cAAc,CAAC,YAAY,CAAC,CAAC;qBAC7D,IAAI,CAAC,GAAG,CAAC,CAAC;gBACnB,MAAM,IAAI,KAAK,CACX,WAAW,SAAS,OAAO,KAAK,kBAAkB,SAAS,GAAG,CAAC,CAAC;aACrE;SACF,CAAC,CAAC;IACL,CAAC;IAED,SAAS,cAAc,CACnB,kBAAgC,EAAE,oBAA4B;;QAEhE,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,kBAAkB,CAAC,MAAM,EAAE,EAAE,GAAG,EAAE;YACxD,MAAM,MAAM,GAAG,kBAAkB,CAAC,GAAG,CAAC,CAAC;YACvC,MAAM,SAAS,GAAG,CAAC,GAAG,KAAK,kBAAkB,CAAC,MAAM,GAAG,CAAC;gBACpD,oBAAoB;gBACpB,kBAAkB,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;YACvC,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,MAAM,IAAI,KAAK,CAAC,gCAAgC,CAAC,CAAC;aACnD;YACD,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBACjB,MAAM,IAAI,KAAK,CAAC,oCAAoC,CAAC,CAAC;aACvD;YACD,IAAI,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,SAAS,EAAE;gBACzC,MAAM,IAAI,KAAK,CAAC,0CAA0C,CAAC,CAAC;aAC7D;YACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBACtC,IAAI,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,EAAE;oBAC7B,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;iBACpE;aACF;SACF;IACH,CAAC;IAED;IACA;IACA;IACA;IACA,SAAS,UAAU,CACf,OAAmB,EAAE,YAAsB,EAC3C,kBAAgC,EAAE,oBAA4B;QAChE,MAAM,WAAW,GAA4B,EAAE,CAAC;QAChD,IAAI,SAAS,GAAG,CAAC,CAAC;QAElB,MAAM,SAAS,GAAG,YAAY,CAAC,MAAM,GAAG,CAAC,GAAG,kBAAkB,CAAC,MAAM,CAAC;QACtE,MAAM,SAAS,GAAG,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;QAEjE,cAAc,CAAC,kBAAkB,EAAE,oBAAoB,CAAC,CAAC;;;;;;;;QASzD,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,YAAY,CAAC,MAAM,GAAG,CAAC,EAAE,EAAE,GAAG,EAAE;YACtD,KAAK,IAAI,YAAY,CAAC,GAAG,CAAC,CAAC;YAC3B,MAAM,SAAS,GAAG,YAAY,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;YACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;gBAClC,SAAS,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC;aACpC;SACF;;;;;;;;;;QAWD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACvC,IAAI,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;YACvB,IAAI,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;;YAG3B,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,kBAAkB,CAAC,MAAM,EAAE,EAAE,GAAG,EAAE;gBACxD,MAAM,MAAM,GAAG,kBAAkB,CAAC,GAAG,CAAC,CAAC;gBACvC,MAAM,MAAM,GAAG,GAAG,GAAG,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC;gBAC7C,IAAI,MAAM,IAAI,CAAC,EAAE;oBACf,MAAM,eAAe,GAAG,SAAS,CAAC,MAAM,CAAC,CAAC;oBAC1C,MAAM,KAAK,GACP,eAAe,CAAC,eAAe,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;oBAChE,KAAK,IAAI,CAAC,GAAG,KAAK,EAAE,CAAC,GAAG,KAAK,EAAE,EAAE,CAAC,EAAE;wBAClC,SAAS,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC;qBAC/C;iBACF;gBACD,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;gBACtB,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;aACvB;YACD,IAAI,KAAK,KAAK,KAAK,EAAE;gBACnB,WAAW,CAAC,IAAI,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;gBACjC,SAAS,IAAI,KAAK,GAAG,KAAK,CAAC;aAC5B;SACF;QAED,OAAO,EAAC,SAAS,EAAE,WAAW,EAAE,SAAS,EAAC,CAAC;IAC7C,CAAC;IAED,SAAS,SAAS,CAAC,SAAqB;QACtC,MAAM,SAAS,GAAiB,EAAE,CAAC;QACnC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACzC,MAAM,SAAS,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;YACtC,MAAM,MAAM,GAAGA,OAAI,CAAC,iBAAiB,CAAC,OAAO,EAAE,SAAS,CAAe,CAAC;YACxE,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAEvB,SAAS,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,CAAS,KAAK,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC;SAC/D;QAED,OAAO,SAAS,CAAC;IACnB,CAAC;IAED,SAAS,oBAAoB,CAAC,IAAc,EAAE,UAAkB;QAC9D,MAAM,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC;QAC1C,OAAO,OAAO,CAAC,MAAM,GAAG,UAAU,EAAE;YAClC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACjB;QAED,KAAK,IAAI,KAAK,GAAG,UAAU,EAAE,KAAK,GAAG,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,EAAE;YACzD,OAAO,CAAC,UAAU,GAAG,CAAC,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,CAAC;SACxC;QAED,OAAO,OAAO,CAAC;IACjB,CAAC;IACD;IACA;IACA;IACA,SAAS,gBAAgB,CACrB,iBAA6B,EAAE,sBAAgC,EAC/D,WAAoC,EAAE,SAAiB,EAAE,MAAkB,EAC3E,WAAqB;QACvB,MAAM,MAAM,GAAG,oBAAoB,CAAC,sBAAsB,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAClE,MAAM,OAAO,GAAG,oBAAoB,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAExD,IAAI,MAAM,GAAG,CAAC,CAAC;QACf,KAAK,MAAM,KAAK,IAAI,WAAW,EAAE;YAC/B,KAAK,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;gBACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;oBAClC,MAAM,CAAC,MAAM,GAAG,OAAO,GAAG,CAAC,CAAC,GAAG,iBAAiB,CAAC,CAAC,GAAG,MAAM,GAAG,CAAC,CAAC,CAAC;iBAClE;gBACD,EAAE,MAAM,CAAC;aACV;SACF;IACH,CAAC;IAED,SAAS,SAAS,CACd,iBAA6B,EAAE,sBAAgC,EAC/D,sBAAgC,EAAE,WAAoC,EACtE,SAAiB;QACnB,MAAM,WAAW,GAAG,sBAAsB,CAAC,KAAK,EAAE,CAAC;QACnD,WAAW,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC;QAE3B,MAAM,SAAS,GAAGA,OAAI,CAAC,iBAAiB,CAClB,sBAAsB,EACtBA,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAe,CAAC;QAErE,MAAM,WAAW,GAAG,iBAAiB,CAAC,MAAM,CAAC;QAC7C,MAAM,SAAS,GACX,WAAW,KAAK,CAAC,GAAG,CAAC,IAAI,WAAW,GAAG,sBAAsB,CAAC,CAAC,CAAC,CAAC,CAAC;QACtE,gBAAgB,CACZ,iBAAiB,EAAE,sBAAsB,EAAE,WAAW,EAAE,SAAS,EACjE,SAAS,EAAE,WAAW,CAAC,CAAC;QAE5B,OAAO,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC;IAClC,CAAC;aACe,gBAAgB,CAC5B,kBAAgC,EAAE,wBAAoC,EACtE,iBAA6B,EAAE,sBAAgC,EAC/D,sBAAgC,EAAE,OAAmB,EACrD,YAAsB,EACtB,gBAAwB;QAC1B,IAAI,kBAAkB,CAAC,MAAM,KAAK,CAAC,EAAE;YACnC,MAAM,IAAI,KAAK,CAAC,sCAAsC,CAAC,CAAC;SACzD;QAED,IAAI,wBAAwB,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YAC5C,MAAM,IAAI,KAAK,CAAC,mCAAmC,CAAC,CAAC;SACtD;QACD,MAAM,SAAS,GAAG,wBAAwB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACrD,eAAe,CAAC,OAAO,EAAE,YAAY,EAAE,SAAS,CAAC,CAAC;QAElD,IAAI,sBAAsB,CAAC,MAAM,KAAK,CAAC,EAAE;YACvC,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;SAChD;QACD,MAAM,oBAAoB,GAAG,sBAAsB,CAAC,CAAC,CAAC,CAAC;;;QAIvD,MAAM,EAAC,SAAS,EAAE,WAAW,EAAE,SAAS,EAAC,GAAG,UAAU,CAClD,OAAO,EAAE,YAAY,EAAE,kBAAkB,EAAE,oBAAoB,CAAC,CAAC;;QAGrE,MAAM,kBAAkB,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC;QAChD,MAAM,iBAAiB,GAAG,SAAS,CAC/B,iBAAiB,EAAE,sBAAsB,EAAE,sBAAsB,EACjE,WAAW,EAAE,SAAS,CAAC,CAAC;QAE5B,OAAO,CAAC,kBAAkB,EAAE,iBAAiB,CAAC,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1E;;ICjOA;;;;;;;;;;;;;;;;IAmBA,IAAO,gBAAgB,GAAGD,eAAY,CAAC,gBAAgB,CAAC;IACxD;IACA;IACA,MAAM,sBAAsB;QAG1B,YACY,KAAiB,EAAU,UAAoB,EAC/C,MAAkB,EAAU,WAAqB,EACjD,WAAqB,EAAU,YAAwB,EACvD,iBAA2B,EAClB,kBAAgC,EAChC,wBAAoC,EACrD,uBAAiC;YANzB,UAAK,GAAL,KAAK,CAAY;YAAU,eAAU,GAAV,UAAU,CAAU;YAC/C,WAAM,GAAN,MAAM,CAAY;YAAU,gBAAW,GAAX,WAAW,CAAU;YACjD,gBAAW,GAAX,WAAW,CAAU;YAAU,iBAAY,GAAZ,YAAY,CAAY;YACvD,sBAAiB,GAAjB,iBAAiB,CAAU;YAClB,uBAAkB,GAAlB,kBAAkB,CAAc;YAChC,6BAAwB,GAAxB,wBAAwB,CAAY;YAEvD,IAAI,CAAC,iBAAiB;gBAClBA,eAAY,CAAC,0BAA0B,CAAC,uBAAuB,CAAC,CAAC;YACrE,IAAI,CAAC,UAAU,GAAGA,eAAY,CAAC,aAAa,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;SACtE;QAEO,8BAA8B,CAAC,SAAiB;YACtD,IAAI,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,KAAK,gBAAgB,CAAC,cAAc,EAAE;gBACjE,OAAO,IAAI,CAAC,iBAAiB,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;aAC9C;iBAAM;gBACL,OAAO,IAAI,CAAC,iBAAiB,CAAC,SAAS,CAAC,CAAC;aAC1C;SACF;;QAGO,qBAAqB,CAAC,SAAiB;YAC7C,IAAI,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,KAAK,gBAAgB,CAAC,cAAc,EAAE;gBACjE,OAAO,IAAI,CAAC,kBAAkB,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;aAC/C;iBAAM;gBACL,OAAO,IAAI,CAAC,kBAAkB,CAAC,SAAS,CAAC,CAAC;aAC3C;SACF;QAEO,WAAW,CAAC,SAAiB;YACnC,MAAM,kBAAkB,GAAG,IAAI,CAAC,qBAAqB,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YACrE,QAAQ,IAAI,CAAC,8BAA8B,CAAC,SAAS,GAAG,CAAC,CAAC;gBACxD,KAAK,gBAAgB,CAAC,YAAY;oBAChC,OAAO,sBAAsB,CAAC,qBAAqB,CAAC,kBAAkB,CAAC,CAAC;gBAC1E,KAAK,gBAAgB,CAAC,UAAU;oBAC9B,OAAO,sBAAsB,CAAC,mBAAmB,CAAC,kBAAkB,CAAC,CAAC;gBACxE;oBACE,MAAM,IAAI,KAAK,CAAC,gCACZ,gBAAgB,CAAC,IAAI,CAAC,8BAA8B,CAChD,SAAS,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;aAC9B;SACF;QAED,OAAO,mBAAmB,CAAC,QAAoB;YAC7C,MAAM,YAAY,GAAG,QAAQ,CAAC,MAAM,CAAC;YACrC,IAAI,YAAY,KAAK,CAAC,IAAI,YAAY,KAAK,CAAC,EAAE;gBAC5C,OAAO,CAAC,CAAC;aACV;YACD,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;gBACzC,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;gBACnD,IAAI,YAAY,GAAG,QAAQ,EAAE;oBAC3B,QAAQ,GAAG,YAAY,CAAC;iBACzB;aACF;YACD,OAAO,QAAQ,CAAC;SACjB;QAED,OAAO,qBAAqB,CAAC,WAAuB;YAClD,MAAM,WAAW,GAAG,WAAW,CAAC,MAAM,CAAC;YACvC,IAAI,WAAW,KAAK,CAAC,EAAE;gBACrB,OAAO,CAAC,CAAC;aACV;YACD,IAAI,eAAe,GAAG,CAAC,CAAC;YACxB,IAAI,oBAAoB,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YAC1C,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,EAAE,CAAC,EAAE;gBACpC,MAAM,KAAK,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;gBAC7B,IAAI,KAAK,KAAK,oBAAoB,EAAE;oBAClC,oBAAoB,GAAG,KAAK,CAAC;oBAC7B,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,eAAe,EAAE,QAAQ,CAAC,CAAC;oBACnD,eAAe,GAAG,CAAC,CAAC;iBACrB;aACF;YACD,OAAO,IAAI,CAAC,GAAG,CAAC,WAAW,GAAG,eAAe,EAAE,QAAQ,CAAC,CAAC;SAC1D;QAEO,qBAAqB,CACzB,CAAa,EAAE,MAAgB,EAAE,SAAS,GAAG,IAAI;YACnD,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,IAAI,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;oBACf,OAAO,EAAE,CAAC;iBACX;gBACD,MAAM,IAAI,KAAK,CACX,gFAAgF,CAAC,CAAC;aACvF;;YAED,OAAO,SAAS,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;SAChC;QAEO,mBAAmB,CAAC,QAAgB;YAC1C,MAAM,UAAU,GAAG,IAAI,CAAC,WAAW,CAAC;YACpC,MAAM,iBAAiB,GAAG,IAAI,CAAC,iBAAiB,CAAC;YAEjDA,eAAY,CAAC,yBAAyB,CAAC,iBAAiB,EAAE,UAAU,CAAC,CAAC;YAEtE,MAAM,KAAK,GAAG,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;YACtE,MAAM,WAAW,GAAGA,eAAY,CAAC,iCAAiC,CAC9D,IAAI,CAAC,UAAU,EAAE,KAAK,EAAE,UAAU,CAAC,CAAC;YAExC,MAAM,MAAM,GAAG,WAAW,CAAC;YAE3B,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBACjB,MAAM,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;aACtB;YACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;gBACzC,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;oBACjB,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;iBACjC;aACF;YAED,OAAO,MAAM,CAAC;SACf;;;;;;;;;;;QAYO,+BAA+B,CACnC,cAAsB,EAAE,qBAA6B,EACrD,oBAA4B;YAC9B,MAAM,YAAY,GAAG,IAAI,CAAC,GAAG,CAAC,cAAc,EAAE,oBAAoB,CAAC,CAAC;YACpE,MAAM,MAAM,GAAa,EAAE,CAAC;YAC5B,IAAI,kBAAkB,GAAG,CAAC,CAAC;YAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAC3B,EAAE,CAAC,EAAE,kBAAkB,IAAI,qBAAqB,EAAE;gBACrD,MAAM,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;aACjC;YACD,KAAK,IAAI,CAAC,GAAG,YAAY,EAAE,CAAC,GAAG,cAAc,EAAE,EAAE,CAAC,EAAE;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;aACjB;YACDC,OAAI,CAAC,MAAM,CACP,MAAM,CAAC,MAAM,KAAK,cAAc,EAChC,MAAM,yDAAyD,CAAC,CAAC;YAErE,OAAO,MAAM,CAAC;SACf;QAEO,4BAA4B,CAChC,QAAoB,EAAE,iBAA2B,EACjD,qBAA6B,EAAE,UAAkB;YACnD,MAAM,YAAY,GAAG,QAAQ,CAAC,MAAM,CAAC;YACrC,MAAM,MAAM,GAAa,EAAE,CAAC;YAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;gBACzC,MAAM,SAAS,GAAG,QAAQ,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;gBAChD,IAAI,UAAU,GAAG,IAAI,CAAC,GAAG,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC;gBACjD,IAAI,wBAAwB,GAAG,iBAAiB,CAAC,CAAC,CAAC,CAAC;gBAEpD,IAAI,wBAAwB,KAAK,CAAC,CAAC,EAAE;oBACnC,UAAU,GAAG,CAAC,CAAC;iBAChB;gBACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;oBACnC,MAAM,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;oBACtC,wBAAwB,IAAI,qBAAqB,CAAC;iBACnD;gBACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;oBAC/C,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;iBACjB;aACF;YACD,IAAI,YAAY,GAAG,CAAC,IAAI,MAAM,CAAC,MAAM,KAAK,QAAQ,CAAC,YAAY,GAAG,CAAC,CAAC,EAAE;gBACpE,MAAM,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC;aAC5C;YAED,OAAO,MAAM,CAAC;SACf;;;;;;;;;;;;;;;;;;;;;;QAuBO,8BAA8B,CAClC,WAAuB,EAAE,iBAA2B,EACpD,qBAA6B,EAAE,UAAkB;YACnD,MAAM,SAAS,GAAG,WAAW,CAAC,MAAM,CAAC;YACrC,MAAM,MAAM,GAAa,EAAE,CAAC;YAC5B,IAAI,SAAS,KAAK,CAAC,EAAE;gBACnB,OAAO,EAAE,CAAC;aACX;YAED,IAAI,mBAAmB,GAAG,CAAC,CAAC;YAC5B,IAAI,iBAAiB,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YAEvC,IAAI,iBAAiB,IAAI,iBAAiB,CAAC,MAAM,EAAE;gBACjD,MAAM,IAAI,KAAK,CACX,yBAAyB,iBAAiB,4BACtC,iBAAiB,CAAC,MAAM,EAAE,CAAC,CAAC;aACrC;YAED,IAAI,kBAAkB,GAAG,iBAAiB,CAAC,iBAAiB,CAAC,CAAC;YAC9D,MAAM,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;YAChC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;gBAClC,MAAM,cAAc,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;gBACtC,IAAI,cAAc,KAAK,iBAAiB,EAAE;oBACxC,IAAI,kBAAkB,IAAI,CAAC,EAAE;wBAC3B,EAAE,mBAAmB,CAAC;wBACtB,IAAI,mBAAmB,GAAG,UAAU,EAAE;4BACpC,kBAAkB,IAAI,qBAAqB,CAAC;yBAC7C;6BAAM;4BACL,kBAAkB,GAAG,CAAC,CAAC,CAAC;yBACzB;qBACF;iBACF;qBAAM;oBACL,mBAAmB,GAAG,CAAC,CAAC;oBACxB,iBAAiB,GAAG,cAAc,CAAC;oBAEnC,IAAI,cAAc,IAAI,iBAAiB,CAAC,MAAM,EAAE;wBAC9C,MAAM,IAAI,KAAK,CACX,sBAAsB,cAAc,2BAChC,iBAAiB,CAAC,MAAM,EAAE,CAAC,CAAC;qBACrC;oBAED,kBAAkB,GAAG,iBAAiB,CAAC,cAAc,CAAC,CAAC;iBACxD;gBACD,MAAM,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;aACjC;YAED,IAAI,MAAM,CAAC,MAAM,KAAK,WAAW,CAAC,MAAM,EAAE;gBACxC,MAAM,IAAI,KAAK,CAAC,kBAAkB,CAAC,CAAC;aACrC;YAED,OAAO,MAAM,CAAC;SACf;QAEO,oBAAoB,CACxB,SAAiB,EAAE,iBAA2B,EAC9C,qBAA6B,EAAE,UAAkB;YACnD,MAAM,kBAAkB,GAAG,IAAI,CAAC,qBAAqB,CAAC,SAAS,CAAC,CAAC;YACjE,MAAM,aAAa,GAAG,IAAI,CAAC,8BAA8B,CAAC,SAAS,CAAC,CAAC;YACrE,QAAQ,aAAa;gBACnB,KAAK,gBAAgB,CAAC,YAAY;oBAChC,OAAO,IAAI,CAAC,8BAA8B,CACtC,kBAAkB,EAAE,iBAAiB,EAAE,qBAAqB,EAC5D,UAAU,CAAC,CAAC;gBAClB,KAAK,gBAAgB,CAAC,UAAU;oBAC9B,IAAI,kBAAkB,CAAC,MAAM,GAAG,CAAC,GAAG,iBAAiB,CAAC,MAAM,EAAE;wBAC5D,MAAM,IAAI,KAAK,CAAC,mDACZ,kBAAkB,CAAC,MAAM,GAAG,CAAC,MAAM,iBAAiB,CAAC,MAAM,EAAE,CAAC,CAAC;qBACpE;oBACD,OAAO,IAAI,CAAC,4BAA4B,CACpC,kBAAkB,EAAE,iBAAiB,EAAE,qBAAqB,EAC5D,UAAU,CAAC,CAAC;gBAClB;oBACE,MAAM,IAAI,KAAK,CACX,+BAA+B,gBAAgB,CAAC,aAAa,CAAC,EAAE,CAAC,CAAC;aACzE;SACF;QAEO,qBAAqB;YAC3B,MAAM,oBAAoB,GAAG,IAAI,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC;YACxD,IAAI,IAAI,CAAC,iBAAiB,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvC,MAAM,IAAI,KAAK,CAAC,+BAA+B,CAAC,CAAC;aAClD;YACD,MAAM,kBAAkB,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;YACrD,QAAQ,kBAAkB;gBACxB,KAAK,gBAAgB,CAAC,cAAc;oBAClC,OAAO,oBAAoB,CAAC,CAAC,CAAC,CAAC;gBACjC,KAAK,gBAAgB,CAAC,YAAY;oBAChC,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;gBACpE,KAAK,gBAAgB,CAAC,UAAU;oBAC9B,OAAO,IAAI,CAAC,wBAAwB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;gBACjD;oBACE,MAAM,IAAI,KAAK,CACX,sBAAsB,gBAAgB,CAAC,kBAAkB,CAAC,EAAE,CAAC,CAAC;aACrE;SACF;QAED,OAAO;YACL,MAAM,oBAAoB,GAAG,IAAI,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC;YACxD,IAAI,oBAAoB,CAAC,MAAM,IAAI,CAAC,EAAE;gBACpC,MAAM,IAAI,KAAK,CACX,iCAAiC;oBACjC,uCAAuC,CAAC,CAAC;aAC9C;YACD,MAAM,cAAc,GAAG,IAAI,CAAC,qBAAqB,EAAE,CAAC;YACpD,MAAM,UAAU,GAAG,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAC;YAC5D,MAAM,UAAU,GAAa,IAAI,KAAK,CAAC,IAAI,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC;YAE5D,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YACtC,KAAK,IAAI,CAAC,GAAG,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,EAAE,CAAC,EAAE;gBAC/C,UAAU,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aACvD;;YAED,MAAM,WAAW,GAAa,SAAS,CAAC,UAAU,EAAE,KAAK,CAAC,CAAC;YAC3D,MAAM,YAAY,GACdA,OAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,WAAW,EAAEA,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAe,CAAC;YAEzE,MAAM,QAAQ,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAC/C,IAAI,QAAQ,GAAG,CAAC,EAAE;gBAChB,IAAI,WAAW,GAAG,IAAI,CAAC,+BAA+B,CAClD,cAAc,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;gBAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;oBACzC,MAAM,cAAc,GAAG,IAAI,CAAC,oBAAoB,CAC5C,CAAC,GAAG,CAAC,EAAE,WAAW,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;oBACtD,WAAW,GAAG,cAAc,CAAC;iBAC9B;gBAED,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,UAAU,EAAE,WAAW,EAAE,YAAY,EAAE,WAAW,CAAC,CAAC;aACzE;YAED,OAAO,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;SACpC;QACD,SAAS,CACL,UAAkB,EAAE,WAAqB,EAAE,YAAwB,EACnE,WAAqB;YACvB,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,OAAO;aACR;YAED,MAAM,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC;YAC/B,MAAM,UAAU,GAAG,YAAY,CAAC;YAEhC,IAAI,YAAY,GAAG,WAAW,CAAC,KAAK,EAAE,CAAC;YACvC,YAAY,GAAG,YAAY,CAAC,KAAK,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC;YAClD,MAAM,gBAAgB,GAAGA,OAAI,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;YAC1D,MAAM,eAAe,GAAG,WAAW,CAAC,MAAM,CAAC;;;YAI3C,IAAI,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC;YACrC,IAAI,YAAY,CAAC,MAAM,KAAK,gBAAgB,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE;gBACzE,MAAM,QAAQ,GAAG,IAAI,CAAC,iBAAiB,CAAC;gBACxCoB,OAAI,CAAC;oBACH,MAAM,kBAAkB,GAAGC,UAAO,CAAC,YAAY,EAAE,QAAQ,CAAC,CAAC;oBAC3D,MAAM,YAAY,GAAGC,cAAW,CAAC,kBAAkB,EAAE,YAAY,CAAC,CAAC;oBACnE,YAAY,GAAG,YAAY,CAAC,QAAQ,EAAE,CAAC;iBACxC,CAAC,CAAC;aACJ;;;;YAKD,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,IAAI,MAAM,GAAG,CAAC,CAAC;YACf,KAAK,IAAI,IAAI,GAAG,CAAC,EAAE,IAAI,IAAI,eAAe,EAAE,EAAE,IAAI,EAAE;;gBAElD,IAAI,IAAI,GAAG,IAAI,GAAG,eAAe,GAAG,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;;;gBAI3D,IAAI,IAAI,KAAK,MAAM,EAAE;oBACnB,EAAE,MAAM,CAAC;oBACT,SAAS;iBACV;;;;;gBAMD,IAAI,QAAQ,GAAG,MAAM,EAAE;;oBAErB,MAAM,GAAG,GAAG,UAAU,CAAC,QAAQ,CAAC,QAAQ,GAAG,gBAAgB,CAAC,CAAC;oBAC7D,MAAM,GAAG,GAAG,UAAU,CAAC,QAAQ,CAAC,QAAQ,GAAG,gBAAgB,CAAC,CAAC;oBAC7D,MAAM,KAAK,GAAG,CAAC,MAAM,GAAG,QAAQ,IAAI,gBAAgB,CAAC;oBACrD,SAAS,CAAC,GAAG,EAAE,GAAG,EAAE,KAAK,CAAC,CAAC;iBAC5B;;gBAGD,IAAI,IAAI,IAAI,eAAe,EAAE;;oBAE3B,MAAM,UAAU,GAAG,YAAY,CAAC,MAAM,CAAC;oBACvC,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,gBAAgB,CAAC,CAAC;iBAClD;gBACD,IAAI,IAAI,GAAG,MAAM,EAAE;oBACjB,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE;wBAClC,UAAU;6BACL,QAAQ,CAAC,MAAM,GAAG,gBAAgB,EAAE,IAAI,GAAG,gBAAgB,CAAC;6BAC5D,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;wBAChC,MAAM,GAAG,IAAI,CAAC;qBACf;yBAAM;wBACL,OAAO,IAAI,GAAG,MAAM,EAAE;4BACpB,MAAM,GAAG,GAAG,UAAU,CAAC,KAAK,CAAC,MAAM,GAAG,gBAAgB,CAAC,CAAC;4BACxD,SAAS,CAAC,GAAG,EAAE,YAAY,EAAE,gBAAgB,CAAC,CAAC;4BAC/C,EAAE,MAAM,CAAC;yBACV;qBACF;iBACF;;gBAGD,IAAI,IAAI,GAAG,CAAC,EAAE;;oBAEZ,QAAQ,GAAG,IAAI,GAAG,CAAC,CAAC;oBACpB,QAAQ,GAAG,MAAM,CAAC;iBACnB;qBAAM;;oBAEL,QAAQ,GAAG,IAAI,CAAC;oBAChB,QAAQ,GAAG,MAAM,CAAC;oBAClB,MAAM,GAAG,QAAQ,GAAG,CAAC,CAAC;iBACvB;aACF;SACF;KACF;IAED,SAAS,SAAS,CAAC,GAAe,EAAE,GAAe,EAAE,IAAY;QAC/D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;YAC7B,GAAG,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC;SACjB;IACH,CAAC;IAED,SAAS,SAAS,CAAC,KAA0B,EAAE,SAAkB;QAC/D,MAAM,GAAG,GAAa,EAAE,CAAC;QACzB,KAAK,IAAI,GAAG,IAAI,KAAK,EAAE;YACrB,IAAI,GAAG,GAAG,CAAC,EAAE;gBACX,IAAI,CAAC,SAAS,EAAE;oBACd,MAAM,IAAI,KAAK,CAAC,aAAa,GAAG,eAAe,CAAC,CAAC;iBAClD;gBACD,IAAI,GAAG,GAAG,CAAC,CAAC,EAAE;oBACZ,MAAM,IAAI,KAAK,CAAC,aAAa,GAAG,gBAAgB,CAAC,CAAC;iBACnD;gBACD,GAAG,GAAG,CAAC,CAAC,CAAC;aACV;YACD,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;SACf;QAED,OAAO,GAAG,CAAC;IACb,CAAC;aAEe,wBAAwB,CACpC,KAAiB,EAAE,WAAqB,EAAE,MAAkB,EAC5D,WAAqB,EAAE,WAAqB,EAAE,YAAwB,EACtE,iBAA2B,EAAE,kBAAgC,EAC7D,wBAAoC,EACpC,iBAA2B;QAC7B,OAAO,IAAI,sBAAsB,CACtB,KAAK,EAAE,WAAW,EAAE,MAAM,EAAE,WAAW,EAAE,WAAW,EAAE,YAAY,EAClE,iBAAiB,EAAE,kBAAkB,EAAE,wBAAwB,EAC/D,iBAAiB,CAAC;aACxB,OAAO,EAAE,CAAC;IACjB;;IC9dA;;;;;;;;;;;;;;;;aAmBgB,SAAS,CACrB,KAAa,EAAE,IAAY,EAAE,IAAY,EACzC,KAAwB;QAC1B,MAAM,aAAa,GAAG,KAAK,KAAK,IAAI,CAAC;QACrC,MAAM,2BAA2B,GAAG,KAAK,GAAG,IAAI,IAAI,IAAI,GAAG,CAAC,CAAC;QAC7D,MAAM,2BAA2B,GAAG,IAAI,GAAG,KAAK,IAAI,IAAI,GAAG,CAAC,CAAC;QAE7D,IAAI,aAAa,IAAI,2BAA2B;YAC5C,2BAA2B,EAAE;YAC/B,OAAOtB,OAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;SAC3C;QAED,MAAM,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,GAAG,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC;QAC/D,MAAM,MAAM,GAAGA,OAAI,CAAC,mBAAmB,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;QAE5D,IAAI,IAAI,GAAG,KAAK,IAAI,IAAI,KAAK,CAAC,EAAE;;;YAG9B,IAAI,GAAG,CAAC,CAAC,CAAC;SACX;QAED,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;QAClB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC;SAClC;QACD,OAAO,MAAM,CAAC;IAChB;;IC7CA;;;;;;;;;;;;;;;;IAsBO,MAAM,SAAS,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;;ICtBzE;;;;;;;;;;;;;;;;aA0BA,WAAW,CACP,OAAiC,EAAE,OAA2B,EAC9D,KAAe,EAAE,UAAkB,EAAE,SAAiB,EAAE,UAAkB,EAC1E,SAAiB,EAAE,OAAiB,EAAE,YAAoC,EAC1E,cAAuB;QACzB,MAAM,YAAY,GAAG,CAAC,UAAU,GAAG,SAAS,EAAE,SAAS,CAAC,CAAC;QAEzD,MAAM,WAAW,GAAG,OAAO,CAAC,MAAoB,CAAC;QACjD,MAAM,WAAW,GAAG,OAAO,CAAC,MAAM,CAAC;QAEnC,IAAI,UAAU,KAAK,CAAC,EAAE;YACpB,OAAOM,SAAM,CAAC,KAAoB,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC;SACpD;QAED,MAAM,MAAM,GAAGA,SAAM,CAAC,YAAY,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC;QACnD,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE;YACnC,MAAM,CAAC,MAAmB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;SAChD;aAAM,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE;YAC1C,MAAM,CAAC,MAAqB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;SAClD;aAAM,IAAI,OAAO,YAAY,KAAK,SAAS,EAAE;YAC3C,MAAM,CAAC,MAAqB,CAAC,IAAI,CAAC,CAAC,YAAY,CAAC,CAAC;SACnD;QAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,EAAE;YACnC,MAAM,KAAK,GAAG,EAAE,CAAC;YACjB,IAAI,YAAY,GAAG,CAAC,CAAC;YACrB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,MAAM,GAAG,GAAG,WAAW,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC;gBAC3C,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAChB,YAAY,IAAI,GAAG,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;aAClC;YAED,IAAI,YAAY,GAAG,CAAC,IAAI,YAAY,IAAI,UAAU,GAAG,SAAS,EAAE;gBAC9D,MAAM,IAAI,KAAK,CAAC,oBAAoB,KAAK,wBAAwB,KAAK,EAAE,CAAC,CAAC;aAC3E;YAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,IAAI,cAAc,EAAE;oBACjB,MAAM,CAAC,MAAqB,CAAC,YAAY,GAAG,SAAS,GAAG,CAAC,CAAC;wBACtD,WAA0B,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC;iBACpD;qBAAM;oBACL,MAAM,CAAC,MAAM,CAAC,YAAY,GAAG,SAAS,GAAG,CAAC,CAAC,GAAG,OAAO,CAAC,IAAI,KAAK,CAAC;wBAC5D,WAAW,CAAC,CAAC,CAAC;wBACd,WAAW,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC;iBACpC;aACF;SACF;QAED,OAAO,MAA4B,CAAC;IACtC;;IC3EA;;;;;;;;;;;;;;;;IAsBO,MAAM,WAAW,GACpB,qBAAqB,CAAC,CAAC,EAAE,KAAK,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;;ICvB1D;;;;;;;;;;;;;;;;aAsBgB,SAAS,CACrB,IAAmB,EAAE,KAAe,EAAE,IAAc,EAAE,KAAe,EACrE,KAAe;QACjB,MAAM,WAAW,GAAGiB,aAAU,CAAC,gBAAgB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;QACpE,MAAM,MAAM,GAAGvB,OAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;QACxC,MAAM,QAAQ,GAAGA,OAAI,CAAC,cAAc,CAAC,KAAK,CAAC,CAAC;QAE5C,IAAI,WAAW,EAAE;YACf,MAAM,UAAU,GAAGuB,aAAU,CAAC,iBAAiB,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;YAEjE,IAAI,KAAK,KAAK,QAAQ,EAAE;gBACtB,OAAQ,IAAqB,CAAC,KAAK,CAAC,UAAU,EAAE,UAAU,GAAG,MAAM,CAAC,CAAC;aACtE;YAED,OAAQ,IAAmB,CAAC,QAAQ,CAAC,UAAU,EAAE,UAAU,GAAG,MAAM,CAAC,CAAC;SACvE;QAED,MAAM,WAAW,GAAG,KAAK,KAAK,QAAQ;YAClCxB,eAAY,CAAC,sBAAsB,CAAC,IAAoB,CAAC;YACzD,IAAkB,CAAC;QAEvB,MAAM,KAAK,GAAGO,SAAM,CAAC,KAAK,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;QAChD,MAAM,MAAM,GAAGA,SAAM,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QACnC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;YACpC,MAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACpC,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,GAAW,EAAE,CAAC,KAAK,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAC7D,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC,EAAE,GAAG,MAAM,CAAC,CAAC;SAC5C;QAED,IAAI,KAAK,KAAK,QAAQ,EAAE;YACtB,OAAOP,eAAY,CAAC,sBAAsB,CAAC,MAAM,CAAC,MAAkB,CAAC,CAAC;SACvE;QACD,OAAO,MAAM,CAAC,MAAoB,CAAC;IACrC;;ICvDA;;;;;;;;;;;;;;;;aAmBgB,uBAAuB,CACnC,OAAmB,EAAE,YAAsB,EAAE,YAAsB,EACnE,MAAkB,EAAE,WAAqB,EAAE,UAAsB,EACjE,YAAoB;QAEtB,MAAM,YAAY,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAEhC,MAAM,iBAAiB,GAAc,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC;QAC1D,MAAM,eAAe,GAAa,IAAI,KAAK,CAAC,YAAY,CAAC,CAAC;QAE1D,MAAM,IAAI,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;QAE7B,IAAI,SAAS,KAAK,CAAC,EAAE;YACnB,IAAI,YAAY,KAAK,CAAC,EAAE;gBACtB,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,+CAA+C,CACxD,YAAY,CAAC,CAAC,CAAC;aACxB;YACD,MAAM,aAAa,GAAGC,OAAI,CAAC,iBAAiB,CAAC,YAAY,EAAE,CAAC,CAAe,CAAC;YAC5E,MAAM,YAAY,GAAGA,OAAI,CAAC,iBAAiB,CAAC,WAAW,EAAE,CAAC,CAAe,CAAC;YAC1E,OAAO;gBACL,aAAa,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,YAAY,EAAE,iBAAiB,EAAE,eAAe;aAC3E,CAAC;SACH;QAED,IAAI,cAAc,GAAG,IAAI,CAAC;QAC1B,IAAI,cAAc,GAAG,CAAC,CAAC;QACvB,MAAM,SAAS,GAAa,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAEzD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAAE,EAAE,CAAC,EAAE;;YAErC,MAAM,GAAG,GAAG,OAAO,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC;YAC9B,IAAI,GAAG,GAAG,CAAC,EAAE;gBACX,MAAM,IAAI,KAAK,CACXD,eAAY,CAAC,+CAA+C,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC;aAC3E;YACD,IAAI,GAAG,IAAI,SAAS,EAAE;gBACpB,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,iDAAiD,CAC1D,CAAC,EAAE,GAAG,EAAE,SAAS,CAAC,CAAC,CAAC;aAC7B;YACD,EAAE,SAAS,CAAC,GAAG,CAAC,CAAC;YACjB,cAAc,GAAG,cAAc,KAAK,GAAG,IAAI,cAAc,CAAC,CAAC;YAC3D,cAAc,GAAG,GAAG,CAAC;SACtB;QAED,IAAI,WAAW,GAAG,IAAI,CAAC;QACvB,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,SAAS,EAAE,EAAE,GAAG,EAAE;;YAExC,MAAM,QAAQ,IAAI,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;YACxC,iBAAiB,CAAC,GAAG,CAAC,GAAG,QAAQ,CAAC;YAClC,WAAW,GAAG,WAAW,IAAI,CAAC,QAAQ,CAAC;;YAEvC,SAAS,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,SAAS,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;;;;;;;YAO7C,IAAI,GAAG,GAAG,CAAC,EAAE;gBACX,SAAS,CAAC,GAAG,CAAC,IAAI,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;aACtC;SACF;QAED,IAAI,WAAW,IAAI,cAAc,EAAE;YACjC,MAAM,aAAa,GAAe,OAAO,CAAC;YAC1C,MAAM,YAAY,GAAe,MAAM,CAAC;YACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAAE,EAAE,CAAC,EAAE;gBACrC,eAAe,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aACxB;YACD,OAAO;gBACL,aAAa,EAAE,CAAC,YAAY,EAAE,IAAI,CAAC,EAAE,YAAY,EAAE,iBAAiB;gBACpE,eAAe;aAChB,CAAC;SACH;aAAM;YACL,MAAM,gBAAgB,GAAG,SAAS,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAClD,MAAM,aAAa,GACfC,OAAI,CAAC,iBAAiB,CAAC,YAAY,EAAE,gBAAgB,GAAG,IAAI,CAClD,CAAC;YACf,MAAM,YAAY,GACdA,OAAI,CAAC,iBAAiB,CAAC,WAAW,EAAE,gBAAgB,CAAe,CAAC;YACxE,MAAM,WAAW,GAAa,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;;YAG3D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAAE,EAAE,CAAC,EAAE;;gBAErC,MAAM,GAAG,GAAG,OAAO,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC;gBAC9B,MAAM,MAAM,GAAG,WAAW,CAAC,GAAG,CAAC,CAAC;gBAChC,MAAM,OAAO,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,IAAI,CAAC,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,IAAI,MAAM,CAAC;gBAChE,WAAW,CAAC,GAAG,CAAC,EAAE,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,EAAE,CAAC,EAAE;;oBAE7B,aAAa,CAAC,OAAO,GAAG,IAAI,GAAG,CAAC,CAAC,GAAG,OAAO,CAAC,CAAC,GAAG,IAAI,GAAG,CAAC,CAAC,CAAC;iBAC3D;gBACD,YAAY,CAAC,OAAO,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;;gBAElC,eAAe,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;aAC9B;;YAGD,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,SAAS,EAAE,EAAE,GAAG,EAAE;gBACxC,MAAM,QAAQ,GAAG,WAAW,CAAC,GAAG,CAAC,CAAC;gBAClC,IAAI,QAAQ,KAAK,CAAC,EAAE;oBAClB,MAAM,aAAa,GAAG,CAAC,GAAG,KAAK,CAAC,IAAI,CAAC,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;;;;oBAI3D,aAAa,CAAC,aAAa,GAAG,IAAI,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;oBAC9C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,IAAI,EAAE,EAAE,GAAG,EAAE;wBACnC,aAAa,CAAC,aAAa,GAAG,IAAI,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC;qBAC/C;oBACD,YAAY,CAAC,aAAa,CAAC,GAAG,YAAY,CAAC;iBAC5C;aACF;YACD,OAAO;gBACL,aAAa,EAAE,CAAC,gBAAgB,EAAE,IAAI,CAAC,EAAE,YAAY,EAAE,iBAAiB;gBACxE,eAAe;aAChB,CAAC;SACH;IACH;;IC5IA;;;;;;;;;;;;;;;;aAmBgB,iBAAiB,CAC7B,YAAwB,EAAE,iBAA2B,EAAE,UAAoB,EAC3E,UAAoB,EACpB,WAAqB;QACvB,MAAM,SAAS,GAAGA,OAAI,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;QACjD,MAAM,GAAG,GAAG,iBAAiB,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,UAAU,GAAG,WAAW,CAAC,MAAM,CAAC;;;QAItC,MAAM,WAAW,GAAa,EAAE,CAAC;QACjC,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,IAAI,YAAY,GAAG,CAAC,CAAC,CAAC;QACtB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;YACnC,MAAM,IAAI,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YAC5B,IAAI,IAAI,KAAK,CAAC,CAAC,EAAE;gBACf,IAAI,YAAY,KAAK,CAAC,CAAC,EAAE;oBACvB,MAAM,IAAI,KAAK,CACXD,eAAY;yBACP,wDAAwD,CACrD,YAAY,EAAE,CAAC,CAAC,CAAC,CAAC;iBAC/B;gBACD,YAAY,GAAG,CAAC,CAAC;gBACjB,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aACrB;iBAAM;gBACL,IAAI,IAAI,GAAG,CAAC,EAAE;oBACZ,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,6CAA6C,CACtD,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;iBACnB;gBACD,OAAO,IAAI,IAAI,CAAC;gBAChB,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;aACxB;SACF;QACD,IAAI,YAAY,KAAK,CAAC,CAAC,EAAE;YACvB,IAAI,OAAO,IAAI,CAAC,EAAE;gBAChB,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,oDAAoD,EAAE,CAAC,CAAC;aAC1E;YACD,MAAM,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,OAAO,CAAC,CAAC;YAChD,IAAI,OAAO,GAAG,OAAO,KAAK,SAAS,EAAE;gBACnC,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,+CAA+C,CACxD,UAAU,EAAE,WAAW,CAAC,CAAC,CAAC;aACnC;YAED,WAAW,CAAC,YAAY,CAAC,GAAG,OAAO,CAAC;SACrC;QACD,MAAM,UAAU,GAAGC,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAI,UAAU,KAAK,SAAS,EAAE;YAC5B,MAAM,IAAI,KAAK,CACXD,eAAY,CAAC,+CAA+C,CACxD,UAAU,EAAE,WAAW,CAAC,CAAC,CAAC;SACnC;QAED,MAAM,SAAS,GAAG,UAAU,CAAC,MAAM,CAAC;QACpC,MAAM,YAAY,GAAa,EAAE,CAAC;QAClC,IAAI,SAAS,GAAG,CAAC,EAAE;YACjB,YAAY,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YAChC,KAAK,IAAI,CAAC,GAAG,SAAS,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,EAAE,CAAC,EAAE;gBACvC,YAAY,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aAC3D;SACF;QAED,MAAM,aAAa,GAAa,EAAE,CAAC;QACnC,IAAI,UAAU,GAAG,CAAC,EAAE;YAClB,aAAa,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YAClC,KAAK,IAAI,CAAC,GAAG,UAAU,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,EAAE,CAAC,EAAE;gBACxC,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,WAAW,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aAC9D;SACF;QAED,MAAM,UAAU,GACZC,OAAI,CAAC,iBAAiB,CAAC,UAAU,EAAE,GAAG,GAAG,UAAU,CAAe,CAAC;QACvE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,EAAE,CAAC,EAAE;YAC5B,IAAI,EAAE,GAAG,CAAC,CAAC;YACX,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;;gBAElC,EAAE,IAAI,YAAY,CAAC,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;aACzD;YACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;;gBAEnC,UAAU,CAAC,CAAC,GAAG,UAAU,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,EAAE,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC;gBACnE,EAAE,IAAI,aAAa,CAAC,CAAC,CAAC,CAAC;aACxB;SACF;QACD,OAAO,CAAC,UAAU,EAAE,CAAC,GAAG,EAAE,UAAU,CAAC,EAAE,WAAW,CAAC,CAAC;IACtD;;IC1GA;;;;;;;;;;;;;;;;aAmBgB,0BAA0B,CACtC,KAAiB,EAAE,UAAoB,EAAE,UAAoB,EAC7D,OAAmB,EAAE,UAAsB,EAAE,MAAM,GAAG,KAAK,EAC3D,YAAY,GAAG,CAAC;QAClB,MAAM,UAAU,GAAG,OAAO,CAAC,MAAM,CAAC;;QAGlC,MAAM,SAAS,GAAa,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,MAAM,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,MAAM,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;;;QAG5B,MAAM,oBAAoB,GACtB,UAAU,GAAG,CAAC,GAAG,UAAU,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QACxD,MAAM,UAAU,GAAG,oBAAoB,CAAC;QAExC,IAAI,UAAU,GAAG,CAAC,EAAE;YAClB,MAAM,IAAI,KAAK,CACXD,eAAY,CAAC,uDAAuD,EAAE,CAAC,CAAC;SAC7E;QAED,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;QACvC,WAAW,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;QAE5B,MAAM,YAAY,GACd,WAAW,CAAC,MAAM,CAAC,CAAC,OAAO,EAAE,KAAK,KAAK,OAAO,GAAG,KAAK,EAAE,CAAC,CAAC,CAAC;;QAE/D,MAAM,MAAM,GAAGC,OAAI,CAAC,iBAAiB,CAAC,UAAU,EAAE,YAAY,CAAe,CAAC;;;QAI9E,IAAI,UAAU,KAAK,CAAC,EAAE;YACpB,IAAI,UAAU,GAAG,CAAC,EAAE;gBAClB,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;aAC3B;YACD,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;SAC9B;QAED,IAAI,UAAU,IAAI,CAAC,EAAE;YACnB,MAAM,IAAI,KAAK,CACXD,eAAY,CAAC,uDAAuD,EAAE,CAAC,CAAC;SAC7E;QAED,IAAI,KAAK,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC;;QAEvB,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,IAAI,QAAQ,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC;QAEjC,OAAO,IAAI,EAAE;;YAEX,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,IAAI,GAAG,GAAG,UAAU,EAAE;gBACpB,SAAS,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC;gBAC5B,IAAI,QAAQ,KAAK,SAAS,EAAE;oBAC1B,EAAE,GAAG,CAAC;oBACN,SAAS;iBACV;;gBAED,IAAI,QAAQ,IAAI,SAAS,EAAE;oBACzB,MAAM,IAAI,KAAK,CAACA,eAAY;yBACvB,4DAA4D,EAAE,CAAC,CAAC;iBACtE;aACF;YAED,IAAI,QAAQ,GAAG,CAAC,IAAI,QAAQ,IAAI,UAAU,EAAE;gBAC1C,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,wDAAwD,CACjE,QAAQ,EAAE,UAAU,CAAC,CAAC,CAAC;aAChC;;;YAID,IAAI,QAAQ,GAAG,kBAAkB,EAAE;gBACjC,MAAM,CAAC,IAAI,CAAC,YAAY,EAAE,kBAAkB,GAAG,MAAM,EAAE,QAAQ,GAAG,MAAM,CAAC,CAAC;aAC3E;YAED,KAAK,IAAI,CAAC,GAAG,KAAK,EAAE,CAAC,GAAG,GAAG,EAAE,EAAE,CAAC,EAAE;gBAChC,MAAM,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;gBACzB,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,SAAS,CAAC,CAAC,CAAC,EAAE;oBACtC,MAAM,IAAI,KAAK,CACXA,eAAY,CAAC,sDAAsD,CAC/D,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;iBACvC;gBACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;oBAC/B,MAAM,CAAC,QAAQ,GAAG,MAAM,GAAG,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC,CAAC;iBAC5D;aACF;YAED,IAAI,MAAM,EAAE;gBACV,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;oBAC/B,MAAM,CAAC,QAAQ,GAAG,MAAM,GAAG,CAAC,CAAC,IAAI,GAAG,GAAG,KAAK,CAAC;iBAC9C;aACF;YAED,KAAK,GAAG,GAAG,CAAC;YACZ,EAAE,GAAG,CAAC;YACN,kBAAkB,GAAG,QAAQ,GAAG,CAAC,CAAC;YAClC,QAAQ,GAAG,SAAS,CAAC;YACrB,IAAI,GAAG,GAAG,UAAU,EAAE;gBACpB,MAAM;aACP;SACF;;QAGD,IAAI,kBAAkB,GAAG,UAAU,EAAE;YACnC,MAAM,CAAC,IAAI,CAAC,YAAY,EAAE,kBAAkB,GAAG,MAAM,EAAE,UAAU,GAAG,MAAM,CAAC,CAAC;SAC7E;QAED,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC/B;;IC/HA;;;;;;;;;;;;;;;;IAsBO,MAAM,QAAQ,GAAG,qBAAqB,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;;ICtBpE;;;;;;;;;;;;;;;;IAsBO,MAAM,qBAAqB,GAC9B,4BAA4B,EAAE,CAAC,CAAS,EAAE,CAAS;QACjD,MAAM,IAAI,GAAG,CAAC,GAAG,CAAC,CAAC;QACnB,OAAO,IAAI,GAAG,IAAI,CAAC;IACrB,CAAC,EAAE;;IC1BP;;;;;;;;;;;;;;;;aAmBgB,gBAAgB,CAC5B,QAAkB,EAAE,IAAqB,EAAE,OAAiB,EAC5D,KAAe;QACjB,MAAM,MAAM,GAAGO,SAAM,CAAC,QAAQ,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;QAE5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE;YACpC,MAAM,GAAG,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEjC,MAAM,MAAM,GAAa,IAAI,KAAK,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC/C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBACtC,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;aAC5C;YACD,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC;SACzC;QAED,OAAO,MAAyB,CAAC;IACnC;;ICnCA;;;;;;;;;;;;;;;;IAmBA;;;;;;IAMA,MAAM,cAAc;QAQlB,YACI,SAAiB,EAAE,WAAqB,EAAE,OAAe,EACzD,QAAgB,EAAE,QAAgB,EAAE,sBAA+B;YACrE,IAAI,CAAC,SAAS,GAAGN,OAAI,CAAC,YAAY,CAAC,SAAS,CAAC,CAAC;YAC9C,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,OAAO,GAAGA,OAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC;YAC1C,IAAI,CAAC,QAAQ,GAAGA,OAAI,CAAC,YAAY,CAAC,QAAQ,CAAC,CAAC;YAC5C,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;YACzB,IAAI,CAAC,aAAa,GAAG,sBAAsB,CAAC;SAC7C;QAEO,WAAW,CAAC,UAAkB;;;;YAIpC,OAAO,IAAI,CAAC,GAAG,CACX,IAAI,CAAC,QAAQ,GAAG,CAAC,GAAG,UAAU,GAAG,CAAC,GAAG,IAAI,CAAC,QAAQ,EAAE,UAAU,GAAG,CAAC,CAAC,CAAC;SACzE;QAEO,YAAY,CAAC,MAAc,EAAE,UAAkB;YACrD,MAAM,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;YAC9C,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,MAAM,GAAG,CAAC,GAAG,QAAQ,IAAI,UAAU,IAAI,CAAC,CAAC,CAAC;SAChE;QAEO,YAAY,CAChB,IAAkB,EAAE,UAAkB,EAAE,MAAoB,EAC5D,gBAAwB,EAAE,SAAiB,EAAE,UAAkB;YACjE,KAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,SAAS,EAAE,EAAE,UAAU,EAAE;gBAC7D,MAAM,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;gBAC9C,MAAM,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,GAAG,UAAU,CAAC,CAAC;gBACvD,MAAM,YAAY,GACd,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,IAAI,SAAS,IAAI,UAAU,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC3D,MAAM,SAAS,GAAG,UAAU,IAAI,WAAW,GAAG,YAAY,CAAC,CAAC;gBAC5D,MAAM,cAAc,GAChB,UAAU,IAAI,WAAW,GAAG,CAAC,GAAG,CAAC,GAAG,UAAU,GAAG,QAAQ,CAAC,CAAC;;;gBAI/D,IAAI,SAAS,GAAG,CAAC,CAAC;;gBAElB,SAAS,IAAI,WAAW,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;;gBAE/C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;oBAClC,SAAS,IAAI,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;iBAC9C;;gBAED,SAAS,IAAI,YAAY,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;;gBAEjD,MAAM,aAAa,GAAG,WAAW,GAAG,YAAY,GAAG,SAAS,GAAG,CAAC,CAAC;gBACjE,SAAS,IAAI,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC;;gBAGnD,MAAM,CAAC,gBAAgB,GAAG,UAAU,CAAC,GAAG,IAAI,UAAU,CAAC,SAAS,CAAC,CAAC;gBAClE,MAAM,KAAK,GAAG,MAAM,CAAC,gBAAgB,GAAG,UAAU,CAAC,CAAC;gBAEpD,IAAI,cAAc,GAAG,CAAC,CAAC;gBACvB,MAAM,aAAa,GAAG,CAAC,GAAe,KAClC,GAAG,CAAC,OAAO,CAAC,CAAC,KAAK,KAAK,KAAK,CAAC,cAAc,EAAE,CAAC,GAAG,KAAK,CAAC,CAAC;gBAE5D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,EAAE,CAAC,EAAE;oBACpC,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;oBAC5B,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;iBAC/B;;gBAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;oBACtC,aAAa,CAAC,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC,CAAC,CAAC;oBACxC,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;iBAC/B;;;gBAGD,IAAI,SAAS,GAAG,CAAC,EAAE;;;;oBAIjB,aAAa,CAAC,IAAI,CAAC,cAAc,GAAG,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC;oBACpD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAAE,EAAE,CAAC,EAAE;wBACrC,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;wBAC9B,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;qBAC9B;iBACF;qBAAM;;;;;oBAKL,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;wBACzC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;wBAC7B,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;qBAC/B;oBACD,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;iBAC9B;aACF;SACF;;;;QAKM,OAAO,CAAC,IAAkB,EAAE,MAAkB;;;YAInD,MAAM,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC;YAClC,MAAM,UAAU,GAAG,MAAM,CAAC,MAAM,CAAC;YACjC,IAAI,UAAU,GAAG,CAAC,EAAE;gBAClB,IAAI,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBAC1B,IAAI,SAAS,KAAK,CAAC,EAAE;oBACnB,MAAM,IAAI,KAAK,CAAC,oCAAoC,SAAS,EAAE,CAAC,CAAC;iBAClE;gBACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;oBACnC,IAAI,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,IAAI,SAAS,CAAC;oBACzC,WAAW,GAAG,WAAW,KAAK,MAAM,CAAC,CAAC,CAAC,IAAI,aAAa,CAAC,CAAC;oBAC1D,IAAI,CAAC,WAAW,EAAE;wBAChB,MAAM,IAAI,KAAK,CAAC,uBAAuB,MAAM,CAAC,CAAC,CAAC,iBAC5C,SAAS,KAAK,aAAa,GAAG,CAAC,CAAC;qBACrC;oBACD,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;iBACvB;gBACD,IAAI,SAAS,KAAK,aAAa,EAAE;oBAC/B,MAAM,IAAI,KAAK,CAAC,gDACZ,aAAa,SAAS,SAAS,EAAE,CAAC,CAAC;iBACxC;aACF;YAED,MAAM,aAAa,GAAG,UAAU,GAAG,CAAC,CAAC;YACrC,MAAM,YAAY,GAAGA,OAAI,CAAC,iBAAiB,CAAC,OAAO,EAAE,UAAU,CAAC,CAAC;;YAEjE,IAAI,aAAa,KAAK,CAAC,IAAI,UAAU,KAAK,CAAC,EAAE;gBAC3C,MAAM,KAAK,GAAiB,IAAI,KAAK,CAAC,aAAa,CAAC,CAAC;gBACrD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,aAAa,EAAE,EAAE,CAAC,EAAE;oBACvC,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;iBACrB;gBACD,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;aAC9B;YAED,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;YACpB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,aAAa,EAAE,EAAE,CAAC,EAAE;gBACvC,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBACzC,IAAI,SAAS,GAAG,CAAC,CAAC;gBAClB,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,UAAU;oBAClC,SAAS,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;iBACpD,CAAC,CAAC;gBACH,IAAI,IAAI,CAAC,aAAa,IAAI,MAAM,GAAG,CAAC,IAAI,SAAS,KAAK,CAAC,EAAE;oBACvD,SAAS,GAAG,CAAC,CAAC;iBACf;gBACD,YAAY,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,SAAS,CAAC;aACnD;YAED,MAAM,MAAM,GAAiB,IAAI,KAAK,CAAC,YAAY,CAAC,aAAa,CAAC,CAAC,CAAC;YAEpE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,aAAa,EAAE,EAAE,CAAC,EAAE;gBACtC,MAAM,UAAU,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBAC7B,IAAI,cAAc,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;gBACrC,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,UAAU;oBAClC,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;oBACzC,MAAM,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;oBACxD,IAAI,CAAC,YAAY,CACb,IAAI,EAAE,UAAU,EAAE,MAAM,EAAE,cAAc,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;oBACrE,cAAc,IAAI,SAAS,CAAC;iBAC7B,CAAC,CAAC;;;;;;gBAMH,IAAI,IAAI,CAAC,aAAa,IAAI,cAAc,KAAK,YAAY,CAAC,CAAC,CAAC,EAAE;oBAC5D,MAAM,UAAU,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;;;oBAG7C,IAAI,UAAU,KAAK,CAAC,EAAE;wBACpB,SAAS;qBACV;;;;oBAID,MAAM,UAAU,GAAG,UAAU,GAAG,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC;oBAClD,MAAM,SAAS,GAAG,CAAC,CAAC;oBACpB,IAAI,CAAC,YAAY,CACb,IAAI,EAAE,UAAU,EAAE,MAAM,EAAE,cAAc,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;iBACtE;aACF;YACD,OAAO,CAAC,MAAM,EAAE,YAAY,CAAC,CAAC;SAC/B;KACF;aAEe,gBAAgB,CAC5B,IAAkB,EAAE,UAAsB,EAAE,SAAiB,EAC7D,WAAqB,EAAE,OAAe,EAAE,QAAgB,EAAE,QAAgB,EAC1E,sBAA+B;QACjC,OAAO,IAAI,cAAc,CACd,SAAS,EAAE,WAAW,EAAE,OAAO,EAAE,QAAQ,EAAE,QAAQ,EACnD,sBAAsB,CAAC;aAC7B,OAAO,CAAC,IAAI,EAAE,UAAU,CAAC,CAAC;IACjC;;IChOA;;;;;;;;;;;;;;;;IAmBA,SAAS,KAAK,CACV,GAAe,EAAE,UAAsB,EAAE,SAAkB,EAC3D,MAAoB;QACtB,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE;YACf,OAAO;SACR;;QAED,IAAI,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE;YAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBACnC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;aACrC;YACD,OAAO;SACR;;QAED,IAAI,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE;YAC3B,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAChC,IAAI,CAAC,GAAG,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;YAC/B,OAAO,CAAC,KAAK,CAAC,CAAC,EAAE;gBACf,MAAM,KAAK,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACjC,IAAI,CAAC,SAAS,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;oBACpC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;iBACpB;gBACD,GAAG,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC1B,CAAC,GAAG,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;aAC5B;YACD,IAAI,CAAC,SAAS,IAAI,GAAG,CAAC,MAAM,KAAK,CAAC,EAAE;gBAClC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;aAClB;YACD,OAAO;SACR;;;QAGD,IAAI,UAAU,GAAG,CAAC,CAAC;QACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;YACvC,IAAI,CAAC,CAAC,KAAK,GAAG,CAAC,MAAM,MAAM,UAAU,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE;gBAC7D,MAAM,KAAK,GAAG,GAAG,CAAC,QAAQ,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC;gBAC1C,IAAI,CAAC,SAAS,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;oBACpC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;iBACpB;gBACD,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;aACpB;SACF;IACH,CAAC;aAEe,eAAe,CAC3B,KAAmB,EAAE,SAAqB,EAC1C,SAAkB;QACpB,MAAM,SAAS,GAAG,KAAK,CAAC,MAAM,CAAC;;QAG/B,MAAM,MAAM,GAAiB,EAAE,CAAC;QAEhC,IAAI,UAAU,GAAG,CAAC,CAAC;QACnB,IAAI,aAAa,GAAG,CAAC,CAAC;QACtB,MAAM,UAAU,GAAa,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;YAClC,MAAM,gBAAgB,GAAG,MAAM,CAAC,MAAM,CAAC;YACvC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,CAAC,CAAC;YAC9C,MAAM,QAAQ,GAAG,MAAM,CAAC,MAAM,GAAG,gBAAgB,CAAC;YAClD,UAAU,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;YACzB,UAAU,IAAI,QAAQ,CAAC;YACvB,aAAa,GAAG,IAAI,CAAC,GAAG,CAAC,aAAa,EAAE,QAAQ,CAAC,CAAC;SACnD;QAED,MAAM,OAAO,GAAGA,OAAI,CAAC,iBAAiB,CAAC,OAAO,EAAE,UAAU,GAAG,CAAC,CAAe,CAAC;QAC9E,MAAM,MAAM,GAAiB,IAAI,KAAK,CAAC,UAAU,CAAC,CAAC;QACnD,MAAM,KAAK,GAAqB,CAAC,SAAS,EAAE,aAAa,CAAC,CAAC;QAE3D,IAAI,CAAC,GAAG,CAAC,CAAC;QACV,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;YAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;;gBAEtC,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;gBACnB,OAAO,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;gBACvB,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACtB,EAAE,CAAC,CAAC;aACL;SACF;QAED,OAAO,CAAC,OAAO,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;IAClC;;ICnGA;;;;;;;;;;;;;;;;aAmBgB,0BAA0B,CACtC,KAAmB,EAAE,UAAkB;QACzC,MAAM,MAAM,GAAGA,OAAI,CAAC,iBAAiB,CAAC,OAAO,EAAE,KAAK,CAAC,MAAM,CAAe,CAAC;QAE3E,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACLA,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,kBAAkB,EAAE,CAAC;SAC1E;QAED,OAAO,MAAM,CAAC;IAChB;;IC7BA;;;;;;;;;;;;;;;;IAsBO,MAAM,OAAO,GAAG,4BAA4B,EAC9C,CAAC,MAAc,EAAE,MAAc,KAAK,MAAM,GAAG,MAAM,EAAE;;ICvB1D;;;;;;;;;;;;;;;;IAmBA;;;;aAKgB,QAAQ,CACpB,IAA+B,EAC/B,IAAc;QAChB,MAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAChD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACxC,QAAQ,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;SACvC;QACD,MAAM,MAAM,GAAGM,SAAM,CAAC,QAAQ,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;QAC5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC7C,MAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEpC,MAAM,WAAW,GAAa,IAAI,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBAC3C,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;aAC5C;YAED,MAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,CAAC;YAEnD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;SAC/C;QACD,OAAO,MAAmC,CAAC;IAC7C;;IC7CA;;;;;;;;;;;;;;;;IA0BA,MAAM,WAAW,GAAG,CAAC,CAAO,EAAE,CAAO;QACnC,MAAM,SAAS,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC;QACpC,OAAO,SAAS,KAAK,CAAC,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK,GAAG,SAAS,CAAC;IACzD,CAAC,CAAC;IAEF;;;;;;;;;;;IAWA,SAASkB,QAAM,CAAC,KAAa,EAAE,CAAS,EAAE,IAAI,GAAG,CAAC,EAAE,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC;QAC1E,OAAO,KAAK,GAAG,IAAI,EAAE;;;;YAInB,IAAI,KAAK,GAAG,IAAI,GAAG,GAAG,EAAE;gBACtB,MAAM,CAAC,GAAG,KAAK,GAAG,IAAI,GAAG,CAAC,CAAC;gBAC3B,MAAM,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,CAAC;gBACvB,MAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;gBACtB,MAAM,CAAC,GAAG,GAAG,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;gBACpC,MAAM,EAAE,GAAG,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;gBACvE,MAAM,OAAO,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;gBAC/D,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;gBACvEA,QAAM,CAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,QAAQ,CAAC,CAAC;aACrC;;YAED,MAAM,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YACnB,IAAI,CAAC,GAAG,IAAI,CAAC;YACb,IAAI,CAAC,GAAG,KAAK,CAAC;YAEdxB,OAAI,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;YAE1B,IAAI,WAAW,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE;gBACpCA,OAAI,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;aAC/B;YACD,OAAO,CAAC,GAAG,CAAC,EAAE;gBACZA,OAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;gBACvB,CAAC,EAAE,CAAC;gBACJ,CAAC,EAAE,CAAC;gBACJ,OAAO,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE;oBACnC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;iBACX;gBACD,OAAO,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE;oBACnC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;iBACX;aACF;YACD,IAAI,WAAW,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,EAAE;gBACrCA,OAAI,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;aAC3B;iBAAM;gBACL,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;gBACVA,OAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;aAC5B;;;YAGD,IAAI,CAAC,IAAI,CAAC,EAAE;gBACV,IAAI,GAAG,CAAC,GAAG,CAAC,CAAC;aACd;YACD,IAAI,CAAC,IAAI,CAAC,EAAE;gBACV,KAAK,GAAG,CAAC,GAAG,CAAC,CAAC;aACf;SACF;IACH,CAAC;aAEe,QAAQ,CACpB,CAAa,EAAE,MAAgB,EAAE,MAAuB,EAAE,CAAS,EACnE,MAAe;;QAGjB,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,KAAK,EAAE,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,GAAG,OAAO,EAAE,OAAO,CAAC,CAAC;QACpD,MAAM,WAAW,GAAGA,OAAI,CAAC,sBAAsB,CAAC,MAAM,EAAE,KAAK,GAAG,CAAC,CAAC,CAAC;QACnE,MAAM,cAAc,GAAGA,OAAI,CAAC,sBAAsB,CAAC,OAAO,EAAE,KAAK,GAAG,CAAC,CAAC,CAAC;QAEvE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;YAC9B,MAAM,MAAM,GAAG,CAAC,GAAG,IAAI,CAAC;YACxB,MAAM,IAAI,GAAG,CAAC,CAAC,QAAQ,CAAC,MAAM,EAAE,MAAM,GAAG,IAAI,CAAC,CAAC;YAE/C,IAAI,SAAS,GAAW,IAAI,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAC/C,IAAI,CAAC,OAAO,CACR,CAAC,KAAa,EAAE,KAAa,KAAK,SAAS,CAAC,KAAK,CAAC,GAAG,EAAC,KAAK,EAAE,KAAK,EAAC,CAAC,CAAC;YAEzE,IAAI,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE;gBACxBwB,QAAM,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBACrB,SAAS,GAAG,SAAS,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;aACnC;YAED,IAAI,MAAM,EAAE;gBACV,SAAS,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;aAC7B;YAED,MAAM,SAAS,GAAG,CAAC,GAAG,CAAC,CAAC;YACxB,MAAM,QAAQ,GAAG,WAAW,CAAC,QAAQ,CAAC,SAAS,EAAE,SAAS,GAAG,CAAC,CAAC,CAAC;YAChE,MAAM,WAAW,GAAG,cAAc,CAAC,QAAQ,CAAC,SAAS,EAAE,SAAS,GAAG,CAAC,CAAC,CAAC;YACtE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;gBAC1B,QAAQ,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;gBACjC,WAAW,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;aACrC;SACF;;;QAGD,MAAM,WAAW,GAAG,MAAM,CAAC,KAAK,EAAE,CAAC;QACnC,WAAW,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;QAExC,OAAO;YACLlB,SAAM,CAAC,WAA0B,EAAE,MAAM,EAAE,WAAW,CAAC;YACvDA,SAAM,CAAC,WAA0B,EAAE,OAAO,EAAE,cAAc,CAAC;SAC5D,CAAC;IACJ;;IC3IA;;;;;;;;;;;;;;;;aAmBgB,UAAU,CACtB,MAAqB,EAAE,IAAY,EAAE,KAAe,EAAE,KAAe;;QAMvE,MAAM,KAAK,GAAGN,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAyDlD,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;YAC9B,QAAQ,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;SACzB;QACD,QAAQ,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,KAAK,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAC7C,QAAQ,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;SACzB;;;QAID,MAAM,cAAc,GAA4B,EAAE,CAAC;;;QAGnD,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;;QAE7C,MAAM,WAAW,GAAG,IAAIyB,eAAY,CAAC,QAAQ,EAAE,KAAK,EAAE,MAAoB,CAAC,CAAC;;;QAG5E,MAAM,aAAa,GAAa,EAAE,CAAC;QACnC,MAAM,UAAU,GAAG,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QAC1D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC,EAAE,EAAE;;YAErC,IAAI,OAAe,CAAC;YACpB,IAAI,UAAU,EAAE;;gBAEd,OAAO,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAE,CAAC;aAChC;iBAAM;gBACL,MAAM,UAAU,GAAG,EAAE,CAAC;gBACtB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;oBACpC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;wBACpC,UAAU,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;qBAC3C;iBACF;gBACD,OAAO,GAAG,UAAU,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;aAChC;;YAGD,IAAI,cAAc,CAAC,OAAO,CAAC,KAAK,SAAS,EAAE;gBACzC,OAAO,CAAC,CAAC,CAAC,GAAG,cAAc,CAAC,OAAO,CAAC,CAAC;aACtC;iBAAM;gBACL,MAAM,WAAW,GAAG,MAAM,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC;gBACvD,cAAc,CAAC,OAAO,CAAC,GAAG,WAAW,CAAC;gBACtC,OAAO,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC;gBACzB,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aACvB;SACF;;;;QAKD,MAAM,cAAc,GAAG,QAAQ,CAAC,KAAK,EAAE,CAAC;QACxC,cAAc,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC;QACvD,MAAM,YAAY,GAAG,IAAIA,eAAY,CAAC,cAAc,EAAE,KAAK,CAAC,CAAC;QAC7D,aAAa,CAAC,OAAO,CAAC,CAAC,kBAAkB,EAAE,CAAC;YAC1C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;gBACpC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;oBACpC,YAAY,CAAC,GAAG,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,EAAE,kBAAkB,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;iBACtE;aACF;SACF,CAAC,CAAC;;;QAIH,MAAM,WAAW,GAAG,KAAK,CAAC,KAAK,EAAE,CAAC;QAClC,WAAW,CAAC,KAAK,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC;QAEvC,OAAO;YACL,YAAY,EAAE,YAAY,CAAC,MAAuB;YAClD,WAAW;YACX,OAAO;SACR,CAAC;IACJ;;IC3JA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICAA;;;;;;;;;;;;;;;;IA4BA,MAAM,EACJ,OAAO,EAAE,UAAU,EACnB,QAAQ,EAAE,WAAW,EACrB,QAAQ,EAAE,WAAW,EACrB,UAAU,EAAE,aAAa,EACzB,SAAS,EAAE,YAAY,EACvB,OAAO,EAAE,UAAU,EACnB,SAAS,EAAE,YAAY,EACvB,SAAS,EAAE,YAAY,EACvB,YAAY,EAAE,eAAe,EAC7B,YAAY,EAAE,eAAe,EAC7B,gBAAgB,EAAE,mBAAmB,EACrC,WAAW,EAAE,cAAc,EAC3B,aAAa,EAAE,gBAAgB,EAC/B,QAAQ,EAAE,WAAW,EACrB,OAAO,EAAE,UAAU,EACnB,OAAO,EAAE,UAAU,EACnB,WAAW,EAAE,cAAc,EAC3B,WAAW,EAAE,cAAc,EAC3B,YAAY,EAAE,eAAe,EAC7B,OAAO,EAAE,UAAU,EACnB,YAAY,EAAE,eAAe,EAC7B,QAAQ,EAAE,WAAW,EACrB,SAAS,EAAE,YAAY,EACvB,SAAS,EAAE,YAAY,EACvB,WAAW,EAAE,cAAc,EAC3B,aAAa,EAAE,gBAAgB,EAC/B,SAAS,EAAE,YAAY,EACvB,gBAAgB,EAAE,mBAAmB,EACrC,gBAAgB,EAAE,mBAAmB,EACrC,OAAO,EAAE,UAAU,EACnB,QAAQ,EAAE,WAAW,EACrB,QAAQ,EAAE,WAAW,EACrB,aAAa,EAAE,gBAAgB,EAC/B,UAAU,EAAE,aAAa,GAC1B,GAAG,MAAM;;IC/DV;;;;;;;;;;;;;;;;IAsBO,MAAM,GAAG,GACZ,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,GAAG,EAAE,aAAa,EAAE,gBAAgB,EAAC,CAAC,CAAC;IAEzE,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,aAAa,GAAG,gBAAgB,CACzC,EAAC,MAAM,EAAE,YAAY,CAAC,GAAG,EAAE,aAAa,EAAEC,UAAM,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;IAEvE,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,aAAa;KAC1B;;IC9BD;;;;;;;;;;;;;;;;UAoBa,iBAAiB;QAU5B,YAAY,MAAkB;YAJ9B,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YAC7B,IAAI,CAAC,aAAa,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,IAAI,CAAC,EAAE,CAAC,CAAC;YACnD,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAChC,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC;SACzB;QAED,WAAW;YACT,MAAM,QAAQ,GAAa,EAAE,CAAC;;YAE9B,IAAI,CAAC,aAAa,CAAC,OAAO,CAAC,QAAQ;gBACjC,QAAQ,CAAC,IAAI,CAAC,QAAQ,QAAQ,SAAS,QAAQ,yBAAyB,CAAC,CAAC;aAC3E,CAAC,CAAC;;YAEH,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa;iBACb,GAAG,CAAC,QAAQ;gBACX,OAAO,IAAI,QAAQ,EAAE,CAAC;aACvB,CAAC;iBACD,IAAI,CAAC,KAAK,CAAC,CAAC;YAEnC,MAAM,QAAQ,GAAG;QACbjB,mBAAI,CAAC,OAAO,CAAC;8BACS,IAAI,CAAC,aAAa;oCACZ,IAAI,CAAC,aAAa;;;cAGxC,QAAQ,CAAC,IAAI,CAAC,YAAY,CAAC;0CACC,SAAS;;;;KAI9C,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IClEH;;;;;;;;;;;;;;;;aAwBgB,IAAI,CAAC,IAAkD;QAErE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAE/B,MAAM,OAAO,GAAG,MAAM,CAAC;QACvB,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SACrD;QAED,MAAM,KAAK,GACP,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,EAAE,KAAKO,aAAU,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC;QACzC,MAAM,OAAO,GAAG,IAAI,iBAAiB,CAAC,MAAM,CAAC,CAAC;QAC9C,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,OAAO,EAAE,KAAK,CAAC,CAAC;IAC3D,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEW,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;IC5CD;;;;;;;;;;;;;;;;UAqBa,gBAAgB;QAc3B,YAAY,UAAoB,EAAE,IAAY,EAAE,UAAuB;YATvE,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,sBAAsB,CAAC;YAIlC,SAAI,GAAG,IAAI,CAAC;YAIV,MAAM,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC;YAEpB,IAAI,CAAC,EAAE,GAAG,UAAU,KAAK,KAAK,GAAG,GAAG,GAAG,GAAG,CAAC;;YAG3C,MAAM,CAAC,WAAW,EAAE,WAAW,CAAC,GAC5B9B,eAAY,CAAC,yBAAyB,CAAC,UAAU,EAAE,IAAI,CAAC,CAAC;YAE7D,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC;YAChE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;;;;;;YAM3D,IAAIC,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,GAAG,EAAE;gBACpCA,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,GAAG,IAAI,EAAE;gBAC1C,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC;gBACpB,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;aAChE;iBAAM;gBACL,IAAI,CAAC,IAAI,GAAG,QAAQ,CAAC;;;gBAGrB,IAAI,CAAC,QAAQ;oBACT,eAAe,CAAC,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aACvE;YAED,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,SAAS,GAAG,aAAa,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,IAAI,EAAE,CAAC;SACtD;QAED,WAAW;YACT,MAAM,oBAAoB,GAAG;gBAC3B,IAAI,IAAI,CAAC,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE;oBAChC,OAAO,iBAAiB,CAAC;iBAC1B;qBAAM;oBACL,OAAO,mBAAmB,YAAY,CAAC,IAAI,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC;iBACtE;aACF,CAAC;YAEF,MAAM,iBAAiB,GAAG;gBACxB,IAAI,OAAO,GAAG,EAAE,CAAC;gBACjB,IAAI,IAAI,CAAC,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;oBACjC,IAAI,IAAI,CAAC,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE;wBAChC,OAAO,IAAI,eAAe,CAAC;qBAC5B;iBACF;qBAAM;oBACL,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;wBAChD,OAAO,IAAI,gBAAgB,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC;qBAC/C;iBACF;gBACD,OAAO,OAAO,CAAC;aAChB,CAAC;YAEF,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBAC1B,MAAM,mBAAmB,GAAG;iDACe,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;gDACtB,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;KAChE,CAAC;gBACA,MAAM,QAAQ,GAAG;;;;;QAKf,mBAAmB;;QAEnBW,mBAAI,CAAC,OAAO,CAAC;;6BAEQ,oBAAoB,EAAE;;;;;;;iCAOlB,iBAAiB,EAAE;+CACL,IAAI,CAAC,EAAE;;;;;;;;;;;;;;;4BAe1B,IAAI,CAAC,EAAE;;;;;;;;;;;;;;KAc9B,CAAC;gBACA,OAAO,QAAQ,CAAC;aACjB;iBAAM;gBACL,MAAM,QAAQ,GAAG;QACfA,mBAAI,CAAC,OAAO,CAAC;;;;iCAIY,iBAAiB,EAAE;+BACrB,oBAAoB,EAAE;;mCAElB,iBAAiB,EAAE;4BAC1B,IAAI,CAAC,EAAE;;;;;;;;OAQ5B,CAAC;gBACF,OAAO,QAAQ,CAAC;aACjB;SACF;;;ICrKH;;;;;;;;;;;;;;;;UAoBa,sBAAsB;QASjC,YAAY,MAAgB,EAAE,MAAgB;YAR9C,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;;YAMtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;YAGpD,MAAM,WAAW,GAAa,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACvD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBAC3C,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACpC;YACD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YACvC,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAE1E,IAAI,CAAC,SAAS,GAAG,iBAAiB,CAAC;SACpC;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;yBACI,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;+CACC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC,MAChE,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;QACrB,sBAAsB,EAAE;;;;;;;;;;;;;;;;;;;KAmB3B,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICpEH;;;;;;;;;;;;;;;;UAoBa,gBAAgB;QAW3B,YAAY,MAAgB,EAAE,MAAgB;YAV9C,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YAKtB,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAGV,MAAM,WAAW,GAAa,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACvD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBAC3C,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACpC;YACD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEhC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;YACrB,IAAI,CAAC,SAAS,GAAG,aAAa,MAAM,EAAE,CAAC;SACxC;QAED,WAAW;YACT,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;YACzD,MAAM,QAAQ,GAAG,iBAAiB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAEhD,MAAM,QAAQ,GAAG;QACbA,mBAAI,CAAC,OAAO,CAAC;6BACQ,IAAI,CAAC,aAAa;oCACX,IAAI,CAAC,aAAa;;;8DAI9C,IAAI,CAAC,WAAW,CAAC,MAAM;gBACf,KAAK,IAAI,QAAQ;;;;KAI5B,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;KACF;IAED,SAAS,iBAAiB,CAAC,MAAgB;QACzC,MAAM,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC;QAC3B,IAAI,IAAI,GAAG,CAAC,EAAE;YACZ,MAAM,KAAK,CAAC,sBAAsB,IAAI,uBAAuB,CAAC,CAAC;SAChE;QACD,MAAM,cAAc,GAAG,IAAI,KAAK,CAAC,IAAI,CAAC,CAAC;QACvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,cAAc,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,SAAS,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC;SACxD;QAED,OAAO,cAAc,CAAC,IAAI,EAAE,CAAC;IAC/B;;IC9EA;;;;;;;;;;;;;;;;aAyBgB,SAAS,CAAC,IAIzB;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QACrB,MAAM,aAAa,GAAG,OAAO,CAAC;QAE9B,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC;QAC5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACxC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;SAChC;QACD,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;YACnC,MAAM,KAAK,GAAG,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YACpD,MAAM,MAAM,GAAG,KAAK,CAAC,MAAoB,CAAC;YAC1C,MAAM,SAAS,GAAGmB,gBAAY,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;YACzE,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;SAC7D;QACD,IAAI,CAAC,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI9B,OAAI,CAAC,WAAW,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE;YAC1D,MAAM,OAAO,GAAG,IAAI,sBAAsB,CAAC,CAAC,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;YAC1D,OAAO,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;SAC9D;QACD,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;QACpD,OAAO,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;IAC/D,CAAC;IAEM,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAE+B,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAA6B;KAC1C;;IC1DD;;;;;;;;;;;;;;;;aAwBgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QAErB,IAAI,IAAI,GAAG/B,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,YAAY,GAAGD,eAAY,CAAC,kBAAkB,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAC3E,IAAI,EAAE,GAAG,CAAC,CAAC;QACX,MAAM,uBAAuB,GAAG,EAAE,CAAC;QACnC,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,EAAE,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,YAAY,EAAC,EAAC,CAAC,CAAC;YACpE,uBAAuB,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;YACjC,IAAI,GAAGA,eAAY,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;SACpE;QAEDA,eAAY,CAAC,0BAA0B,CAAC,QAAQ,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAC9E,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAAC,EAAE,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,MAAM,CAAC,iBAAiB,CAAC,EAAC,CAAC,CAAC;QAC1E,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,EAAE,CAAC,EAAE,OAAO,EAAE,WAAW,CAAC,CAAC;QAC1E,uBAAuB,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACpE,OAAO,GAAG,CAAC;IACb,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEiC,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICrDD;;;;;;;;;;;;;;;;aAwBgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QAErB,IAAI,IAAI,GAAGhC,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,YAAY,GAAGD,eAAY,CAAC,kBAAkB,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAC3E,IAAI,EAAE,GAAG,CAAC,CAAC;QACX,MAAM,uBAAuB,GAAG,EAAE,CAAC;QACnC,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,EAAE,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,YAAY,EAAC,EAAC,CAAC,CAAC;YACpE,uBAAuB,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;YACjC,IAAI,GAAGA,eAAY,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;SACpE;QAEDA,eAAY,CAAC,0BAA0B,CAAC,QAAQ,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAC9E,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAAC,EAAE,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,MAAM,CAAC,iBAAiB,CAAC,EAAC,CAAC,CAAC;QAC1E,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,EAAE,CAAC,EAAE,OAAO,EAAE,WAAW,CAAC,CAAC;QAC1E,uBAAuB,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACpE,OAAO,GAAG,CAAC;IACb,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEkC,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICrDD;;;;;;;;;;;;;;;;IAqBO,MAAM,KAAK,GAAG,gBAAgB,CAAC,EAAC,MAAM,EAAE,YAAY,CAAC,KAAK,EAAC,CAAC,CAAC;IAE7D,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC3BD;;;;;;;;;;;;;;;;UAqBa,aAAa;QAcxB,YAAY,QAAiC,EAAE,QAAqB;YATpE,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GACJ,0GAA0G,CAAC;;;YAG/G,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAEtD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YAErC,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAE3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,UAAU,QAAQ,EAAE,CAAC;YACtC,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;SAC1B;QAED,WAAW;YACT,IAAI,aAAa,GAAG,wCAAwC,CAAC;YAC7D,IAAI,IAAI,CAAC,QAAQ,KAAK,KAAK,EAAE;gBAC3B,aAAa,GAAG,yDAAyD,CAAC;aAC3E;YAED,IAAI,WAAW,GAAG,aAAa,CAAC;YAChC,IAAI,IAAI,CAAC,QAAQ,KAAK,KAAK,EAAE;gBAC3B,WAAW,GAAG,qBAAqB,CAAC;aACrC;YAED,MAAM,QAAQ,GAAG;QACbvB,mBAAI,CAAC,OAAO,CAAC;;;;;;;;8BASb,IAAI,CAAC,QAAQ,KAAK,KAAK,GAAG,KAAK,GAAG,yBAAyB;;;;;;;;;;;;;;;;;gBAiBnD,aAAa;;;;oCAIO,WAAW;;;KAG1C,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC9FH;;;;;;;;;;;;;;;;UAqBa,kCAAkC;QAU7C,YAAY,QAAiC;YAL7C,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,qBAAqB,CAAC;YACjC,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACtD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAE3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,6BAA6B,CAAC;SAChD;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACbA,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;KAchB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC3DH;;;;;;;;;;;;;;;;UAqBa,aAAa;QAYxB,YACI,UAAmC,EACnC,UAA2C;YAT/C,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,mBAAmB,CAAC;YAG/B,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,UAAU,GAAG,CAAC,UAAU,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,CAAC,CAAC;YAC5D,MAAM,CAAC,WAAW,EAAG,GACjBZ,eAAY,CAAC,yBAAyB,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACjE,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC;YAEhE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;;;YAG3D,IAAI,CAAC,QAAQ;gBACT,eAAe,CAAC,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEtE,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,SAAS,GAAG,UAAU,UAAU,EAAE,CAAC;SACzC;QAED,WAAW;YACT,IAAI,QAAQ,GAAG,EAAE,CAAC;YAClB,IAAI,SAAS,GAAG,KAAK,CAAC;YACtB,IAAI,IAAI,CAAC,UAAU,KAAK,KAAK,IAAI,IAAI,CAAC,UAAU,KAAK,KAAK,EAAE;gBAC1D,QAAQ,GAAG;;;qDAIP,IAAI,CAAC,UAAU,KAAK,KAAK,GAAG,GAAG,GAAG,GAAG;uCACR,CAAC;gBAClC,SAAS,GAAG,gBAAgB,CAAC;aAC9B;iBAAM,IAAI,IAAI,CAAC,UAAU,KAAK,KAAK,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAClE,QAAQ,GAAG,sCAAsC,CAAC;aACnD;iBAAM,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBACrC,QAAQ,GAAG,sCAAsC,CAAC;gBAClD,SAAS,GAAG,KAAK,CAAC;aACnB;YAED,MAAM,aAAa,GAAG,IAAI,CAAC,UAAU,KAAK,MAAM;;gBAE5C,sEAAsE;gBACtE,2CAA2C,CAAC;YAEhD,MAAM,mBAAmB,GAAG;mDACmB,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;QAChE,CAAC;YAEL,MAAM,QAAQ,GAAG;;;;;SAKZ,mBAAmB;;;wBAIpB,IAAI,CAAC,WAAW,CAAC,MAAM,KAAK,CAAC;YACzB,cAAc;YACd,iBAAiB;;;SAGpBY,mBAAI,CAAC,OAAO,CAAC;;;2BAGK,SAAS;;;;;;aAMvB,QAAQ;;;;;;;;;;;cAWP,QAAQ;;;;;;;;YAQV,aAAa;;;MAGnB,CAAC;YACH,OAAO,QAAQ,CAAC;SACjB;;;IC7HH;;;;;;;;;;;;;;;;aA4BgB,MAAM,CAClB,CAAa,EAAE,IAAqB,EAAE,QAAiB,EACvD,UAAuB,EAAE,OAAsB;QACjD,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,SAAS,GAAG,EAAE,CAAC;QAErB,MAAM,QAAQ,GAAGX,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QACpD,IAAI,IAAI,GAAG,QAAQ,CAAC;QACpB,MAAM,YAAY,GAAGD,eAAY,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QAElE,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,KAAK,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,YAAY,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACvE,IAAI,GAAGA,eAAY,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;YACzD,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACvB;QAEDA,eAAY,CAAC,0BAA0B,CAAC,UAAU,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;QAEjE,MAAM,CAAC,cAAc,EAAE,WAAW,CAAC,GAC/BA,eAAY,CAAC,yBAAyB,CAAC,KAAK,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;QAC9D,IAAI,WAAW,GAAG,cAAc,CAAC;QACjC,IAAI,QAAQ,EAAE;;YAEZ,WAAW,GAAGA,eAAY,CAAC,oBAAoB,CAAC,cAAc,EAAE,QAAQ,CAAC,CAAC;SAC3E;QAED,IAAI,GAAG,CAAC;QACR,IAAI,CAAC,UAAU,KAAK,KAAK,IAAI,UAAU,KAAK,MAAM;YAC9C,OAAO,CAAC,kBAAkB,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;YACvC,MAAM,KAAK,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,MAAoB,CAAC;YACvE,QAAQ,UAAU;gBAChB,KAAK,KAAK;oBACR,MAAM,SAAS,GAAG,UAAU,CACxB,KAAK,EAAEC,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;oBAClE,GAAG,GAAG,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;oBAC9D,MAAM;gBACR,KAAK,MAAM;oBACT,MAAM,EAAC,OAAO,EAAE,QAAQ,EAAE,QAAQ,EAAC,GAC/B,WAAW,CAAC,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBACvD,GAAG,GAAG,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,QAAQ,EAAE,OAAO,CAAC,CAAC;oBAC1D,MAAM;gBACR;oBACE,MAAM,IAAI,KAAK,CACX,GAAG,UAAU,2CAA2C,CAAC,CAAC;aACjE;SACF;aAAM;YACL,MAAM,MAAM,GAAGA,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;YAC/C,MAAM,KAAK,GAAGA,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;YAC9C,MAAM,SAAS,GAAG,KAAK,GAAG,MAAM,CAAC;YAEjC,MAAM,UAAU,GAAG,EAAC,UAAU,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC;YACvE,MAAM,KAAK,GAAG,UAAU,KAAK,MAAM,GAAG,SAAS,GAAGmC,aAAU,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACtE,MAAM,WAAW,GAAG;gBAClB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,MAAM,CAAC,EAAC;aAChC,CAAC;YACF,MAAM,OAAO,GAAG,IAAI,aAAa,CAAC,UAAU,EAAE,UAAU,CAAC,CAAC;YAC1D,MAAM,OAAO,GACT,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;YACnE,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;YAExB,GAAG,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SAC7E;QAED,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QAEtD,OAAO,GAAG,CAAC;IACb;;IC/FA;;;;;;;;;;;;;;;;aAsBgB,GAAG,CACf,IAAkE;QAEpE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,gBAAgB,EAAE,QAAQ,EAAC,GAAG,KAAK,CAAC;QAE3C,OAAO,MAAM,CAAC,CAAC,EAAE,gBAAgB,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IAC/D,CAAC;IAEM,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAuB;KACpC;;ICpCD;;;;;;;;;;;;;;;;aAsBgB,IAAI,CAChB,IAAoE;QAEtE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,QAAQ,EAAE,IAAI,EAAC,GAAG,KAAK,CAAC;QAE/B,OAAO,MAAM,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;IACpD,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICpCD;;;;;;;;;;;;;;;;aA4BgB,QAAQ,CACpB,CAAa,EAAE,QAAiC,EAAE,QAAkB,EACpE,OAAsB;QACxB,IAAI,QAAQ,CAAC,WAAW,KAAK,CAAC,IAAI,QAAQ,CAAC,YAAY,KAAK,CAAC;YACzDrC,OAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,OAAO,EAAE,QAAQ,CAAC,QAAQ,CAAC,EAAE;YACzD,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SACzC;QAED,IAAI,QAAQ,CAAC,WAAW,KAAK,QAAQ,CAAC,OAAO;YACzC,QAAQ,CAAC,YAAY,KAAK,QAAQ,CAAC,QAAQ,IAAI,QAAQ,CAAC,SAAS,KAAK,CAAC;YACvE,QAAQ,CAAC,OAAO,CAAC,IAAI,KAAK,OAAO,EAAE;YACrC,MAAM,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;YAC9B,MAAM,QAAQ,GAAG,OAAO,CAAC;gBACvB,MAAM,EAAE,EAAC,CAAC,EAAC;gBACX,OAAO;gBACP,KAAK,EAAE;oBACL,KAAK,EAAE;wBACL,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;wBACzC,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;qBACpB;iBACF;aACF,CAAC,CAAC;YACH,IAAI,OAAO,CAAC;YACZ,IAAI,QAAQ,KAAK,KAAK,EAAE;gBACtB,OAAO,GAAG,IAAI,CACV,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,CAAC,EAAE,QAAQ,EAAE,KAAK,EAAC,EAAC,CAAC,CAAC;aAC1E;iBAAM;gBACLA,OAAI,CAAC,MAAM,CAAC,QAAQ,KAAK,KAAK,EAAE,MAAM,qBAAqB,QAAQ,EAAE,CAAC,CAAC;gBACvE,OAAO,GAAG,GAAG,CAAC;oBACZ,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC;oBACrB,OAAO;oBACP,KAAK,EAAE,EAAC,gBAAgB,EAAE,CAAC,EAAE,QAAQ,EAAE,KAAK,EAAC;iBAC9C,CAAC,CAAC;aACJ;YAED,MAAM,MAAM,GAAG,OAAO,CAClB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,CAAC,QAAQ,EAAC,EAAC,CAAC,CAAC;YACxE,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,WAAW,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;YACpC,OAAO,MAAM,CAAC;SACf;QAED,IAAI,OAAyD,CAAC;QAC9D,MAAM,UAAU,GACZ,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC,CAAC,CAAC;QAC3E,IAAI,QAAQ,CAAC,YAAY,KAAK,CAAC,IAAI,QAAQ,CAAC,WAAW,KAAK,CAAC,EAAE;YAC7D,OAAO,GAAG,IAAI,kCAAkC,CAAC,QAAQ,CAAC,CAAC;SAC5D;aAAM;YACL,IAAI,QAAQ,KAAK,KAAK,EAAE;gBACtB,OAAO,GAAG,IAAI,aAAa,CAAC,QAAQ,EAAE,KAAK,CAAC,CAAC;aAC9C;iBAAM;gBACLA,OAAI,CAAC,MAAM,CAAC,QAAQ,KAAK,KAAK,EAAE,MAAM,qBAAqB,QAAQ,EAAE,CAAC,CAAC;gBACvE,OAAO,GAAG,IAAI,aAAa,CAAC,QAAQ,EAAE,KAAK,CAAC,CAAC;aAC9C;YAED,UAAU,CAAC,IAAI,CACX,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAC,EAAE;gBACpE,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE,CAAC,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,aAAa,CAAC;aACxD,EACD,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,OAAO,CAAC,EAAC,EAAE;gBAC5D,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE,CAAC,QAAQ,CAAC,qBAAqB,EAAE,QAAQ,CAAC,oBAAoB,CAAC;aACtE,CAAC,CAAC;SACR;QAED,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAU,CAAC,CAAC;IACrE;;IC/FA;;;;;;;;;;;;;;;;aAqBgB,OAAO,CACnB,IAA0E;QAE5E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,UAAU,EAAE,OAAO,EAAE,GAAG,EAAE,eAAe,EAAC,GAAG,KAAK,CAAC;QAC1D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAGD,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAAE,UAAU,EAAE,OAAO,EAChE,SAAS,EAAE,GAAG,EAAE,eAAe,CAAC,CAAC;QAErC,OAAO,QAAQ,CAAC,CAAC,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IAC/C,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEuC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;ICvCD;;;;;;;;;;;;;;;;aAsBgB,WAAW,CAAC,IAI3B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,CAAC,EAAC,GAAG,MAAM,CAAC;QACtB,MAAM,EAAC,UAAU,EAAE,UAAU,EAAC,GAAG,KAAK,CAAC;QAEvC,OAAO,eAAe,CAAC,EAAC,CAAC,EAAE,CAAC,EAAE,UAAU,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;IAClE,CAAC;IAEM,MAAM,iBAAiB,GAAiB;QAC7C,UAAU,EAAEC,cAAW;QACvB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,WAA+B;KAC5C;;ICtCD;;;;;;;;;;;;;;;;UAoBa,YAAY;QAavB,YAAY,KAAe,EAAE,QAAkB;YAZ/C,kBAAa,GAAG,CAAC,QAAQ,CAAC,CAAC;YAO3B,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC;YAC5B,IAAI,CAAC,IAAI,GAAG,QAAQ,CAAC,MAAM,CAAC;YAC5B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEhC,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC;YACnB,IAAI,CAAC,QAAQ,GAAG,WAAW,iBAAiB,CAAC,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,OAAO,CAAC;SAC1B;QAED,WAAW;YACT,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC3C,MAAM,YAAY,GAAGC,WAAS,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC1C,IAAI,QAAQ,CAAC;YACb,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC3B,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;oBACnC,OAAO,sCAAsC,CAAC;iBAC/C,CAAC,CAAC;aACJ;iBAAM;gBACL,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;oBACnC,OAAO,aAAa,MAAM,CAAC,CAAC,CAAC,qBACzB,YAAY,CAAC,CAAC,CAAC,aAAa,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC;iBAC9C,CAAC,CAAC;aACJ;YAED,MAAM,QAAQ,GAAG;QACb7B,mBAAI,CAAC,OAAO,CAAC;;4BAEO,KAAK;;YAErB,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC;8CACe,YAAY;;;KAGrD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;KACF;IAED,MAAM,MAAM,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;IAE9C,SAAS6B,WAAS,CAAC,IAAY;QAC7B,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,OAAO,WAAW,CAAC;SACpB;aAAM,IAAI,IAAI,IAAI,CAAC,EAAE;YACpB,OAAO,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,CAAC,KAAK,IAAI,aAAa,KAAK,EAAE,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;SAC3E;aAAM;YACL,MAAM,KAAK,CAAC,oBAAoB,IAAI,uBAAuB,CAAC,CAAC;SAC9D;IACH;;ICrFA;;;;;;;;;;;;;;;;aAuBgB,KAAK,CACjB,IAAsE;QAExE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,KAAK,EAAE,IAAI,EAAC,GAAG,KAAK,CAAC;QAE5B,MAAM,CAAC,MAAM,EAAE,KAAK,CAAC,GAAGjB,aAAU,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;QACpEA,aAAU,CAAC,iBAAiB,CAAC,CAAC,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;QAE/C,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YAC3D,MAAM,WAAW,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YACpD,MAAM,SAAS,GAAG,YAAY,CAC1B,WAAW,CAAC,MAAoB,EAAE,MAAM,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;YACvE,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;SAC1D;QAED,IAAIvB,OAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;YACnC,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;SACnD;;QAGD,MAAM,OAAO,GAAG,IAAI,YAAY,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;QAChD,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,MAAM,EAAC,CAAC,CAAC;QACpD,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IACtE,CAAC;IAEM,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEyC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAyB;KACtC;;ICtDD;;;;;;;;;;;;;;;;IAyBO,MAAM,cAAc,GAAG,CAAC,IAI9B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,UAAU,EAAE,KAAK,EAAC,GAAG,KAAK,CAAC;QAElCzC,OAAI,CAAC,MAAM,CACP,CAAC,CAAC,KAAK,CAAC,MAAM,IAAI,CAAC,EACnB,MAAM,wDAAwD;YAC1D,iBAAiB,CAAC,CAAC;QAC3B,MAAM,IAAI,GAAG,UAAU,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;QAEhD,MAAM,QAAQ,GAAGD,eAAY,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC;QACrE,MAAM,QAAQ,GAAGA,eAAY,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,EAAE,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9E,MAAM,gBAAgB,GAClBA,eAAY,CAAC,mBAAmB,CAAC,CAAC,CAAC,KAAK,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC;QAChE,MAAM,gBAAgB,GAClBA,eAAY,CAAC,mBAAmB,CAAC,KAAK,EAAE,UAAU,CAAC,MAAM,CAAC,CAAC;QAC/D,MAAM,SAAS,GACXA,eAAY,CAAC,YAAY,CAAC,gBAAgB,EAAE,KAAK,EAAE,UAAU,CAAC,MAAM,CAAC,CAAC;QAE1E,MAAM,SAAS,GAAG,EAAE,CAAC;QAErB,MAAM,oBAAoB,GACtB,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QAC9D,MAAM,sBAAsB,GAAG,SAAS,CACpC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,oBAAoB,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QAC3E,MAAM,qBAAqB,GAAG,OAAO,CAAC;YACpC,MAAM,EAAE,EAAC,CAAC,EAAE,sBAAsB,EAAC;YACnC,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,gBAAgB,EAAC;SACjC,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,KAAK,CAAC;YACnB,MAAM,EAAE,EAAC,CAAC,EAAE,qBAAqB,EAAC;YAClC,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,gBAAgB,EAAE,IAAI,EAAE,SAAS,EAAC;SAClD,CAAC,CAAC;QAEH,SAAS,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACrC,SAAS,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;QACvC,SAAS,CAAC,IAAI,CAAC,qBAAqB,CAAC,CAAC;QAEtC,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QAEtD,OAAO,MAAM,CAAC;IAChB,CAAC,CAAC;IAEK,MAAM,oBAAoB,GAAiB;QAChD,UAAU,EAAE2C,iBAAc;QAC1B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,cAAkC;KAC/C;;IC/ED;;;;;;;;;;;;;;;;IAuBO,MAAM,QAAQ,GAAG,gBAAgB,CAAC;QACvC,MAAM,EAAE,YAAY,CAAC,SAAS;QAC9B,KAAK,EAAE,MAAM;QACb,aAAa,EAAEC,eAAW;KAC3B,CAAC,CAAC;IAEI,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAEC,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAAQ;KACrB;;ICjCD;;;;;;;;;;;;;;;;aAsBgB,IAAI,CAAC,IAAkD;QAErE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,KAAK,EAAC,GAAG,MAAM,CAAC;QACvB,MAAM,SAAS,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAEtD,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,SAAS,CAAC,kBAAkB,CAAC,IAAI,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;IAC7E,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICnCD;;;;;;;;;;;;;;;;aAsBgB,GAAG,CAAC,KAAiB,EAAE,OAAsB;QAC3D,MAAM,OAAO,GAAG,IAAI,cAAc,CAAC,KAAK,CAAC,KAAK,EAAE,WAAW,CAAC,MAAM,CAAC,CAAC;QACpE,MAAM,MAAM,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,EAAE,OAAO,CAAC,CAAC;QACnE,OAAO,EAAC,MAAM,EAAE,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAC,CAAC;IAC3E;;IC1BA;;;;;;;;;;;;;;;;aA6BgB,IAAI,CAChB,IAAoE;QAEtE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,KAAK,EAAC,GAAG,KAAK,CAAC;;QAGtB,IAAI,KAAK,KAAK,WAAW,EAAE;YACzB,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;gBAC3B,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;aACzC;;YAGD,MAAM,WAAW,GAAGC,aAAE,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACtC,MAAM,MAAM,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,SAAS,EAAC,EAAC,CAAC,CAAC;YAEvE,MAAM,MAAM,GACR,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,IAAI,EAAE,MAAM,EAAE,IAAI,EAAE,WAAW,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAElE,WAAW,CAAC,OAAO,EAAE,CAAC;YACtB,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YAEnC,OAAO,MAAM,CAAC;SACf;;QAGD,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;YAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,MAAM,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAC,EAAC,CAAC,CAAC;YACtE,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,MAAM,CAAC;SACf;QAED,IAAI,CAAC9C,OAAI,CAAC,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,EAAE;;;YAGzC,MAAM,MAAM,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAChD,OAAO,EAAC,MAAM,EAAE,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,KAAK,EAAC,CAAC;SAC5D;QAED,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;YACnC,MAAM,MAAM,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB,CAAC;YACpE,MAAM,CAAC,WAAW,EAAE,UAAU,EAAE,UAAU,CAAC,GACvC,WAAW,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;YACjD,OAAO,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC;SACpE;QAED,IAAI,KAAK,KAAK,OAAO,EAAE;YACrB,OAAO,GAAG,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;SACxB;QAED,IAAI,KAAK,KAAK,MAAM,EAAE;YACpB,MAAM,eAAe,GAAG,OAAO,CAAC,cAAc,CAC1C,EAAE,EAAE,MAAM,EAAEA,OAAI,CAAC,sBAAsB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC,CAAC;YAExD,MAAM,YAAY,GAAiB,EAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC;YAE9D,MAAM,MAAM,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,YAAY,EAAE,OAAO,EAAC,CAAe,CAAC;YACvE,OAAO,CAAC,WAAW,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;YAC5C,OAAO,MAAM,CAAC;SACf;QAED,MAAM,IAAI,KAAK,CAAC,iCAAiC,CAAC,CAAC,KAAK,OAAO,KAAK,EAAE,CAAC,CAAC;IAC1E,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAE+C,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICnGD;;;;;;;;;;;;;;;;IAsBO,MAAM,IAAI,GACb,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAE,aAAa,EAAE,WAAW,EAAC,CAAC,CAAC;IAErE,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC7BD;;;;;;;;;;;;;;;;UAoBa,eAAe;QAY1B,YAAY,WAAqB;YATjC,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,6BAA6B,CAAC;YAGzC,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,WAAM,GAAG,IAAI,CAAC;YACd,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAChC,IAAI,CAAC,SAAS,GAAG,UAAU,CAAC;SAC7B;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACbrC,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;KAehB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC5DH;;;;;;;;;;;;;;;;UAoBa,WAAW;QAYtB,YAAY,WAAqB;YATjC,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,6BAA6B,CAAC;YAGzC,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAGrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC;SACzB;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACbA,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;KAUhB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICvDH;;;;;;;;;;;;;;;;aAwBgB,WAAW,CAAC,IAI3B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,YAAY,EAAE,YAAY,EAAC,GAAG,KAAK,CAAC;QAE3C,IAAI,OAAoC,CAAC;QACzC,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,YAAY,CAAC,EAAC;YACvC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,YAAY,CAAC,EAAC;SACxC,CAAC;QACF,IAAIX,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;YACzC,OAAO,GAAG,IAAI,eAAe,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;SACxC;aAAM;YACL,OAAO,GAAG,IAAI,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;SACpC;QACD,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IACtE,CAAC;IAEM,MAAM,iBAAiB,GAAiB;QAC7C,UAAU,EAAEiD,cAAW;QACvB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,WAA+B;KAC5C;;IClDD;;;;;;;;;;;;;;;;UAqBa,aAAa;QAYxB,YAAY,MAA+B;YAN3C,aAAQ,GAAG,EAAE,CAAC;YACd,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAIV,IAAI,CAAC,WAAW;gBACZlD,eAAY,CAAC,eAAe,CAAC,MAAM,EAAE,CAAC,YAAgC,CAAC;YAC3E,IAAI,CAAC,aAAa,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,IAAI,CAAC,EAAE,CAAC,CAAC;YACnD,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEhC,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;YACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,YAAY,EAAE,CAAC,EAAE,EAAE;gBAC1C,IAAI,CAAC,QAAQ,IAAI,SAAS,CAAC,SAAS,CAAC;aACtC;YACD,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;SAC3B;QAED,WAAW;YACT,MAAM,QAAQ,GAAa,EAAE,CAAC;YAC9B,IAAI,IAAI,CAAC,YAAY,GAAG,CAAC,EAAE;gBACzB,QAAQ,CAAC,IAAI,CACT,qFAAqF,CAAC,CAAC;gBAC3F,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,YAAY,EAAE,CAAC,EAAE,EAAE;oBAC1C,QAAQ,CAAC,IAAI,CACT,gCAAgC,CAAC,CAAC,CAAC,KAAK;wBACxC,6CACI,CAAC,4BAA4B,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC;iBACpD;gBACD,MAAM,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC;gBACpC,MAAM,cAAc,GAAG,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC;gBAC7C,QAAQ,CAAC,IAAI,CAAC,oDACV,SAAS,4BAA4B,cAAc,OAAO,CAAC,CAAC;aACjE;iBAAM;gBACL,QAAQ,CAAC,IAAI,CAAC,uDAAuD,CAAC,CAAC;aACxE;YAED,MAAM,QAAQ,GAAG;QACbY,mBAAI,CAAC,OAAO,CAAC;6BACQ,IAAI,CAAC,aAAa;oCACX,IAAI,CAAC,aAAa;;;;;;cAMxC,QAAQ,CAAC,IAAI,CAAC,YAAY,CAAC;;;;KAIpC,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICnFH;;;;;;;;;;;;;;;;aAsBgB,IAAI,CAAC,IAAkD;QAErE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,KAAK,EAAC,GAAG,MAAM,CAAC;QACvB,MAAM,SAAS,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAEtD,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,SAAS,CAAC,kBAAkB,CAAC,IAAI,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;IAC7E,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEuC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICnCD;;;;;;;;;;;;;;;;aA4BgB,UAAU,CACtB,MAAoB,EAAE,IAAY,EAAE,OAAsB;QAC5D,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QAC9B,IAAI,KAAK,KAAK,WAAW,EAAE;YACzB,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;YACrE,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;YAErE,MAAM,YAAY,GAAG,UAAU,CAAC,KAAK,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;YACtD,MAAM,YAAY,GAAG,UAAU,CAAC,KAAK,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;YAEtD,MAAM,MAAM,GACR,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,IAAI,EAAE,YAAY,EAAE,IAAI,EAAE,YAAY,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAEzE,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;YAClD,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;YAClD,OAAO,CAAC,WAAW,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;YACzC,OAAO,CAAC,WAAW,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;YAEzC,OAAO,MAAM,CAAC;SACf;QAED,IAAI,QAAQ,GAAG,OAAO,CAAC,kBAAkB,CAAC,MAAM,CAAC,CAAC;;;;;;;QAQlD,IAAI,KAAK,KAAK,QAAQ,EAAE;YACtB,QAAQ,GAAG,IAAI,CAAC;SACjB;QAED,IAAI,QAAQ,EAAE;;;;;;;;YAQZ,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC;gBAC5B,MAAM,SAAS,GAAGlD,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;gBAC1D,MAAM,KAAK,GAAG,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;gBAC9B,OAAO,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAC,EAAC,CAAC,CAAC;aAC3D,CAAC,CAAC;YAEH,MAAM,eAAe,GAAG,SAAS,CAAC,GAAG,CAAC,CAAC;gBACrC,OAAO,EAAC,IAAI,EAAE,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC,CAAC;aAC3D,CAAC,CAAC;;YAGH,MAAM,QAAQ,GACVD,eAAY,CAAC,eAAe,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,YAAY,CAAC;YAC5E,MAAM,YAAY,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACjD,MAAM,OAAO,GACT,aAAa,CAAC,eAAe,EAAE,QAAQ,EAAE,KAAK,EAAE,YAAY,CAAC,CAAC;YAElE,MAAM,aAAa,GACfA,eAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,CAAC;YAEjE,MAAM,OAAO,GAAG,OAAO,CAAC,cAAc,CAAC,aAAa,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;YAEtE,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;YAEtD,OAAO,OAAO,CAAC;SAChB;;;QAID,MAAM,WAAW,GAAG,OAAO,CAAC,MAAM,CAAC,MAAM,CAAC,+BAA+B,GAAG,CAAC,CAAC;QAC9E,IAAI,MAAM,CAAC,MAAM,GAAG,WAAW,EAAE;YAC/B,MAAM,aAAa,GAAG,EAAE,CAAC;YACzB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,IAAI,WAAW,EAAE;gBACnD,MAAM,QAAQ,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,CAAC;gBAClD,aAAa,CAAC,IAAI,CAAC,UAAU,CAAC,QAAQ,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC,CAAC;aACzD;YACD,MAAM,MAAM,GAAG,UAAU,CAAC,aAAa,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;YAExD,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;gBAC7B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;aAC/B;YAED,OAAO,MAAM,CAAC;SACf;QAED,MAAM,EAAC,SAAS,EAAE,QAAQ,EAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;QACtE,MAAM,MAAM,GAAG,CAAC,SAAS,EAAE,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAyB,CAAC,CAAC;QACjE,MAAM,OAAO,GAAG,IAAI,aAAa,CAAC,MAAM,CAAC,CAAC;QAE1C,MAAM,WAAW,GAA0C,EAAE,CAAC;QAC9D,MAAM,OAAO,GAAa,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACvD,IAAI,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;YACtB,OAAO,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC1B,WAAW,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;YACtD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBACvC,OAAO,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC3C,WAAW,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;aACvD;SACF;QAED,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAChC,OAAO,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QACzD,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QAEtD,MAAM,cAAc,GAChB,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;QACnE,OAAO,CAAC,WAAW,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAChC,OAAO,cAAc,CAAC;IACxB,CAAC;IAED,SAAS,gBAAgB,CACrB,MAAoB,EAAE,IAAY,EAAE,OAAsB;QAC5D,MAAM,QAAQ,GAAGA,eAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,CAAC;QAC9E,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,OAAO,CAAC;YACX,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC;YACd,OAAO;YACP,KAAK,EAAE;gBACL,KAAK,EAAE;oBACLC,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;oBAC1CA,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;iBACxC;aACF;SACF,CAAC,CAAC,CAAC;QAEjC,OAAO,EAAC,SAAS,EAAE,QAAQ,EAAC,CAAC;IAC/B;;IC1JA;;;;;;;;;;;;;;;;aAwBgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QAErB,MAAM,KAAK,GAAGA,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAE5D,MAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC;QACxCD,eAAY,CAAC,sBAAsB,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;QAEnD,MAAM,QAAQ,GACVA,eAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,CAAC;QAClE,IAAIC,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAE;YACtC,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;SAC9D;;QAGD,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAIA,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;QACpE,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SACrD;QAED,OAAO,UAAU,CAAC,OAAO,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEmD,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICtDD;;;;;;;;;;;;;;;;IAwBA,SAAS,mBAAmB,CACxB,cAAuB,EAAE,SAAkB,EAAE,SAAkB,EAC/D,QAAiB,EAAE,OAAO,GAAG,KAAK,EAClC,aAAsC,IAAI,EAC1C,yBAAyB,GAAG,KAAK,EAAE,iBAAiB,GAAG,CAAC,EACxD,iBAAiB,GAAG,CAAC,EAAE,gBAAgB,GAAG,CAAC;QAC7C,MAAM,WAAW,GAAG,CAAC,gBAAwB;YAC3C,QAAQ,gBAAgB;gBACtB,KAAK,CAAC;oBACJ,OAAO,sBAAsB,CAAC;gBAChC,KAAK,CAAC;oBACJ,OAAO,+DAA+D,CAAC;gBACzE,KAAK,CAAC;oBACJ,OAAO,0BAA0B,CAAC;gBACpC;oBACE,MAAM,IAAI,KAAK,CACX,oBAAoB,gBAAgB,oBAAoB,CAAC,CAAC;aACjE;SACF,CAAC;QACF,MAAM,WAAW,GAAG,CAAC,gBAAwB;YAC3C,QAAQ,gBAAgB;gBACtB,KAAK,CAAC;oBACJ,OAAO,6CAA6C,CAAC;gBACvD,KAAK,CAAC;oBACJ,OAAO,iDAAiD,CAAC;gBAC3D;oBACE,MAAM,IAAI,KAAK,CACX,oBAAoB,gBAAgB,oBAAoB,CAAC,CAAC;aACjE;SACF,CAAC;QACF,MAAM,aAAa,GAAG,cAAc,GAAG;;OAElC;YACkC;;OAElC,CAAC;QAEN,MAAM,eAAe,GAAG,cAAc,GAAG;;;;;;OAMpC;YACoC;;;;;;OAMpC,CAAC;QAEN,MAAM,MAAM,GAAG,cAAc,GAAG,oBAAoB,GAAG,oBAAoB,CAAC;QAC5E,MAAM,MAAM,GAAG,cAAc,GAAG,oBAAoB,GAAG,oBAAoB,CAAC;QAC5E,MAAM,GAAG,GAAG,cAAc,GAAG,KAAK,GAAG,KAAK,CAAC;QAC3C,MAAM,GAAG,GAAG,cAAc,GAAG,KAAK,GAAG,KAAK,CAAC;QAC3C,MAAM,YAAY,GAAG;;uBAGjB,cAAc,GAAG,sBAAsB,GAAG,sBAAsB;qBACjD,GAAG;qBACH,GAAG;;mBAEL,GAAG;mBACH,GAAG;;;kBAGJ,GAAG;sBACC,WAAW,CAAC,iBAAiB,CAAC;;;gCAGpB,MAAM,2BAA2B,MAAM;UAC7D,aAAa;;UAEb,WAAW,CAAC,iBAAiB,CAAC;;sBAElB,CAAC;QAErB,MAAM,OAAO,GAAG,cAAc,IAAI,SAAS,IAAI,QAAQ,GAAG;0BAClC,iBAAiB;QACnC,YAAY,EAAE;YACsC;0BAClC,iBAAiB;;UAEjC,YAAY;;eAEP,WAAW,CAAC,iBAAiB,CAAC,QAAQ;aACjB,QAAQ,IAAI,SAAS,GAAG;0BAClC,iBAAiB;QACnC,YAAY,EAAE;gBACsC;0BAClC,iBAAiB;;UAEjC,YAAY;;eAEP,WAAW,CAAC,iBAAiB,CAAC,QAAQ,CAAC,CAAC;QAErD,MAAM,OAAO,GAAG,GAAG,WAAW,CAAC,iBAAiB,CAAC,EAAE,CAAC;QAEpD,MAAM,OAAO,GAAG,WAAW,CAAC,gBAAgB,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,cAAc,GAAG,WAAW,CAAC,iBAAiB,CAAC;YAC9B,WAAW,CAAC,iBAAiB,CAAC,CAAC;QAC9D,MAAM,KAAK,GAAG,cAAc,GAAG,WAAW,CAAC,iBAAiB,CAAC;YAC9B,WAAW,CAAC,iBAAiB,CAAC,CAAC;QAC9D,MAAM,QAAQ,GAAG;QAEb,mBAAmB,CACf,UAAU,EAAE,yBAAyB,EAAE,gBAAgB,KAAK,CAAC,EAAE,CAAC,CAAC;2DAChB,KAAK;UACtD,cAAc,GAAG,OAAO,GAAG,OAAO;;;2DAGe,KAAK;UACtD,cAAc,GAAG,OAAO,GAAG,OAAO;;;kEAGsB,OAAO;4BAC7C,gBAAgB;;;;yBAKtC,cAAc,GAAG,sBAAsB,GAAG,sBAAsB;UAC5D,eAAe;UACf,qBAAqB,CAAC,OAAO,EAAE,UAAU,CAAC;;;QAG5C,CAAC;QACP,OAAO,QAAQ,CAAC;IAClB,CAAC;UAEY,eAAe;QAyB1B,YACI,QAAiC,EAAE,SAAiB,EAAE,SAAiB,EACvE,QAAgB,EAAE,OAAO,GAAG,KAAK,EACjC,aAAsC,IAAI,EAC1C,yBAAyB,GAAG,KAAK,EAAE,yBAAyB,GAAG,KAAK;YAxBxE,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAE3B,aAAQ,GACJ,sIAAsI,CAAC;YAsBzI,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;YAC7D,IAAI,CAAC,MAAM;gBACP,CAAC,CAAC,CAAC,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC,IAAI,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC;oBAC/D,IAAI,CAAC,cAAc;qBACnB,QAAQ,CAAC,QAAQ,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,cAAc,CAAC;oBACtD,QAAQ,CAAC,WAAW,GAAG,CAAC,KAAK,CAAC,CAAC;YACnC,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC;gBAC3B,EAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YACxE,IAAI,CAAC,aAAa,GAAG,6BAA6B,CAC9C,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;YACxD,IAAI,CAAC,iBAAiB,GAAG,6BAA6B,CAClD,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;YAExD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,IAAI,CAAC,iBAAiB,CAAC,CAAC;YAE5B,IAAI,IAAI,CAAC,MAAM,EAAE;gBACf,IAAI,IAAI,CAAC,cAAc,IAAI,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC,EAAE;oBACxD,IAAI,CAAC,gBAAgB,GAAG,CAAC,CAAC;oBAC1B,IAAI,CAAC,aAAa,GAAG,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;iBAC3C;qBAAM;oBACL,IAAI,CAAC,gBAAgB,GAAG,CAAC,CAAC;oBAC1B,IAAI,CAAC,aAAa,GAAG,CAAC,WAAW,EAAE,WAAW,CAAC,CAAC;iBACjD;gBAED,IAAI,OAAO,EAAE;oBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;oBAChC,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;iBACtC;gBAED,IAAI,yBAAyB,EAAE;oBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;oBAClD,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;iBACtC;aACF;iBAAM;gBACL,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;gBAClD,IAAI,OAAO,EAAE;oBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;iBACjC;gBAED,IAAI,yBAAyB,EAAE;oBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;iBACnD;aACF;YAED,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAC3D,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAE3D,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;YACpE,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC;YACpE,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,GAAG,CACrB,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,gBAAgB,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC;YAE1E,IAAI,CAAC,SAAS,GAAG,SAAS,GAAG,IAAI,CAAC,UAAU,KAAK,CAAC,CAAC;YACnD,IAAI,CAAC,SAAS,GAAG,SAAS,GAAG,IAAI,CAAC,UAAU,KAAK,CAAC,CAAC;YACnD,IAAI,CAAC,QAAQ,GAAG,QAAQ,GAAG,IAAI,CAAC,SAAS,KAAK,CAAC,CAAC;YAEhD,IAAI,CAAC,SAAS,GAAG,YAAY,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,UAAU,KAClE,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,MAAM,IAChE,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,cAAc,IAC5C,IAAI,CAAC,yBAAyB,EAAE,CAAC;SACtC;QAED,WAAW;YACT,MAAM,YAAY,GAAG,IAAI,CAAC,MAAM;gBAC5B,0BAA0B,CACtB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,IAAI,CAAC,cAAc,EAChE,IAAI,CAAC,SAAS,CAAC;gBACnB,sBAAsB,CAClB,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,IAAI,CAAC,cAAc,EAChE,IAAI,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,yBAAyB,CAAC,CAAC;YACrE,MAAM,YAAY,GACd,IAAI,CAAC,MAAM,GAAG,CAAC,IAAI,CAAC,gBAAgB,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC5D,MAAM,QAAQ,GAAG;MAEb,mBAAmB,CACf,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAClE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,EAC7D,YAAY,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC;MACxD,YAAY;GACf,CAAC;YACA,OAAO,QAAQ,CAAC;SACjB;;;IC/QH;;;;;;;;;;;;;;;;UAuBa,kBAAkB;QAc7B,YACI,QAAiC,EAAE,OAAO,GAAG,KAAK,EAClD,aAAsC,IAAI,EAC1C,yBAAyB,GAAG,KAAK;YAZrC,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GACJ,gFAAgF,CAAC;YACrF,kBAAa,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAUlD,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;YAC7D,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC;gBAC3B,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC;YACxE,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,yBAAyB,GAAG,yBAAyB,CAAC;YAE3D,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YAED,IAAI,yBAAyB,EAAE;gBAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,SAAS,GAAG,eAAe,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC;SAC1E;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;SAEb,mBAAmB,CACf,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,yBAAyB,EAAE,KAAK,EAAE,CAAC,CAAC;;;;;;;;;;;;;;;;;;wBAmB9D,IAAI,CAAC,cAAc,GAAG,mCAAmC;YACnC,mCAAmC;;;aAGpD,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC;;;;SAIxDxC,mBAAI,CAAC,OAAO,CAAC;;;4BAGM,IAAI,CAAC,cAAc,GAAG,YAAY,GAAG,YAAY;wBACrD,IAAI,CAAC,cAAc,GAAG,YAAY,GAAG,YAAY;wBACjD,IAAI,CAAC,cAAc,GAAG,YAAY,GAAG,YAAY;;;;;;iDAOjE,IAAI,CAAC,cAAc,GAAG,qBAAqB;YACrB,qBAAqB;iBAE3C,IAAI,CAAC,cAAc,GAAG,+CAA+C;YAC/C,+CAA+C;;;;;;;;MAQvE,CAAC;YACH,OAAO,QAAQ,CAAC;SACjB;;;ICvHH;;;;;;;;;;;;;;;;IAsCA;IACA;IACA;IACA;IACA;IACA;IACA,SAAS,sBAAsB,CAC3B,KAAe,EAAE,cAAuB;QAC1C,MAAM,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QAC5B,IAAI,MAAM,IAAI,CAAC,EAAE;YACf,OAAO,cAAc;gBACjB;oBACE,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;oBACrB,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;oBACrC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;iBAClB;gBACD;oBACE,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,cAAc,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;oBACpD,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;iBACtC,CAAC;SACP;aAAM,IAAI,CAAC,cAAc,IAAI,MAAM,KAAK,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;YAC1D,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SACtB;aAAM;YACL,OAAO,IAAI,CAAC;SACb;IACH,CAAC;IAED;IACA;IACA;IACA,SAAS,cAAc,CAAC,EACtB,CAAC,EACD,MAAM,EACN,QAAQ,EACR,OAAO,EACP,IAAI,GAAG,IAAI,EACX,sBAAsB,GAAG,IAAI,EAC7B,cAAc,GAAG,CAAC,EAClB,UAAU,GAAG,IAAI,EACJ;QACb,MAAM,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;QAC9D,MAAM,UAAU,GAAG,cAAc,GAAG,KAAK,GAAG,IAAI,CAAC;QACjD,MAAM,UAAU,GAAG,KAAK,CAAC;QAEzB,MAAM,QAAQ,GAAG,cAAc;YAC3B,QAAQ,CAAC,YAAY,KAAK,QAAQ,CAAC,QAAQ;YAC3C,QAAQ,CAAC,WAAW,KAAK,QAAQ,CAAC,OAAO;YACzC,QAAQ,CAAC,OAAO,CAAC,IAAI,KAAK,OAAO,CAAC;QACtC,MAAM,aAAa,GAAiB,EAAE,CAAC;QACvC,IAAI,SAAS,CAAC;QACd,IAAI,cAAc,CAAC;QAEnB,IAAI,QAAQ,EAAE;YACZ,MAAM,SAAS,GACX,QAAQ,CAAC,QAAQ,GAAG,QAAQ,CAAC,OAAO,GAAG,QAAQ,CAAC,UAAU,CAAC;YAC/D,SAAS,GAAG,OAAO,CAAC;gBAClB,MAAM,EAAE,EAAC,CAAC,EAAC;gBACX,OAAO;gBACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,QAAQ,CAAC,SAAS,EAAE,SAAS,CAAC,EAAC;aACnD,CAAC,CAAC;YACH,cAAc,GAAG,OAAO,CAAC;gBACvB,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;gBACnB,OAAO;gBACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,SAAS,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;aACrD,CAAC,CAAC;SACJ;aAAM;YACL,SAAS,GAAG,OAAO,CAAC;gBAClB,MAAM,EAAE,EAAC,CAAC,EAAC;gBACX,OAAO;gBACP,KAAK,EAAE;oBACL,KAAK,EAAE,cAAc;wBACjB;4BACE,QAAQ,CAAC,SAAS,EAAE,QAAQ,CAAC,QAAQ,GAAG,QAAQ,CAAC,OAAO;4BACxD,QAAQ,CAAC,UAAU;yBACpB;wBACD;4BACE,QAAQ,CAAC,SAAS,EAAE,QAAQ,CAAC,UAAU;4BACvC,QAAQ,CAAC,QAAQ,GAAG,QAAQ,CAAC,OAAO;yBACrC;iBACN;aACF,CAAC,CAAC;YACH,cAAc,GAAG,OAAO,CAAC;gBACvB,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;gBACnB,OAAO;gBACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,QAAQ,CAAC,UAAU,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;aAC/D,CAAC,CAAC;SACJ;QACD,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QAC9B,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAEnC,IAAI,sBAAsB,IAAI,IAAI,EAAE;YAClC,MAAM,WAAW,GACb,sBAAsB,CAAC,sBAAsB,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;YACzE,IAAI,WAAW,IAAI,IAAI,EAAE;gBACvB,sBAAsB,GAAG,OAAO,CAAC;oBAC/B,MAAM,EAAE,EAAC,CAAC,EAAE,sBAAsB,EAAC;oBACnC,OAAO;oBACP,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC;iBAC5B,CAAC,CAAC;gBACH,aAAa,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;aAC5C;SACF;QAED,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,MAAM,WAAW,GAAG,sBAAsB,CAAC,IAAI,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;YACvE,IAAI,WAAW,IAAI,IAAI,EAAE;gBACvB,IAAI,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,IAAI,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC,EAAC,CAAC,CAAC;gBAC1E,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;aAC1B;SACF;QAED,MAAM,MAAM,GAAG,eAAe,CAAC;YAC7B,CAAC,EAAE,cAAc,GAAG,SAAS,GAAG,cAAc;YAC9C,CAAC,EAAE,cAAc,GAAG,cAAc,GAAG,SAAS;YAC9C,UAAU;YACV,UAAU;YACV,OAAO;YACP,IAAI;YACJ,UAAU;YACV,sBAAsB;YACtB,cAAc;SACf,CAAC,CAAC;QACH,MAAM,GAAG,GAAG,OAAO,CACf,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,CAAC,QAAQ,EAAC,EAAC,CAAC,CAAC;QACvE,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QAE3B,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;YAC7B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;SAC/B;QAED,OAAO,GAAG,CAAC;IACb,CAAC;aAEe,UAAU,CAAC,EACzB,CAAC,EACD,MAAM,EACN,QAAQ,EACR,OAAO,EACP,IAAI,GAAG,IAAI,EACX,sBAAsB,GAAG,IAAI,EAC7B,cAAc,GAAG,CAAC,EAClB,UAAU,GAAG,IAAI,EACJ;QACb,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;QAC7B,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;QACjE,MAAM,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;QAC9D,MAAM,QAAQ,GAAG,cAAc;YAC3B,QAAQ,CAAC,YAAY,KAAK,QAAQ,CAAC,QAAQ;YAC3C,QAAQ,CAAC,WAAW,KAAK,QAAQ,CAAC,OAAO;YACzC,QAAQ,CAAC,OAAO,CAAC,IAAI,KAAK,OAAO,CAAC;QACtC,MAAM,cAAc,GAAGb,MAAG,EAAE,CAAC,OAAO,CAAC,+BAA+B,CAAC,CAAC;QAEtE,IAAI,CAAC,cAAc;aACd,QAAQ;iBACP,QAAQ,CAAC,YAAY,KAAK,CAAC,IAAI,QAAQ,CAAC,WAAW,KAAK,CAAC;oBACzD,QAAQ,CAAC,cAAc,KAAK,CAAC,IAAI,QAAQ,CAAC,aAAa,KAAK,CAAC;oBAC7D,QAAQ,CAAC,YAAY,KAAK,CAAC,IAAI,QAAQ,CAAC,WAAW,KAAK,CAAC;qBACxD,QAAQ,CAAC,OAAO,CAAC,IAAI,KAAK,MAAM;wBAChC,QAAQ,CAAC,OAAO,CAAC,IAAI,KAAK,OAAO,CAAC,CAAC,CAAC,EAAE;YAC3C,OAAO,cAAc,CAAC;gBACpB,CAAC;gBACD,MAAM;gBACN,QAAQ;gBACR,OAAO;gBACP,IAAI;gBACJ,UAAU;gBACV,sBAAsB;gBACtB,cAAc;aACf,CAAC,CAAC;SACJ;QAED,IAAI,OAAsB,CAAC;QAC3B,MAAM,OAAO,GAAG,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC9D,MAAM,UAAU,GAAG;YACjB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;YACpE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,GAAG,OAAO,CAAC,EAAC;YACnC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;YACpE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,aAAa,CAAC,EAAC;SACzE,CAAC;QACF,IAAI,cAAc,EAAE;YAClB,OAAO,GAAG,IAAI,kBAAkB,CAC5B,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE,yBAAyB,CAAC,CAAC;SAC/D;aAAM;YACL,MAAM,SAAS,GAAG,cAAc,GAAG,QAAQ,CAAC,SAAS,GAAG,QAAQ,CAAC,QAAQ;gBACtC,QAAQ,CAAC,WAAW,CAAC;YACxD,MAAM,SAAS,GAAG,cAAc,GAAG,QAAQ,CAAC,WAAW;gBACpB,QAAQ,CAAC,SAAS,GAAG,QAAQ,CAAC,QAAQ,CAAC;YAC1E,MAAM,QAAQ,GACV,QAAQ,CAAC,YAAY,GAAG,QAAQ,CAAC,WAAW,GAAG,QAAQ,CAAC,UAAU,CAAC;YACvE,UAAU,CAAC,IAAI,CACX,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EACtE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,EAAC,CAAC,CAAC;;YAGvC,MAAM,yBAAyB,GAAG,OAAO,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;YAChE,OAAO,GAAG,IAAI,eAAe,CACzB,QAAQ,EAAE,SAAS,EAAE,SAAS,EAAE,QAAQ,EAAE,OAAO,EAAE,UAAU,EAC7D,yBAAyB,EAAE,yBAAyB,CAAC,CAAC;SAC3D;QAED,MAAM,aAAa,GAAiB,EAAE,CAAC;QACvC,MAAM,QAAQ,GAAiB,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;QAC3C,IAAI,OAAO,EAAE;YACX,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC9C,IAAI,GAAG,OAAO,CACV,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,IAAI,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAC,EAAC,CAAC,CAAC;gBACzE,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;aAC1B;YACD,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SACrB;QACD,IAAI,yBAAyB,EAAE;YAC7B,IAAI,CAAC,cAAc,IAAI,sBAAsB,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;gBAChE,sBAAsB,GAAG,OAAO,CAAC;oBAC/B,MAAM,EAAE,EAAC,CAAC,EAAE,sBAAsB,EAAC;oBACnC,OAAO;oBACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,sBAAsB,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAC;iBACxD,CAAC,CAAC;gBACH,aAAa,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;aAC5C;YACD,QAAQ,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;SACvC;QACD,IAAI,UAAU,KAAK,WAAW,EAAE;YAC9B,UAAU,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,cAAc,CAAC,EAAC,CAAC,CAAC;YAC3D,OAAO,CAAC,QAAQ,IAAI,eAAe,CAAC;SACrC;QACD,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,QAAQ,EAAE,CAAC,CAAC,KAAK,EAAE,UAAU,CAAC,CAAC;QAC7E,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;YAC7B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;SAC/B;QACD,OAAO,GAAG,CAAC;IACb;;IC5QA;;;;;;;;;;;;;;;;aAuBgB,MAAM,CAClB,IAAwE;QAC1E,MAAM,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QAC3B,MAAM,EAAC,OAAO,EAAE,GAAG,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,EAAC,GAAG,KAAK,CAAC;QACrE,MAAM,WAAW,GAAGC,eAAY,CAAC,uBAAuB,CAAC,UAAU,CAAC,CAAC;QACrE,MAAM,QAAQ,GAAGA,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAC3C,MAAM,CAAC,KAAyC,EAAE,OAAO,EAAE,SAAS,EAAE,GAAG,EACzE,eAAe,EAAE,KAAK,kBAAkB,WAAW,CAAC,CAAC;QACzD,OAAO,UAAU,CAAC,EAAC,CAAC,EAAE,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAC,CAAC,CAAC;IACpD,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEqD,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICxCD;;;;;;;;;;;;;;;;IAuBA,SAAS,4BAA4B,CAAC,gBAAgB,GAAG,CAAC;QACxD,MAAM,WAAW,GAAG,CAAC,gBAAwB;YAC3C,QAAQ,gBAAgB;gBACtB,KAAK,CAAC;oBACJ,OAAO,yDAAyD,CAAC;gBACnE,KAAK,CAAC;oBACJ,OAAO;;;;;;;;;aASF,CAAC;gBACR;oBACE,MAAM,IAAI,KAAK,CACX,oBAAoB,gBAAgB,oBAAoB,CAAC,CAAC;aACjE;SACF,CAAC;QAEF,MAAM,YAAY,GAAG;;;;;;;;;iBASN,WAAW,CAAC,gBAAgB,CAAC;;;iBAG7B,WAAW,CAAC,gBAAgB,CAAC;;;;;;;8DAQxC,gBAAgB,IAAI,CAAC;QAEzB,MAAM,OAAO,GAAG;UACR,YAAY;;eAEP,WAAW,CAAC,gBAAgB,CAAC,QAAQ,CAAC;QAEnD,MAAM,QAAQ,GAAG;uDAEb,WAAW,CAAC,gBAAgB,CAAC;wBACX,gBAAgB;MAClC,OAAO;;;uDAIP,WAAW,CAAC,gBAAgB,CAAC;wBACX,gBAAgB;;;;;;;;;QAShC,WAAW,CAAC,gBAAgB,CAAC;;aAExB,WAAW,CAAC,gBAAgB,CAAC;;;iEAIpC,WAAW,CAAC,gBAAgB,CAAC;wBACX,gBAAgB;6CAElC,gBAAgB,GAAG,CAAC;;;;;;;iEAQpB,gBAAgB;;IAElB,CAAC;QACH,OAAO,QAAQ,CAAC;IAClB,CAAC;UAEY,uBAAuB;QAalC,YAAY,QAAiC;YAR7C,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAE3B,aAAQ,GACJ,0IAA0I,CAAC;YAM7I,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,OAAO,CAAC;YAEpCpD,OAAI,CAAC,MAAM,CACP,QAAQ,CAAC,UAAU,KAAK,cAAc,EACtC,MAAM,6BAA6B,CAAC,CAAC;YACzC,IAAI,CAAC,MAAM;gBACP,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC,IAAI,QAAQ,CAAC,WAAW,GAAG,CAAC,KAAK,CAAC,CAAC;YACpE,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC;YAClD,IAAI,CAAC,aAAa,GAAG,6BAA6B,CAC9C,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;YACxD,IAAI,CAAC,iBAAiB,GAAG,6BAA6B,CAClD,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;YAExD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,IAAI,CAAC,iBAAiB,CAAC,CAAC;YAE5B,IAAI,IAAI,CAAC,MAAM,EAAE;gBACf,IAAI,CAAC,aAAa,GAAG,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;aAC3C;YAED,IAAI,CAAC,SAAS;gBACV,oBAAoB,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,iBAAiB,EAAE,CAAC;SACjE;QAED,WAAW;YACT,MAAM,YAAY,GAAG,IAAI,CAAC,MAAM;gBAC5B,0BAA0B,CAAC,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,CAAC;gBACtE,sBAAsB,CAAC,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YACvE,MAAM,QAAQ,GAAG;MACf,4BAA4B,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC;MACjD,YAAY;KACb,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICjKH;;;;;;;;;;;;;;;;UAqBa,qBAAqB;QAYhC,YAAY,QAAiC;YAX7C,kBAAa,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;YAC5B,aAAQ,GACJ,wFAAwF,CAAC;YAK7F,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,OAAO,CAAC;YACpC,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;YAC7D,IAAI,CAAC,SAAS,GAAG,kBAAkB,IAAI,CAAC,cAAc,EAAE,CAAC;SAC1D;QAED,WAAW;YACT,MAAM,MAAM,GAAG,IAAI,CAAC,cAAc,GAAG,CAAC,GAAG,CAAC,CAAC;YAC3C,MAAM,MAAM,GAAG,IAAI,CAAC,cAAc,GAAG,CAAC,GAAG,CAAC,CAAC;YAC3C,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,GAAG,CAAC,GAAG,CAAC,CAAC;YAC/C,OAAO;MACLW,mBAAI,CAAC,OAAO,CAAC;;;;0BAIO,UAAU;;0CAEM,MAAM,aACxC,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;oBA0BM,IAAI,CAAC,cAAc;;;;;;;;;;;;;;;;GAgBpC,CAAC;SACD;;;ICjGH;;;;;;;;;;;;;;;;aAuBgB,mBAAmB,CAAC,IAInC;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,EAAE,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QAC5B,MAAM,EAAC,UAAU,EAAE,OAAO,EAAE,GAAG,EAAE,UAAU,EAAE,eAAe,EAAC,GAAG,KAAK,CAAC;QAEtE,MAAM,WAAW,GAAGZ,eAAY,CAAC,uBAAuB,CAAC,UAAU,CAAC,CAAC;QACrE,MAAM,QAAQ,GAAGA,eAAY,CAAC,iBAAiB,CAC3C,UAAU,EAAE,MAAM,CAAC,KAAyC,EAAE,OAAO,EACrE,CAAC,kBAAkB,GAAG,EAAE,eAAe,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;QAEjE,MAAM,UAAU,GAAG;YACjB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;YACpE;gBACE,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE;oBACJ,QAAQ,CAAC,YAAY,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG;oBAChD,QAAQ,CAAC,WAAW,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI;iBACjD;aACF;YACD,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;YACpE;gBACE,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE;oBACJ,QAAQ,CAAC,SAAS,EAAE,QAAQ,CAAC,SAAS,EAAE,QAAQ,CAAC,QAAQ;oBACzD,QAAQ,CAAC,WAAW;iBACrB;aACF;SACF,CAAC;QACF,IAAI,OAAsD,CAAC;;;QAG3D,IAAID,MAAG,EAAE,CAAC,OAAO,CAAC,mCAAmC,CAAC;YAClD,QAAQ,CAAC,YAAY,IAAI,CAAC,IAAI,QAAQ,CAAC,WAAW,IAAI,CAAC;gBACnD,QAAQ,CAAC,WAAW,IAAI,EAAE,IAAI,QAAQ,CAAC,UAAU,KAAK,CAAC,EAAE;YAC/D,OAAO,GAAG,IAAI,qBAAqB,CAAC,QAAQ,CAAC,CAAC;SAC/C;aAAM;YACL,OAAO,GAAG,IAAI,uBAAuB,CAAC,QAAQ,CAAC,CAAC;YAChD,MAAM,SAAS,GAAG,QAAQ,CAAC,QAAQ,GAAG,QAAQ,CAAC,OAAO,CAAC;YACvD,MAAM,SAAS,GAAG,QAAQ,CAAC,UAAU,CAAC;YACtC,MAAM,QAAQ,GACV,QAAQ,CAAC,YAAY,GAAG,QAAQ,CAAC,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;YACxE,UAAU,CAAC,IAAI,CACX,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EACnC,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EACnC,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,EAAC,CAAC,CAAC;SACzC;QACD,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,EAAE,EAAE,MAAM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;IAChF,CAAC;IAEM,MAAM,yBAAyB,GAAiB;QACrD,UAAU,EAAEuD,sBAAmB;QAC/B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,mBAAuC;KACpD;;IChFD;;;;;;;;;;;;;;;;IAuBO,MAAM,GAAG,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,GAAG,EAAC,CAAC,CAAC;IAEvD,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,IAAI,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;IAEzD,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC7BD;;;;;;;;;;;;;;;;UAoBa,oBAAoB;QAa/B,YACI,QAAgB,EAAE,QAA0B,EAAE,QAA0B,EACxE,MAA4B;YAVhC,kBAAa,GAAG,CAAC,OAAO,EAAE,OAAO,EAAE,QAAQ,CAAC,CAAC;YAC7C,aAAQ,GAAG,2BAA2B,CAAC;YACvC,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAIrD,SAAI,GAAG,IAAI,CAAC;YAKV,MAAM,CAAC,QAAQ,EAAG,GAAG,QAAQ,CAAC;YAC9B,IAAI,CAAC,WAAW,GAAG,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;YAClE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,QAAQ,GAAG,MAAM,KAAK,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;YAC9C,IAAI,CAAC,qBAAqB,GAAG,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;YACrD,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;YACpD,IAAI,CAAC,SAAS,GAAG,iBAAiB,IAAI,CAAC,QAAQ,IAC3C,IAAI,CAAC,qBAAqB,IAAI,IAAI,CAAC,oBAAoB,EAAE,CAAC;SAC/D;QAED,WAAW;YACT,MAAM,CAAC,gBAAgB,EAAE,eAAe,CAAC,GACrC,CAAC,iCAAiC,EAAE,iCAAiC,CAAC,CAAC;YAE3E,MAAM,CAAC,WAAW,EAAE,WAAW,EAAE,GAAG,CAAC,GAAG,IAAI,CAAC,qBAAqB;gBAC9D;oBACE,IAAI,gBAAgB,mCAAmC;oBACvD,wBAAwB;oBACxB,MAAM,gBAAgB,0BAA0B;iBACjD;gBACD;oBACE,KAAK;oBACL,KAAK;oBACL,mBAAmB,gBAAgB,EAAE;iBACtC,CAAC;YACN,MAAM,CAAC,UAAU,EAAE,UAAU,EAAE,GAAG,CAAC,GAAG,IAAI,CAAC,oBAAoB;gBAC3D;oBACE,IAAI,eAAe,mCAAmC;oBACtD,uBAAuB;oBACvB,MAAM,eAAe,yBAAyB;iBAC/C;gBACD;oBACE,KAAK;oBACL,KAAK;oBACL,mBAAmB,eAAe,EAAE;iBACrC,CAAC;;;;YAKN,MAAM,QAAQ,GAAG;MACf5C,mBAAI,CAAC,OAAO,CAAC;;;iCAGc,WAAW;gCACZ,UAAU;;;;;;;;;;;;;;;6BAeb,WAAW;4BACZ,UAAU;qBACjB,GAAG;mCACW,gBAAgB;;;;qBAI9B,GAAG;mCACW,eAAe;;;;;aAKrC,IAAI,CAAC,QAAQ;;;;;;;;;;;;;;;;;;;;;;;KAuBrB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICzIH;;;;;;;;;;;;;;;;IAsBO,MAAM,aAAa,GAAG,CAAC,IAI7B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QACtC,MAAM,EAAC,QAAQ,EAAE,MAAM,EAAE,kBAAkB,EAAC,GAAG,KAAK,CAAC;QAErD,MAAM,OAAO,GAAG,IAAI,oBAAoB,CACpC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,KAAyB,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC;QACvE,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,kBAAkB,CAAC,EAAC,CAAC,CAAC;QACpE,OAAO,OAAO,CAAC,gBAAgB,CAC3B,OAAO,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;IAC/D,CAAC,CAAC;IAEK,MAAM,mBAAmB,GAAiB;QAC/C,UAAU,EAAE6C,gBAAa;QACzB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,aAAiC;KAC9C;;IC1CD;;;;;;;;;;;;;;;;IAoBA,IAAY,SAGX;IAHD,WAAY,SAAS;QACnB,uBAAU,CAAA;QACV,sBAAS,CAAA;IACX,CAAC,EAHW,SAAS,KAAT,SAAS,QAGpB;UAEY,UAAU;QAcrB,YACI,EAAa,EAAE,KAAe,EAAE,SAAkB,EAAE,OAAgB;YAVxE,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;;YAGtB,aAAQ,GAAG,cAAc,CAAC;YAC1B,SAAI,GAAG,IAAI,CAAC;YAOV,MAAM,cAAc,GAAG,GAAG,CAAC;YAC3B,IAAI,CAAC,aAAa,GAAG,CAAC,cAAc,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC5C,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;YAC3B,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,EAAE,GAAG,EAAE,CAAC;YACb,IAAI,CAAC,SAAS,GAAG,OAAO,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,OAAO,EAAE,CAAC;SACrE;QAED,WAAW;YACT,MAAM,IAAI,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACrC,MAAM,OAAO,GAAG,IAAI,CAAC,EAAE,KAAK,SAAS,CAAC,IAAI,GAAG,KAAK,GAAG,KAAK,CAAC;YAC3D,MAAM,GAAG,GAAG,IAAI,CAAC,SAAS,GAAG,OAAO;gBACP,QAAQ,SAAS,CAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,CAAC;YAC3E,MAAM,MAAM,GAAG,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAC7D,IAAI,SAAS,GAAG,EAAE,CAAC;YACnB,IAAI,SAAS,GAAG,EAAE,CAAC;;;;YAInB,IAAI,IAAI,CAAC,SAAS,EAAE;gBAClB,SAAS,GAAG,IAAI,CAAC,OAAO,GAAG,UAAU,MAAM,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC;gBAC/D,SAAS,GAAG,IAAI,CAAC,OAAO,GAAG,SAAS,GAAG,SAAS,CAAC;aAClD;iBAAM;gBACL,SAAS,GAAG,IAAI,CAAC,OAAO,GAAG,gBAAgB,MAAM,EAAE,GAAG,aAAa,CAAC;gBACpE,SAAS,IAAI,IAAI,CAAC,OAAO,GAAG,YAAY,GAAG,YAAY,CAAC,CAAC;aAC1D;YACD,OAAO;QACH7C,mBAAI,CAAC,OAAO,CAAC;;;;qBAIA,aAAa,CAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,CAAC,EAAE,CAAC;qBACtC,GAAG;;eAET,SAAS;uBACD,SAAS;aACnB,aAAa,CAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,CAAC,EAAE,CAAC;iBAClC,IAAI,CAAC,EAAE,UAAU,SAAS,CAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,CAAC,EAAE,CAAC;;;;;KAK/D,CAAC;SACH;KACF;IAED,SAAS,SAAS,CAAC,IAAY,EAAE,IAAY,EAAE,EAAa;QAC1D,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,OAAO,GAAG,IAAI,EAAE,CAAC;SAClB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,OAAO,IAAI,IAAI,CAAC;SAC/B;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,OAAO,IAAI,OAAO,IAAI,IAAI,CAAC;SAC1C;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,OAAO,IAAI,OAAO,IAAI,OAAO,IAAI,IAAI,CAAC;SACrD;aAAM;YACL,MAAM,KAAK,CAAC,cAAc,EAAE,aAAa,IAAI,uBAAuB,CAAC,CAAC;SACvE;IACH,CAAC;IAED,SAAS,aAAa,CAAC,IAAY,EAAE,IAAY,EAAE,EAAa;QAC9D,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,OAAO,GAAG,IAAI,EAAE,CAAC;SAClB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,IAAI,CAAC;SACpB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,IAAI,CAAC;SACpB;aAAM,IAAI,IAAI,KAAK,CAAC,EAAE;YACrB,OAAO,GAAG,IAAI,IAAI,CAAC;SACpB;aAAM;YACL,MAAM,KAAK,CAAC,cAAc,EAAE,aAAa,IAAI,uBAAuB,CAAC,CAAC;SACvE;IACH;;ICrHA;;;;;;;;;;;;;;;;aAyBgB,OAAO,CACnB,EAAa,EAAE,CAAa,EAAE,OAAsB,EAAE,IAAY,EAClE,SAAkB,EAAE,OAAgB;QACtC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,WAAW,GAAGZ,eAAY,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,CAAC,CAAC;QACnE,IAAI,SAAS,GAAG,CAAC,CAAC;QAClB,IAAI,WAAW,IAAI,IAAI,EAAE;YACvB,SAAS,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,WAAW,EAAC,EAAC,CAAC,CAAC;SAC3E;QACD,MAAM,YAAY,GAAGA,eAAY,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAEhE,IAAI,YAAY,KAAK,KAAK,GAAG,CAAC,EAAE;YAC9B,MAAM,IAAI,KAAK,CACX,oDACI,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,GAAG;gBACzB,gBAAgB,IAAI,EAAE,CAAC,CAAC;SAC7B;QACD,MAAM,IAAI,GAAG,SAAS,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC;QAC3C,IAAI,MAAM,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,SAAS,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;;;;;QAMzD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;YACxD,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,SAAS,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;YACpE,MAAM,UAAU,GAAG,MAAM,CAAC;YAC1B,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;YACnD,MAAM;gBACF,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;YAC3E,OAAO,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;SACxC;;;QAGD,IAAI,SAAS,EAAE;YACb,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,SAAS,CAAC,KAAK,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;YACxE,MAAM,UAAU,GAAG,MAAM,CAAC;YAC1B,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;YACnD,MAAM;gBACF,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;YAC3E,OAAO,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;SACxC;QAED,IAAI,WAAW,IAAI,IAAI,EAAE;YACvB,MAAM,kBAAkB,GAAGA,eAAY,CAAC,sBAAsB,CAAC,WAAW,CAAC,CAAC;YAC5E,MAAM,uBAAuB,GAAG,SAAS,CACrC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,kBAAkB,EAAC,EAAC,CAAC,CAAC;YAEvE,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACnC,OAAO,CAAC,WAAW,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;YAEtC,OAAO,uBAAuB,CAAC;SAChC;QAED,OAAO,MAAM,CAAC;IAChB;;IChFA;;;;;;;;;;;;;;;;aAuBgB,OAAO,CACnB,IAA0E;QAE5E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAC,GAAG,KAAK,CAAC;QACzC,OAAO,OAAO,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,EAAE,OAAO,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;IACvE,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAE0D,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;ICpCD;;;;;;;;;;;;;;;;aAuBgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAC,GAAG,KAAK,CAAC;QACzC,OAAO,OAAO,CAAC,SAAS,CAAC,GAAG,EAAE,CAAC,EAAE,OAAO,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;IACtE,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEC,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICpCD;;;;;;;;;;;;;;;;UAoBa,mBAAmB;QAW9B,YAAY,WAAqB,EAAE,UAAyB;YAV5D,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YAMtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YACZ,aAAQ,GAAG,kBAAkB,CAAC;YAG5B,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,gBAAgB,UAAU,EAAE,CAAC;YAC9C,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;SAC9B;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACb/C,mBAAI,CAAC,OAAO,CAAC;;;;oBAID,IAAI,CAAC,oBAAoB,EAAE;oBAC3B,IAAI,CAAC,mBAAmB,EAAE;oBAC1B,IAAI,CAAC,mBAAmB,EAAE;;;;;;;cAOhC,IAAI,CAAC,kBAAkB,EAAE;;;sBAGjB,IAAI,CAAC,sBAAsB,EAAE;;;QAG3C,CAAC;YACL,OAAO,QAAQ,CAAC;SACjB;QAEO,oBAAoB;YAC1B,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAC9B,OAAO,WAAW,CAAC;aACpB;iBAAM;gBACL,OAAO,WAAW,CAAC;aACpB;SACF;QAEO,mBAAmB;YACzB,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAC9B,OAAO,WAAW,CAAC;aACpB;iBAAM;gBACL,OAAO,WAAW,CAAC;aACpB;SACF;QAEO,mBAAmB;YACzB,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAC9B,OAAO,WAAW,CAAC;aACpB;iBAAM;gBACL,OAAO,WAAW,CAAC;aACpB;SACF;QAEO,kBAAkB;YACxB,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAC9B,OAAO,sBAAsB,CAAC;aAC/B;iBAAM;gBACL,OAAO,sBAAsB,CAAC;aAC/B;SACF;QAEO,sBAAsB;YAC5B,IAAI,IAAI,CAAC,UAAU,KAAK,MAAM,EAAE;gBAC9B,OAAO,2BAA2B,CAAC;aACpC;iBAAM;gBACL,OAAO,2BAA2B,CAAC;aACpC;SACF;;;ICvGH;;;;;;;;;;;;;;;;aAsBgB,YAAY,CAAC,IAI5B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,SAAS,EAAE,UAAU,EAAC,GAAG,KAAK,CAAC;QAEtC,MAAM,SAAS,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,WAAW,GAAG,CAAC,UAAU,KAAK,MAAM,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACtE,MAAM,UAAU,GAAG,CAAC,UAAU,KAAK,MAAM,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACrE,MAAM,UAAU,GAAG,CAAC,UAAU,KAAK,MAAM,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAErE,MAAM,YAAY,GAAG,WAAW,GAAG,SAAS,CAAC;QAC7C,MAAM,WAAW,GAAG,UAAU,GAAG,SAAS,CAAC;QAC3C,MAAM,WAAW,GAAG,UAAU,IAAI,SAAS,GAAG,SAAS,CAAC,CAAC;QAEzD,MAAM,WAAW,GAAG,CAAC,UAAU,KAAK,MAAM;YACtC,CAAC,SAAS,EAAE,YAAY,EAAE,WAAW,EAAE,WAAW,CAAC;YACnD,CAAC,SAAS,EAAE,WAAW,EAAE,YAAY,EAAE,WAAW,CAAC,CAAC;QAExD,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;SACnC,CAAC;QAEF,MAAM,OAAO,GAAG,IAAI,mBAAmB,CAAC,WAAW,EAAE,UAAU,CAAC,CAAC;QACjE,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IACtE,CAAC;IAEM,MAAM,kBAAkB,GAAiB;QAC9C,UAAU,EAAEgD,eAAY;QACxB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,YAAgC;KAC7C;;ICxDD;;;;;;;;;;;;;;;;UAuBa,gCAAgC;QAc3C,YACI,WAAqB,EAAE,YAAoB,EAAE,WAAmB,EAChE,OAAO,GAAG,KAAK,EAAE,aAAsC,IAAI,EAC3D,kBAAkB,GAAG,KAAK;YAZ9B,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,sCAAsC,CAAC;YAClD,kBAAa,GAA6B,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;YAWpD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC;YAClD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YACD,IAAI,kBAAkB,EAAE;gBACtB,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,kBAAkB,GAAG,kBAAkB,CAAC;YAC7C,IAAI,CAAC,YAAY,GAAG,YAAY,CAAC;YACjC,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,SAAS,GAAG,iBAAiB,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,YAAY,IAClE,IAAI,CAAC,WAAW,EAAE,CAAC;SACxB;QAED,WAAW;YACT,MAAM,UAAU,GAAG,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,YAAY,CAAC;YACxD,MAAM,aAAa,GACf,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC;YAC1E,MAAM,WAAW,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC;YAClE,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,WAAW,GAAG,CAAC,CAAC;YAEhE,MAAM,QAAQ,GAAG;QACb,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,kBAAkB,EAAE,KAAK,EAAE,CAAC,CAAC;;kDAE7B,UAAU,MAAM,WAAW;kDAC3B,IAAI,CAAC,WAAW,MAC1D,IAAI,CAAC,YAAY;;;;;;;;;;QAUjB,sBAAsB,EAAE;;;;;;;;;;;;;;;;;;;;;;;mDAwBxB,WAAW,2BAA2B,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;qDAE3D,UAAU,2BAA2B,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;;;;;;;;;UAU1D,UAAU,GAAG,aAAa;YACtB,gBAAgB,UAAU,GAAG;YAC7B,kBAAkB,UAAU,uBAAuB,aAAa,GAAG;;;gCAG/C,IAAI,CAAC,WAAW;gCAChB,IAAI,CAAC,WAAW;;;;;;;gCAOhB,IAAI,CAAC,YAAY;kCACf,IAAI,CAAC,WAAW;;;;;;UAMxC,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC;;;;;KAKzD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICnJH;;;;;;;;;;;;;;;;UAsBa,0BAA0B;QAerC,YACI,QAAiC,EAAE,OAAO,GAAG,KAAK,EAClD,aAAsC,IAAI,EAAE,kBAAkB,GAAG,KAAK;YAZ1E,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG,sCAAsC,CAAC;YAClD,kBAAa,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACpD,kBAAa,GAAG,CAAC,CAAC;YAKlB,WAAM,GAAG,IAAI,CAAC;YAKZ,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC;YAClD,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,CAAC,EAAE,IAAI,CAAC,aAAa,EAAE,CAAC,CAAC,CAAC,CAAC;YAEhC3D,OAAI,CAAC,MAAM,CACP,QAAQ,CAAC,UAAU,KAAK,cAAc,EACtC,MAAM,6BAA6B,CAAC,CAAC;YAEzC,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YACD,IAAI,kBAAkB,EAAE;gBACtB,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;YACzB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,kBAAkB,GAAG,kBAAkB,CAAC;YAE7C,IAAI,CAAC,SAAS;gBACV,iBAAiB,UAAU,IAAI,IAAI,CAAC,QAAQ,CAAC,YAAY,IACrD,IAAI,CAAC,QAAQ,CAAC,WAAW,IAAI,IAAI,CAAC,QAAQ,CAAC,YAAY,IACvD,IAAI,CAAC,QAAQ,CAAC,WAAW,IAAI,IAAI,CAAC,aAAa,EAAE,CAAC;SAC3D;QAED,WAAW;YACT,MAAM,OAAO,GAAG,CAAC,IAAI,CAAC,aAAa,GAAG,CAAC,IAAI,IAAI,CAAC,QAAQ,CAAC,WAAW;gBAChE,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC;YAE9B,MAAM,QAAQ,GAAG;QACb,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,kBAAkB,EAAE,IAAI,EAAE,CAAC,CAAC;;;;;;;;;6BASjD,IAAI,CAAC,QAAQ,CAAC,YAAY;4BAC3B,IAAI,CAAC,QAAQ,CAAC,WAAW;QAC7C,sBAAsB,EAAE;;;;oCAII,IAAI,CAAC,aAAa;;;;;;uCAMf,OAAO;yCACL,IAAI,CAAC,aAAa;8BAC7B,IAAI,CAAC,aAAa;;;;;gCAKhB,IAAI,CAAC,QAAQ,CAAC,YAAY;;;kCAGxB,OAAO;;;oCAGL,IAAI,CAAC,QAAQ,CAAC,WAAW;;oCAEzB,IAAI,CAAC,aAAa;;;;;;;8BAOxB,IAAI,CAAC,aAAa;;;;cAIlC,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC;;;;;KAK7D,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;IC/HH;;;;;;;;;;;;;;;;UAuBa,sBAAsB;QAgBjC,YACI,QAAiC,EAAE,OAAO,GAAG,KAAK,EAClD,aAAsC,IAAI,EAAE,kBAAkB,GAAG,KAAK;YAb1E,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC3B,aAAQ,GAAG;mEACsD,CAAC;;YAElE,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAUpD,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,QAAQ,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;YAE7D,IAAI,OAAO,EAAE;gBACX,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACjC;YACD,IAAI,kBAAkB,EAAE;gBACtB,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,wBAAwB,CAAC,CAAC;aACnD;YAED,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;YACzB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,kBAAkB,GAAG,kBAAkB,CAAC;YAC7C,IAAI,CAAC,SAAS,GAAG,aAAa,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC;SACxE;QAED,WAAW;YACT,MAAM,WAAW,GAAG,IAAI,CAAC,cAAc,GAAG,0BAA0B;gBAC1B,0BAA0B,CAAC;YAErE,MAAM,QAAQ,GAAG;QACb,mBAAmB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,kBAAkB,EAAE,KAAK,EAAE,CAAC,CAAC;;QAEvEW,mBAAI,EAAE;;;2CAIN,IAAI,CAAC,cAAc,GAAG,IAAI,GAAG,IAAI;0BACf,IAAI,CAAC,cAAc,GAAG,CAAC,GAAG,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;6BA4BxB,WAAW;;;;;;;;;;;;;;;;;;;;6BAoBX,WAAW;;;;;;YAM5B,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC;;;;;KAK3D,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICvIH;;;;;;;;;;;;;;;;aAwBgB,qBAAqB,CAAC,IAIrC;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QAC3B,MAAM,EAAC,OAAO,EAAE,GAAG,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,EAAC,GAAG,KAAK,CAAC;QACrE,MAAM,WAAW,GAAGZ,eAAY,CAAC,uBAAuB,CAAC,UAAU,CAAC,CAAC;QACrE,IAAI,UAAU,GAAG,SAAS,CAAC;QAC3B,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SACrB;QAED,MAAM,QAAQ,GAAGA,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAC3C,MAAM,CAAC,KAAyC,EAAE,OAAO,EAAE,UAAU,EACrE,GAAG,EAAE,eAAe,EAAE,IAAI,kBAAkB,WAAW,CAAC,CAAC;QAC7D,MAAM,UAAU,GAAG;YACjB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAC;YACpE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,OAAO,CAAC,EAAC;SAC7D,CAAC;QAEF,MAAM,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;QAC9D,IAAI,OACgC,CAAC;QACrC,IAAI,CAAC,cAAc,IAAI,QAAQ,CAAC,QAAQ,GAAG,EAAE,IAAI,QAAQ,CAAC,OAAO,GAAG,EAAE;YAClE,QAAQ,CAAC,YAAY,KAAK,CAAC,IAAI,QAAQ,CAAC,WAAW,KAAK,CAAC;YACzD,QAAQ,CAAC,aAAa,KAAK,CAAC,IAAI,QAAQ,CAAC,cAAc,KAAK,CAAC;YAC7D,QAAQ,CAAC,UAAU,KAAK,QAAQ,CAAC,WAAW,EAAE;YAChD,OAAO,GAAG,IAAI,gCAAgC,CAC1C,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,CAAC;SACrE;aAAM,IACH,cAAc,IAAI,QAAQ,CAAC,QAAQ,GAAG,CAAC,IAAI,QAAQ,CAAC,OAAO,GAAG,CAAC;YAC/D,QAAQ,CAAC,WAAW,IAAI,CAAC;YACzB,QAAQ,CAAC,UAAU,KAAK,QAAQ,CAAC,WAAW;YAC5C,QAAQ,CAAC,cAAc,KAAK,CAAC,IAAI,QAAQ,CAAC,aAAa,KAAK,CAAC;YAC7D,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC,EAAE;YACjC,OAAO,GAAG,IAAI,0BAA0B,CAAC,QAAQ,CAAC,CAAC;SACpD;aAAM;YACL,OAAO,GAAG,IAAI,sBAAsB,CAAC,QAAQ,CAAC,CAAC;YAC/C,UAAU,CAAC,IAAI,CACX,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,CAAC,EAAC,EAC9C,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,WAAW,CAAC,EAAC,EAC7C,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC,EAAE;gBACpE,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE,CAAC,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,aAAa,CAAC;aACxD,CAAC,CAAC;SACR;QAED,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAU,CAAC,CAAC;IAC7E,CAAC;IAEM,MAAM,2BAA2B,GAAiB;QACvD,UAAU,EAAE6D,wBAAqB;QACjC,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,qBAAyC;KACtD;;ICjFD;;;;;;;;;;;;;;;;IAuBO,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;QACjD,MAAM,EAAE,YAAY,CAAC,GAAG;QACxB,aAAa,EAAEC,eAAW;QAC1B,eAAe,EAAE,IAAI;KACtB,CAAC,CAAC;IAEI,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAEC,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,kBAAkB;KAC/B;;ICjCD;;;;;;;;;;;;;;;;aAsBgB,GAAG,CACf,IAAkE;QAEpE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAE,QAAQ,EAAC,GAAG,KAAK,CAAC;QAE/B,OAAO,MAAM,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IACnD,CAAC;IAEM,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAuB;KACpC;;ICpCD;;;;;;;;;;;;;;;;aA0BgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,QAAQ,EAAC,GAAG,KAAK,CAAC;QACzB,MAAM,OAAO,GAAG,MAAkB,CAAC;QAEnC,MAAM,EAAC,OAAO,EAAE,UAAU,EAAE,MAAM,EAAC,GAC/BhE,eAAY,CAAC,oBAAoB,CAAC,QAAQ,EAAE,OAAO,CAAC,MAAM,CAAC,CAAC;QAChEA,eAAY,CAAC,mBAAmB,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;QAClE,MAAM,EAAC,IAAI,EAAE,KAAK,EAAC,GAAGA,eAAY,CAAC,oBAAoB,CAAC,UAAU,EAAE,MAAM,CAAC,CAAC;QAE5E,MAAM,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QAC5B,IAAI,GAAG,GAAoB,IAAI,CAAC;QAChC,IAAI,gBAAgB,GAAG,OAAO,CAAC,MAAM,CAAC;QACtC,MAAM,gBAAgB,GAAiB,EAAE,CAAC;QAC1C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,EAAE,CAAC,EAAE;YAC/B,KAAK,MAAM,MAAM,IAAI,KAAK,CAAC,CAAC,CAAC,EAAE;gBAC7B,MAAM,EAAC,kBAAkB,EAAE,IAAI,EAAE,UAAU,EAAE,YAAY,EAAC,GACtDA,eAAY,CAAC,oBAAoB,CAAC,gBAAgB,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC;gBACxE,IAAI,CAAa,CAAC;gBAClB,IAAIA,eAAY,CAAC,qBAAqB,CAAC,IAAI,CAAC,EAAE;oBAC5C,CAAC,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC;iBACrB;qBAAM;oBACL,CAAC,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAC,EAAC,CAAC,CAAC;oBACtE,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC1B;gBACD,MAAM,WAAW,GAAa,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;gBAC9C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oBAC5C,WAAW,CAAC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;iBAC3C;gBAED,IAAI,CAACC,OAAI,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,EAAE;oBAC3C,CAAC,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC,EAAC,CAAC,CAAC;oBACjE,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC1B;gBACD,IAAI,GAAG,KAAK,IAAI,EAAE;oBAChB,GAAG,GAAG,CAAC,CAAC;iBACT;qBAAM;;oBAEL,GAAG;wBACC,kBAAkB,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAC,CAAe,CAAC;oBACxE,gBAAgB,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;iBAC5B;aACF;YACD,IAAI,CAAC,GAAG,MAAM,GAAG,CAAC,EAAE;gBAClB,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE;oBAChB,GAAG,GAAG,GAAG,CAAC;wBACR,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC;wBAChB,OAAO;wBACP,KAAK,EAAE;4BACL,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC,IAAI,OAAO,CAAC,MAAM,GAAG,gBAAgB,CAAC;4BACnD,QAAQ,EAAE,KAAK;yBAChB;qBACF,CAAC,CAAC;oBACH,gBAAgB,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;iBAC5B;gBACD,gBAAgB,EAAE,CAAC;aACpB;SACF;;QAGD,KAAK,MAAM,UAAU,IAAI,gBAAgB,EAAE;YACzC,IAAI,UAAU,KAAK,GAAG,EAAE;gBACtB,SAAS;aACV;YACD,OAAO,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;SACxC;QAED,OAAO,GAAG,CAAC;IACb,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEgE,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICtGD;;;;;;;;;;;;;;;;IAqBO,MAAM,GAAG,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,GAAG,EAAC,CAAC,CAAC;IAEvD,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC3BD;;;;;;;;;;;;;;;;IAuBO,MAAM,KAAK,GAAG,gBAAgB,CACjC,EAAC,MAAM,EAAE,YAAY,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,aAAa,EAAEC,YAAQ,EAAC,CAAC,CAAC;IAEnE,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC9BD;;;;;;;;;;;;;;;;IAsBO,MAAM,GAAG,GAAG,eAAe,CAAC;QACjC,MAAM,EAAE,WAAW,CAAC,GAAG;QACvB,aAAa,EAAE,UAAU;QACzB,KAAK,EAAE,SAAS;KACjB,CAAC,CAAC;IAEI,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IChCD;;;;;;;;;;;;;;;;aAsBgB,UAAU,CAAC,IAI1B;QACC,MAAM,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,GAAG,EAAC,GAAG,KAAK,CAAC;QACpB,MAAM,EAAC,KAAK,EAAC,GAAG,MAAM,CAAC;QAEvB,MAAM,SAAS,GAAG,KAAK,CAAC,KAAK,CAAC,MAAM,CAAC;QACrC,MAAM,QAAQ,GAAG,KAAK,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QACrC,IAAI,IAAI,GAAG,GAAG,CAAC;QACf,IAAI,GAAG,GAAG,CAAC,EAAE;;YAEXpE,OAAI,CAAC,MAAM,CACP,EAAE,SAAS,GAAG,CAAC,CAAC,IAAI,GAAG,EACvB,MAAM,iCAAiC,EAAG,SAAS,GAAG,CAAC,CAAC,KACpD,SAAS,GAAG,CAAC,CAAC;YACtB,IAAI,GAAG,SAAS,GAAG,GAAG,GAAG,CAAC,CAAC;SAC5B;QACD,QAAQ,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAE5B,OAAO,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,KAAK,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;IAC1E,CAAC;IAEM,MAAM,gBAAgB,GAAiB;QAC5C,UAAU,EAAEqE,aAAU;QACtB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,UAA8B;KAC3C;;ICnDD;;;;;;;;;;;;;;;;IAsBO,MAAM,KAAK,GACd,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,KAAK,EAAE,aAAa,EAAE,YAAY,EAAC,CAAC,CAAC;IAEvE,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC7BD;;;;;;;;;;;;;;;;UAoBa,oBAAoB;QAS/B,YAAY,UAA4C;YARxD,gBAAW,GAAa,EAAE,CAAC;YAI3B,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,UAAU,CAAC;YAC9B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,eAAe,CAAC;SAClC;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACb3D,mBAAI,CAAC,OAAO,CAAC;;;;;;;;KAQhB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICjDH;;;;;;;;;;;;;;;;IAuBO,MAAM,mBAAmB,GAAiB;QAC7C,UAAU,EAAE4D,gBAAa;QACzB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,CAAC,EAAC,MAAM,EAAE,OAAO,EAAC;YAC5B,MAAM,EAAC,KAAK,EAAC,GAAG,MAA6B,CAAC;YAC9C,MAAM,aAAa,GAAG,OAAwB,CAAC;YAE/C,MAAM,OAAO,GAAG,IAAI,oBAAoB,CAAE,KAAkB,CAAC,KAAK,CAAC,CAAC;YACpE,MAAM,MAAM,GACR,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC;YAClE,OAAO,MAAM,CAAC;SACjB;KACF;;IClCD;;;;;;;;;;;;;;;;IAsBO,MAAM,KAAK,GACd,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,KAAK,EAAE,aAAa,EAAE,YAAY,EAAC,CAAC,CAAC;IAEvE,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC9BD;;;;;;;;;;;;;;;;IAsBO,MAAM,QAAQ,GACjB,gBAAgB,CAAC,EAAC,MAAM,EAAE,YAAY,CAAC,OAAO,EAAE,KAAK,EAAE,OAAO,EAAC,CAAC,CAAC;IAE9D,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAEC,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAAQ;KACrB;;IC7BD;;;;;;;;;;;;;;;;UAoBa,iBAAiB;QAW5B,YAAY,WAAqB,EAAE,WAAmB,EAAE,WAAW,GAAG,KAAK;YAR3E,iBAAY,GAAG,IAAI,CAAC;YACpB,gBAAW,GAAa,CAAC,CAAC,CAAC,CAAC;YAG5B,kBAAa,GAAa,EAAE,CAAC;YAC7B,kBAAa,GACT,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAGd,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,WAAW,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEzB,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,SAAS,GAAG,cAAc,IAAI,CAAC,WAAW,EAAE,CAAC;SACnD;QAED,WAAW;YACT,MAAM,WAAW,GAAG,IAAI,CAAC,WAAW;gBAChC,yCAAyC;gBACzC,2CAA2C,CAAC;YAChD,MAAM,WAAW,GACb,IAAI,CAAC,WAAW,GAAG,kBAAkB,GAAG,iBAAiB,CAAC;YAC9D,OAAO;uCAC4B,WAAW;QAC1C9D,mBAAI,CAAC,OAAO,CAAC;;;;yBAII,WAAW;;;;;;GAMjC,CAAC;SACD;;;IC7DH;;;;;;;;;;;;;;;;IAwBO,MAAM,gBAAgB,GAAiB;QAC5C,UAAU,EAAE+D,aAAU;QACtB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,UAA8B;KAC3C,CAAC;IAEF,IAAI,mBAA6C,CAAC;IAClD,IAAI,kBAAkB,GAAG5E,MAAG,EAAE,CAAC,OAAO,CAAC,uCAAuC,CAAC,CAAC;aAGhE,UAAU,CAAC,IAI1B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,IAAI,EAAC,MAAM,EAAC,GAAG,MAAM,CAAC;QACtB,MAAM,EAAC,WAAW,EAAC,GAAG,KAAK,CAAC;QAE5B,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,IAAI,KAAK,CAAC,0DAA0D,CAAC,CAAC;SAC7E;QAED,MAAM,OAAO,GAAG,QAAQ,gBAAgB,CAAC,KAAK,WAAW;YACrD,MAAM,YAAY,gBAAgB,CAAC;QACvC,MAAM,OAAO,GAAG,QAAQ,gBAAgB,CAAC,KAAK,WAAW;YACrD,MAAM,YAAY,gBAAgB,CAAC;QACvC,MAAM,QAAQ,GAAG,CAAC,QAAQ,iBAAiB,CAAC,KAAK,WAAW;YAC1C,MAAM,YAAY,iBAAiB;aAChD,QAAQ,eAAe,CAAC,KAAK,WAAW;gBACxC,MAAM,YAAY,eAAe,CAAC,CAAC;QACxC,MAAM,aAAa,GACf,QAAQ,WAAW,CAAC,KAAK,WAAW,IAAI,MAAM,YAAY,WAAW,CAAC;QAE1E,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,OAAO;YAC3B;gBACG,MAA2B,CAAC,UAAU;gBACtC,MAA2B,CAAC,WAAW;aACzC;YACD,CAAC,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;QAClC,MAAM,WAAW,GAAG,CAAC,MAAM,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;;;QAIjD,MAAM,WAAW,GACb,KAAK,CAAmD,CAAW,CAAC;QACxE,MAAM,cAAc,GAAG,OAAO,IAAI,OAAO,CAAC;QAC1C,IAAI,aAAa,IAAI,QAAQ,IAAI,cAAc,EAAE;YAC/C,IAAI,WAAwB,CAAC;YAkBtB;gBACL,IAAI,cAAc,EAAE;oBAClB,MAAM,qBAAqB,GACvBA,MAAG,EAAE,CAAC,OAAO,CAAC,uCAAuC,CAAC,CAAC;oBAC3D,IAAI,mBAAmB,IAAI,IAAI;wBAC3B,qBAAqB,KAAK,kBAAkB,EAAE;wBAChD,kBAAkB,GAAG,qBAAqB,CAAC;wBAC3C,mBAAmB;4BACf,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,UAAU,CACvC,IAAI,EAAE,EAAC,kBAAkB,EAAC,CAA6B,CAAC;qBACjE;oBACD,mBAAmB,CAAC,MAAM,CAAC,KAAK,GAAG,KAAK,CAAC;oBACzC,mBAAmB,CAAC,MAAM,CAAC,MAAM,GAAG,MAAM,CAAC;oBAC3C,mBAAmB,CAAC,SAAS,CACzB,MAA6C,EAAE,CAAC,EAAE,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;oBACxE,MAAM,GAAG,mBAAmB,CAAC,MAAM,CAAC;iBACrC;gBAED,MAAM,KAAK,GAAG,eAAe,CAAC,QAAQ;oBAClC,eAAe,CAAC,iBAAiB,GAAG,eAAe,CAAC,eAAe,CAAC;gBACxE,MAAM,MAAM,GAAG,YAAgC,CAAC;gBAChD,MAAM,OAAO,GAAG,OAAO,CAAC,cAAc,CAAC,cAAc,CACjD,WAAW,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;gBACnD,OAAO,CAAC,KAAK,CAAC,0BAA0B,CACpC,EAAC,MAAM,EAAE,MAAyC,EAAC,EAAE,EAAC,OAAO,EAAC,EAC9D,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBACtC,WAAW,GAAG,EAAC,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC,CAAC;aACvD;YAED,MAAM,IAAI,GAAGE,OAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;YAC7C,MAAM,OAAO,GAAGA,OAAI,CAAC,cAAc,CAAC,WAAW,CAAC,CAAC;YACjD,MAAM,OAAO,GACT,IAAI,iBAAiB,CAAC,WAAW,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC;YAEjE,MAAM,WAAW,GAAG;gBAClB,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,WAAW,CAAC,EAAC;gBACrE,EAAC,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,GAAG,OAAO,CAAC,EAAC;aACrC,CAAC;YACF,MAAM,KAAK,GAAG,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,EAAE,OAAO,CAAC,CAAC;YAC/D,MAAM,IAAI,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;YACjD,IAAI,CAAC,YAAY,GAAG,WAAW,CAAC;YAEhC,MAAM,MAAM,GACR,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,EAAE,OAAO,EAAE,WAAW,CAAC,CAAC;YACrE,OAAO,CAAC,WAAW,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;YAClC,OAAO,MAAM,CAAC;SACf;;;QAID,MAAM,SAAS,GAAI,MAA6C,CAAC,IAAI,CAAC;QACtE,IAAI,UAAU,GAAG,SAAS,CAAC;QAC3B,IAAI,WAAW,IAAI,IAAI,IAAI,WAAW,KAAK,CAAC,EAAE;YAC5C,UAAU,GAAG,IAAI,UAAU,CAAC,MAAM,CAAC,KAAK,GAAG,MAAM,CAAC,MAAM,GAAG,WAAW,CAAC,CAAC;YAExE,MAAM,UAAU,GAAG,SAAS,CAAC,MAAM,CAAC;YACpC,IAAI,CAAC,GAAG,CAAC,CAAC;YACV,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,EAAE;gBACnC,IAAI,CAAC,GAAG,CAAC,GAAG,WAAW,EAAE;oBACvB,UAAU,CAAC,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;iBAChC;aACF;SACF;QAED,MAAM,MAAM,GACR,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,OAAO,EAAE,IAAI,UAAU,CAAC,UAAU,CAAC,CAAC,CAAC;QAC7E,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QACnC,OAAO,MAAM,CAAC;IAChB;;IC9JA;;;;;;;;;;;;;;;;UAqBa,gBAAgB;QAc3B,YACI,MAAgB,EAAE,SAAmB,EAAE,aAAuB,EAC9D,WAA0B,EAAE,UAAyB;YAVzD,aAAQ,GAAG,wBAAwB,CAAC;;YAEpC,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAItD,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,aAAa,GAAG,CAAC,GAAG,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;YAC/CD,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;YAC3DA,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,WAAW,GAAG,MAAM,CAAC;YAC1B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,WAAW,IAAI,IAAI,EAAE;gBACvBA,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;gBAC7D,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;aACnC;YACD,IAAI,UAAU,IAAI,IAAI,EAAE;gBACtBA,eAAY,CAAC,0BAA0B,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;gBAC5D,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;aAClC;YACD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;YAC7B,IAAI,CAAC,SAAS,GAAG,WAAW,CAAC;SAC9B;QAED,WAAW;YACT,IAAI,aAAa,GAAG,KAAK,CAAC;YAC1B,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBAC5B,aAAa,GAAG,+BAA+B,CAAC;aACjD;YAED,IAAI,YAAY,GAAG,KAAK,CAAC;YACzB,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;gBAC3B,YAAY,GAAG,8BAA8B,CAAC;aAC/C;YAED,MAAM,QAAQ,GAAG;QACbY,mBAAI,CAAC,OAAO,CAAC;;;;;;8BAMS,aAAa;6BACd,YAAY;;;;;GAKtC,CAAC;YACA,OAAO,QAAQ,CAAC;SACjB;;;ICrFH;;;;;;;;;;;;;;;;IAuBO,MAAM,oBAAoB,GAAiB;QAChD,UAAU,EAAEgE,iBAAc;QAC1B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC;YACnC,MAAM,EAAC,CAAC,EAAE,KAAK,EAAE,MAAM,EAAE,IAAI,EAAE,QAAQ,EAAC,GAAG,MAA8B,CAAC;YAC1E,MAAM,EAAC,eAAe,EAAC,GAAG,KAAuC,CAAC;YAClE,MAAM,aAAa,GAAG,OAAwB,CAAC;YAC/C,MAAM,eAAe,GAAG,CAAC,CAAW,EAAE,IAAc,EAAE,QAAkB,CAAC,CAAC;YAC1E,IAAI,WAAW,GAAG,IAAI,CAAC;YACvB,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,WAAW,GAAG,MAAM,CAAC,KAAK,CAAC;gBAC3B,eAAe,CAAC,IAAI,CAAC,MAAgB,CAAC,CAAC;aACxC;YACD,IAAI,UAAU,GAAG,IAAI,CAAC;YACtB,IAAI,KAAK,IAAI,IAAI,EAAE;gBACjB,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;gBACzB,eAAe,CAAC,IAAI,CAAC,KAAe,CAAC,CAAC;aACvC;YACD,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAChC,CAAC,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,EAAE,QAAQ,CAAC,KAAK,EAAE,WAAW,EAAE,UAAU,CAAC,CAAC;YAClE,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,eAAe,CAAC,EAAC,CAAC,CAAC;YACjE,OAAO,aAAa,CAAC,gBAAgB,CACjC,OAAO,EAAE,eAAe,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;SACrD;KACF;;IC/CD;;;;;;;;;;;;;;;;aAuBgB,WAAW,CAAC,IAI3B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,MAAM,EAAE,IAAI,EAAE,sBAAsB,EAAC,GAAG,MAAM,CAAC;QACzD,MAAM,EACJ,OAAO,EACP,GAAG,EACH,UAAU,EACV,SAAS,EACT,eAAe,EACf,UAAU,EACV,cAAc,EACf,GAAG,KAAK,CAAC;QAEV,MAAM,WAAW,GAAG5E,eAAY,CAAC,uBAAuB,CAAC,UAAU,CAAC,CAAC;QACrE,MAAM,QAAQ,GAAGA,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAC3C,MAAM,CAAC,KAAyC,EAAE,OAAO,EAAE,SAAS,EAAE,GAAG,EACzE,eAAe,EAAE,KAAK,kBAAkB,WAAW,CAAC,CAAC;QAEzD,OAAO,UAAU,CAAC;YAChB,CAAC;YACD,MAAM;YACN,QAAQ;YACR,OAAO;YACP,IAAI;YACJ,sBAAsB;YACtB,cAAc;YACd,UAAU;SACX,CAAC,CAAC;IACL,CAAC;IAEM,MAAM,iBAAiB,GAAiB;QAC7C,UAAU,EAAE6E,cAAW;QACvB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,WAA+B;KAC5C;;IC9DD;;;;;;;;;;;;;;;;aAuBgB,oBAAoB,CAAC,IAIpC;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,MAAM,EAAE,IAAI,EAAE,sBAAsB,EAAC,GAAG,MAAM,CAAC;QACzD,MAAM,EAAC,OAAO,EAAE,GAAG,EAAE,SAAS,EAAE,eAAe,EAAE,UAAU,EAAE,cAAc,EAAC,GACxE,KAAK,CAAC;QAEV,IAAI,UAAU,GAAG,SAAS,CAAC;QAC3B,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SACrB;QAED5E,OAAI,CAAC,MAAM,CACPD,eAAY,CAAC,8BAA8B,CAAC,OAAO,EAAE,UAAU,CAAC,EAChE,MAAM,gEAAgE;YAClE,kBAAkB,OAAO,mBAAmB,UAAU,GAAG,CAAC,CAAC;QAEnE,MAAM,QAAQ,GAAGA,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAC3C,MAAM,CAAC,KAAyC,EAAE,OAAO,EAAE,UAAU,EACrE,GAAG,EAAE,eAAe,EAAE,IAAI,iBAAiB,CAAC;QAEhD,MAAM,aAAa,GAAiB,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;QAEhD,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;QAC7B,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;QAEjE,IAAI,OAAO,EAAE;YACX,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SAC1B;QACD,IAAI,yBAAyB,EAAE;YAC7B,aAAa,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;SAC5C;QAED,MAAM,UAAU,GAAG;YACjB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAC;YACpE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,OAAO,CAAC,EAAC;SAC7D,CAAC;QAEF,IAAI,OAA0D,CAAC;QAC/D,IAAI,QAAQ,CAAC,QAAQ,GAAG,CAAC,IAAI,QAAQ,CAAC,OAAO,GAAG,CAAC;YAC7C,QAAQ,CAAC,WAAW,IAAI,CAAC;YACzB,QAAQ,CAAC,UAAU,KAAK,QAAQ,CAAC,WAAW;YAC5C,QAAQ,CAAC,cAAc,KAAK,CAAC,IAAI,QAAQ,CAAC,aAAa,KAAK,CAAC;YAC7D,QAAQ,CAAC,UAAU,GAAG,CAAC,KAAK,CAAC,EAAE;YACjC,OAAO,GAAG,IAAI,0BAA0B,CACpC,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE,yBAAyB,CAAC,CAAC;SAC/D;aAAM;YACL,OAAO,GAAG,IAAI,sBAAsB,CAChC,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE,yBAAyB,CAAC,CAAC;YAC9D,UAAU,CAAC,IAAI,CACX,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,CAAC,EAAC,EAC9C,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,WAAW,CAAC,EAAC,EAC7C,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC,EAAE;gBACpE,IAAI,EAAE,OAAO;gBACb,IAAI,EAAE,CAAC,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,aAAa,CAAC;aACxD,CAAC,CAAC;SACR;QACD,IAAI,UAAU,KAAK,WAAW,EAAE;YAC9B,UAAU,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,cAAc,CAAC,EAAC,CAAC,CAAC;YAC3D,OAAO,CAAC,QAAQ,IAAI,eAAe,CAAC;SACrC;QACD,MAAM,MAAM,GACR,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,aAAa,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;QAE5E,OAAO,MAAM,CAAC;IAChB,CAAC;IAEM,MAAM,0BAA0B,GAAiB;QACtD,UAAU,EAAE8E,uBAAoB;QAChC,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,oBAAwC;KACrD;;IClGD;;;;;;;;;;;;;;;;UAoBa,eAAe;QAU1B,YAAY,QAAgB,EAAE,KAAe;YAL7C,kBAAa,GAAa,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;YAE3C,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,YAAY,QAAQ,EAAE,CAAC;YACxC,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;YACzB,IAAI,CAAC,QAAQ,GAAG,6BAA6B,iBAAiB,CAAC,QAAQ,CAAC,GAAG,CAAC;SAC7E;QAED,WAAW;YACT,IAAI,YAAY,CAAC;YACjB,IAAI,IAAI,CAAC,QAAQ,GAAG,CAAC,EAAE;gBACrB,YAAY,GAAG,qBAAqB,CAAC;aACtC;iBAAM;gBACL,YAAY,GAAG,kBAAkB,CAAC;aACnC;YACD,MAAM,QAAQ,GAAG;QACblE,mBAAI,CAAC,OAAO,CAAC;;;;;;8BAMS,YAAY;;;;;;;OAOnC,CAAC;YACJ,OAAO,QAAQ,CAAC;SACjB;;;IC/DH;;;;;;;;;;;;;;;;aAyBgB,QAAQ,CACpB,IAAsD;QACxD,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,MAAM,CAAC;QAEjC,MAAM,YAAY,GAAG,OAAO,CAAC,KAAK,CAAC;QACnC,MAAM,SAAS,GAAG,YAAY,CAAC,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACxD,MAAM,UAAU,GAAGX,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAEpD,MAAM,CAAC,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,OAAO,CAAC,GAC9CD,eAAY,CAAC,kBAAkB,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;QAErD,MAAM,cAAc,GAAG,OAAO,CAC1B,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,SAAS,EAAE,SAAS,CAAC,EAAC,EAAC,CAAC,CAAC;QAC7E,MAAM,QAAQ,GAAG,OAAO,CAAC;YACvB,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;YACnB,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,EAAEC,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,SAAS,GAAG,SAAS,CAAC,EAAC;SAC5E,CAAC,CAAC;QACH,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;YAC7C,MAAM,CAAC,KAAK,KAAK,QAAQ,EAAE;YAC7B,MAAM,WAAW,GAAG,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,MAAM,CAAe,CAAC;YACnE,MAAM,SAAS,GAAG,OAAO,CAAC,UAAU,CAAkB,MAAM,CAAC,CAAC;YAC9D,MAAM,QAAQ,GAAG,eAAe,CAC5B,WAAW,EAAE,SAAS,EAAE,MAAM,CAAC,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EACrE,OAAO,EAAE,MAAM,CAAC,KAAK,EAAE,UAAU,CAAC,CAAC;YAEvC,OAAO,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,MAAM,CAAC,KAAK,EAAE,QAAQ,CAAC,MAAM,CAAC,CAAC;SAC3E;QACD,MAAM,OAAO,GAAG,IAAI,eAAe,CAAC,SAAS,EAAE,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;QACvE,MAAM,WAAW,GACb,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,OAAO,EAAC,CAAC,CAAC;QACzE,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAChC,OAAO,EAAE,CAAC,QAAQ,EAAE,cAAc,CAAC,EAAE,QAAQ,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QAEtE,MAAM,QAAQ,GACV,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC,EAAC,CAAC,CAAC;QAEtE,OAAO,CAAC,WAAW,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;QAC3C,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QACrC,OAAO,CAAC,WAAW,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAEhC,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEM,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAE8E,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAA4B;KACzC;;IC1ED;;;;;;;;;;;;;;;;UAoBa,aAAa;QAUxB,YAAY,MAAgB,EAAE,WAAqB;YALnD,kBAAa,GAAa,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;YAC3C,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,MAAM,CAAC,KAAK,EAAE,CAAC;YAClC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;YACrB,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;SAC3B;QAED,WAAW;YACT,MAAM,YAAY,GAAGC,iBAAe,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAClD,MAAM,QAAQ,GAAG;QACbpE,mBAAI,CAAC,OAAO,CAAC;;;;;oDAK+B,YAAY;;;KAG3D,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;KACF;IAED;IACA,SAASoE,iBAAe,CAAC,MAAgB;QACvC,MAAM,aAAa,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;QACnE,MAAM,YAAY,GAAG,EAAE,CAAC;QACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,IAAI,CAAC,KAAK,CAAC,EAAE;gBACX,YAAY,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;aAC7B;iBAAM;gBACL,YAAY,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;aAC1C;SACF;QACD,OAAO,YAAY,CAAC,IAAI,EAAE,CAAC;IAC7B;;ICpEA;;;;;;;;;;;;;;;;aAyBgB,QAAQ,CACpB,IAC0E;QAE5E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAE,OAAO,EAAC,GAAG,MAAM,CAAC;QAC5B,MAAM,EAAC,IAAI,EAAE,SAAS,EAAC,GAAG,KAAK,CAAC;;;QAIhC,MAAM,UAAU,GAAG/E,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAEzD,MAAM,SAAS,GAAGD,eAAY,CAAC,YAAY,CAAC,wBAAwB,CAChE,CAAC,EAAE,OAAO,EAAE,UAAU,EAAE,SAAS,CAAC,CAAC;QAEvC,MAAM,WAAW,GAAGC,OAAI,CAAC,aAAa,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAEtD,MAAM,SAAS,GAAG,EAAE,CAAC;QAErB,MAAM,QAAQ,GAAG,OAAO,CAAC;YACvB,MAAM,EAAE,EAAC,CAAC,EAAC;YACX,OAAO;YACP,KAAK,EAAE;gBACL,KAAK,EAAE;oBACL,SAAS,CAAC,SAAS,EAAE,SAAS,CAAC,SAAS,EAAE,SAAS,CAAC,OAAO;oBAC3D,SAAS,CAAC,SAAS;iBACpB;aACF;SACF,CAAC,CAAC;QAEH,MAAM,YAAY,GAAG,OAAO,CAAC;YAC3B,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC;YACpB,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,SAAS,EAAE,WAAW,GAAG,SAAS,CAAC,SAAS,CAAC,EAAC;SACzE,CAAC,CAAC;QAEH,SAAS,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QACzB,SAAS,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;QAE7B,MAAM,kBAAkB,GAAG;YACzB,SAAS,CAAC,SAAS,EAAE,SAAS,CAAC,SAAS,EAAE,WAAW,GAAG,SAAS,CAAC,SAAS;YAC3E,SAAS,CAAC,SAAS;SACpB,CAAC;QAEF,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE;YAC5C,MAAM,iBAAiB,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;YACrE,MAAM,aAAa,GAAG,iBAAiB,CAAC,MAAoB,CAAC;YAC7D,MAAM,UAAU,GACZM,SAAM,CAAC,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,aAAa,CAC1C,CAAC;YACvB,MAAM,WAAW,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YAC3D,MAAM,OAAO,GAAG,WAAW,CAAC,MAAoB,CAAC;YACjD,MAAM,IAAI,GACNA,SAAM,CAAC,QAAQ,CAAC,KAAK,EAAE,QAAQ,CAAC,KAAK,EAAE,OAAO,CAAuB,CAAC;YAC1E,MAAM,MAAM,GAAG,eAAe,CAAC,IAAI,EAAE,UAAU,EAAE,kBAAkB,CAAC,CAAC;YAErE,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;YAEtD,OAAO,OAAO,CAAC,cAAc,CACzB,SAAS,CAAC,WAAW,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAoB,CAAC,CAAC;SACvE;QAED,MAAM,OAAO,GAAG,IAAI,aAAa,CAAC,QAAQ,CAAC,KAAK,EAAE,kBAAkB,CAAC,CAAC;QACtE,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAChC,OAAO,EAAE,CAAC,QAAQ,EAAE,YAAY,CAAC,EAAE,QAAQ,CAAC,KAAK,CAAC,CAAC;QACvD,SAAS,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAEpB,MAAM,QAAQ,GAAG,OAAO,CACpB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,SAAS,CAAC,WAAW,EAAC,EAAC,CAAC,CAAC;QACxE,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACtD,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEM,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAE0E,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAA4B;KACzC;;ICtGD;;;;;;;;;;;;;;;;IAuBO,MAAM,OAAO,GAAG,gBAAgB,CAAC;QACtC,MAAM,EAAE,YAAY,CAAC,OAAO;QAC5B,aAAa,EAAEC,cAAU;QACzB,KAAK,EAAE,MAAM;KACd,CAAC,CAAC;IAEI,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAAO;KACpB;;ICjCD;;;;;;;;;;;;;;;;IAuBO,MAAM,YAAY,GAAG,gBAAgB,CAAC;QAC3C,MAAM,EAAE,YAAY,CAAC,aAAa;QAClC,KAAK,EAAE,MAAM;QACb,aAAa,EAAEC,mBAAe;KAC/B,CAAC,CAAC;IAEI,MAAM,kBAAkB,GAAiB;QAC9C,UAAU,EAAEC,eAAY;QACxB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,YAAY;KACzB;;ICjCD;;;;;;;;;;;;;;;;IAqBO,MAAM,KAAK,GACd,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,MAAM,EAAE,KAAK,EAAE,MAAM,EAAC,CAAC,CAAC;IAE1D,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC5BD;;;;;;;;;;;;;;;;aAuBgB,SAAS,CAAC,IAIzB;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,KAAK,EAAC,GAAG,KAAK,CAAC;QACtB,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACvD,MAAM,OAAO,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,SAAS,CAAC,CAAC;QACnE,OAAO,CAAC,QAAQ,GAAG,cAAc,CAAC;QAClC,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;IACxE,CAAC;IAEM,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEC,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAA6B;KAC1C;;ICzCD;;;;;;;;;;;;;;;;IAuBO,MAAM,IAAI,GAAG,gBAAgB,CAChC,EAAC,MAAM,EAAE,YAAY,CAAC,IAAI,EAAE,KAAK,EAAE,MAAM,EAAE,aAAa,EAAEC,WAAO,EAAC,CAAC,CAAC;IAEjE,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC9BD;;;;;;;;;;;;;;;;IAuBO,MAAM,SAAS,GAAG,gBAAgB,CAAC;QACxC,MAAM,EAAE,YAAY,CAAC,UAAU;QAC/B,KAAK,EAAE,MAAM;QACb,aAAa,EAAEC,gBAAY;KAC5B,CAAC,CAAC;IAEI,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEC,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAAS;KACtB;;ICjCD;;;;;;;;;;;;;;;;IAsBO,MAAM,GAAG,GACZ,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,GAAG,EAAE,aAAa,EAAE,UAAU,EAAC,CAAC,CAAC;IAEnE,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC7BD;;;;;;;;;;;;;;;;IAsBO,MAAM,UAAU,GACnB,gBAAgB,CAAC,EAAC,MAAM,EAAE,YAAY,CAAC,WAAW,EAAE,KAAK,EAAE,MAAM,EAAC,CAAC,CAAC;IAEjE,MAAM,gBAAgB,GAAiB;QAC5C,UAAU,EAAEC,aAAU;QACtB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,UAAU;KACvB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,UAAU,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,WAAW,EAAC,CAAC,CAAC;IAEtE,MAAM,gBAAgB,GAAiB;QAC5C,UAAU,EAAEC,aAAU;QACtB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,UAAU;KACvB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,OAAO,GAAG,gBAAgB,CAAC;QACtC,MAAM,EAAE,YAAY,CAAC,GAAG;QACxB,aAAa,EAAEC,cAAU;KAC1B,CAAC,CAAC;IAEI,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAAO;KACpB;;IChCD;;;;;;;;;;;;;;;;aAqBgB,OAAO,CACnB,IAA0E;QAE5E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,UAAU,EAAE,OAAO,EAAE,GAAG,EAAE,eAAe,EAAC,GAAG,KAAK,CAAC;QAC1D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAGhG,eAAY,CAAC,iBAAiB,CAC3C,CAAC,CAAC,KAAyC,EAAE,UAAU,EAAE,OAAO,EAChE,SAAS,EAAE,GAAG,EAAE,eAAe,CAAC,CAAC;QAErC,OAAO,QAAQ,CAAC,CAAC,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IAC/C,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEiG,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;ICvCD;;;;;;;;;;;;;;;;aAsBgB,GAAG,CACf,IAAkE;QAEpE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAE,QAAQ,EAAC,GAAG,KAAK,CAAC;QAE/B,OAAO,MAAM,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;IACnD,CAAC;IAEM,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAuB;KACpC;;ICpCD;;;;;;;;;;;;;;;;IAuBO,MAAM,OAAO,GAAG,gBAAgB,CAAC;QACtC,MAAM,EAAE,YAAY,CAAC,GAAG;QACxB,aAAa,EAAEC,cAAU;KAC1B,CAAC,CAAC;IAEI,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAAO;KACpB;;IChCD;;;;;;;;;;;;;;;;UAoBa,gBAAgB;QAY3B,YACI,MAAgB,EAAE,QAAiC,EACnD,IAA2B;YAX/B,aAAQ,GAAG,EAAE,CAAC;YAGd,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAGrD,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,GAAG,CAC3B,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,mBAAmB,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,gBAAgB,CAAC;YACtE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;YACrB,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;gBAChB,IAAI,CAAC,QAAQ,IAAI,OAAO,CAAC,eAAe,CAAC;aAC1C,CAAC,CAAC;YACH,IAAI,CAAC,MAAM,GAAG,IAAI,KAAK,SAAS,GAAG,CAAC,GAAG,CAAC,CAAC;YACzC,IAAI,CAAC,SAAS,GAAG,aAAa,IAAI,EAAE,CAAC;SACtC;QAED,WAAW;YACT,MAAM,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;;YAEhC,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,eAAe,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACzE,MAAM,GAAG,GAAG,IAAI,CAAC,MAAM;iBACN,GAAG,CACA,CAAC,CAAC,EAAE,CAAC,KAAK,eAAe,CAAC,wBACtB,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,GAAG,EAAE,EAAE,CAAC;iBAClC,IAAI,CAAC,GAAG,CAAC,CAAC;YAE3B,MAAM,WAAW,GAAG,IAAI,KAAK,CAAC,GAAG,OAAO,GAAG,UAAU,CAAC;YACtD,MAAM,SAAS,GAAG,IAAI,KAAK,CAAC,GAAG,KAAK,GAAG,QAAQ,CAAC;YAChD,MAAM,UAAU,GAAG,IAAI,KAAK,CAAC,GAAG,MAAM,GAAG,SAAS,CAAC;YACnD,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,CAAC;YACtC,MAAM,cAAc,GAAG,IAAI,GAAG,CAAC;gBAC3B,CAAC,WAAW,EAAE,WAAW,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;gBACnE,QAAQ,CAAC;YAEb,OAAO;QACHxF,mBAAI,CAAC,OAAO,CAAC;;wBAEG,KAAK,IAAI,KAAK;sBAChB,KAAK,IAAI,GAAG;;gCAEF,IAAI;kBAClB,UAAU,MAAM,WAAW;gBAC7B,UAAU,MAAM,WAAW,UAAU,UAAU,MACvD,IAAI,CAAC,MAAM;wBACK,UAAU,OAAO,SAAS;gBAClC,UAAU,OAAO,SAAS,eAAe,UAAU,MAC3D,IAAI,CAAC,MAAM;;;;yCAIsB,cAAc;;;KAGlD,CAAC;SACH;;;ICvFH;;;;;;;;;;;;;;;;IAuBO,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEyF,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC;YACnC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAyB,CAAC;YACtC,MAAM,EAAC,QAAQ,EAAE,IAAI,EAAC,GAAG,KAAkC,CAAC;YAC5D,MAAM,aAAa,GAAG,OAAwB,CAAC;YAE/C,MAAM,WAAW,GAAG,QAAQ,CAAC,GAAG,CAAC,CAAC;gBAChC,OAAO,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC;aAC5C,CAAC,CAAC;YACH,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,EAAE,IAAI,CAAC,CAAC;YAC9D,MAAM,MAAM,GACR,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;YAEvE,OAAO,MAAM,CAAC;SACf;KACF;;ICxCD;;;;;;;;;;;;;;;;IAyBA;IACA;aACgB,GAAG,CAAC,IAAiD;QAEnE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QAEnB,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;YACnC,MAAM,KAAK,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YAC9C,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GACvB,UAAU,CAAC,KAAK,CAAC,MAAoB,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;YAC7D,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;SAC7D;QAED,MAAM,OAAO,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,GAAG,CAAC,CAAC;QAE7D,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;IACzD,CAAC;IAEM,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAuB;KACpC;;IChDD;;;;;;;;;;;;;;;;aAoBgB,mBAAmB,CAAC,IAInC;QACC,OAAO,CAAC,IAAI,CACR,wDAAwD;YACxD,0CAA0C,CAAC,CAAC;QAEhD,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,KAAK,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QAC/B,MAAM,EAAC,aAAa,EAAE,YAAY,EAAE,cAAc,EAAC,GAAG,KAAK,CAAC;QAE5D,MAAM,SAAS,GAAG,OAAO,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,CAAe,CAAC;QAC/D,MAAM,UAAU,GAAG,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,CAAe,CAAC;QAEjE,MAAM,EAAC,eAAe,EAAC,GAAGC,eAAY,CAAC,uBAAuB,CAC1D,SAAS,EAAE,UAAU,EAAE,aAAa,EAAE,YAAY,EAAE,cAAc,CAAC,CAAC;QAExE,OAAO,OAAO,CAAC,cAAc,CACzB,CAAC,eAAe,CAAC,MAAM,CAAC,EAAE,OAAO,EAAE,IAAI,UAAU,CAAC,eAAe,CAAC,CAAC,CAAC;IAC1E,CAAC;IAEM,MAAM,yBAAyB,GAAiB;QACrD,UAAU,EAAEC,sBAAmB;QAC/B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,mBAAuC;KACpD;;IC/CD;;;;;;;;;;;;;;;;aAqBgB,mBAAmB,CAAC,IAInC;QACC,OAAO,CAAC,IAAI,CACR,wDAAwD;YACxD,0CAA0C,CAAC,CAAC;QAEhD,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,KAAK,EAAE,MAAM,EAAC,GAAG,MAAM,CAAC;QAC/B,MAAM,EAAC,aAAa,EAAE,YAAY,EAAE,cAAc,EAAE,YAAY,EAAC,GAAG,KAAK,CAAC;QAE1E,MAAM,SAAS,GAAG,OAAO,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,CAAe,CAAC;QAC/D,MAAM,UAAU,GAAG,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,CAAe,CAAC;QAEjE,MAAM,gBAAgB,GAAG,aAAa,CAAC;QACvC,MAAM,eAAe,GAAG,YAAY,CAAC;QACrC,MAAM,iBAAiB,GAAG,cAAc,CAAC;QACzC,MAAM,eAAe,GAAG,YAAY,CAAC;QAErC,MAAM,EAAC,eAAe,EAAE,cAAc,EAAC,GACnCD,eAAY,CAAC,uBAAuB,CAChC,SAAS,EAAE,UAAU,EAAE,gBAAgB,EAAE,eAAe,EACxD,iBAAiB,EAAE,eAAe,CAAC,CAAC;QAE5C,OAAO;YACL,OAAO,CAAC,cAAc,CAClB,CAAC,eAAe,CAAC,MAAM,CAAC,EAAE,OAAO,EAAE,IAAI,UAAU,CAAC,eAAe,CAAC,CAAC;YACvE,OAAO,CAAC,cAAc,CAClB,CAAC,cAAc,CAAC,MAAM,CAAC,EAAE,SAAS,EAAE,IAAI,YAAY,CAAC,cAAc,CAAC,CAAC;SAC1E,CAAC;IACJ,CAAC;IAEM,MAAM,yBAAyB,GAAiB;QACrD,UAAU,EAAEE,sBAAmB;QAC/B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,mBAAuC;KACpD;;IC3DD;;;;;;;;;;;;;;;;aA0BgB,SAAS,CACrB,IAAuD;QACzD,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;YAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,CAAC,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACtD,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,CAAC,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAEtD,MAAM,MAAM,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,IAAI,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAE9D,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YAC9B,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YAE9B,OAAO,MAAM,CAAC;SACf;aAAM;YACL,OAAO,IAAI,CAAC;gBACV,KAAK,EAAE;oBACL,KAAK,EAAE,CAAC,CAAC,KAAK;oBACd,KAAK,EAAE,CAAC,CAAC,KAAK;oBACd,KAAK,EAAE,CAAC,CAAC,KAAK,KAAK,QAAQ,GAAG,EAAE,GAAG,CAAC;iBACrC;gBACD,OAAO;aACR,CAAC,CAAC;SACJ;IACH,CAAC;IAEM,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEC,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAA6B;KAC1C;;IC5DD;;;;;;;;;;;;;;;;aA2BgB,QAAQ,CACpB,IAAsD;QACxD,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QAEnB,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YACxB,MAAM,IAAI,KAAK,CAAC,8CAA8C,CAAC,CAAC;SACjE;aAAM,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;YAClC,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,CAAC,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YACrD,MAAM,CAAC,GAAG,SAAS,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAEtD,MAAM,MAAM,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,IAAI,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;YAE9D,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YAC9B,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YAE9B,OAAO,MAAM,CAAC;SACf;aAAM;YACL,OAAO,IAAI,CAAC,EAAC,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SAC3E;IACH,CAAC;IAEM,MAAM,cAAc,GAAiB;QAC1C,UAAU,EAAEC,WAAQ;QACpB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,QAA4B;KACzC;;ICzDD;;;;;;;;;;;;;;;;aAuBgB,IAAI,CAChB,IAAoE;QAEtE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QAErB,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YACvB,OAAO,UAAU,CACb,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,GAAG,EAAE,IAAI,EAAC,EAAC,CAAC,CAAC;SAChE;QAED,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QAC9B,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QAE9B,MAAM,CAAC,OAAO,CAAC,CAAC;YACd1G,OAAI,CAAC,iBAAiB,CAClB,KAAK,EAAE,CAAC,CAAC,KAAK,EACd,uDAAuD,CAAC,CAAC;YAC7DA,OAAI,CAAC,MAAM,CACP,KAAK,KAAK,CAAC,CAAC,KAAK,EACjB,MAAM,uDAAuD,CAAC,CAAC;SACpE,CAAC,CAAC;QAEH,MAAM,uBAAuB,GAAiB,EAAE,CAAC;QACjD,MAAM,eAAe,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC;YAClC,MAAM,SAAS,GACX,UAAU,CAAC,EAAC,MAAM,EAAE,EAAC,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,GAAG,EAAE,IAAI,EAAC,EAAC,CAAC,CAAC;YAClE,uBAAuB,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;YACxC,OAAO,SAAS,CAAC;SAClB,CAAC,CAAC;QAEH,MAAM,MAAM,GAAG,MAAM,CAAC,EAAC,MAAM,EAAE,eAAe,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAC,EAAC,CAAC,CAAC;QAEzE,uBAAuB,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QAEpE,OAAO,MAAM,CAAC;IAChB,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAE2G,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICjED;;;;;;;;;;;;;;;;UAoBa,UAAU;QAWrB,YAAY,MAAgB,EAAE,QAAiC;YAN/D,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,sBAAsB,CAAC;YAClC,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,GAAG,CAC3B,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,mBAAmB,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,gBAAgB,CAAC;YACtE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;gBAChB,IAAI,CAAC,QAAQ,IAAI,OAAO,CAAC,eAAe,CAAC;aAC1C,CAAC,CAAC;YACH,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;YACrB,IAAI,CAAC,SAAS,GAAG,KAAK,CAAC;SACxB;QAED,WAAW;YACT,MAAM,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;YAChC,MAAM,IAAI,GAAG,iBAAiB,CAAC,IAAI,CAAC,CAAC;;YAErC,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,eAAe,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACzE,MAAM,GAAG,GAAG,IAAI,CAAC,MAAM;iBACN,GAAG,CACA,CAAC,CAAC,EAAE,CAAC,KAAK,eAAe,CAAC,wBACtB,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,GAAG,EAAE,EAAE,CAAC;iBAClC,IAAI,CAAC,GAAG,CAAC,CAAC;YAC3B,MAAM,UAAU,GAAG,IAAI,GAAG,CAAC,GAAG,GAAG,IAAI,IAAI,KAAK,GAAG,GAAG,GAAG,KAAK,EAAE,CAAC;YAC/D,MAAM,QAAQ,GAAG,IAAI,GAAG,CAAC,GAAG,GAAG,IAAI,IAAI,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,CAAC;YAEzD,MAAM,gBAAgB,GAAG,IAAI,GAAG,CAAC,GAAG,mBAAmB,GAAG,cAAc,CAAC;YACzE,MAAM,iBAAiB,GAAG,IAAI,GAAG,CAAC,GAAG,kBAAkB,GAAG,aAAa,CAAC;YAExE,MAAM,cAAc,GAAG,IAAI,GAAG,CAAC;gBAC3B,CAAC,WAAW,EAAE,WAAW,EAAE,WAAW,EAAE,WAAW,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;gBACnE,QAAQ,CAAC;YAEb,MAAM,QAAQ,GAAG;QACbhG,mBAAI,CAAC,OAAO,CAAC;;wBAEG,UAAU;sBACZ,QAAQ;;;gBAGd,gBAAgB,OAAO,iBAAiB;;;;2CAIb,cAAc;;;;KAIpD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICjFH;;;;;;;;;;;;;;;;IAwBO,MAAM,KAAK,GACd,CAAC,IAEyB;QACxB,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,QAAQ,EAAE,aAAa,EAAC,GAAG,KAAK,CAAC;QACxC,IAAI,QAAQ,CAAC,KAAK,CAAC,CAAC,IAAIX,OAAI,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE;YACpD,OAAO,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;SACzC;QACD,IAAIA,OAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;;;YAGrC,MAAM,WAAW,GAAG,QAAQ,CAAC,GAAG,CAC5B,CAAC,CAAC,EAAE,CAAC,KACD,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,gBAAgB,CAAC;YACjE,OAAO,IAAI,CAAC;gBACV,OAAO;gBACP,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAE,KAAK,EAAE,aAAa,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC;aAClE,CAAC,CAAC;SACJ;QACD,MAAM,WAAW,GAAG,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,aAAa,CAAC,EAAC,CAAC,CAAC;QAC/D,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,WAAW,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACzE,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QAClD,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IACtE,CAAC,CAAC;IAEC,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAE4G,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAyB;KACtC;;ICvDD;;;;;;;;;;;;;;;;IAsBO,MAAM,GAAG,GAAG,gBAAgB,CAAC;QAClC,MAAM,EAAE,YAAY,CAAC,GAAG;KACzB,CAAC,CAAC;IAEI,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC9BD;;;;;;;;;;;;;;;;aAwBgB,KAAK,CAAC,IAAmD;QAEvE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,CAAC,EAAE,KAAK,EAAC,GAAG,MAAM,CAAC;QAE1B,MAAM,OAAO,GAAG,IAAI,eAAe,CAAC,YAAY,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC;QAC9E,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,EAAE,SAAS,CAAC,CAAC;IAClE,CAAC;IAEM,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAyB;KACtC;;ICrCD;;;;;;;;;;;;;;;;aAsBgB,IAAI,CAChB,IAAoE;QAEtE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAE,QAAQ,EAAC,GAAG,KAAK,CAAC;QAE/B,OAAO,MAAM,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;IACpD,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICpCD;;;;;;;;;;;;;;;;IAsBO,MAAM,KAAK,GACd,CAAC,IAAiD;QAChD,MAAM,EAAC,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QAC9B,MAAM,EAAC,KAAK,EAAE,IAAI,EAAE,IAAI,EAAE,KAAK,EAAC,GAAG,KAAK,CAAC;QACzC,MAAM,MAAM,GAAG,YAAY,CAAC,KAAK,EAAE,IAAI,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;QACtD,OAAO,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IAChE,CAAC,CAAC;IAEC,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAyB;KACtC;;IClCD;;;;;;;;;;;;;;;;IAsBO,MAAM,OAAO,GAAG,gBAAgB,CAAC,EAAC,MAAM,EAAE,YAAY,CAAC,GAAG,EAAC,CAAC,CAAC;IAE7D,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;IC5BD;;;;;;;;;;;;;;;;IAqBO,MAAM,UAAU,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,UAAU,EAAC,CAAC,CAAC;IAErE,MAAM,gBAAgB,GAAiB;QAC5C,UAAU,EAAEC,aAAU;QACtB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,UAAU;KACvB;;IC3BD;;;;;;;;;;;;;;;;IAqBO,MAAM,IAAI,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;IAEzD,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC3BD;;;;;;;;;;;;;;;;IAqBO,MAAM,KAAK,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,KAAK,EAAC,CAAC,CAAC;IAE3D,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEC,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC3BD;;;;;;;;;;;;;;;;UAoBa,qBAAqB;QAUhC,YACI,UAA4C,EAAE,SAAiB,EAC/D,QAAgB;YAPpB,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,wDAAwD,CAAC;YACpE,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,WAAW,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,QAAQ,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;YAEvE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAE3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,SAAS,GAAG,gBAAgB,CAAC;SACnC;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;QACbzG,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;KA0ChB,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICzFH;;;;;;;;;;;;;;;;aAsBgB,cAAc,CAAC,IAI9B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,CAAC;QACxB,MAAM,EAAC,YAAY,EAAE,IAAI,EAAE,gBAAgB,EAAC,GAAG,KAAK,CAAC;QAErD,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GAAG,IAAI,CAAC;QACnC,MAAM,YAAY,GAAG,YAAY,IAAI,SAAS,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC;QAC/D,MAAM,WAAW,GAAG,YAAY,IAAI,QAAQ,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC;QAC7D,MAAM,qBAAqB,GAAG,gBAAgB,GAAG,GAAG,GAAG,GAAG,CAAC;QAC3D,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,YAAY,EAAE,WAAW,CAAC,EAAC;YACpD,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,qBAAqB,CAAC,EAAC;SACjD,CAAC;QAEF,MAAM,OAAO,GAAG,IAAI,qBAAqB,CACrC,MAAM,CAAC,KAAyC,EAAE,SAAS,EAAE,QAAQ,CAAC,CAAC;QAE3E,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;IAC7E,CAAC;IAEM,MAAM,oBAAoB,GAAiB;QAChD,UAAU,EAAE0G,iBAAc;QAC1B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,cAAkC;KAC/C;;IClDD;;;;;;;;;;;;;;;;UAoBa,4BAA4B;QAWvC,YACI,UAA4C,EAAE,SAAiB,EAC/D,QAAgB,EAAE,gBAAyB;YAR/C,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YACtB,aAAQ,GAAG,iDAAiD,CAAC;YAC7D,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,WAAW,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,QAAQ,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;YAEvE,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAE3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,gBAAgB,GAAG,gBAAgB,CAAC;YACzC,IAAI,CAAC,SAAS,GAAG,iBAAiB,gBAAgB,EAAE,CAAC;SACtD;QAED,WAAW;YACT,IAAI,iBAAyB,CAAC;YAC9B,IAAI,IAAI,CAAC,gBAAgB,EAAE;gBACzB,iBAAiB;oBACb,wEAAwE;wBACxE,mBAAmB,CAAC;aACzB;iBAAM;gBACL,iBAAiB,GAAG,iDAAiD,CAAC;aACvE;YAED,MAAM,QAAQ,GAAG;QACb1G,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;oCAmBe,iBAAiB;;;;;;;;;;;KAWhD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICxFH;;;;;;;;;;;;;;;;aAsBgB,qBAAqB,CAAC,IAIrC;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,CAAC;QACxB,MAAM,EAAC,YAAY,EAAE,gBAAgB,EAAE,IAAI,EAAC,GAAG,KAAK,CAAC;QAErD,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GAAG,IAAI,CAAC;QACnC,MAAM,YAAY,GAAG,YAAY,IAAI,SAAS,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC;QAC/D,MAAM,WAAW,GAAG,YAAY,IAAI,QAAQ,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC;;QAE7D,MAAM,SAAS,GAAG,YAAY,GAAG,GAAG,GAAG,GAAG,CAAC;QAC3C,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,YAAY,EAAE,WAAW,CAAC,EAAC;YACpD,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;SACrC,CAAC;QAEF,MAAM,OAAO,GAAG,IAAI,4BAA4B,CAC5C,MAAM,CAAC,KAAyC,EAAE,SAAS,EAAE,QAAQ,EACrE,gBAAgB,CAAC,CAAC;QACtB,OAAO,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IAChF,CAAC;IAEM,MAAM,2BAA2B,GAAiB;QACvD,UAAU,EAAE2G,wBAAqB;QACjC,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,qBAAyC;KACtD;;ICnDD;;;;;;;;;;;;;;;;UAoBa,aAAa;QAWxB,YACI,UAA4C,EAC5C,SAA0C;YAZ9C,gBAAW,GAAa,EAAE,CAAC;YAI3B,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YAEtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAErD,SAAI,GAAG,IAAI,CAAC;YAKV,IAAI,CAAC,WAAW,GAAG,UAAU,CAAC;YAC9B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,QAAQ,GAAG;4BACQ,CAAC;YACzB,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;YAC1B,IAAI,CAAC,WAAW,GAAG,UAAU,CAAC;YAE9B,IAAI,OAAO,SAAS,KAAK,QAAQ,EAAE;gBACjC,IAAI,CAAC,QAAQ,IAAI,mBAAmB,CAAC;gBACrC,IAAI,CAAC,WAAW,GAAG,uCAAuC,CAAC;gBAC3D,IAAI,CAAC,SAAS,IAAI,QAAQ,CAAC;aAC5B;iBAAM;gBACL,IAAI,CAAC,QAAQ,IAAI,yBAAyB,CAAC;gBAC3C,IAAI,CAAC,WAAW,GAAG,kDAAkD,CAAC;gBACtE,IAAI,CAAC,SAAS,IAAI,OAAO,CAAC;aAC3B;SACF;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;UACX3G,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;cAWT,IAAI,CAAC,WAAW;;;;;;;;OAQvB,CAAC;YACJ,OAAO,QAAQ,CAAC;SACjB;;;IC7EH;;;;;;;;;;;;;;;;IAuBO,MAAM,sBAAsB,GAAiB;QAChD,UAAU,EAAE4G,mBAAgB;QAC5B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAC;YACnC,MAAM,EAAC,KAAK,EAAC,GAAG,MAAgC,CAAC;YACjD,MAAM,EAAC,OAAO,EAAE,SAAS,EAAE,MAAM,EAAC,GAAG,KAAoC,CAAC;YAC1E,MAAM,aAAa,GAAG,OAAwB,CAAC;YAE/C,MAAM,OAAO,GAAG,IAAI,aAAa,CAAE,KAAkB,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;YACxE,MAAM,CAAC,OAAO,EAAE,OAAO,CAAC,GACpBxH,eAAY,CAAC,cAAc,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YACxE,MAAM,WAAW,GAAG;gBACd,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,EAAC;gBAClC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,EAAC;gBAClC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAC;gBAC5C,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAC;aAC7C,CAAC;YAEN,IAAI,OAAO,SAAS,KAAK,QAAQ,EAAE;gBACjC,WAAW,CAAC,IAAI,CACZ,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,MAAM,CAAC,UAAU,CAAC,SAAS,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;aACzE;iBAAM;gBACL,WAAW,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,SAAS,EAAC,CAAC,CAAC;aACtD;YAED,MAAM,MAAM,GAAG,aAAa,CAAC,gBAAgB,CACzC,OAAO,EAAE,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;YAChD,OAAO,MAAM,CAAC;SAChB;KACF;;ICpDF;;;;;;;;;;;;;;;;IAsBO,MAAM,KAAK,GACd,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,KAAK,EAAE,aAAa,EAAE,YAAY,EAAC,CAAC,CAAC;IAEvE,MAAM,WAAW,GAAiB;QACvC,UAAU,EAAEyH,QAAK;QACjB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,KAAK;KAClB;;IC7BD;;;;;;;;;;;;;;;;UAqBa,cAAc;QAezB,YACI,aAAuB,EAAE,QAAgB,EAAE,WAAmB,EAC9D,WAAmB,EAAE,OAAiB,EAAE,KAAe,EACvD,WAAqB,EAAE,cAAc,GAAG,IAAI;YAjBhD,kBAAa,GAAG,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC;YAOvC,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAIrD,WAAM,GAAG,IAAI,CAAC;YAOZ,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,IAAI,GAAG,WAAW,CAAC;YACxB,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,aAAa,CAAC,CAAC;;YAExD,IAAI,CAAC,QAAQ;gBACT,eAAe,CAAC,IAAI,CAAC,cAAc,EAAE,aAAa,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC5E,IAAI,CAAC,sBAAsB,GAAG,QAAQ,GAAG,CAAC,CAAC;YAC3C,IAAI,CAAC,SAAS,GAAG,WAAW,WAAW,IAAI,WAAW,IAClD,IAAI,CAAC,sBAAsB,IAAI,WAAW,IAAI,cAAc,EAAE,CAAC;YACnE,MAAM,WAAW,GAAG,iBAAiB,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;YACtD,IAAI,CAAC,QAAQ,GAAG,4BAA4B,WAAW,cAAc,CAAC;YACtE,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;SAChC;QAED,WAAW;YACT,IAAI,aAAa,GAAG,EAAE,CAAC;YACvB,IAAI,IAAI,CAAC,WAAW,KAAK,CAAC,EAAE;gBAC1B,aAAa,GAAG,WAAW,CAAC;aAC7B;iBAAM,IAAI,IAAI,CAAC,WAAW,KAAK,CAAC,EAAE;gBACjC,aAAa,GAAG,cAAc,CAAC;aAChC;YACD,MAAM,cAAc,GAAG,cAAc,aAAa,GAAG,CAAC;YAEtD,MAAM,YAAY,GAAG,IAAI,CAAC,sBAAsB,GAAG,qBAAqB;gBACrB,kBAAkB,CAAC;YAEtE,IAAI,eAAe,GAAG,EAAE,CAAC;YACzB,IAAI,6BAA6B,GAAG,EAAE,CAAC;YACvC,IAAI,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;gBACtC,eAAe,GAAG,gBAAgB,CAAC;gBACnC,6BAA6B,GAAG;;;;OAI/B,CAAC;aACH;iBAAM,IAAI,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7C,eAAe,GAAG,sCAAsC,CAAC;gBACzD,6BAA6B,GAAG;;;;;;;;;;;OAW/B,CAAC;aACH;YACD,MAAM,aAAa,GACf,KAAK,CAAC,IAAI,CAAC,EAAC,MAAM,EAAE,IAAI,CAAC,WAAW,EAAC,EAAE,CAAC,CAAC,EAAE,GAAG,KAAK,UAAU,GAAG,GAAG,CAAC,CAAC;YACzE,MAAM,cAAc,GAAG,cAAc,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;YAEjE,MAAM,SAAS,GAAG,CAAC,GAAW,EAAE,GAAW;gBACzC,IAAI,gBAAgB,GAAG,aAAa,GAAG,kBAAkB,GAAG,IAAI,CAAC;gBACjE,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;oBAC3B,gBAAgB,GAAG;;;yCAGc,GAAG;;qDAES,GAAG;;;;;;2CAMb,GAAG;;;;SAIrC,CAAC;iBACH;gBACD,MAAM,kBAAkB,GAAG,eAAe,GAAG,kBAAkB,GAAG,KAAK,CAAC;gBACxE,OAAO,IAAI,CAAC,cAAc,GAAG,gBAAgB,GAAG,kBAAkB,CAAC;aACpE,CAAC;YAEF,MAAM,QAAQ,GAAG;MACf,6BAA6B;;QAE3B7G,mBAAI,CAAC,OAAO,CAAC;;;;;0CAKqB,cAAc;8DACM,YAAY;;;gBAG1D,cAAc,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,cAAc;qDACb,eAAe;;YAExD,SAAS,CAAC,oBAAoB,EAAE,aAAa,CAAC;;QAElD,CAAC;YACL,OAAO,QAAQ,CAAC;SACjB;;;IC3IH;;;;;;;;;;;;;;;;aAyBgB,SAAS,CAAC,IAIzB;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,OAAO,EAAE,OAAO,EAAC,GAAG,MAAM,CAAC;QAClC,MAAM,EAAC,KAAK,EAAC,GAAG,KAAK,CAAC;QAEtB,MAAM,EAAC,SAAS,EAAE,UAAU,EAAE,SAAS,EAAE,OAAO,EAAE,UAAU,EAAC,GACzDZ,eAAY,CAAC,eAAe,CAAC,OAAO,EAAE,OAAO,EAAE,KAAK,CAAC,CAAC;QAE1D,MAAM,YAAY,GAAG,CAAC,UAAU,GAAG,SAAS,EAAE,SAAS,CAAC,CAAC;QAEzD,IAAI,UAAU,KAAK,CAAC,EAAE;YACpB,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC;SACrD;QAED,MAAM,cAAc,GAAG,OAAO,CAC1B,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,EAAC,EAAC,CAAC,CAAC;QAC9E,MAAM,QAAQ,GAAG,OAAO,CACpB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,EAAC,EAAC,CAAC,CAAC;QAE9E,MAAM,IAAI,GAAG,QAAQ,CAAC,KAAK,CAAC;QAC5B,MAAM,MAAM,GACR,IAAI,CAAC,EAAC,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,YAAY,EAAE,KAAK,EAAE,CAAC,EAAE,KAAK,EAAE,IAAI,EAAC,EAAC,CAAC,CAAC;QACzE,MAAM,IAAI,GAAGC,OAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;QAChD,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,OAAO,EAAC;YAClE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,EAAC;SAC9B,CAAC;QACF,MAAM,OAAO,GAAG,IAAI,cAAc,CAC9B,QAAQ,CAAC,KAAK,EAAE,SAAS,EAAE,cAAc,CAAC,KAAK,CAAC,MAAM,EACtD,QAAQ,CAAC,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,YAAY,EAAE,IAAI,CAAC,CAAC;QACxD,MAAM,GAAG,GAAG,OAAO,CAAC,gBAAgB,CAChC,OAAO,EAAE,CAAC,QAAQ,EAAE,cAAc,CAAC,EAAE,IAAI,EAAE,WAAW,EAAE,MAAM,CAAC,CAAC;QAEpE,MAAM,QAAQ,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAC,EAAC,CAAC,CAAC;QAEtE,OAAO,CAAC,WAAW,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;QAC3C,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QACrC,OAAO,CAAC,WAAW,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAEhC,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEM,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEyH,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAA6B;KAC1C;;IC3ED;;;;;;;;;;;;;;;;UAoBa,aAAa;QAWxB,YAAY,KAAa,EAAE,KAAe,EAAE,IAAY;YAVxD,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;YAKhC,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAGrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAE/D,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC;YACnB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;YACjB,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;SAC3B;QAED,WAAW;;YAET,IAAI,OAAO,CAAC;YACZ,IAAI,QAAQ,CAAC;YACb,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBACjB,MAAM,KAAK,CAAC,kBAAkB,IAAI,CAAC,IAAI,uBAAuB,CAAC,CAAC;aACjE;YAED,IAAI,IAAI,CAAC,IAAI,KAAK,CAAC,EAAE;gBACnB,QAAQ,GAAG,OAAO,CAAC;gBACnB,OAAO,GAAG,OAAO,CAAC;aACnB;iBAAM;gBACL,MAAM,aAAa,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;gBACnE,MAAM,UAAU,GAAG,EAAE,CAAC;gBACtB,MAAM,WAAW,GAAG,EAAE,CAAC;gBACvB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;oBAChD,WAAW,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;oBACxC,IAAI,CAAC,GAAG,IAAI,CAAC,KAAK,EAAE;wBAClB,UAAU,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;qBACxC;iBACF;gBACD,OAAO,GAAG,UAAU,CAAC,IAAI,EAAE,CAAC;gBAC5B,QAAQ,GAAG,WAAW,CAAC,IAAI,EAAE,CAAC;aAC/B;YAED,MAAM,QAAQ,GAAG;QACb9G,mBAAI,CAAC,OAAO,CAAC;;;4BAGO,OAAO;;2CAEQ,QAAQ;;2CAER,QAAQ;;;;KAI9C,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;;;ICjFH;;;;;;;;;;;;;;;;aAsBgB,MAAM,CAAC,IAAoD;QAEzE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAC,GAAG,IAAI,CAAC;QAC/B,MAAM,EAAC,SAAS,EAAE,CAAC,EAAE,CAAC,EAAC,GAAG,MAAM,CAAC;QAEjC,MAAM,OAAO,GACT,IAAI,aAAa,CAAC,SAAS,CAAC,KAAK,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QACvE,OAAO,OAAO,CAAC,gBAAgB,CAC3B,OAAO,EAAE,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,CAAC,EAAEO,aAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;IAChE,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEwG,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICrCD;;;;;;;;;;;;;;;;IAqBO,MAAM,OAAO,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,OAAO,EAAC,CAAC,CAAC;IAE/D,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEC,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAAO;KACpB;;IC3BD;;;;;;;;;;;;;;;;IAuBO,MAAM,GAAG,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,GAAG,EAAC,CAAC,CAAC;IAEvD,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,IAAI,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;IAEzD,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC7BD;;;;;;;;;;;;;;;;IAuBO,MAAM,GAAG,GAAG,gBAAgB,CAC/B,EAAC,MAAM,EAAE,YAAY,CAAC,GAAG,EAAE,aAAa,EAAEC,UAAM,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;IAEvE,MAAM,SAAS,GAAiB;QACrC,UAAU,EAAEC,MAAG;QACf,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,GAAG;KAChB;;IC9BD;;;;;;;;;;;;;;;;aA4BgB,OAAO,CACnB,IAA0E;QAE5E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,CAAC;QACxB,MAAM,EAAC,GAAG,EAAC,GAAG,KAAK,CAAC;QAEpB,MAAM,IAAI,GAAG/H,OAAI,CAAC,cAAc,CAAC,CAAC,GAAG,CAAC,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;QAEtD,MAAM,QAAQ,GAAG,GAAG,CAAC;YACnB,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;YACnB,OAAO;YACP,KAAK,EAAE,EAAC,gBAAgB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAC;SACjD,CAAC,CAAC;QAEH,MAAM,aAAa,GAAGD,eAAY,CAAC,oBAAoB,CAAC,QAAQ,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;QAE9E,MAAM,iBAAiB,GACnB,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,aAAa,EAAC,EAAC,CAAC,CAAC;QAC7E,MAAM,CAAC,GACH,GAAG,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,iBAAiB,EAAC,EAAE,OAAO,EAAC,CAAe,CAAC;QAC5E,MAAM,CAAC,GAAG,GAAG,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAe,CAAC;QACvD,MAAM,MAAM,GACR,GAAG,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAC,EAAC,CAAC,CAAC;QACzE,MAAM,cAAc,GAChB,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,aAAa,EAAC,EAAC,CAAC,CAAC;QAC3E,MAAM,GAAG,GACL,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,cAAc,EAAC,EAAE,OAAO,EAAC,CAAe,CAAC;QAExE,OAAO,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QACrC,OAAO,CAAC,WAAW,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAC;QAC9C,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;QAC9B,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;QAC9B,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QACnC,OAAO,CAAC,WAAW,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;QAE3C,OAAO,GAAG,CAAC;IACb,CAAC;IAEM,MAAM,aAAa,GAAiB;QACzC,UAAU,EAAEiI,UAAO;QACnB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,OAA2B;KACxC;;ICvED;;;;;;;;;;;;;;;;IAyBO,MAAM,cAAc,GAAG,CAAC,IAI9B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,UAAU,EAAE,QAAQ,EAAC,GAAG,KAAK,CAAC;QAErChI,OAAI,CAAC,MAAM,CACP,CAAC,CAAC,KAAK,CAAC,MAAM,IAAI,CAAC,EACnB,MAAM,wDAAwD;YAC1D,iBAAiB,CAAC,CAAC;QAE3B,MAAM,IAAI,GAAG,UAAU,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;QAEhD,MAAM,gBAAgB,GAA4B,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3D,gBAAgB,CAAC,IAAI,CAAC,GAAG,QAAmC,CAAC,CAAC;QAC9D,KAAK,IAAI,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC3D,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;SAC/B;QAED,MAAM,SAAS,GAAG,EAAE,CAAC;QAErB,MAAM,OAAO,GAAG,KAAK,CAAC;YACpB,MAAM,EAAE,EAAC,CAAC,EAAC;YACX,OAAO;YACP,KAAK,EAAE,EAAC,QAAQ,EAAE,gBAAgB,EAAE,aAAa,EAAE,CAAC,EAAC;SACtD,CAAC,CAAC;QAEH,MAAM,mBAAmB,GACrBD,eAAY,CAAC,WAAW,CAAC,OAAO,CAAC,KAAK,EAAE,UAAU,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;QAErE,MAAM,iCAAiC,GAAGA,eAAY,CAAC,WAAW,CAC9D,mBAAmB,CAAC,MAAM,EAAE,UAAU,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;QAE1D,MAAM,YAAY,GACdA,eAAY,CAAC,mBAAmB,CAAC,OAAO,CAAC,KAAK,EAAE,UAAU,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;QAE7E,MAAM,eAAe,GAAG,OAAO,CAC3B,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,mBAAmB,EAAC,EAAC,CAAC,CAAC;QAE1E,MAAM,QAAQ,GAAG,SAAS,CAAC;YACzB,MAAM,EAAE,EAAC,CAAC,EAAE,eAAe,EAAC;YAC5B,OAAO;YACP,KAAK,EAAE,EAAC,IAAI,EAAE,iCAAiC,EAAC;SACjD,CAAC,CAAC;QAEH,MAAM,MAAM,GACR,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,YAAY,EAAC,EAAC,CAAC,CAAC;QAE5E,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QACxB,SAAS,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAChC,SAAS,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAEzB,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QAEtD,OAAO,MAAM,CAAC;IAChB,CAAC,CAAC;IAEK,MAAM,oBAAoB,GAAiB;QAChD,UAAU,EAAEkI,iBAAc;QAC1B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,cAAkC;KAC/C;;ICzFD;;;;;;;;;;;;;;;;UAoBa,WAAW;QAUtB,YAAY,MAAgB,EAAE,IAAc;YAT5C,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;YAKtB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAIV,MAAM,WAAW,GAAa,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACvD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;gBAC3C,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;aACtC;YACD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;YAC/B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACpC,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC;SACzB;QAED,WAAW;YACT,MAAM,YAAY,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,EAAE,WAAW,CAAC,CAAC;YAE7D,MAAM,QAAQ,GAAG;QACbtH,mBAAI,CAAC,OAAO,CAAC;;;yCAGoB,YAAY;;;KAGhD,CAAC;YACF,OAAO,QAAQ,CAAC;SACjB;KACF;IAED,SAAS,eAAe,CAAC,IAAY,EAAE,aAAa,GAAG,EAAE;QACvD,IAAI,IAAI,IAAI,CAAC,EAAE;YACb,MAAM,KAAK,CAAC,iBAAiB,IAAI,uBAAuB,CAAC,CAAC;SAC3D;QACD,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,OAAO,YAAY,aAAa,SAAS,CAAC;SAC3C;QAED,MAAM,aAAa,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;QACnE,MAAM,YAAY,GAAG,EAAE,CAAC;QACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;YAC7B,YAAY,CAAC,IAAI,CAAC,IAAI,aAAa,CAAC,CAAC,CAAC,MAAM,aAAa,UAAU,CAAC,IAAI,CAAC,CAAC;SAC3E;QACD,OAAO,YAAY,CAAC,IAAI,EAAE,CAAC;IAC7B;;ICxEA;;;;;;;;;;;;;;;;aAuBgB,IAAI,CAChB,MAAsE;QAExE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,MAAM,CAAC;QACxC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;;QAGrB,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ;YACvD,CAAC,CAAC,KAAK,CAAC,MAAM,IAAI,CAAC,EAAE;;;YAGvB,MAAM,IAAI,GAAG,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;YACxC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,KAAK,QAAQ;gBAC7B,IAAqB,CAAC,GAAG,CAAC,CAAC,IAAIX,OAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;gBACrD,IAAkB,CAAC;YACvB,MAAM,GAAG,GAAGM,SAAM,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;YAC5C,MAAM,MAAM,GAAG,WAAW,CAAC,GAAG,EAAE,IAAI,CAAC,CAAC;YACtC,OAAO,OAAO,CAAC,cAAc,CAAC,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;SAC1E;QAED,MAAM,OAAO,GAAG,IAAI,WAAW,CAAC,CAAC,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;QAC/C,MAAM,MAAM,GAAG,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAE/D,OAAO,MAAM,CAAC;IAChB,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAE4H,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICtDD;;;;;;;;;;;;;;;;aA2BgB,aAAa,CAAC,IAI7B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,aAAa,EAAE,YAAY,EAAE,YAAY,EAAC,GAAG,MAAM,CAAC;QAC3D,MAAM,EAAC,WAAW,EAAC,GAAG,KAAK,CAAC;QAE5B,MAAM,EAAC,SAAS,EAAE,UAAU,EAAE,SAAS,EAAE,OAAO,EAAE,UAAU,EAAC,GACzDnI,eAAY,CAAC,eAAe,CAAC,YAAY,EAAE,aAAa,EAAE,WAAW,CAAC,CAAC;QAE3E,MAAM,cAAc,GAAG,KAAK,CAAC;QAC7B,IAAI,YAAY,CAAC,KAAK,KAAK,QAAQ,EAAE;YACnC,MAAM,UAAU,GAAG,OAAO,CAAC,UAAU,CAAgB,aAAa,CAAC,CAAC;YACpE,MAAM,UAAU,GAAG,OAAO,CAAC,UAAU,CAAiB,YAAY,CAAC,CAAC;YACpE,MAAM,aAAa,GAAGC,OAAI,CAAC,YAAY,CACnC,OAAO,CAAC,QAAQ,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,CAAe,CAAC,CAAC;YAC5D,MAAM,MAAM,GAAG,cAAc,CACzB,UAAU,EAAE,UAAU,EAAE,WAAW,EAAE,UAAU,EAAE,SAAS,EAAE,UAAU,EACtE,SAAS,EAAE,OAAO,EAAE,aAAa,EAAE,cAAc,CAAC,CAAC;YACvD,OAAO,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;SACzE;QAED,MAAM,YAAY,GAAG,CAAC,UAAU,GAAG,SAAS,EAAE,SAAS,CAAC,CAAC;QAEzD,MAAM,cAAc,GAAG,OAAO,CAAC;YAC7B,MAAM,EAAE,EAAC,CAAC,EAAE,aAAa,EAAC;YAC1B,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,EAAC;SACxC,CAAC,CAAC;QACH,MAAM,aAAa,GAAG,YAAY,CAAC,KAAK,CAAC,MAAM;YAC3C,OAAO,CAAC;gBACN,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC;gBACzB,OAAO;gBACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,EAAC;aACxC,CAAC;YACF,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAEnD,MAAM,IAAI,GAAG,aAAa,CAAC,KAAK,CAAC;QACjC,MAAM,IAAI,GACN,OAAO,CAAC,cAAc,CAAC,EAAE,EAAE,IAAI,EAAEA,OAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;;QAGxE,MAAM,aAAa,GAAG,OAAO,CAAC;YAC5B,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC;YACzB,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,KAAK,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,EAAC;SACnD,CAAC,CAAC;QACH,MAAM,YAAY,GACd,IAAI,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,aAAa,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,YAAY,EAAC,EAAC,CAAC,CAAC;QAE7E,MAAM,IAAI,GAAGA,OAAI,CAAC,aAAa,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACzD,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;YAClC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,OAAO,EAAC;YAC9B,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,EAAC;SAC9B,CAAC;QAEF,QAAQ,UAAU;YAChB,KAAK,CAAC;gBACJ,MAAM;YACR,KAAK,CAAC;gBACM;oBACR,MAAM,OAAO,GAAG,IAAI,cAAc,CAC9B,CAAC,UAAU,EAAE,SAAS,CAAC,EAAE,SAAS,EAAE,cAAc,CAAC,KAAK,CAAC,MAAM,EAC/D,aAAa,CAAC,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,YAAY,EAAE,IAAI,EACvD,cAAc,CAAC,CAAC;oBACpB,OAAO,CAAC,gBAAgB,CACpB,OAAO,EAAE,CAAC,aAAa,EAAE,cAAc,CAAC,EAAE,IAAI,EAAE,WAAW,EAC3D,YAAY,CAAC,CAAC;iBACnB;gBACD,MAAM;YACR;gBACY;;oBAER,MAAM,OAAO,GAAG,IAAI,cAAc,CAC9B,CAAC,UAAU,EAAE,SAAS,CAAC,EAAE,SAAS,EAAE,cAAc,CAAC,KAAK,CAAC,MAAM,EAC/D,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,YAAY,EAAE,IAAI,EAAE,cAAc,CAAC,CAAC;oBACpE,OAAO,CAAC,gBAAgB,CACpB,OAAO,EAAE,CAAC,IAAI,EAAE,cAAc,CAAC,EAAE,IAAI,EAAE,WAAW,EAAE,YAAY,CAAC,CAAC;iBACvE;gBACD;;oBAEE,MAAM,OAAO,GAAG,IAAI,cAAc,CAC9B,CAAC,UAAU,EAAE,SAAS,CAAC,EAAE,SAAS,EAAE,cAAc,CAAC,KAAK,CAAC,MAAM,EAC/D,aAAa,CAAC,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,YAAY,EAAE,IAAI,CAAC,CAAC;oBAC7D,OAAO,CAAC,gBAAgB,CACpB,OAAO,EAAE,CAAC,aAAa,EAAE,cAAc,CAAC,EAAE,IAAI,EAAE,WAAW,EAC3D,YAAY,CAAC,CAAC;iBACnB;SACJ;QAED,MAAM,WAAW,GAAG,OAAO,CACvB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,WAAW,EAAC,EAAC,CAAC,CAAC;QAEvE,OAAO,CAAC,WAAW,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;QAC3C,OAAO,CAAC,WAAW,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QAC1C,OAAO,CAAC,WAAW,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QAC1C,OAAO,CAAC,WAAW,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QACjC,OAAO,CAAC,WAAW,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;QACzC,OAAO,WAAW,CAAC;IACrB,CAAC;IAEM,MAAM,mBAAmB,GAAiB;QAC/C,UAAU,EAAEmI,gBAAa;QACzB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,aAAiC;KAC9C;;ICvID;;;;;;;;;;;;;;;;aAsBgB,MAAM,CAClB,IAAwE;QAE1E,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,eAAe,EAAE,IAAI,EAAC,GAAG,KAAK,CAAC;QAEtC,MAAM,KAAK,GAAGnI,OAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,UAAU,GAAGD,eAAY,CAAC,gBAAgB,CAAC,CAAC,EAAE,eAAe,EAAE,KAAK,CAAC,CAAC;QAE5E,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,KAAK,GAAG,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,IAAI,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QAE7B,OAAO,UAAU,CAAC,GAAG,CAAC,CAAC;YACrB,MAAM,SAAS,GAAG,CAAC,GAAG,IAAI,CAAC,CAAC;YAC5B,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;YACrB,MAAM,MAAM,GACR,KAAK,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,IAAI,EAAE,SAAS,EAAC,EAAC,CAAC,CAAC;YACnE,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;YAClB,OAAO,MAAM,CAAC;SACf,CAAC,CAAC;IACL,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEqI,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;IClDD;;;;;;;;;;;;;;;;IAqBO,MAAM,IAAI,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;IAEzD,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC3BD;;;;;;;;;;;;;;;;IAsBO,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEC,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,CAAC,EAAC,MAAM,EAAE,OAAO,EAAC;YAC5B,MAAM,EAAC,CAAC,EAAC,GAAG,MAAsB,CAAC;YACnC,MAAM,aAAa,GAAG,OAAwB,CAAC;YAC/C,MAAM,OAAO,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,MAAM,CAAC,CAAC;YAChE,OAAO,aAAa,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;SAC9D;KACF;;IC/BD;;;;;;;;;;;;;;;;IAsBO,MAAM,iBAAiB,GAAG,gBAAgB,CAAC;QAChD,MAAM,EAAE,YAAY,CAAC,kBAAkB;KACxC,CAAC,CAAC;IAEI,MAAM,uBAAuB,GAAiB;QACnD,UAAU,EAAEC,oBAAiB;QAC7B,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,iBAAiB;KAC9B;;IC9BD;;;;;;;;;;;;;;;;UAoBa,mBAAmB;QAY9B,YAAY,QAAkB;YAX9B,kBAAa,GAAG,CAAC,GAAG,CAAC,CAAC;;YAOtB,kBAAa,GAAG,CAAC,CAAC;YAClB,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC;YAC5B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,EACzD,CAAC,IAAI,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAEhC,MAAM,KAAK,GAAG,iBAAiB,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;YACzD,IAAI,CAAC,QAAQ,GAAG,WAAW,KAAK,gBAAgB,KAAK,IAAI,CAAC;YAC1D,IAAI,CAAC,SAAS,GAAG,cAAc,CAAC;SACjC;QAED,WAAW;YACT,MAAM,IAAI,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACrC,IAAI,SAAS,GAAG,EAAE,CAAC;YACnB,IAAI,IAAI,KAAK,CAAC,EAAE;gBACd,SAAS,GAAG,4CAA4C,CAAC;aAC1D;iBAAM;gBACL,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,SAAS;oBACL,IAAI,CAAC,WAAW;yBACX,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC;wBACR,UAAU,EAAE,CAAC;wBACb,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,KAAK,CAAC;4BAChC,6BAA6B,CAAC,sBAAsB,CAAC,GAAG;4BACxD,UAAU,UAAU,GAAG,CAAC,wBACpB,CAAC,sBAAsB,CAAC,GAAG,CAAC;qBACrC,CAAC;yBACD,IAAI,CAAC,GAAG,CAAC,CAAC;aACpB;YAED,MAAM,QAAQ,GAAG;SACZ5H,mBAAI,CAAC,OAAO,CAAC;;;0CAGoB,SAAS;;;MAG7C,CAAC;YACH,OAAO,QAAQ,CAAC;SACjB;;;ICxEH;;;;;;;;;;;;;;;;aA0BgB,YAAY,CAAC,IAI5B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EACJ,KAAK,EACL,GAAG,EACH,OAAO,EACP,SAAS,EACT,OAAO,EACP,YAAY,EACZ,WAAW,EACX,cAAc,EACf,GAAG,KAAK,CAAC;QAEV,MAAM,EACJ,gBAAgB,EAChB,UAAU,EACV,UAAU,EACV,SAAS,EACT,aAAa,EACb,KAAK,EAAE,MAAM,EACb,GAAG,EAAE,IAAI,EACT,OAAO,EAAE,QAAQ,EAClB,GACGY,aAAU,CAAC,SAAS,CAChB,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,GAAG,EAAE,OAAO,EAAE,SAAS,EAAE,OAAO,EAAE,YAAY,EAC9D,WAAW,EAAE,cAAc,CAAC,CAAC;QAErC,IAAI,MAAM,CAAC;QAEX,IAAI,UAAU,EAAE;;YAEd,MAAM,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,UAAU,EAAC,EAAC,CAAC,CAAC;SACtE;aAAM,IAAI,SAAS,IAAI,aAAa,EAAE;;YAErCvB,OAAI,CAAC,MAAM,CACP,CAAC,CAAC,KAAK,CAAC,MAAM,IAAI,CAAC,EACnB,MAAM,yCAAyC,CAAC,CAAC,KAAK,CAAC,MAAM,EAAE,CAAC,CAAC;YAErE,MAAM,IAAI,GAAGuB,aAAU,CAAC,eAAe,CAAC,MAAM,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;;YAEhE,MAAM,MAAM,GAAG,KAAK,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,MAAM,EAAE,IAAI,EAAC,EAAC,CAAC,CAAC;YAC3E,MAAM;gBACF,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,UAAU,EAAC,EAAC,CAAC,CAAC;YACxE,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;SACpC;aAAM;YACL,MAAM,kBAAkB,GAAG,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC3D,IAAI,kBAAkB,EAAE;gBACtB,MAAM,MAAM,GAAG,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAe,CAAC;gBACxD,MAAM,IAAI,GAAGjB,SAAM,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,MAAM,CAAuB,CAAC;gBACpE,MAAM,YAAY,GACd,mBAAmB,CAAC,gBAAgB,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC;gBAClE,MAAM,GAAG,OAAO,CAAC,cAAc,CAAC,UAAU,EAAE,CAAC,CAAC,KAAK,EAAE,YAAY,CAAC,MAAM,CAAC,CAAC;aAC3E;iBAAM;gBACL,MAAM,OAAO,GAAG,IAAI,mBAAmB,CAAC,gBAAgB,CAAC,CAAC;gBAC1D,MAAM,WAAW,GACb,CAAC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,MAAM,EAAC,EAAE,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,QAAQ,EAAC,CAAC,CAAC;gBACrE,MAAM,YAAY,GACd,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;gBACjE,MAAM,GAAG,OAAO,CACZ,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,YAAY,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,UAAU,EAAC,EAAC,CAAC,CAAC;gBACtE,OAAO,CAAC,WAAW,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;aAC1C;SACF;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;IAEM,MAAM,kBAAkB,GAAiB;QAC9C,UAAU,EAAEkI,eAAY;QACxB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,YAAgC;KAC7C;;ICtGD;;;;;;;;;;;;;;;;aAsBgB,YAAY,CAAC,IAI5B;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EACJ,SAAS,EACT,WAAW,EACX,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,sBAAsB,EACvB,GAAG,KAAK,CAAC;QACV,MAAM,EAAC,IAAI,EAAE,UAAU,EAAC,GAAG,MAAM,CAAC;QAClC,MAAM,KAAK,GAAG,OAAO,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAiB,CAAC;QAC5D,MAAM,WAAW,GAAG,OAAO,CAAC,QAAQ,CAAC,UAAU,CAAC,MAAM,CAAe,CAAC;QAEtE,MAAM,CAAC,MAAM,EAAE,YAAY,CAAC,GAAG,mBAAmB,CAC9C,KAAK,EAAE,WAAW,EAAE,SAAS,EAAE,WAAW,EAAE,OAAO,EAAE,QAAQ,EAAE,QAAQ,EACvE,sBAAsB,CAAC,CAAC;QAC5B,OAAO;YACL,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,QAAQ,EAAE,MAAM,CAAC;YACzD,OAAO,CAAC,cAAc,CAAC,UAAU,CAAC,KAAK,EAAE,OAAO,EAAE,YAAY,CAAC;SAChE,CAAC;IACJ,CAAC;IAEM,MAAM,kBAAkB,GAAiB;QAC9C,UAAU,EAAEC,eAAY;QACxB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,YAAgC;KAC7C;;ICrDD;;;;;;;;;;;;;;;;IAqBO,MAAM,IAAI,GAAG,eAAe,CAAC,EAAC,MAAM,EAAE,WAAW,CAAC,IAAI,EAAC,CAAC,CAAC;IAEzD,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAEC,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAI;KACjB;;IC3BD;;;;;;;;;;;;;;;;IAoBA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;UAEa,WAAW;QAUtB,YAAY,KAAe;YAL3B,kBAAa,GAAG,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;YAEjC,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACtD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,QAAQ,GAAG;8BACU,CAAC;YAC3B,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC;SACzB;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;UACX/H,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAkEhB,CAAC;YACJ,OAAO,QAAQ,CAAC;SACjB;KACF;UAEY,YAAY;QAUvB,YAAY,KAAe;YAL3B,kBAAa,GAAG,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;YAEjC,kBAAa,GAA6B,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACtD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,KAAK,CAAC;YACzB,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;;;;;YAK/D,IAAI,CAAC,QAAQ,GAAG,4CAA4C,CAAC;YAC7D,IAAI,CAAC,SAAS,GAAG,OAAO,CAAC;SAC1B;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;UACXA,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA0DhB,CAAC;YACJ,OAAO,QAAQ,CAAC;SACjB;;;IChNH;;;;;;;;;;;;;;;;IA2BA,SAAS,mCAAmC,CACxC,OAAsB,EAAE,UAAsB;QAChD,IAAI,UAAU,KAAK,IAAI,EAAE;YACvB,OAAO,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;SACxC;IACH,CAAC;IAED,SAAS,aAAa,CAAC,GAAW;QAChC,IAAI,IAAI,GAAG,CAAC,CAAC;QACb,OAAO,IAAI,GAAG,GAAG,EAAE;YACjB,IAAI,IAAI,CAAC,CAAC;SACX;QACD,OAAO,IAAI,CAAC;IACd,CAAC;IAED;IACA;aACgB,IAAI,CAChB,IAAoE;QAEtE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,CAAC,EAAC,GAAG,MAAM,CAAC;QACnB,MAAM,EAAC,CAAC,EAAE,MAAM,EAAC,GAAE,KAAK,CAAC;QAEzB,MAAM,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC;QACvB,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAE1C,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;YACnC,MAAM,KAAK,GAAG,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAe,CAAC;YACvD,MAAM,CAAC,WAAW,EAAE,cAAc,CAAC,GAC/B,WAAW,CAAC,KAAK,EAAE,MAAM,EAAE,CAAC,CAAC,KAAwB,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC;YAEtE,OAAO;gBACL,OAAO,CAAC,cAAc,CAClB,WAAW,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,WAAW,CAAC,MAAM,CAAC;gBAC7D,OAAO,CAAC,cAAc,CAClB,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,MAAM,CAAC;aACvE,CAAC;SACH;QAED,IAAI,CAAC,KAAK,CAAC,EAAE;YACX,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YAC9B,OAAO;gBACL,OAAO,CAAC,cAAc,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC;gBAC3C,OAAO,CAAC,cAAc,CAAC,MAAM,EAAE,OAAO,EAAE,EAAE,CAAC;aAC5C,CAAC;SACH;QAED,IAAI,OAAO,KAAK,CAAC,kBAAkB;YACjC,OAAO;gBACL,CAAC,EAAE,IAAI,CAAC,EAAC,KAAK,EAAE,EAAC,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC;aACrE,CAAC;SACH;;QAGD,MAAM,KAAK,GAAGX,OAAI,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QACzC,MAAM,KAAK,GAAG,KAAK,GAAG,OAAO,CAAC;QAC9B,MAAM,GAAG,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,KAAK,EAAE,OAAO,CAAC,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAE9E,MAAM,KAAK,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QAC/B,MAAM,WAAW,GAAG,aAAa,CAAC,OAAO,CAAC,CAAC;;;;;QAM3C,IAAI,OAAO,GAAe,IAAI,CAAC;;;;QAK/B,MAAM,SAAS,GAAG,MAAM,OAAO,KAAK,IAAI,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,OAAO,CAAC,CAAC;QAEvE,MAAM,OAAO,GAAG,CAAC,GAAW,EAAE,GAAW,EAAE,KAAe;YACxD,MAAM,MAAM,GAAG,SAAS,EAAE,CAAC;YAC3B,MAAM,OAAO,GAAG,IAAI,WAAW,CAAC,KAAK,CAAC,CAAC;YACvC,MAAM,SAAS,GAAG,OAAO,KAAK,IAAI,GAAG,CAAC,GAAG,CAAC,CAAC;YAC3C,MAAM,eAAe,GAAG;gBACpB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,EAAC;gBAChC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;gBAClC,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,MAAM,CAAC,iBAAiB,CAAC,EAAC;gBACnD,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,GAAG,CAAC,EAAC;gBAC5B,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,GAAG,CAAC,EAAC;aAC/B,CAAC;YACF,MAAM,WAAW,GAAG,OAAO,CAAC;YAC5B,OAAO,GAAG,OAAO,CAAC,gBAAgB,CAC9B,OAAO,EAAE,MAAM,EAAE,OAAO,EAAE,eAAe,CAAC,CAAC;YAC/C,mCAAmC,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;SAC3D,CAAC;;QAGF,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,KAAK,EAAE,GAAG,IAAI,CAAC,EAAE;YACvC,MAAM,GAAG,GAAG,GAAG,GAAG,CAAC,CAAC;YACpB,KAAK,IAAI,GAAG,GAAG,GAAG,EAAE,GAAG,IAAI,CAAC,EAAE,GAAG,IAAI,CAAC,EAAE;gBACtC,OAAO,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC,CAAC;aACzC;SACF;;QAGD,KAAK,IAAI,WAAW,GAAG,WAAW,EAAE,WAAW,GAAG,KAAK,EAAE,WAAW,IAAI,CAAC,EAAE;YACzE,MAAM,MAAM,GAAG,SAAS,EAAE,CAAC;YAC3B,MAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,KAAK,EAAE,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC;YAChE,MAAM,SAAS,GAAG,OAAO,KAAK,IAAI,GAAG,CAAC,GAAG,CAAC,CAAC;YAC3C,MAAM,gBAAgB,GAAG;gBACrB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,OAAO,CAAC,EAAC;gBAChC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;gBAClC,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,KAAK,CAAC,EAAC;aACjC,CAAC;YACF,MAAM,WAAW,GAAG,OAAO,CAAC;YAC5B,OAAO,GAAG,OAAO,CAAC,gBAAgB,CAC9B,YAAY,EAAE,MAAM,EAAE,OAAO,EAAE,gBAAgB,CAAC,CAAC;YACrD,mCAAmC,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;;YAG1D,MAAM,GAAG,GAAG,KAAK,GAAG,CAAC,CAAC;YACtB,MAAM,GAAG,GAAG,GAAG,GAAG,CAAC,CAAC;YACpB,KAAK,IAAI,GAAG,GAAG,GAAG,EAAE,GAAG,IAAI,CAAC,EAAE,GAAG,IAAI,CAAC,EAAE;gBACtC,OAAO,CAAC,GAAG,EAAE,GAAG,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC;aAClC;SACF;;QAGD,IAAI,WAAW,GAAG,OAAO,CAAC;QAC1B,OAAO,GAAG,KAAK,CACX,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,KAAK,EAAE,CAAC,CAAC,EAAC,EAAC,CAAC,CAAC;QAC1E,mCAAmC,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;;QAG1D,IAAI,MAAM,GAAG,QAAQ,CACjB,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,GAAG,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,IAAI,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAC,EAAC,CAAC,CAAC;QAC1E,mCAAmC,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC;;;QAIlD,MAAM,QAAQ,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAEjB,WAAW,GAAG,OAAO,CAAC;QACtB,OAAO,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAC7E,mCAAmC,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAE1D,MAAM,UAAU,GAAG,MAAM,CAAC;QAC1B,MAAM,GAAG,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QAC3E,mCAAmC,CAAC,OAAO,EAAE,UAAU,CAAC,CAAC;QAEzD,OAAO,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;IAC3B,CAAC;IAEM,MAAM,UAAU,GAAiB;QACtC,UAAU,EAAE2I,OAAI;QAChB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,IAAwB;KACrC;;ICnLD;;;;;;;;;;;;;;;;UAoBa,gBAAgB;QAU3B,YAAY,QAA0C;YATtD,kBAAa,GAAG,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;YAExC,aAAQ,GAAG,+DAA+D,CAAC;YAI3E,kBAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACrD,SAAI,GAAG,IAAI,CAAC;YAGV,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC;YAC5B,IAAI,CAAC,cAAc,GAAG,kBAAkB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC3D,IAAI,CAAC,QAAQ,GAAG,eAAe,CAC3B,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;YAC/D,IAAI,CAAC,SAAS,GAAG,WAAW,CAAC;SAC9B;QAED,WAAW;YACT,MAAM,QAAQ,GAAG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YAgEThI,mBAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;SAoDhB,CAAC;YACN,OAAO,QAAQ,CAAC;SACjB;;;IC7JH;;;;;;;;;;;;;;;;aAsBgB,SAAS,CAAC,IAIzB;QACC,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,KAAK,EAAE,UAAU,EAAC,GAAG,MAAM,CAAC;QACnC,MAAM,EAAC,aAAa,EAAE,QAAQ,EAAE,SAAS,EAAE,WAAW,EAAC,GAAG,KAAK,CAAC;QAEhE,MAAM,CAAC,KAAK,EAAE,WAAW,EAAE,UAAU,EAAE,WAAW,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC;QAClE,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GACvB,WAAW,IAAI,IAAI,GAAG,WAAW,GAAG,CAAC,WAAW,EAAE,UAAU,CAAC,CAAC;QAClE,MAAM,QAAQ,GACV,CAAC,KAAK,EAAE,SAAS,EAAE,QAAQ;YAC1B,WAAW,CAAqC,CAAC;QAEtD,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAAC,QAAQ,CAAC,CAAC;QAC/C,MAAM,mBAAmB,GAAG,aAAa,KAAK,SAAS,GAAG,CAAC,GAAG,CAAC,CAAC;QAChE,IAAI,UAAkB,CAAC;QACvB,QAAQ,QAAQ;YACd,KAAK,UAAU;gBACb,UAAU,GAAG,CAAC,CAAC;gBACf,MAAM;YACR,KAAK,SAAS;gBACZ,UAAU,GAAG,CAAC,CAAC;gBACf,MAAM;YACR,KAAK,MAAM;gBACT,UAAU,GAAG,CAAC,CAAC;gBACf,MAAM;YACR,KAAK,SAAS;gBACZ,UAAU,GAAG,CAAC,CAAC;gBACf,MAAM;YACR;gBACE,UAAU,GAAG,CAAC,CAAC;gBACf,MAAM;SACT;QACD,MAAM,WAAW,GAAG;YAClB,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,mBAAmB,CAAC,EAAC;YAC5C,EAAC,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC,UAAU,CAAC,EAAC,EAAE,EAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,CAAC,SAAS,CAAC,EAAC;SAC1E,CAAC;QACF,OAAO,OAAO,CAAC,gBAAgB,CAC3B,OAAO,EAAE,CAAC,KAAK,EAAE,UAAU,CAAC,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;IAC5D,CAAC;IAEM,MAAM,eAAe,GAAiB;QAC3C,UAAU,EAAEiI,YAAS;QACrB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,SAA6B;KAC1C;;ICtED;;;;;;;;;;;;;;;;aAwBgB,MAAM,CAClB,IACsE;QAExE,MAAM,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,GAAG,IAAI,CAAC;QACtC,MAAM,EAAC,KAAK,EAAC,GAAG,MAAM,CAAC;QACvB,IAAI,EAAC,IAAI,EAAC,GAAG,KAAK,CAAC;QAEnB,IAAI,IAAI,GAAG,CAAC,EAAE;YACZ,IAAI,IAAI,KAAK,CAAC,KAAK,CAAC,MAAM,CAAC;SAC5B;QAED,MAAM,CAAC,GAAG,KAAK,CAAC;QAChB,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;QAE7B,MAAM,GAAG,GAAG,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;QAC9B,MAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QAChD,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;YAC9B,IAAI,CAAC,KAAK,IAAI,EAAE;gBACd,QAAQ,CAAC,QAAQ,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;aACnC;SACF;QAED,MAAM,SAAS,GAAG,EAAE,CAAC;QAErB,MAAM,KAAK,GAAG,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,IAAI,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QAC7B,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACf,MAAM,GAAG,GAAiB,IAAI,KAAK,CAAC,GAAG,CAAC,CAAC;QACzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACnC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YAChB,MAAM,MAAM,GAAG,KAAK,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,IAAI,EAAC,EAAC,CAAC,CAAC;YACnE,MAAM,QAAQ,GACV,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;YACtE,GAAG,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;YAElB,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;SACxB;QAED,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACtD,OAAO,GAAG,CAAC;IACb,CAAC;IAEM,MAAM,YAAY,GAAiB;QACxC,UAAU,EAAEC,SAAM;QAClB,WAAW,EAAE,QAAQ;QACrB,UAAU,EAAE,MAA0B;KACvC;;ICxED;;;;;;;;;;;;;;;;IA2HA;IACA,MAAM,aAAa,GAAmB;QACpC,kBAAkB;QAClB,SAAS;QACT,SAAS;QACT,UAAU;QACV,YAAY;QACZ,YAAY;QACZ,WAAW;QACX,aAAa;QACb,iBAAiB;QACjB,oBAAoB;QACpB,UAAU;QACV,UAAU;QACV,iBAAiB;QACjB,aAAa;QACb,YAAY;QACZ,YAAY;QACZ,yBAAyB;QACzB,SAAS;QACT,UAAU;QACV,mBAAmB;QACnB,aAAa;QACb,YAAY;QACZ,kBAAkB;QAClB,2BAA2B;QAC3B,YAAY;QACZ,SAAS;QACT,WAAW;QACX,SAAS;QACT,gBAAgB;QAChB,WAAW;QACX,UAAU;QACV,mBAAmB;QACnB,gBAAgB;QAChB,WAAW;QACX,cAAc;QACd,oBAAoB;QACpB,iBAAiB;QACjB,0BAA0B;QAC1B,cAAc;QACd,cAAc;QACd,aAAa;QACb,kBAAkB;QAClB,cAAc;QACd,UAAU;QACV,WAAW;QACX,eAAe;QACf,UAAU;QACV,eAAe;QACf,SAAS;QACT,gBAAgB;QAChB,gBAAgB;QAChB,SAAS;QACT,aAAa;QACb,aAAa;QACb,UAAU;QACV,SAAS;QACT,aAAa;QACb,eAAe;QACf,cAAc;QACd,SAAS;QACT,yBAAyB;QACzB,yBAAyB;QACzB,cAAc;QACd,cAAc;QACd,UAAU;QACV,WAAW;QACX,SAAS;QACT,WAAW;QACX,UAAU;QACV,WAAW;QACX,UAAU;QACV,aAAa;QACb,gBAAgB;QAChB,UAAU;QACV,WAAW;QACX,aAAa;QACb,oBAAoB;QACpB,2BAA2B;QAC3B,sBAAsB;QACtB,WAAW;QACX,eAAe;QACf,YAAY;QACZ,aAAa;QACb,SAAS;QACT,UAAU;QACV,WAAW;QACX,kBAAkB;QAClB,kBAAkB;QAClB,aAAa;QACb,oBAAoB;QACpB,mBAAmB;QACnB,YAAY;QACZ,UAAU;QACV,YAAY;QACZ,uBAAuB;QACvB,SAAS;QACT,SAAS;QACT,UAAU;QACV,UAAU;QACV,UAAU;QACV,eAAe;QACf,eAAe;QACf,YAAY;QACZ,eAAe;KAChB,CAAC;IAEF,KAAK,MAAM,YAAY,IAAI,aAAa,EAAE;QACxCC,iBAAc,CAAC,YAAY,CAAC,CAAC;;;;;;;;;;;;"}